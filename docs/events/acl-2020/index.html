<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Annual Meeting of the Association for Computational Linguistics (2020) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Annual Meeting of the Association for Computational Linguistics (2020)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2020acl-main>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a>
<span class="badge badge-info align-middle ml-1">245&nbsp;papers</span></li><li><a class=align-middle href=#2020acl-demos>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a>
<span class="badge badge-info align-middle ml-1">15&nbsp;papers</span></li><li><a class=align-middle href=#2020acl-srw>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a>
<span class="badge badge-info align-middle ml-1">15&nbsp;papers</span></li><li><a class=align-middle href=#2020acl-tutorials>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020alvr-1>Proceedings of the First Workshop on Advances in Language and Vision Research</a>
<span class="badge badge-info align-middle ml-1">4&nbsp;papers</span></li><li><a class=align-middle href=#2020autosimtrans-1>Proceedings of the First Workshop on Automatic Simultaneous Translation</a>
<span class="badge badge-info align-middle ml-1">2&nbsp;papers</span></li><li><a class=align-middle href=#2020bea-1>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</a>
<span class="badge badge-info align-middle ml-1">10&nbsp;papers</span></li><li><a class=align-middle href=#2020bionlp-1>Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2020challengehml-1>Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)</a>
<span class="badge badge-info align-middle ml-1">2&nbsp;papers</span></li><li><a class=align-middle href=#2020ecnlp-1>Proceedings of The 3rd Workshop on e-Commerce and NLP</a>
<span class="badge badge-info align-middle ml-1">5&nbsp;papers</span></li><li><a class=align-middle href=#2020fever-1>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020figlang-1>Proceedings of the Second Workshop on Figurative Language Processing</a>
<span class="badge badge-info align-middle ml-1">14&nbsp;papers</span></li><li><a class=align-middle href=#2020iwpt-1>Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies</a>
<span class="badge badge-info align-middle ml-1">9&nbsp;papers</span></li><li><a class=align-middle href=#2020iwslt-1>Proceedings of the 17th International Conference on Spoken Language Translation</a>
<span class="badge badge-info align-middle ml-1">14&nbsp;papers</span></li><li><a class=align-middle href=#2020ngt-1>Proceedings of the Fourth Workshop on Neural Generation and Translation</a>
<span class="badge badge-info align-middle ml-1">8&nbsp;papers</span></li><li><a class=align-middle href=#2020nli-1>Proceedings of the First Workshop on Natural Language Interfaces</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020nlp4convai-1>Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2020nlpcovid19-acl>Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2020nlpmc-1>Proceedings of the First Workshop on Natural Language Processing for Medical Conversations</a>
<span class="badge badge-info align-middle ml-1">4&nbsp;papers</span></li><li><a class=align-middle href=#2020nuse-1>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a>
<span class="badge badge-info align-middle ml-1">6&nbsp;papers</span></li><li><a class=align-middle href=#2020repl4nlp-1>Proceedings of the 5th Workshop on Representation Learning for NLP</a>
<span class="badge badge-info align-middle ml-1">10&nbsp;papers</span></li><li><a class=align-middle href=#2020sigmorphon-1>Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2020socialnlp-1>Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li></ul></div></div><div id=2020acl-main><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.acl-main/>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.acl-main.0/>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></strong><br><a href=/people/d/dan-jurafsky/>Dan Jurafsky</a>
|
<a href=/people/j/joyce-chai/>Joyce Chai</a>
|
<a href=/people/n/natalie-schluter/>Natalie Schluter</a>
|
<a href=/people/j/joel-tetreault/>Joel Tetreault</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928816 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.4" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.4/>Designing Precise and Robust Dialogue Response Evaluators</a></strong><br><a href=/people/t/tianyu-zhao/>Tianyu Zhao</a>
|
<a href=/people/d/divesh-lala/>Divesh Lala</a>
|
<a href=/people/t/tatsuya-kawahara/>Tatsuya Kawahara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--4><div class="card-body p-3 small">Automatic dialogue response evaluator has been proposed as an alternative to <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automated metrics</a> and <a href=https://en.wikipedia.org/wiki/Evaluation>human evaluation</a>. However, existing automatic evaluators achieve only moderate correlation with <a href=https://en.wikipedia.org/wiki/Judgement>human judgement</a> and they are not robust. In this work, we propose to build a reference-free evaluator and exploit the power of semi-supervised training and pretrained (masked) language models. Experimental results demonstrate that the proposed evaluator achieves a strong correlation (0.6) with <a href=https://en.wikipedia.org/wiki/Judgement>human judgement</a> and generalizes robustly to diverse responses and corpora. We open-source the code and data in https://github.com/ZHAOTING/dialog-processing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929055 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.6/>Generating Informative Conversational Response using Recurrent Knowledge-Interaction and Knowledge-Copy</a></strong><br><a href=/people/x/xiexiong-lin/>Xiexiong Lin</a>
|
<a href=/people/w/weiyu-jian/>Weiyu Jian</a>
|
<a href=/people/j/jianshan-he/>Jianshan He</a>
|
<a href=/people/t/taifeng-wang/>Taifeng Wang</a>
|
<a href=/people/w/wei-chu/>Wei Chu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--6><div class="card-body p-3 small">Knowledge-driven conversation approaches have achieved remarkable research attention recently. However, generating an informative response with multiple relevant knowledge without losing fluency and <a href=https://en.wikipedia.org/wiki/Coherence_(linguistics)>coherence</a> is still one of the main challenges. To address this issue, this paper proposes a method that uses recurrent knowledge interaction among response decoding steps to incorporate appropriate knowledge. Furthermore, we introduce a knowledge copy mechanism using a knowledge-aware pointer network to copy words from external knowledge according to knowledge attention distribution. Our joint neural conversation model which integrates recurrent Knowledge-Interaction and knowledge Copy (KIC) performs well on generating informative responses. Experiments demonstrate that our model with fewer parameters yields significant improvements over competitive baselines on two datasets Wizard-of-Wikipedia(average Bleu +87 % ; abs. : 0.034) and DuConv(average Bleu +20 % ; abs. : 0.047)) with different knowledge formats (textual & structured) and different languages (English & Chinese).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928822 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.10/>Slot-consistent NLG for Task-oriented Dialogue Systems with Iterative Rectification Network<span class=acl-fixed-case>NLG</span> for Task-oriented Dialogue Systems with Iterative Rectification Network</a></strong><br><a href=/people/y/yangming-li/>Yangming Li</a>
|
<a href=/people/k/kaisheng-yao/>Kaisheng Yao</a>
|
<a href=/people/l/libo-qin/>Libo Qin</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/x/xiaolong-li/>Xiaolong Li</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--10><div class="card-body p-3 small">Data-driven approaches using <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> have achieved promising performances in natural language generation (NLG). However, neural generators are prone to make mistakes, e.g., neglecting an input slot value and generating a redundant slot value. Prior works refer this to <a href=https://en.wikipedia.org/wiki/Hallucination>hallucination phenomenon</a>. In this paper, we study slot consistency for building reliable NLG systems with all slot values of input dialogue act (DA) properly generated in output sentences. We propose Iterative Rectification Network (IRN) for improving general NLG systems to produce both correct and fluent responses. It applies a <a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>bootstrapping algorithm</a> to sample training candidates and uses <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> to incorporate discrete reward related to slot inconsistency into training. Comprehensive studies have been conducted on multiple benchmark datasets, showing that the proposed methods have significantly reduced the slot error rate (ERR) for all strong baselines. Human evaluations also have confirmed its effectiveness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929160 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.12" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.12/>Zero-Shot Transfer Learning with <a href=https://en.wikipedia.org/wiki/Synthesizer>Synthesized Data</a> for Multi-Domain Dialogue State Tracking</a></strong><br><a href=/people/g/giovanni-campagna/>Giovanni Campagna</a>
|
<a href=/people/a/agata-foryciarz/>Agata Foryciarz</a>
|
<a href=/people/m/mehrad-moradshahi/>Mehrad Moradshahi</a>
|
<a href=/people/m/monica-lam/>Monica Lam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--12><div class="card-body p-3 small">Zero-shot transfer learning for multi-domain dialogue state tracking can allow us to handle new domains without incurring the high cost of <a href=https://en.wikipedia.org/wiki/Data_acquisition>data acquisition</a>. This paper proposes new zero-short transfer learning technique for dialogue state tracking where the in-domain training data are all synthesized from an abstract dialogue model and the ontology of the domain. We show that <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> through synthesized data can improve the accuracy of zero-shot learning for both the TRADE model and the BERT-based SUMBT model on the MultiWOZ 2.1 dataset. We show training with only synthesized in-domain data on the SUMBT model can reach about 2/3 of the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> obtained with the full training dataset. We improve the zero-shot learning state of the art on average across domains by 21 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929268 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.25/>Reverse Engineering Configurations of Neural Text Generation Models</a></strong><br><a href=/people/y/yi-tay/>Yi Tay</a>
|
<a href=/people/d/dara-bahri/>Dara Bahri</a>
|
<a href=/people/c/che-zheng/>Che Zheng</a>
|
<a href=/people/c/clifford-brunk/>Clifford Brunk</a>
|
<a href=/people/d/donald-metzler/>Donald Metzler</a>
|
<a href=/people/a/andrew-tomkins/>Andrew Tomkins</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--25><div class="card-body p-3 small">Recent advances in neural text generation modeling have resulted in a number of societal concerns related to how such approaches might be used in malicious ways. It is therefore desirable to develop a deeper understanding of the fundamental properties of such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. The study of artifacts that emerge in machine generated text as a result of modeling choices is a nascent research area. To this end, the extent and degree to which these artifacts surface in generated text is still unclear. In the spirit of better understanding generative text models and their artifacts, we propose the new task of distinguishing which of several variants of a given <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> generated some piece of text. Specifically, we conduct an extensive suite of <a href=https://en.wikipedia.org/wiki/Statistical_hypothesis_testing>diagnostic tests</a> to observe whether <a href=https://en.wikipedia.org/wiki/Statistical_model>modeling choices</a> (e.g., <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>sampling methods</a>, top-k probabilities, <a href=https://en.wikipedia.org/wiki/Computer_simulation>model architectures</a>, etc.) leave detectable artifacts in the text they generate. Our key finding, which is backed by a rigorous set of experiments, is that such artifacts are present and that different modeling choices can be inferred by looking at generated text alone. This suggests that neural text generators may actually be more sensitive to various modeling choices than previously thought.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928768 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.28/>Unsupervised Paraphrasing by Simulated Annealing</a></strong><br><a href=/people/x/xianggen-liu/>Xianggen Liu</a>
|
<a href=/people/l/lili-mou/>Lili Mou</a>
|
<a href=/people/f/fandong-meng/>Fandong Meng</a>
|
<a href=/people/h/hao-zhou/>Hao Zhou</a>
|
<a href=/people/j/jie-zhou/>Jie Zhou</a>
|
<a href=/people/s/sen-song/>Sen Song</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--28><div class="card-body p-3 small">We propose UPSA, a novel approach that accomplishes Unsupervised Paraphrasing by Simulated Annealing. We model <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> as an <a href=https://en.wikipedia.org/wiki/Optimization_problem>optimization problem</a> and propose a sophisticated <a href=https://en.wikipedia.org/wiki/Loss_function>objective function</a>, involving <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a>, expression diversity, and language fluency of paraphrases. UPSA searches the sentence space towards this objective by performing a sequence of local editing. We evaluate our approach on various datasets, namely, <a href=https://en.wikipedia.org/wiki/Quora>Quora</a>, <a href=https://en.wikipedia.org/wiki/Wikianswers>Wikianswers</a>, MSCOCO, and <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. Extensive results show that UPSA achieves the state-of-the-art performance compared with previous <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a> in terms of both automatic and human evaluations. Further, our approach outperforms most existing domain-adapted supervised models, showing the generalizability of UPSA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.31.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--31 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.31 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929373 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.31" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.31/>Every Document Owns Its Structure : Inductive Text Classification via Graph Neural Networks</a></strong><br><a href=/people/y/yufeng-zhang/>Yufeng Zhang</a>
|
<a href=/people/x/xueli-yu/>Xueli Yu</a>
|
<a href=/people/z/zeyu-cui/>Zeyu Cui</a>
|
<a href=/people/s/shu-wu/>Shu Wu</a>
|
<a href=/people/z/zhongzhen-wen/>Zhongzhen Wen</a>
|
<a href=/people/l/liang-wang/>Liang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--31><div class="card-body p-3 small">Text classification is fundamental in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a> and Graph Neural Networks (GNN) are recently applied in this task. However, the existing graph-based works can neither capture the contextual word relationships within each document nor fulfil the inductive learning of new words. Therefore in this work, to overcome such problems, we propose TextING for inductive text classification via GNN. We first build individual <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a> for each document and then use GNN to learn the fine-grained word representations based on their local structure, which can also effectively produce embeddings for unseen words in the new document. Finally, the <a href=https://en.wikipedia.org/wiki/Node_(computer_science)>word nodes</a> are aggregated as the document embedding. Extensive experiments on four benchmark datasets show that our method outperforms state-of-the-art text classification methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928999 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.32/>Neural Topic Modeling with Bidirectional Adversarial Training</a></strong><br><a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/x/xuemeng-hu/>Xuemeng Hu</a>
|
<a href=/people/d/deyu-zhou/>Deyu Zhou</a>
|
<a href=/people/y/yulan-he/>Yulan He</a>
|
<a href=/people/y/yuxuan-xiong/>Yuxuan Xiong</a>
|
<a href=/people/c/chenchen-ye/>Chenchen Ye</a>
|
<a href=/people/h/haiyang-xu/>Haiyang Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--32><div class="card-body p-3 small">Recent years have witnessed a surge of interests of using neural topic models for automatic topic extraction from text, since they avoid the complicated mathematical derivations for <a href=https://en.wikipedia.org/wiki/Statistical_inference>model inference</a> as in traditional <a href=https://en.wikipedia.org/wiki/Topic_model>topic models</a> such as Latent Dirichlet Allocation (LDA). However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> either typically assume <a href=https://en.wikipedia.org/wiki/Improper_prior>improper prior</a> (e.g. Gaussian or Logistic Normal) over latent topic space or could not infer topic distribution for a given document. To address these limitations, we propose a neural topic modeling approach, called Bidirectional Adversarial Topic (BAT) model, which represents the first attempt of applying bidirectional adversarial training for neural topic modeling. The proposed BAT builds a <a href=https://en.wikipedia.org/wiki/Projection_(linear_algebra)>two-way projection</a> between the document-topic distribution and the document-word distribution. It uses a generator to capture the semantic patterns from texts and an <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> for topic inference. Furthermore, to incorporate word relatedness information, the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT) is extended from BAT. To verify the effectiveness of BAT and Gaussian-BAT, three benchmark corpora are used in our experiments. The experimental results show that BAT and Gaussian-BAT obtain more coherent topics, outperforming several competitive baselines. Moreover, when performing text clustering based on the extracted topics, our models outperform all the baselines, with more significant improvements achieved by Gaussian-BAT where an increase of near 6 % is observed in accuracy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.34.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--34 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.34 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928867 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.34/>Content Word Aware Neural Machine Translation</a></strong><br><a href=/people/k/kehai-chen/>Kehai Chen</a>
|
<a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichiro Sumita</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--34><div class="card-body p-3 small">Neural machine translation (NMT) encodes the source sentence in a universal way to generate the target sentence word-by-word. However, NMT does not consider the importance of word in the sentence meaning, for example, some words (i.e., content words) express more important meaning than others (i.e., function words). To address this limitation, we first utilize word frequency information to distinguish between content and function words in a sentence, and then design a content word-aware NMT to improve <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance. Empirical results on the WMT14 English-to-German, WMT14 English-to-French, and WMT17 Chinese-to-English translation tasks show that the proposed methods can significantly improve the performance of Transformer-based NMT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.35.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--35 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.35 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929375 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.35/>Evaluating Explanation Methods for Neural Machine Translation</a></strong><br><a href=/people/j/jierui-li/>Jierui Li</a>
|
<a href=/people/l/lemao-liu/>Lemao Liu</a>
|
<a href=/people/h/huayang-li/>Huayang Li</a>
|
<a href=/people/g/guanlin-li/>Guanlin Li</a>
|
<a href=/people/g/guoping-huang/>Guoping Huang</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--35><div class="card-body p-3 small">Recently many efforts have been devoted to interpreting the black-box NMT models, but little progress has been made on <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to evaluate explanation methods. Word Alignment Error Rate can be used as such a <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> that matches human understanding, however, it can not measure explanation methods on those target words that are not aligned to any source word. This paper thereby makes an initial attempt to evaluate explanation methods from an alternative viewpoint. To this end, it proposes a principled <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> based on <a href=https://en.wikipedia.org/wiki/Fidelity>fidelity</a> in regard to the predictive behavior of the NMT model. As the exact computation for this <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> is intractable, we employ an efficient approach as its approximation. On six standard translation tasks, we quantitatively evaluate several explanation methods in terms of the proposed <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> and we reveal some valuable findings for these explanation methods in our experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.36.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--36 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.36 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928715 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.36/>Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation</a></strong><br><a href=/people/j/junliang-guo/>Junliang Guo</a>
|
<a href=/people/l/linli-xu/>Linli Xu</a>
|
<a href=/people/e/enhong-chen/>Enhong Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--36><div class="card-body p-3 small">The masked language model has received remarkable attention due to its effectiveness on various natural language processing tasks. However, few works have adopted this <a href=https://en.wikipedia.org/wiki/Scientific_technique>technique</a> in the <a href=https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations>sequence-to-sequence models</a>. In this work, we introduce a jointly masked sequence-to-sequence model and explore its application on non-autoregressive neural machine translation~(NAT). Specifically, we first empirically study the functionalities of the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and the <a href=https://en.wikipedia.org/wiki/Code>decoder</a> in NAT models, and find that the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> takes a more important role than the <a href=https://en.wikipedia.org/wiki/Code>decoder</a> regarding the translation quality. Therefore, we propose to train the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> more rigorously by masking the encoder input while training. As for the <a href=https://en.wikipedia.org/wiki/Encoder>decoder</a>, we propose to train it based on the consecutive masking of the decoder input with an <a href=https://en.wikipedia.org/wiki/Loss_function>n-gram loss function</a> to alleviate the problem of translating duplicate words. The two types of <a href=https://en.wikipedia.org/wiki/Mask>masks</a> are applied to the <a href=https://en.wikipedia.org/wiki/Model_(person)>model</a> jointly at the training stage. We conduct experiments on five benchmark machine translation tasks, and our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can achieve 27.69/32.24 BLEU scores on WMT14 English-German / German-English tasks with 5 + times speed up compared with an <a href=https://en.wikipedia.org/wiki/Autoregressive_model>autoregressive model</a>.<tex-math>n</tex-math>-gram loss function to alleviate the problem of translating duplicate words. The two types of masks are applied to the model jointly at the training stage. We conduct experiments on five benchmark machine translation tasks, and our model can achieve 27.69/32.24 BLEU scores on WMT14 English-German/German-English tasks with <tex-math>5+</tex-math> times speed up compared with an autoregressive model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.38.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--38 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.38 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928681 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.38/>Lipschitz Constrained Parameter Initialization for Deep Transformers</a></strong><br><a href=/people/h/hongfei-xu/>Hongfei Xu</a>
|
<a href=/people/q/qiuhui-liu/>Qiuhui Liu</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a>
|
<a href=/people/d/deyi-xiong/>Deyi Xiong</a>
|
<a href=/people/j/jingyi-zhang/>Jingyi Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--38><div class="card-body p-3 small">The Transformer translation model employs residual connection and layer normalization to ease the optimization difficulties caused by its multi-layer encoder / decoder structure. Previous research shows that even with residual connection and layer normalization, deep Transformers still have difficulty in training, and particularly Transformer models with more than 12 encoder / decoder layers fail to converge. In this paper, we first empirically demonstrate that a simple modification made in the official implementation, which changes the computation order of residual connection and layer normalization, can significantly ease the optimization of deep Transformers. We then compare the subtle differences in computation order in considerable detail, and present a parameter initialization method that leverages the Lipschitz constraint on the initialization of Transformer parameters that effectively ensures training convergence. In contrast to findings in previous research we further demonstrate that with Lipschitz parameter initialization, deep Transformers with the original computation order can converge, and obtain significant BLEU improvements with up to 24 layers. In contrast to previous research which focuses on deep encoders, our approach additionally enables <a href=https://en.wikipedia.org/wiki/Transformers_(toy_line)>Transformers</a> to also benefit from deep decoders.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.40.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--40 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.40 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928953 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.40" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.40/>Multiscale Collaborative Deep Models for Neural Machine Translation</a></strong><br><a href=/people/x/xiangpeng-wei/>Xiangpeng Wei</a>
|
<a href=/people/h/heng-yu/>Heng Yu</a>
|
<a href=/people/y/yue-hu/>Yue Hu</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/r/rongxiang-weng/>Rongxiang Weng</a>
|
<a href=/people/w/weihua-luo/>Weihua Luo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--40><div class="card-body p-3 small">Recent evidence reveals that Neural Machine Translation (NMT) models with deeper neural networks can be more effective but are difficult to train. In this paper, we present a MultiScale Collaborative (MSC) framework to ease the training of NMT models that are substantially deeper than those used previously. We explicitly boost the gradient back-propagation from top to bottom levels by introducing a block-scale collaboration mechanism into <a href=https://en.wikipedia.org/wiki/Deep_learning>deep NMT models</a>. Then, instead of forcing the whole encoder stack directly learns a desired <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representation</a>, we let each encoder block learns a fine-grained representation and enhance it by encoding spatial dependencies using a context-scale collaboration. We provide empirical evidence showing that the MSC nets are easy to optimize and can obtain improvements of translation quality from considerably increased depth. On IWSLT translation tasks with three translation directions, our extremely deep models (with 72-layer encoders) surpass strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> by +2.2~+3.1 <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>BLEU points</a>. In addition, our deep MSC achieves a BLEU score of 30.56 on WMT14 English-to-German task that significantly outperforms state-of-the-art <a href=https://en.wikipedia.org/wiki/Deep_learning>deep NMT models</a>. We have included the source code in supplementary materials.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.42.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--42 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.42 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929355 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.42/>Opportunistic Decoding with Timely Correction for Simultaneous Translation</a></strong><br><a href=/people/r/renjie-zheng/>Renjie Zheng</a>
|
<a href=/people/m/mingbo-ma/>Mingbo Ma</a>
|
<a href=/people/b/baigong-zheng/>Baigong Zheng</a>
|
<a href=/people/k/kaibo-liu/>Kaibo Liu</a>
|
<a href=/people/l/liang-huang/>Liang Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--42><div class="card-body p-3 small">Simultaneous translation has many important application scenarios and attracts much attention from both academia and industry recently. Most existing <a href=https://en.wikipedia.org/wiki/Software_framework>frameworks</a>, however, have difficulties in balancing between the translation quality and <a href=https://en.wikipedia.org/wiki/Latency_(engineering)>latency</a>, i.e., the decoding policy is usually either too aggressive or too conservative. We propose an opportunistic decoding technique with timely correction ability, which always (over-)generates a certain mount of extra words at each step to keep the audience on track with the latest information. At the same time, it also corrects, in a timely fashion, the mistakes in the former overgenerated words when observing more source context to ensure high translation quality. Experiments show our technique achieves substantial reduction in <a href=https://en.wikipedia.org/wiki/Latency_(engineering)>latency</a> and up to +3.1 increase in BLEU, with revision rate under 8 % in Chinese-to-English and English-to-Chinese translation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.43.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--43 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.43 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928908 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.43/>A Formal Hierarchy of RNN Architectures<span class=acl-fixed-case>RNN</span> Architectures</a></strong><br><a href=/people/w/william-merrill/>William Merrill</a>
|
<a href=/people/g/gail-weiss/>Gail Weiss</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a>
|
<a href=/people/r/roy-schwartz/>Roy Schwartz</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a>
|
<a href=/people/e/eran-yahav/>Eran Yahav</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--43><div class="card-body p-3 small">We develop a formal hierarchy of the expressive capacity of RNN architectures. The hierarchy is based on two formal properties : <a href=https://en.wikipedia.org/wiki/Space_complexity>space complexity</a>, which measures the RNN&#8217;s memory, and rational recurrence, defined as whether the recurrent update can be described by a weighted finite-state machine. We place several RNN variants within this <a href=https://en.wikipedia.org/wiki/Hierarchy>hierarchy</a>. For example, we prove the LSTM is not rational, which formally separates it from the related QRNN (Bradbury et al., 2016). We also show how these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>&#8217; expressive capacity is expanded by stacking multiple layers or composing them with different pooling functions. Our results build on the theory of saturated RNNs (Merrill, 2019). While formally extending these findings to unsaturated RNNs is left to future work, we hypothesize that the practical learnable capacity of unsaturated RNNs obeys a similar hierarchy. We provide empirical results to support this conjecture. Experimental findings from training unsaturated networks on <a href=https://en.wikipedia.org/wiki/Formal_language>formal languages</a> support this conjecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.49.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--49 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.49 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929242 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.49/>Integrating Semantic and Structural Information with Graph Convolutional Network for Controversy Detection</a></strong><br><a href=/people/l/lei-zhong/>Lei Zhong</a>
|
<a href=/people/j/juan-cao/>Juan Cao</a>
|
<a href=/people/q/qiang-sheng/>Qiang Sheng</a>
|
<a href=/people/j/junbo-guo/>Junbo Guo</a>
|
<a href=/people/z/ziang-wang/>Ziang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--49><div class="card-body p-3 small">Identifying controversial posts on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> is a fundamental task for mining public sentiment, assessing the influence of events, and alleviating the polarized views. However, existing methods fail to 1) effectively incorporate the semantic information from content-related posts ; 2) preserve the structural information for reply relationship modeling ; 3) properly handle posts from topics dissimilar to those in the training set. To overcome the first two limitations, we propose Topic-Post-Comment Graph Convolutional Network (TPC-GCN), which integrates the information from the graph structure and content of topics, posts, and comments for post-level controversy detection. As to the third limitation, we extend our model to Disentangled TPC-GCN (DTPC-GCN), to disentangle topic-related and topic-unrelated features and then fuse dynamically. Extensive experiments on two real-world datasets demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> outperform existing <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>. Analysis of the results and cases proves that our <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> can integrate both semantic and structural information with significant generalizability.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.53.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--53 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.53 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929359 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.53" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.53/>Efficient Dialogue State Tracking by Selectively Overwriting Memory</a></strong><br><a href=/people/s/sungdong-kim/>Sungdong Kim</a>
|
<a href=/people/s/sohee-yang/>Sohee Yang</a>
|
<a href=/people/g/gyuwan-kim/>Gyuwan Kim</a>
|
<a href=/people/s/sang-woo-lee/>Sang-Woo Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--53><div class="card-body p-3 small">Recent works in dialogue state tracking (DST) focus on an open vocabulary-based setting to resolve scalability and generalization issues of the predefined ontology-based approaches. However, they are inefficient in that they predict the dialogue state at every turn from scratch. Here, we consider dialogue state as an explicit fixed-sized memory and propose a selectively overwriting mechanism for more efficient DST. This mechanism consists of two steps : (1) predicting state operation on each of the <a href=https://en.wikipedia.org/wiki/Random-access_memory>memory slots</a>, and (2) overwriting the <a href=https://en.wikipedia.org/wiki/Random-access_memory>memory</a> with new values, of which only a few are generated according to the predicted state operations. Our method decomposes DST into two sub-tasks and guides the <a href=https://en.wikipedia.org/wiki/Codec>decoder</a> to focus only on one of the tasks, thus reducing the burden of the <a href=https://en.wikipedia.org/wiki/Codec>decoder</a>. This enhances the effectiveness of <a href=https://en.wikipedia.org/wiki/Training>training</a> and <a href=https://en.wikipedia.org/wiki/Distance_education>DST</a> performance. Our SOM-DST (Selectively Overwriting Memory for Dialogue State Tracking) model achieves state-of-the-art joint goal accuracy with 51.72 % in MultiWOZ 2.0 and 53.01 % in MultiWOZ 2.1 in an open vocabulary-based DST setting. In addition, we analyze the accuracy gaps between the current and the ground truth-given situations and suggest that it is a promising direction to improve state operation prediction to boost the <a href=https://en.wikipedia.org/wiki/Discrete_cosine_transform>DST</a> performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.57.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--57 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.57 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.57.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929454 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.57/>Learning Low-Resource End-To-End Goal-Oriented Dialog for Fast and Reliable System Deployment</a></strong><br><a href=/people/y/yinpei-dai/>Yinpei Dai</a>
|
<a href=/people/h/hangyu-li/>Hangyu Li</a>
|
<a href=/people/c/chengguang-tang/>Chengguang Tang</a>
|
<a href=/people/y/yongbin-li/>Yongbin Li</a>
|
<a href=/people/j/jian-sun/>Jian Sun</a>
|
<a href=/people/x/xiaodan-zhu/>Xiaodan Zhu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--57><div class="card-body p-3 small">Existing end-to-end dialog systems perform less effectively when data is scarce. To obtain an acceptable success in real-life online services with only a handful of training examples, both fast adaptability and reliable performance are highly desirable for dialog systems. In this paper, we propose the Meta-Dialog System (MDS), which combines the advantages of both meta-learning approaches and human-machine collaboration. We evaluate our methods on a new extended-bAbI dataset and a transformed MultiWOZ dataset for low-resource goal-oriented dialog learning. Experimental results show that MDS significantly outperforms non-meta-learning baselines and can achieve more than 90 % per-turn accuracies with only 10 dialogs on the extended-bAbI dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.61.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--61 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.61 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929327 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.61/>Response-Anticipated Memory for On-Demand Knowledge Integration in Response Generation</a></strong><br><a href=/people/z/zhiliang-tian/>Zhiliang Tian</a>
|
<a href=/people/w/wei-bi/>Wei Bi</a>
|
<a href=/people/d/dongkyu-lee/>Dongkyu Lee</a>
|
<a href=/people/l/lanqing-xue/>Lanqing Xue</a>
|
<a href=/people/y/yiping-song/>Yiping Song</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/n/nevin-l-zhang/>Nevin L. Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--61><div class="card-body p-3 small">Neural conversation models are known to generate appropriate but non-informative responses in general. A scenario where informativeness can be significantly enhanced is Conversing by Reading (CbR), where conversations take place with respect to a given external document. In previous work, the external document is utilized by (1) creating a context-aware document memory that integrates information from the document and the conversational context, and then (2) generating responses referring to the <a href=https://en.wikipedia.org/wiki/Memory>memory</a>. In this paper, we propose to create the document memory with some anticipated responses in mind. This is achieved using a teacher-student framework. The teacher is given the external document, the context, and the ground-truth response, and learns how to build a response-aware document memory from three sources of information. The student learns to construct a response-anticipated document memory from the first two sources, and teacher&#8217;s insight on memory creation. Empirical results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> for the CbR task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.63.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--63 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.63 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929439 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.63" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.63/>Towards <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>Unsupervised Language Understanding</a> and Generation by Joint Dual Learning</a></strong><br><a href=/people/s/shang-yu-su/>Shang-Yu Su</a>
|
<a href=/people/c/chao-wei-huang/>Chao-Wei Huang</a>
|
<a href=/people/y/yun-nung-chen/>Yun-Nung Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--63><div class="card-body p-3 small">In modular dialogue systems, <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding (NLU)</a> and <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation (NLG)</a> are two critical components, where NLU extracts the <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> from the given texts and NLG is to construct corresponding natural language sentences based on the input semantic representations. However, the dual property between <a href=https://en.wikipedia.org/wiki/Understanding>understanding</a> and <a href=https://en.wikipedia.org/wiki/Generation>generation</a> has been rarely explored. The prior work is the first attempt that utilized the duality between NLU and NLG to improve the performance via a dual supervised learning framework. However, the prior work still learned both components in a supervised manner ; instead, this paper introduces a general learning framework to effectively exploit such duality, providing flexibility of incorporating both supervised and unsupervised learning algorithms to train language understanding and generation models in a joint fashion. The benchmark experiments demonstrate that the proposed approach is capable of boosting the performance of both NLU and NLG. The source code is available at : https://github.com/MiuLab/DuaLUG.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.64.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--64 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.64 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928829 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.64" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.64/>USR : An Unsupervised and Reference Free Evaluation Metric for Dialog Generation<span class=acl-fixed-case>USR</span>: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation</a></strong><br><a href=/people/s/shikib-mehri/>Shikib Mehri</a>
|
<a href=/people/m/maxine-eskenazi/>Maxine Eskenazi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--64><div class="card-body p-3 small">The lack of meaningful automatic evaluation metrics for <a href=https://en.wikipedia.org/wiki/Dialogue>dialog</a> has impeded open-domain dialog research. Standard language generation metrics have been shown to be ineffective for evaluating dialog models. To this end, this paper presents USR, an UnSupervised and Reference-free evaluation metric for <a href=https://en.wikipedia.org/wiki/Dialogue>dialog</a>. USR is a reference-free metric that trains <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised models</a> to measure several desirable qualities of <a href=https://en.wikipedia.org/wiki/Dialogue>dialog</a>. USR is shown to strongly correlate with human judgment on both Topical-Chat (turn-level : 0.42, system-level : 1.0) and PersonaChat (turn-level : 0.48 and system-level : 1.0). USR additionally produces interpretable measures for several desirable properties of <a href=https://en.wikipedia.org/wiki/Dialogue>dialog</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.66.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--66 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.66 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929231 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.66/>Improved <a href=https://en.wikipedia.org/wiki/Natural-language_generation>Natural Language Generation</a> via Loss Truncation</a></strong><br><a href=/people/d/daniel-kang/>Daniel Kang</a>
|
<a href=/people/t/tatsunori-b-hashimoto/>Tatsunori B. Hashimoto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--66><div class="card-body p-3 small">Neural language models are usually trained to match the distributional properties of large-scale corpora by minimizing the <a href=https://en.wikipedia.org/wiki/Log_loss>log loss</a>. While straightforward to optimize, this approach forces the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to reproduce all variations in the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, including <a href=https://en.wikipedia.org/wiki/Noisy_data>noisy and invalid references</a> (e.g., misannotations and hallucinated facts). Even a small fraction of <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noisy data</a> can degrade the performance of <a href=https://en.wikipedia.org/wiki/Log_loss>log loss</a>. As an alternative, prior work has shown that minimizing the <a href=https://en.wikipedia.org/wiki/Distinguishing>distinguishability</a> of generated samples is a principled and robust loss that can handle invalid references. However, distinguishability has not been used in practice due to challenges in <a href=https://en.wikipedia.org/wiki/Mathematical_optimization>optimization</a> and <a href=https://en.wikipedia.org/wiki/Estimation_theory>estimation</a>. We propose loss truncation : a simple and scalable procedure which adaptively removes high log loss examples as a way to optimize for distinguishability. Empirically, we demonstrate that loss truncation outperforms existing baselines on distinguishability on a summarization task. Furthermore, we show that samples generated by the loss truncation model have factual accuracy ratings that exceed those of baselines and match human references.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.68.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--68 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.68 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928912 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.68" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.68/>Rigid Formats Controlled Text Generation</a></strong><br><a href=/people/p/piji-li/>Piji Li</a>
|
<a href=/people/h/haisong-zhang/>Haisong Zhang</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--68><div class="card-body p-3 small">Neural text generation has made tremendous progress in various <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a>. One common characteristic of most of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> is that the texts are not restricted to some <a href=https://en.wikipedia.org/wiki/File_format>rigid formats</a> when generating. However, we may confront some special text paradigms such as <a href=https://en.wikipedia.org/wiki/Lyrics>Lyrics</a> (assume the music score is given), <a href=https://en.wikipedia.org/wiki/Sonnet>Sonnet</a>, SongCi (classical Chinese poetry of the Song dynasty), etc. The typical characteristics of these <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>texts</a> are in three folds : (1) They must comply fully with the rigid predefined formats. (2) They must obey some <a href=https://en.wikipedia.org/wiki/Rhyme_scheme>rhyming schemes</a>. (3) Although they are restricted to some formats, the sentence integrity must be guaranteed. To the best of our knowledge, <a href=https://en.wikipedia.org/wiki/Text_generator>text generation</a> based on the predefined rigid formats has not been well investigated. Therefore, we propose a simple and elegant <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> named <a href=https://en.wikipedia.org/wiki/SongNet>SongNet</a> to tackle this problem. The backbone of the <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is a Transformer-based auto-regressive language model. Sets of symbols are tailor-designed to improve the modeling performance especially on <a href=https://en.wikipedia.org/wiki/File_format>format</a>, <a href=https://en.wikipedia.org/wiki/Rhyme>rhyme</a>, and sentence integrity. We improve the attention mechanism to impel the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to capture some future information on the format. A pre-training and fine-tuning framework is designed to further improve the generation quality. Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates significantly better results in terms of both automatic metrics and the human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.69.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--69 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.69 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.69.Source.zip data-toggle=tooltip data-placement=top title=Source><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.69.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929019 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block style=text-decoration:line-through><strong><a class=align-middle href=/2020.acl-main.69/>Syn-QG : Syntactic and Shallow Semantic Rules for Question Generation<span class=acl-fixed-case>QG</span>: Syntactic and Shallow Semantic Rules for Question Generation</a></strong><br><a href=/people/k/kaustubh-dhole/>Kaustubh Dhole</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--69><div class="card-body p-3 small">Question Generation (QG) is fundamentally a simple syntactic transformation ; however, many aspects of <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> influence what questions are good to form. We implement this observation by developing Syn-QG, a set of transparent syntactic rules leveraging universal dependencies, shallow semantic parsing, lexical resources, and custom rules which transform declarative sentences into question-answer pairs. We utilize PropBank argument descriptions and VerbNet state predicates to incorporate shallow semantic content, which helps generate questions of a descriptive nature and produce inferential and semantically richer questions than existing systems. In order to improve syntactic fluency and eliminate grammatically incorrect questions, we employ <a href=https://en.wikipedia.org/wiki/Back-translation>back-translation</a> over the output of these syntactic rules. A set of crowd-sourced evaluations shows that our system can generate a larger number of highly grammatical and relevant questions than previous QG systems and that back-translation drastically improves <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a> at a slight cost of generating irrelevant questions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.73.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--73 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.73 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928818 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.73/>Tree-Structured Neural Topic Model<span class=acl-fixed-case>T</span>ree-<span class=acl-fixed-case>S</span>tructured <span class=acl-fixed-case>N</span>eural <span class=acl-fixed-case>T</span>opic <span class=acl-fixed-case>M</span>odel</a></strong><br><a href=/people/m/masaru-isonuma/>Masaru Isonuma</a>
|
<a href=/people/j/junichiro-mori/>Junichiro Mori</a>
|
<a href=/people/d/danushka-bollegala/>Danushka Bollegala</a>
|
<a href=/people/i/ichiro-sakata/>Ichiro Sakata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--73><div class="card-body p-3 small">This paper presents a tree-structured neural topic model, which has a topic distribution over a tree with an infinite number of branches. Our model parameterizes an unbounded ancestral and fraternal topic distribution by applying doubly-recurrent neural networks. With the help of autoencoding variational Bayes, our model improves data scalability and achieves competitive performance when inducing latent topics and tree structures, as compared to a prior tree-structured topic model (Blei et al., 2010). This work extends the tree-structured topic model such that it can be incorporated with neural models for downstream tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.74.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--74 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.74 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928954 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.74/>Unsupervised FAQ Retrieval with Question Generation and BERT<span class=acl-fixed-case>FAQ</span> Retrieval with Question Generation and <span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/y/yosi-mass/>Yosi Mass</a>
|
<a href=/people/b/boaz-carmeli/>Boaz Carmeli</a>
|
<a href=/people/h/haggai-roitman/>Haggai Roitman</a>
|
<a href=/people/d/david-konopnicki/>David Konopnicki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--74><div class="card-body p-3 small">We focus on the task of Frequently Asked Questions (FAQ) retrieval. A given <a href=https://en.wikipedia.org/wiki/Web_search_query>user query</a> can be matched against the questions and/or the answers in the <a href=https://en.wikipedia.org/wiki/FAQ>FAQ</a>. We present a fully unsupervised method that exploits the FAQ pairs to train two BERT models. The two <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> match <a href=https://en.wikipedia.org/wiki/Information_retrieval>user queries</a> to <a href=https://en.wikipedia.org/wiki/FAQ>FAQ answers</a> and questions, respectively. We alleviate the <a href=https://en.wikipedia.org/wiki/Missing_data>missing labeled data</a> of the latter by automatically generating high-quality question paraphrases. We show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is on par and even outperforms <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> on existing datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.79.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--79 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.79 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929254 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.79/>Interpreting Twitter User Geolocation<span class=acl-fixed-case>T</span>witter User Geolocation</a></strong><br><a href=/people/t/ting-zhong/>Ting Zhong</a>
|
<a href=/people/t/tianliang-wang/>Tianliang Wang</a>
|
<a href=/people/f/fan-zhou/>Fan Zhou</a>
|
<a href=/people/g/goce-trajcevski/>Goce Trajcevski</a>
|
<a href=/people/k/kunpeng-zhang/>Kunpeng Zhang</a>
|
<a href=/people/y/yi-yang/>Yi Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--79><div class="card-body p-3 small">Identifying user geolocation in online social networks is an essential task in many <a href=https://en.wikipedia.org/wiki/Location-based_service>location-based applications</a>. Existing methods rely on the similarity of text and network structure, however, they suffer from a lack of interpretability on the corresponding results, which is crucial for understanding model behavior. In this work, we adopt influence functions to interpret the behavior of GNN-based models by identifying the importance of training users when predicting the locations of the testing users. This <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> helps with providing meaningful explanations on prediction results. Furthermore, it also initiates an attempt to uncover the so-called black-box GNN-based models by investigating the effect of individual nodes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.83.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--83 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.83 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928862 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.83/>A Frame-based Sentence Representation for Machine Reading Comprehension</a></strong><br><a href=/people/s/shaoru-guo/>Shaoru Guo</a>
|
<a href=/people/r/ru-li/>Ru Li</a>
|
<a href=/people/h/hongye-tan/>Hongye Tan</a>
|
<a href=/people/x/xiaoli-li/>Xiaoli Li</a>
|
<a href=/people/y/yong-guan/>Yong Guan</a>
|
<a href=/people/h/hongyan-zhao/>Hongyan Zhao</a>
|
<a href=/people/y/yueping-zhang/>Yueping Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--83><div class="card-body p-3 small">Sentence representation (SR) is the most crucial and challenging task in Machine Reading Comprehension (MRC). MRC systems typically only utilize the information contained in the sentence itself, while human beings can leverage their semantic knowledge. To bridge the gap, we proposed a novel Frame-based Sentence Representation (FSR) method, which employs frame semantic knowledge to facilitate sentence modelling. Specifically, different from existing methods that only model lexical units (LUs), Frame Representation Models, which utilize both LUs in frame and Frame-to-Frame (F-to-F) relations, are designed to model frames and sentences with attention schema. Our proposed FSR method is able to integrate multiple-frame semantic information to get much better <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence representations</a>. Our extensive experimental results show that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> performs better than state-of-the-art technologies on machine reading comprehension task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.87.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--87 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.87 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929253 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.87/>Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension</a></strong><br><a href=/people/f/fei-yuan/>Fei Yuan</a>
|
<a href=/people/l/linjun-shou/>Linjun Shou</a>
|
<a href=/people/x/xuanyu-bai/>Xuanyu Bai</a>
|
<a href=/people/m/ming-gong/>Ming Gong</a>
|
<a href=/people/y/yaobo-liang/>Yaobo Liang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/y/yan-fu/>Yan Fu</a>
|
<a href=/people/d/daxin-jiang/>Daxin Jiang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--87><div class="card-body p-3 small">Multilingual pre-trained models could leverage the training data from a rich source language (such as English) to improve performance on low resource languages. However, the transfer quality for multilingual Machine Reading Comprehension (MRC) is significantly worse than sentence classification tasks mainly due to the requirement of MRC to detect the word level answer boundary. In this paper, we propose two auxiliary tasks in the fine-tuning stage to create additional phrase boundary supervision : (1) A mixed MRC task, which translates the question or passage to other languages and builds cross-lingual question-passage pairs ; (2) A language-agnostic knowledge masking task by leveraging knowledge phrases mined from web. Besides, extensive experiments on two cross-lingual MRC datasets show the effectiveness of our proposed approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.88.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--88 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.88 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928988 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.88" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.88/>Explicit Memory Tracker with Coarse-to-Fine Reasoning for Conversational Machine Reading</a></strong><br><a href=/people/y/yifan-gao/>Yifan Gao</a>
|
<a href=/people/c/chien-sheng-wu/>Chien-Sheng Wu</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a>
|
<a href=/people/i/irwin-king/>Irwin King</a>
|
<a href=/people/m/michael-lyu/>Michael Lyu</a>
|
<a href=/people/s/steven-c-h-hoi/>Steven C.H. Hoi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--88><div class="card-body p-3 small">The goal of conversational machine reading is to answer user questions given a knowledge base text which may require asking clarification questions. Existing approaches are limited in their decision making due to struggles in extracting question-related rules and reasoning about them. In this paper, we present a new framework of conversational machine reading that comprises a novel Explicit Memory Tracker (EMT) to track whether conditions listed in the rule text have already been satisfied to make a decision. Moreover, our framework generates clarification questions by adopting a coarse-to-fine reasoning strategy, utilizing sentence-level entailment scores to weight token-level distributions. On the ShARC benchmark (blind, held-out) testset, <a href=https://en.wikipedia.org/wiki/Emergency_medical_technician>EMT</a> achieves new state-of-the-art results of 74.6 % micro-averaged decision accuracy and 49.5 BLEU4. We also show that <a href=https://en.wikipedia.org/wiki/Emergency_medical_technician>EMT</a> is more interpretable by visualizing the entailment-oriented reasoning process as the conversation flows. Code and models are released at https://github.com/Yifan-Gao/explicit_memory_tracker.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.96.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--96 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.96 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929119 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.96/>Code-Switching Patterns Can Be an Effective Route to Improve Performance of Downstream NLP Applications : A Case Study of Humour, Sarcasm and Hate Speech Detection<span class=acl-fixed-case>NLP</span> Applications: A Case Study of Humour, Sarcasm and Hate Speech Detection</a></strong><br><a href=/people/s/srijan-bansal/>Srijan Bansal</a>
|
<a href=/people/v/vishal-garimella/>Vishal Garimella</a>
|
<a href=/people/a/ayush-suhane/>Ayush Suhane</a>
|
<a href=/people/j/jasabanta-patro/>Jasabanta Patro</a>
|
<a href=/people/a/animesh-mukherjee/>Animesh Mukherjee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--96><div class="card-body p-3 small">In this paper, we demonstrate how code-switching patterns can be utilised to improve various downstream NLP applications. In particular, we encode various switching features to improve <a href=https://en.wikipedia.org/wiki/Humour>humour</a>, <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> and hate speech detection tasks. We believe that this simple linguistic observation can also be potentially helpful in improving other similar NLP applications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.114.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--114 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.114 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929452 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.114/>Multimodal Quality Estimation for <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a></a></strong><br><a href=/people/s/shu-okabe/>Shu Okabe</a>
|
<a href=/people/f/frederic-blain/>Frdric Blain</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--114><div class="card-body p-3 small">We propose approaches to Quality Estimation (QE) for <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a> that explore both text and visual modalities for Multimodal QE. We compare various multimodality integration and fusion strategies. For both sentence-level and document-level predictions, we show that state-of-the-art neural and feature-based QE frameworks obtain better results when using the additional modality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.117.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--117 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.117 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928787 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.117/>The TechQA Dataset<span class=acl-fixed-case>T</span>ech<span class=acl-fixed-case>QA</span> Dataset</a></strong><br><a href=/people/v/vittorio-castelli/>Vittorio Castelli</a>
|
<a href=/people/r/rishav-chakravarti/>Rishav Chakravarti</a>
|
<a href=/people/s/saswati-dana/>Saswati Dana</a>
|
<a href=/people/a/anthony-ferritto/>Anthony Ferritto</a>
|
<a href=/people/r/radu-florian/>Radu Florian</a>
|
<a href=/people/m/martin-franz/>Martin Franz</a>
|
<a href=/people/d/dinesh-garg/>Dinesh Garg</a>
|
<a href=/people/d/dinesh-khandelwal/>Dinesh Khandelwal</a>
|
<a href=/people/j/j-scott-mccarley/>Scott McCarley</a>
|
<a href=/people/m/michael-mccawley/>Michael McCawley</a>
|
<a href=/people/m/mohamed-nasr/>Mohamed Nasr</a>
|
<a href=/people/l/lin-pan/>Lin Pan</a>
|
<a href=/people/c/cezar-pendus/>Cezar Pendus</a>
|
<a href=/people/j/john-f-pitrelli/>John Pitrelli</a>
|
<a href=/people/s/saurabh-pujar/>Saurabh Pujar</a>
|
<a href=/people/s/salim-roukos/>Salim Roukos</a>
|
<a href=/people/a/andrzej-sakrajda/>Andrzej Sakrajda</a>
|
<a href=/people/a/avirup-sil/>Avi Sil</a>
|
<a href=/people/r/rosario-uceda-sosa/>Rosario Uceda-Sosa</a>
|
<a href=/people/t/todd-ward/>Todd Ward</a>
|
<a href=/people/r/rong-zhang/>Rong Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--117><div class="card-body p-3 small">We introduce TECHQA, a domain-adaptation question answering dataset for the technical support domain. The TECHQA corpus highlights two real-world issues from the automated customer support domain. First, it contains actual questions posed by users on a technical forum, rather than questions generated specifically for a competition or a task. Second, it has a real-world size 600 training, 310 dev, and 490 evaluation question / answer pairs thus reflecting the cost of creating large labeled datasets with actual data. Hence, TECHQA is meant to stimulate research in <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> rather than as a resource to build <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA systems</a> from scratch. TECHQA was obtained by crawling the IBMDeveloper and DeveloperWorks forums for questions with accepted answers provided in an IBM Technotea technical document that addresses a specific technical issue. We also release a collection of the 801,998 Technotes available on the web as of April 4, 2019 as a companion resource that can be used to learn representations of the IT domain language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.121.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--121 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.121 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928726 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.121/>Attend, Translate and Summarize : An Efficient Method for Neural Cross-Lingual Summarization</a></strong><br><a href=/people/j/junnan-zhu/>Junnan Zhu</a>
|
<a href=/people/y/yu-zhou/>Yu Zhou</a>
|
<a href=/people/j/jiajun-zhang/>Jiajun Zhang</a>
|
<a href=/people/c/chengqing-zong/>Chengqing Zong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--121><div class="card-body p-3 small">Cross-lingual summarization aims at summarizing a document in one language (e.g., Chinese) into another language (e.g., English). In this paper, we propose a novel method inspired by the translation pattern in the process of obtaining a cross-lingual summary. We first attend to some words in the source text, then translate them into the target language, and summarize to get the final summary. Specifically, we first employ the encoder-decoder attention distribution to attend to the source words. Second, we present three strategies to acquire the translation probability, which helps obtain the translation candidates for each source word. Finally, each summary word is generated either from the neural distribution or from the translation candidates of source words. Experimental results on Chinese-to-English and English-to-Chinese summarization tasks have shown that our proposed method can significantly outperform the baselines, achieving comparable performance with the state-of-the-art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.123.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--123 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.123 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929335 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.123" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.123/>Improving Truthfulness of Headline Generation</a></strong><br><a href=/people/k/kazuki-matsumaru/>Kazuki Matsumaru</a>
|
<a href=/people/s/sho-takase/>Sho Takase</a>
|
<a href=/people/n/naoaki-okazaki/>Naoaki Okazaki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--123><div class="card-body p-3 small">Most studies on abstractive summarization report ROUGE scores between <a href=https://en.wikipedia.org/wiki/System>system</a> and reference summaries. However, we have a concern about the truthfulness of generated summaries : whether all facts of a generated summary are mentioned in the source text. This paper explores improving the truthfulness in headline generation on two popular datasets. Analyzing <a href=https://en.wikipedia.org/wiki/Headline>headlines</a> generated by the state-of-the-art encoder-decoder model, we show that the model sometimes generates untruthful headlines. We conjecture that one of the reasons lies in untruthful supervision data used for training the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. In order to quantify the truthfulness of article-headline pairs, we consider the <a href=https://en.wikipedia.org/wiki/Textual_entailment>textual entailment</a> of whether an article entails its headline. After confirming quite a few untruthful instances in the datasets, this study hypothesizes that removing untruthful instances from the supervision data may remedy the problem of the untruthful behaviors of the model. Building a binary classifier that predicts an entailment relation between an article and its headline, we filter out untruthful instances from the supervision data. Experimental results demonstrate that the headline generation model trained on filtered supervision data shows no clear difference in ROUGE scores but remarkable improvements in automatic and manual evaluations of the generated headlines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.125.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--125 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.125 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929451 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.125/>Self-Attention Guided Copy Mechanism for Abstractive Summarization</a></strong><br><a href=/people/s/song-xu/>Song Xu</a>
|
<a href=/people/h/haoran-li/>Haoran Li</a>
|
<a href=/people/p/peng-yuan/>Peng Yuan</a>
|
<a href=/people/y/youzheng-wu/>Youzheng Wu</a>
|
<a href=/people/x/xiaodong-he/>Xiaodong He</a>
|
<a href=/people/b/bowen-zhou/>Bowen Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--125><div class="card-body p-3 small">Copy module has been widely equipped in the recent abstractive summarization models, which facilitates the decoder to extract words from the source into the summary. Generally, the encoder-decoder attention is served as the copy distribution, while how to guarantee that important words in the source are copied remains a challenge. In this work, we propose a Transformer-based model to enhance the copy mechanism. Specifically, we identify the importance of each source word based on the <a href=https://en.wikipedia.org/wiki/Degree_centrality>degree centrality</a> with a <a href=https://en.wikipedia.org/wiki/Directed_graph>directed graph</a> built by the self-attention layer in the Transformer. We use the <a href=https://en.wikipedia.org/wiki/Centralisation>centrality</a> of each source word to guide the copy process explicitly. Experimental results show that the self-attention graph provides useful guidance for the copy distribution. Our proposed <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> significantly outperform the baseline methods on the CNN / Daily Mail dataset and the Gigaword dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.134.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--134 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.134 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928825 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.134/>Fast and Accurate Non-Projective Dependency Tree Linearization</a></strong><br><a href=/people/x/xiang-yu/>Xiang Yu</a>
|
<a href=/people/s/simon-tannert/>Simon Tannert</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a>
|
<a href=/people/j/jonas-kuhn/>Jonas Kuhn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--134><div class="card-body p-3 small">We propose a graph-based method to tackle the dependency tree linearization task. We formulate the task as a Traveling Salesman Problem (TSP), and use a biaffine attention model to calculate the edge costs. We facilitate the decoding by solving the <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>TSP</a> for each subtree and combining the solution into a projective tree. We then design a <a href=https://en.wikipedia.org/wiki/Transition_system>transition system</a> as <a href=https://en.wikipedia.org/wiki/Post-processing>post-processing</a>, inspired by non-projective transition-based parsing, to obtain non-projective sentences. Our proposed method outperforms the state-of-the-art <a href=https://en.wikipedia.org/wiki/Linearizer>linearizer</a> while being 10 times faster in <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> and <a href=https://en.wikipedia.org/wiki/Decoding_methods>decoding</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.137.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--137 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.137 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928870 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.137" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.137/>In Laymans Terms : Semi-Open Relation Extraction from Scientific Texts</a></strong><br><a href=/people/r/ruben-kruiper/>Ruben Kruiper</a>
|
<a href=/people/j/julian-vincent/>Julian Vincent</a>
|
<a href=/people/j/jessica-chen-burger/>Jessica Chen-Burger</a>
|
<a href=/people/m/marc-desmulliez/>Marc Desmulliez</a>
|
<a href=/people/i/ioannis-konstas/>Ioannis Konstas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--137><div class="card-body p-3 small">Information Extraction (IE) from <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific texts</a> can be used to guide readers to the central information in <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific documents</a>. But narrow IE systems extract only a fraction of the information captured, and Open IE systems do not perform well on the long and complex sentences encountered in scientific texts. In this work we combine the output of both types of <a href=https://en.wikipedia.org/wiki/System>systems</a> to achieve Semi-Open Relation Extraction, a new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> that we explore in the Biology domain. First, we present the Focused Open Biological Information Extraction (FOBIE) dataset and use FOBIE to train a state-of-the-art narrow scientific IE system to extract trade-off relations and arguments that are central to biology texts. We then run both the narrow IE system and a state-of-the-art Open IE system on a corpus of 10 K open-access scientific biological texts. We show that a significant amount (65 %) of erroneous and uninformative Open IE extractions can be filtered using narrow IE extractions. Furthermore, we show that the retained extractions are significantly more often informative to a reader.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--140 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929091 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.140" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.140/>Probing Linguistic Features of Sentence-Level Representations in Neural Relation Extraction</a></strong><br><a href=/people/c/christoph-alt/>Christoph Alt</a>
|
<a href=/people/a/aleksandra-gabryszak/>Aleksandra Gabryszak</a>
|
<a href=/people/l/leonhard-hennig/>Leonhard Hennig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--140><div class="card-body p-3 small">Despite the recent progress, little is known about the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> captured by state-of-the-art neural relation extraction (RE) models. Common methods encode the source sentence, conditioned on the entity mentions, before classifying the relation. However, the complexity of the task makes it difficult to understand how <a href=https://en.wikipedia.org/wiki/Encoder>encoder architecture</a> and supporting linguistic knowledge affect the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> learned by the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a>. We introduce 14 probing tasks targeting linguistic properties relevant to RE, and we use them to study representations learned by more than 40 different encoder architecture and linguistic feature combinations trained on two datasets, TACRED and SemEval 2010 Task 8. We find that the bias induced by the architecture and the inclusion of <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> are clearly expressed in the probing task performance. For example, adding contextualized word representations greatly increases performance on probing tasks with a focus on <a href=https://en.wikipedia.org/wiki/Named_entity>named entity</a> and part-of-speech information, and yields better results in RE. In contrast, entity masking improves <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>RE</a>, but considerably lowers performance on entity type related probing tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.145.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--145 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.145 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929029 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.145/>Character-Level Translation with Self-attention</a></strong><br><a href=/people/y/yingqiang-gao/>Yingqiang Gao</a>
|
<a href=/people/n/nikola-i-nikolov/>Nikola I. Nikolov</a>
|
<a href=/people/y/yuhuang-hu/>Yuhuang Hu</a>
|
<a href=/people/r/richard-h-r-hahnloser/>Richard H.R. Hahnloser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--145><div class="card-body p-3 small">We explore the suitability of self-attention models for character-level neural machine translation. We test the standard transformer model, as well as a novel variant in which the encoder block combines information from nearby characters using <a href=https://en.wikipedia.org/wiki/Convolution>convolutions</a>. We perform extensive experiments on WMT and UN datasets, testing both bilingual and multilingual translation to <a href=https://en.wikipedia.org/wiki/English_language>English</a> using up to three input languages (French, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, and Chinese). Our <a href=https://en.wikipedia.org/wiki/Transformer>transformer variant</a> consistently outperforms the standard <a href=https://en.wikipedia.org/wiki/Transformer>transformer</a> at the <a href=https://en.wikipedia.org/wiki/Character_encoding>character-level</a> and converges faster while learning more robust <a href=https://en.wikipedia.org/wiki/Character_encoding>character-level alignments</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.146.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--146 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.146 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929138 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.146/>End-to-End Neural Word Alignment Outperforms GIZA++<span class=acl-fixed-case>GIZA</span>++</a></strong><br><a href=/people/t/thomas-zenkel/>Thomas Zenkel</a>
|
<a href=/people/j/joern-wuebker/>Joern Wuebker</a>
|
<a href=/people/j/john-denero/>John DeNero</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--146><div class="card-body p-3 small">Word alignment was once a core unsupervised learning task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> because of its essential role in training statistical machine translation (MT) models. Although unnecessary for training neural MT models, <a href=https://en.wikipedia.org/wiki/Word_alignment>word alignment</a> still plays an important role in interactive applications of <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>, such as annotation transfer and lexicon injection. While statistical MT methods have been replaced by neural approaches with superior performance, the twenty-year-old GIZA++ toolkit remains a key component of state-of-the-art word alignment systems. Prior work on neural word alignment has only been able to outperform GIZA++ by using its output during training. We present the first end-to-end neural word alignment method that consistently outperforms GIZA++ on three data sets. Our approach repurposes a Transformer model trained for supervised translation to also serve as an unsupervised word alignment model in a manner that is tightly integrated and does not affect translation quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.152.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--152 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.152 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929223 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.152" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.152/>Parallel Sentence Mining by Constrained Decoding</a></strong><br><a href=/people/p/pinzhen-chen/>Pinzhen Chen</a>
|
<a href=/people/n/nikolay-bogoychev/>Nikolay Bogoychev</a>
|
<a href=/people/k/kenneth-heafield/>Kenneth Heafield</a>
|
<a href=/people/f/faheem-kirefu/>Faheem Kirefu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--152><div class="card-body p-3 small">We present a novel method to extract <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel sentences</a> from two monolingual corpora, using <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. Our method relies on translating sentences in one corpus, but constraining the decoding by a <a href=https://en.wikipedia.org/wiki/Prefix_tree>prefix tree</a> built on the other corpus. We argue that a neural machine translation system by itself can be a sentence similarity scorer and it efficiently approximates <a href=https://en.wikipedia.org/wiki/Pairwise_comparison>pairwise comparison</a> with a modified <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a>. When benchmarked on the BUCC shared task, our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> achieves results comparable to other submissions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.159.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--159 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.159 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.159.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929385 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.159/>Inflecting When Theres No Majority : Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals<span class=acl-fixed-case>G</span>erman Plurals</a></strong><br><a href=/people/k/kate-mccurdy/>Kate McCurdy</a>
|
<a href=/people/s/sharon-goldwater/>Sharon Goldwater</a>
|
<a href=/people/a/adam-lopez/>Adam Lopez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--159><div class="card-body p-3 small">Can <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>artificial neural networks</a> learn to represent <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>inflectional morphology</a> and generalize to new words as <a href=https://en.wikipedia.org/wiki/Speech>human speakers</a> do? Kirov and Cotterell (2018) argue that the answer is yes : modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995): that neural models may learn to extend not the regular, but the most frequent class and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> from <a href=https://en.wikipedia.org/wiki/German_language>German speakers</a> (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two <a href=https://en.wikipedia.org/wiki/Suffix>suffixes</a> evince &#8216;regular&#8217; behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or &#8216;regular&#8217; extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.161.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--161 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.161 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928796 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.161" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.161/>Modelling Suspense in Short Stories as Uncertainty Reduction over Neural Representation</a></strong><br><a href=/people/d/david-wilmot/>David Wilmot</a>
|
<a href=/people/f/frank-keller/>Frank Keller</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--161><div class="card-body p-3 small">Suspense is a crucial ingredient of <a href=https://en.wikipedia.org/wiki/Narrative>narrative fiction</a>, engaging readers and making stories compelling. While there is a vast theoretical literature on <a href=https://en.wikipedia.org/wiki/Suspense>suspense</a>, it is computationally not well understood. We compare two ways for modelling <a href=https://en.wikipedia.org/wiki/Suspense>suspense</a> : <a href=https://en.wikipedia.org/wiki/Surprise_(emotion)>surprise</a>, a backward-looking measure of how unexpected the current state is given the story so far ; and uncertainty reduction, a forward-looking measure of how unexpected the continuation of the story is. Both can be computed either directly over story representations or over their <a href=https://en.wikipedia.org/wiki/Probability_distribution>probability distributions</a>. We propose a hierarchical language model that encodes stories and computes <a href=https://en.wikipedia.org/wiki/Surprise_(emotion)>surprise</a> and uncertainty reduction. Evaluating against <a href=https://en.wikipedia.org/wiki/Short_story>short stories</a> annotated with human suspense judgements, we find that uncertainty reduction over <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> is the best predictor, resulting in near human accuracy. We also show that uncertainty reduction can be used to predict suspenseful events in movie synopses.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.164.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--164 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.164 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928914 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.164" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.164/>Automatic Detection of Generated Text is Easiest when Humans are Fooled</a></strong><br><a href=/people/d/daphne-ippolito/>Daphne Ippolito</a>
|
<a href=/people/d/daniel-duckworth/>Daniel Duckworth</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a>
|
<a href=/people/d/douglas-eck/>Douglas Eck</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--164><div class="card-body p-3 small">Recent advancements in neural language modelling make it possible to rapidly generate vast amounts of human-sounding text. The capabilities of <a href=https://en.wikipedia.org/wiki/Human>humans</a> and <a href=https://en.wikipedia.org/wiki/Discriminator>automatic discriminators</a> to detect machine-generated text have been a large source of research interest, but humans and machines rely on different cues to make their decisions. Here, we perform careful benchmarking and analysis of three popular sampling-based decoding strategiestop-_k _, nucleus sampling, and untruncated random samplingand show that improvements in decoding methods have primarily optimized for fooling humans. This comes at the expense of introducing <a href=https://en.wikipedia.org/wiki/Statistical_significance>statistical abnormalities</a> that make <a href=https://en.wikipedia.org/wiki/Detection>detection</a> easy for <a href=https://en.wikipedia.org/wiki/Automation>automatic systems</a>. We also show that though both human and automatic detector performance improve with longer excerpt length, even multi-sentence excerpts can fool expert human raters over 30 % of the time. Our findings reveal the importance of using both human and automatic detectors to assess the humanness of text generation systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.167.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--167 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.167 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929147 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.167" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.167/>GPT-too : A Language-Model-First Approach for AMR-to-Text Generation<span class=acl-fixed-case>GPT</span>-too: A Language-Model-First Approach for <span class=acl-fixed-case>AMR</span>-to-Text Generation</a></strong><br><a href=/people/m/manuel-mager/>Manuel Mager</a>
|
<a href=/people/r/ramon-fernandez-astudillo/>Ramn Fernandez Astudillo</a>
|
<a href=/people/t/tahira-naseem/>Tahira Naseem</a>
|
<a href=/people/m/md-arafat-sultan/>Md Arafat Sultan</a>
|
<a href=/people/y/young-suk-lee/>Young-Suk Lee</a>
|
<a href=/people/r/radu-florian/>Radu Florian</a>
|
<a href=/people/s/salim-roukos/>Salim Roukos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--167><div class="card-body p-3 small">Abstract Meaning Representations (AMRs) are broad-coverage sentence-level semantic graphs. Existing approaches to generating text from AMR have focused on training sequence-to-sequence or graph-to-sequence models on AMR annotated data only. In this paper, we propose an alternative approach that combines a strong pre-trained language model with cycle consistency-based re-scoring. Despite the simplicity of the approach, our experimental results show these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> outperform all previous techniques on the English LDC2017T10 dataset, including the recent use of transformer architectures. In addition to the standard evaluation metrics, we provide human evaluation experiments that further substantiate the strength of our approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.169.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--169 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.169 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929267 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.169/>Politeness Transfer : A Tag and Generate Approach</a></strong><br><a href=/people/a/aman-madaan/>Aman Madaan</a>
|
<a href=/people/a/amrith-setlur/>Amrith Setlur</a>
|
<a href=/people/t/tanmay-parekh/>Tanmay Parekh</a>
|
<a href=/people/b/barnabas-poczos/>Barnabas Poczos</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/y/yiming-yang/>Yiming Yang</a>
|
<a href=/people/r/ruslan-salakhutdinov/>Ruslan Salakhutdinov</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a>
|
<a href=/people/s/shrimai-prabhumoye/>Shrimai Prabhumoye</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--169><div class="card-body p-3 small">This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>meaning</a>. We also provide a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of more than 1.39 instances automatically labeled for <a href=https://en.wikipedia.org/wiki/Politeness>politeness</a> to encourage benchmark evaluations on this new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For <a href=https://en.wikipedia.org/wiki/Politeness>politeness</a> as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a>, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at https://github.com/tag-and-generate.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.170.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--170 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.170 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928817 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.170" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.170/>BPE-Dropout : Simple and Effective Subword Regularization<span class=acl-fixed-case>BPE</span>-Dropout: Simple and Effective Subword Regularization</a></strong><br><a href=/people/i/ivan-provilkov/>Ivan Provilkov</a>
|
<a href=/people/d/dmitrii-emelianenko/>Dmitrii Emelianenko</a>
|
<a href=/people/e/elena-voita/>Elena Voita</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--170><div class="card-body p-3 small">Subword segmentation is widely used to address the open vocabulary problem in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. The dominant approach to subword segmentation is Byte Pair Encoding (BPE), which keeps the most frequent words intact while splitting the rare ones into multiple tokens. While multiple segmentations are possible even with the same vocabulary, BPE splits words into unique sequences ; this may prevent a model from better learning the compositionality of words and being robust to segmentation errors. So far, the only way to overcome this BPE imperfection, its deterministic nature, was to create another subword segmentation algorithm (Kudo, 2018). In contrast, we show that BPE itself incorporates the ability to produce multiple segmentations of the same word. We introduce BPE-dropout-simple and effective subword regularization method based on and compatible with conventional BPE. It stochastically corrupts the segmentation procedure of BPE, which leads to producing multiple segmentations within the same fixed BPE framework. Using BPE-dropout during <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> and the standard BPE during inference improves translation quality up to 2.3 BLEU compared to BPE and up to 0.9 BLEU compared to the previous subword regularization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.172.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--172 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.172 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929326 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.172/>Attend to Medical Ontologies : Content Selection for Clinical Abstractive Summarization</a></strong><br><a href=/people/s/sajad-sotudeh-gharebagh/>Sajad Sotudeh Gharebagh</a>
|
<a href=/people/n/nazli-goharian/>Nazli Goharian</a>
|
<a href=/people/r/ross-filice/>Ross Filice</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--172><div class="card-body p-3 small">Sequence-to-sequence (seq2seq) network is a well-established <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for text summarization task. It can learn to produce readable content ; however, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> falls short in effectively identifying key regions of the source. In this paper, we approach the content selection problem for clinical abstractive summarization by augmenting salient ontological terms into the summarizer. Our experiments on two publicly available <a href=https://en.wikipedia.org/wiki/Clinical_trial>clinical data sets</a> (107,372 reports of MIMIC-CXR, and 3,366 reports of OpenI) show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> statistically significantly boosts state-of-the-art results in terms of ROUGE metrics (with improvements : 2.9 % RG-1, 2.5 % RG-2, 1.9 % RG-L), in the <a href=https://en.wikipedia.org/wiki/Health_care>healthcare domain</a> where any range of improvement impacts patients&#8217; welfare.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.173.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--173 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.173 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929071 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.173" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.173/>On Faithfulness and Factuality in Abstractive Summarization</a></strong><br><a href=/people/j/joshua-maynez/>Joshua Maynez</a>
|
<a href=/people/s/shashi-narayan/>Shashi Narayan</a>
|
<a href=/people/b/bernd-bohnet/>Bernd Bohnet</a>
|
<a href=/people/r/ryan-mcdonald/>Ryan McDonald</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--173><div class="card-body p-3 small">It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> and <a href=https://en.wikipedia.org/wiki/Storytelling>story generation</a>. In this paper we have analyzed limitations of these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> for abstractive document summarization and found that these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>raw metrics</a>, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with <a href=https://en.wikipedia.org/wiki/Faithfulness>faithfulness</a> than standard <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.179.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--179 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.179 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929008 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.179" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.179/>Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment<span class=acl-fixed-case>E</span>nglish-Like Relative Clause Attachment</a></strong><br><a href=/people/f/forrest-davis/>Forrest Davis</a>
|
<a href=/people/m/marten-van-schijndel/>Marten van Schijndel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--179><div class="card-body p-3 small">A standard approach to evaluating language models analyzes how <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations, where stark grammaticality differences are absent. We compare model performance in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in <a href=https://en.wikipedia.org/wiki/English_language>English</a> but not <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. Thus, English models may appear to acquire human-like syntactic preferences, while <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> trained on <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>comprehension</a> (i.e. typical language model use cases) and production (which generates the training data for language models), suggesting that necessary linguistic biases are not present in the training signal at all.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.180.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--180 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.180 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929286 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.180/>Speakers enhance contextually confusable words</a></strong><br><a href=/people/e/eric-meinhardt/>Eric Meinhardt</a>
|
<a href=/people/e/eric-bakovic/>Eric Bakovic</a>
|
<a href=/people/l/leon-bergen/>Leon Bergen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--180><div class="card-body p-3 small">Recent work has found evidence that <a href=https://en.wikipedia.org/wiki/Natural_language>natural languages</a> are shaped by pressures for efficient communication e.g. the more contextually predictable a word is, the fewer speech sounds or syllables it has (Piantadosi et al. Research on the degree to which speech and language are shaped by pressures for effective communication robustness in the face of <a href=https://en.wikipedia.org/wiki/Noise>noise</a> and <a href=https://en.wikipedia.org/wiki/Uncertainty>uncertainty</a> has been more equivocal. We develop a measure of contextual confusability during <a href=https://en.wikipedia.org/wiki/Word_recognition>word recognition</a> based on <a href=https://en.wikipedia.org/wiki/Psychoacoustics>psychoacoustic data</a>. Applying this measure to naturalistic speech corpora, we find evidence suggesting that speakers alter their productions to make contextually more confusable words easier to understand.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.193.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--193 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.193 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928969 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.193" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.193/>Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling</a></strong><br><a href=/people/o/ouyu-lan/>Ouyu Lan</a>
|
<a href=/people/x/xiao-huang/>Xiao Huang</a>
|
<a href=/people/b/bill-yuchen-lin/>Bill Yuchen Lin</a>
|
<a href=/people/h/he-jiang/>He Jiang</a>
|
<a href=/people/l/liyuan-liu/>Liyuan Liu</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--193><div class="card-body p-3 small">Sequence labeling is a fundamental task for a range of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing problems</a>. When used in practice, its performance is largely influenced by the annotation quality and quantity, and meanwhile, obtaining ground truth labels is often costly. In many cases, ground truth labels do not exist, but noisy annotations or <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> from different domains are accessible. In this paper, we propose a novel framework Consensus Network (ConNet) that can be trained on annotations from multiple sources (e.g., crowd annotation, cross-domain data). It learns individual representation for every source and dynamically aggregates source-specific knowledge by a context-aware attention module. Finally, it leads to a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> reflecting the agreement (consensus) among multiple sources. We evaluate the proposed framework in two practical settings of multi-source learning : learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves significant improvements over existing <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> in both settings. We also demonstrate that the <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> can apply to various <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> and cope with different <a href=https://en.wikipedia.org/wiki/Code>encoders</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.194.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--194 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.194 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929239 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.194" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.194/>MixText : Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification<span class=acl-fixed-case>M</span>ix<span class=acl-fixed-case>T</span>ext: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification</a></strong><br><a href=/people/j/jiaao-chen/>Jiaao Chen</a>
|
<a href=/people/z/zichao-yang/>Zichao Yang</a>
|
<a href=/people/d/diyi-yang/>Diyi Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--194><div class="card-body p-3 small">This paper presents MixText, a semi-supervised learning method for text classification, which uses our newly designed data augmentation method called TMix. TMix creates a large amount of augmented training samples by interpolating text in hidden space. Moreover, we leverage recent advances in <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> to guess low-entropy labels for unlabeled data, hence making them as easy to use as labeled data. By mixing labeled, unlabeled and augmented data, MixText significantly outperformed current pre-trained and fined-tuned models and other state-of-the-art semi-supervised learning methods on several text classification benchmarks. The improvement is especially prominent when <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a> is extremely limited. We have publicly released our code at https://github.com/GT-SALT/MixText.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.197.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--197 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.197 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928798 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.197" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.197/>SMART : Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization<span class=acl-fixed-case>SMART</span>: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization</a></strong><br><a href=/people/h/haoming-jiang/>Haoming Jiang</a>
|
<a href=/people/p/pengcheng-he/>Pengcheng He</a>
|
<a href=/people/w/weizhu-chen/>Weizhu Chen</a>
|
<a href=/people/x/xiaodong-liu/>Xiaodong Liu</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a>
|
<a href=/people/t/tuo-zhao/>Tuo Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--197><div class="card-body p-3 small">Transfer learning has fundamentally changed the landscape of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>. Many state-of-the-art models are first pre-trained on a large text corpus and then fine-tuned on downstream tasks. However, due to limited data resources from downstream tasks and the extremely high complexity of pre-trained models, aggressive fine-tuning often causes the fine-tuned model to overfit the training data of downstream tasks and fail to generalize to unseen data. To address such an issue in a principled manner, we propose a new learning framework for robust and efficient <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> for pre-trained models to attain better <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> performance. The proposed <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> contains two important ingredients : 1. Smoothness-inducing regularization, which effectively manages the <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>complexity</a> of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> ; 2. Bregman proximal point optimization, which is an instance of trust-region methods and can prevent aggressive updating. Our experiments show that the proposed framework achieves new state-of-the-art performance on a number of NLP tasks including GLUE, SNLI, SciTail and ANLI. Moreover, it also outperforms the state-of-the-art T5 model, which is the largest pre-trained model containing 11 billion parameters, on GLUE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.199.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--199 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.199 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928766 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.199/>Taxonomy Construction of Unseen Domains via Graph-based Cross-Domain Knowledge Transfer</a></strong><br><a href=/people/c/chao-shang/>Chao Shang</a>
|
<a href=/people/s/sarthak-dash/>Sarthak Dash</a>
|
<a href=/people/m/md-faisal-mahbub-chowdhury/>Md. Faisal Mahbub Chowdhury</a>
|
<a href=/people/n/nandana-mihindukulasooriya/>Nandana Mihindukulasooriya</a>
|
<a href=/people/a/alfio-gliozzo/>Alfio Gliozzo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--199><div class="card-body p-3 small">Extracting lexico-semantic relations as graph-structured taxonomies, also known as taxonomy construction, has been beneficial in a variety of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP applications</a>. Recently Graph Neural Network (GNN) has shown to be powerful in successfully tackling many <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. However, there has been no attempt to exploit GNN to create <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>taxonomies</a>. In this paper, we propose Graph2Taxo, a GNN-based cross-domain transfer framework for the taxonomy construction task. Our main contribution is to learn the latent features of <a href=https://en.wikipedia.org/wiki/Taxonomy_(general)>taxonomy construction</a> from existing domains to guide the structure learning of an unseen domain. We also propose a novel method of directed acyclic graph (DAG) generation for <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>taxonomy construction</a>. Specifically, our proposed Graph2Taxo uses a noisy graph constructed from automatically extracted noisy hyponym hypernym candidate pairs, and a set of <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>taxonomies</a> for some known domains for training. The learned model is then used to generate <a href=https://en.wikipedia.org/wiki/Taxonomy_(general)>taxonomy</a> for a new unknown domain given a set of terms for that domain. Experiments on benchmark datasets from science and environment domains show that our approach attains significant improvements correspondingly over the state of the art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--203 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929199 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.203" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.203/>A Girl Has A Name : Detecting Authorship Obfuscation</a></strong><br><a href=/people/a/asad-mahmood/>Asad Mahmood</a>
|
<a href=/people/z/zubair-shafiq/>Zubair Shafiq</a>
|
<a href=/people/p/padmini-srinivasan/>Padmini Srinivasan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--203><div class="card-body p-3 small">Authorship attribution aims to identify the author of a text based on the <a href=https://en.wikipedia.org/wiki/Stylometry>stylometric analysis</a>. Authorship obfuscation, on the other hand, aims to protect against authorship attribution by modifying a text&#8217;s style. In this paper, we evaluate the stealthiness of state-of-the-art authorship obfuscation methods under an adversarial threat model. An <a href=https://en.wikipedia.org/wiki/Obfuscator>obfuscator</a> is stealthy to the extent an adversary finds it challenging to detect whether or not a text modified by the <a href=https://en.wikipedia.org/wiki/Obfuscator>obfuscator</a> is obfuscated a decision that is key to the adversary interested in authorship attribution. We show that the existing authorship obfuscation methods are not stealthy as their obfuscated texts can be identified with an average <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> of 0.87. The reason for the lack of stealthiness is that these obfuscators degrade text smoothness, as ascertained by neural language models, in a detectable manner. Our results highlight the need to develop stealthy authorship obfuscation methods that can better protect the identity of an author seeking anonymity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.205.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--205 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.205 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929395 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.205/>Efficient Strategies for Hierarchical Text Classification : External Knowledge and Auxiliary Tasks</a></strong><br><a href=/people/k/kervy-rivas-rojas/>Kervy Rivas Rojas</a>
|
<a href=/people/g/gina-bustamante/>Gina Bustamante</a>
|
<a href=/people/a/arturo-oncevay/>Arturo Oncevay</a>
|
<a href=/people/m/marco-antonio-sobrevilla-cabezudo/>Marco Antonio Sobrevilla Cabezudo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--205><div class="card-body p-3 small">In hierarchical text classification, we perform a sequence of <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference steps</a> to predict the category of a document from top to bottom of a given class taxonomy. Most of the studies have focused on developing novels neural network architectures to deal with the hierarchical structure, but we prefer to look for efficient ways to strengthen a baseline model. We first define the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> as a sequence-to-sequence problem. Afterwards, we propose an auxiliary synthetic task of bottom-up-classification. Then, from external dictionaries, we retrieve textual definitions for the classes of all the hierarchy&#8217;s layers, and map them into the word vector space. We use the class-definition embeddings as an additional input to condition the prediction of the next layer and in an adapted beam search. Whereas the modified search did not provide large gains, the combination of the auxiliary task and the additional input of class-definitions significantly enhance the classification accuracy. With our efficient approaches, we outperform previous studies, using a drastically reduced number of parameters, in two well-known English datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.207.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--207 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.207 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928763 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.207" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.207/>SPECTER : Document-level Representation Learning using Citation-informed Transformers<span class=acl-fixed-case>SPECTER</span>: Document-level Representation Learning using Citation-informed Transformers</a></strong><br><a href=/people/a/arman-cohan/>Arman Cohan</a>
|
<a href=/people/s/sergey-feldman/>Sergey Feldman</a>
|
<a href=/people/i/iz-beltagy/>Iz Beltagy</a>
|
<a href=/people/d/doug-downey/>Doug Downey</a>
|
<a href=/people/d/daniel-s-weld/>Daniel Weld</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--207><div class="card-body p-3 small">Representation learning is a critical ingredient for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing systems</a>. Recent Transformer language models like <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> learn powerful textual representations, but these models are targeted towards token- and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power. For applications on <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific documents</a>, such as <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>classification</a> and <a href=https://en.wikipedia.org/wiki/Recommender_system>recommendation</a>, accurate embeddings of documents are a necessity. We propose SPECTER, a new method to generate document-level embedding of scientific papers based on pretraining a Transformer language model on a powerful signal of document-level relatedness : the <a href=https://en.wikipedia.org/wiki/Citation_graph>citation graph</a>. Unlike existing pretrained language models, <a href=https://en.wikipedia.org/wiki/Specter>Specter</a> can be easily applied to downstream applications without task-specific fine-tuning. Additionally, to encourage further research on document-level models, we introduce SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation. We show that <a href=https://en.wikipedia.org/wiki/Specter>Specter</a> outperforms a variety of competitive baselines on the <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.208.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--208 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.208 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.208.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929435 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.208" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.208/>Semantic Scaffolds for Pseudocode-to-Code Generation</a></strong><br><a href=/people/r/ruiqi-zhong/>Ruiqi Zhong</a>
|
<a href=/people/m/mitchell-stern/>Mitchell Stern</a>
|
<a href=/people/d/dan-klein/>Dan Klein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--208><div class="card-body p-3 small">We propose a method for program generation based on semantic scaffolds, lightweight structures representing the high-level semantic and syntactic composition of a program. By first searching over plausible scaffolds then using these as constraints for a beam search over programs, we achieve better coverage of the search space when compared with existing techniques. We apply our hierarchical search method to the SPoC dataset for pseudocode-to-code generation, in which we are given line-level natural language pseudocode annotations and aim to produce a program satisfying execution-based test cases. By using semantic scaffolds during <a href=https://en.wikipedia.org/wiki/Inference>inference</a>, we achieve a 10 % absolute improvement in top-100 accuracy over the previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>. Additionally, we require only 11 candidates to reach the top-3000 performance of the previous best approach when tested against unseen problems, demonstrating a substantial improvement in efficiency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.209.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--209 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.209 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929433 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.209" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.209/>Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction</a></strong><br><a href=/people/s/samuel-broscheit/>Samuel Broscheit</a>
|
<a href=/people/k/kiril-gashteovski/>Kiril Gashteovski</a>
|
<a href=/people/y/yanjie-wang/>Yanjie Wang</a>
|
<a href=/people/r/rainer-gemulla/>Rainer Gemulla</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--209><div class="card-body p-3 small">Open Information Extraction systems extract (subject text, relation text, object text) triples from raw text. Some triples are textual versions of facts, i.e., non-canonicalized mentions of entities and relations. In this paper, we investigate whether it is possible to infer new facts directly from the open knowledge graph without any <a href=https://en.wikipedia.org/wiki/Canonicalization>canonicalization</a> or any supervision from curated knowledge. For this purpose, we propose the open link prediction task, i.e., predicting test facts by completing (subject text, relation text,?) questions. An evaluation in such a setup raises the question if a correct prediction is actually a new fact that was induced by reasoning over the open knowledge graph or if it can be trivially explained. For example, facts can appear in different paraphrased textual variants, which can lead to test leakage. To this end, we propose an evaluation protocol and a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> for creating the open link prediction benchmark OlpBench. We performed experiments with a prototypical knowledge graph embedding model for openlink prediction. While the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is very challenging, our results suggests that it is possible to predict genuinely new facts, which can not be trivially explained.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--214 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929139 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.214" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.214/>Integrating Multimodal Information in Large Pretrained Transformers</a></strong><br><a href=/people/w/wasifur-rahman/>Wasifur Rahman</a>
|
<a href=/people/m/md-kamrul-hasan/>Md Kamrul Hasan</a>
|
<a href=/people/s/sangwu-lee/>Sangwu Lee</a>
|
<a href=/people/a/amirali-bagher-zadeh/>AmirAli Bagher Zadeh</a>
|
<a href=/people/c/chengfeng-mao/>Chengfeng Mao</a>
|
<a href=/people/l/louis-philippe-morency/>Louis-Philippe Morency</a>
|
<a href=/people/e/ehsan-hoque/>Ehsan Hoque</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--214><div class="card-body p-3 small">Recent Transformer-based contextual word representations, including <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> and XLNet, have shown state-of-the-art performance in multiple disciplines within <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. Fine-tuning the trained contextual models on task-specific datasets has been the key to achieving superior performance downstream. While fine-tuning these pre-trained models is straightforward for lexical applications (applications with only language modality), it is not trivial for multimodal language (a growing area in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> focused on modeling face-to-face communication). More specifically, this is due to the fact that pre-trained models do n&#8217;t have the necessary components to accept two extra modalities of <a href=https://en.wikipedia.org/wiki/Visual_perception>vision</a> and <a href=https://en.wikipedia.org/wiki/Acoustics>acoustic</a>. In this paper, we proposed an attachment to BERT and XLNet called Multimodal Adaptation Gate (MAG). MAG allows BERT and XLNet to accept multimodal nonverbal data during <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>. It does so by generating a shift to internal representation of BERT and XLNet ; a shift that is conditioned on the visual and acoustic modalities. In our experiments, we study the commonly used CMU-MOSI and CMU-MOSEI datasets for <a href=https://en.wikipedia.org/wiki/Multimodal_sentiment_analysis>multimodal sentiment analysis</a>. Fine-tuning MAG-BERT and MAG-XLNet significantly boosts the <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> performance over previous baselines as well as language-only fine-tuning of <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> and XLNet. On the CMU-MOSI dataset, MAG-XLNet achieves human-level multimodal sentiment analysis performance for the first time in the NLP community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.215.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--215 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.215 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929009 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.215/>MultiQT : <a href=https://en.wikipedia.org/wiki/Multimodal_learning>Multimodal learning</a> for real-time question tracking in speech<span class=acl-fixed-case>M</span>ulti<span class=acl-fixed-case>QT</span>: Multimodal learning for real-time question tracking in speech</a></strong><br><a href=/people/j/jakob-d-havtorn/>Jakob D. Havtorn</a>
|
<a href=/people/j/jan-latko/>Jan Latko</a>
|
<a href=/people/j/joakim-edin/>Joakim Edin</a>
|
<a href=/people/l/lars-maaloe/>Lars Maale</a>
|
<a href=/people/l/lasse-borgholt/>Lasse Borgholt</a>
|
<a href=/people/l/lorenzo-belgrano/>Lorenzo Belgrano</a>
|
<a href=/people/n/nicolai-jacobsen/>Nicolai Jacobsen</a>
|
<a href=/people/r/regitze-sdun/>Regitze Sdun</a>
|
<a href=/people/z/zeljko-agic/>eljko Agi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--215><div class="card-body p-3 small">We address a challenging and practical task of labeling questions in speech in real time during telephone calls to emergency medical services in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, which embeds within a broader <a href=https://en.wikipedia.org/wiki/Decision_support_system>decision support system</a> for emergency call-takers. We propose a novel multimodal approach to real-time sequence labeling in speech. Our model treats <a href=https://en.wikipedia.org/wiki/Speech>speech</a> and its own textual representation as two separate modalities or views, as it jointly learns from streamed audio and its noisy transcription into text via automatic speech recognition. Our results show significant gains of jointly learning from the two modalities when compared to text or audio only, under <a href=https://en.wikipedia.org/wiki/Noise_(electronics)>adverse noise</a> and limited volume of training data. The results generalize to medical symptoms detection where we observe a similar pattern of improvements with <a href=https://en.wikipedia.org/wiki/Multimodal_learning>multimodal learning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.219.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--219 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.219 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928905 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.219/>Image-Chat : Engaging Grounded Conversations</a></strong><br><a href=/people/k/kurt-shuster/>Kurt Shuster</a>
|
<a href=/people/s/samuel-humeau/>Samuel Humeau</a>
|
<a href=/people/a/antoine-bordes/>Antoine Bordes</a>
|
<a href=/people/j/jason-weston/>Jason Weston</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--219><div class="card-body p-3 small">To achieve the long-term goal of machines being able to engage humans in conversation, our <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> should captivate the interest of their speaking partners. Communication grounded in images, whereby a <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a> is conducted based on a given photo, is a setup naturally appealing to humans (Hu et al., 2014). In this work we study <a href=https://en.wikipedia.org/wiki/Computer_architecture>large-scale architectures</a> and <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> for this goal. We test a set of neural architectures using state-of-the-art image and text representations, considering various ways to fuse the <a href=https://en.wikipedia.org/wiki/Component-based_software_engineering>components</a>. To test such models, we collect a dataset of grounded human-human conversations, where speakers are asked to play roles given a provided emotional mood or style, as the use of such traits is also a key factor in engagingness (Guo et al., 2019). Our dataset, Image-Chat, consists of 202k dialogues over 202k images using 215 possible style traits. Automatic metrics and human evaluations of engagingness show the efficacy of our approach ; in particular, we obtain state-of-the-art performance on the existing IGC task, and our best performing model is almost on par with humans on the Image-Chat test set (preferred 47.7 % of the time).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.221.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--221 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.221 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928926 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.221" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.221/>Neural Generation of Dialogue Response Timings</a></strong><br><a href=/people/m/matthew-roddy/>Matthew Roddy</a>
|
<a href=/people/n/naomi-harte/>Naomi Harte</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--221><div class="card-body p-3 small">The timings of spoken response offsets in human dialogue have been shown to vary based on contextual elements of the dialogue. We propose neural models that simulate the distributions of these response offsets, taking into account the response turn as well as the preceding turn. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> are designed to be integrated into the pipeline of an incremental spoken dialogue system (SDS). We evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using offline experiments as well as human listening tests. We show that human listeners consider certain response timings to be more natural based on the dialogue context. The introduction of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> into SDS pipelines could increase the perceived naturalness of interactions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.224.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--224 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.224 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929169 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.224/>Bridging the Structural Gap Between <a href=https://en.wikipedia.org/wiki/Code>Encoding</a> and <a href=https://en.wikipedia.org/wiki/Code>Decoding</a> for Data-To-Text Generation</a></strong><br><a href=/people/c/chao-zhao/>Chao Zhao</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--224><div class="card-body p-3 small">Generating sequential natural language descriptions from <a href=https://en.wikipedia.org/wiki/Graph_(abstract_data_type)>graph-structured data</a> (e.g., knowledge graph) is challenging, partly because of the structural differences between the input <a href=https://en.wikipedia.org/wiki/Graph_(abstract_data_type)>graph</a> and the output text. Hence, popular sequence-to-sequence models, which require serialized input, are not a natural fit for this task. Graph neural networks, on the other hand, can better encode the input graph but broaden the structural gap between the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and <a href=https://en.wikipedia.org/wiki/Codec>decoder</a>, making faithful generation difficult. To narrow this gap, we propose DualEnc, a dual encoding model that can not only incorporate the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a>, but can also cater to the <a href=https://en.wikipedia.org/wiki/Linearity>linear structure</a> of the output text. Empirical comparisons with strong single-encoder baselines demonstrate that dual encoding can significantly improve the quality of the generated text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.235.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--235 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.235 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928824 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.235" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.235/>A Batch Normalized Inference Network Keeps the KL Vanishing Away<span class=acl-fixed-case>KL</span> Vanishing Away</a></strong><br><a href=/people/q/qile-zhu/>Qile Zhu</a>
|
<a href=/people/w/wei-bi/>Wei Bi</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/x/xiyao-ma/>Xiyao Ma</a>
|
<a href=/people/x/xiaolin-li/>Xiaolin Li</a>
|
<a href=/people/d/dapeng-wu/>Dapeng Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--235><div class="card-body p-3 small">Variational Autoencoder (VAE) is widely used as a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> to approximate a model&#8217;s posterior on <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> by combining the amortized variational inference and <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a>. However, when paired with strong autoregressive decoders, VAE often converges to a degenerated local optimum known as posterior collapse. Previous approaches consider the KullbackLeibler divergence (KL) individual for each datapoint. We propose to let the KL follow a distribution across the whole dataset, and analyze that it is sufficient to prevent posterior collapse by keeping the expectation of the KL&#8217;s distribution positive. Then we propose Batch Normalized-VAE (BN-VAE), a simple but effective approach to set a lower bound of the expectation by regularizing the distribution of the approximate posterior&#8217;s parameters. Without introducing any new model component or modifying the objective, our approach can avoid the posterior collapse effectively and efficiently. We further show that the proposed BN-VAE can be extended to conditional VAE (CVAE). Empirically, our approach surpasses strong autoregressive baselines on language modeling, text classification and dialogue generation, and rivals more complex approaches while keeping almost the same training time as VAE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.239.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--239 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.239 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928819 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.239/>Low Resource Sequence Tagging using Sentence Reconstruction</a></strong><br><a href=/people/t/tal-perl/>Tal Perl</a>
|
<a href=/people/s/sriram-chaudhury/>Sriram Chaudhury</a>
|
<a href=/people/r/raja-giryes/>Raja Giryes</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--239><div class="card-body p-3 small">This work revisits the task of training sequence tagging models with limited resources using <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>. We investigate several proposed approaches introduced in recent works and suggest a new <a href=https://en.wikipedia.org/wiki/Loss_function>loss</a> that relies on sentence reconstruction from normalized embeddings. Specifically, our method demonstrates how by adding a decoding layer for sentence reconstruction, we can improve the performance of various <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>. We show improved results on the CoNLL02 NER and UD 1.2 POS datasets and demonstrate the power of the method for <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> with low-resources achieving 0.6 F1 score in <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a> using only one sample from it.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.247.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--247 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.247 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929129 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.247" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.247/>Span Selection Pre-training for <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a></a></strong><br><a href=/people/m/michael-glass/>Michael Glass</a>
|
<a href=/people/a/alfio-gliozzo/>Alfio Gliozzo</a>
|
<a href=/people/r/rishav-chakravarti/>Rishav Chakravarti</a>
|
<a href=/people/a/anthony-ferritto/>Anthony Ferritto</a>
|
<a href=/people/l/lin-pan/>Lin Pan</a>
|
<a href=/people/g/g-p-shrivatsa-bhargav/>G P Shrivatsa Bhargav</a>
|
<a href=/people/d/dinesh-garg/>Dinesh Garg</a>
|
<a href=/people/a/avirup-sil/>Avi Sil</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--247><div class="card-body p-3 small">BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pretrained on two auxiliary tasks : Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> to better align the pre-training from <a href=https://en.wikipedia.org/wiki/Memorization>memorization</a> to <a href=https://en.wikipedia.org/wiki/Understanding>understanding</a>. Span Selection PreTraining (SSPT) poses cloze-like training instances, but rather than draw the answer from the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>&#8217;s parameters, it is selected from a relevant passage. We find significant and consistent improvements over both BERT-BASE and BERT-LARGE on multiple Machine Reading Comprehension (MRC) datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer prediction. We also show significant impact in HotpotQA, improving answer prediction F1 by 4 points and supporting fact prediction F1 by 1 point and outperforming the previous best system. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the <a href=https://en.wikipedia.org/wiki/Learning_curve>learning curve</a> by a large amount.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.250.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--250 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.250 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929349 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.250/>schuBERT : Optimizing Elements of BERT<span class=acl-fixed-case>BERT</span>: Optimizing Elements of <span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/a/ashish-khetan/>Ashish Khetan</a>
|
<a href=/people/z/zohar-karnin/>Zohar Karnin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--250><div class="card-body p-3 small">Transformers have gradually become a key component for many state-of-the-art natural language representation models. A recent Transformer based model- BERTachieved state-of-the-art results on various natural language processing tasks, including GLUE, SQuAD v1.1, and SQuAD v2.0. This <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> however is computationally prohibitive and has a huge number of parameters. In this work we revisit the architecture choices of BERT in efforts to obtain a lighter model. We focus on reducing the number of parameters yet our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> can be applied towards other objectives such FLOPs or <a href=https://en.wikipedia.org/wiki/Latency_(engineering)>latency</a>. We show that much efficient light BERT models can be obtained by reducing algorithmically chosen correct architecture design dimensions rather than reducing the number of Transformer encoder layers. In particular, our schuBERT gives 6.6 % higher average accuracy on GLUE and SQuAD datasets as compared to BERT with three encoder layers while having the same number of parameters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.258.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--258 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.258 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928698 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.258/>Predicting Degrees of Technicality in Automatic Terminology Extraction</a></strong><br><a href=/people/a/anna-hatty/>Anna Htty</a>
|
<a href=/people/d/dominik-schlechtweg/>Dominik Schlechtweg</a>
|
<a href=/people/m/michael-dorna/>Michael Dorna</a>
|
<a href=/people/s/sabine-schulte-im-walde/>Sabine Schulte im Walde</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--258><div class="card-body p-3 small">While automatic term extraction is a well-researched area, computational approaches to distinguish between degrees of technicality are still understudied. We semi-automatically create a German gold standard of technicality across four domains, and illustrate the impact of a web-crawled general-language corpus on technicality prediction. When defining a classification approach that combines general-language and domain-specific word embeddings, we go beyond previous work and align vector spaces to gain comparative embeddings. We suggest two novel models to exploit general- vs. domain-specific comparisons : a simple <a href=https://en.wikipedia.org/wiki/Neural_network>neural network model</a> with pre-computed comparative-embedding information as input, and a multi-channel model computing the comparison internally. Both <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> outperform previous approaches, with the multi-channel model performing best.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.260.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--260 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.260 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928955 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.260/>Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer</a></strong><br><a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/s/subhabrata-mukherjee/>Subhabrata Mukherjee</a>
|
<a href=/people/s/saghar-hosseini/>Saghar Hosseini</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/a/ahmed-hassan-awadallah/>Ahmed Hassan Awadallah</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--260><div class="card-body p-3 small">Multilingual representations embed words from many languages into a single <a href=https://en.wikipedia.org/wiki/Semantic_space>semantic space</a> such that words with similar meanings are close to each other regardless of the language. These embeddings have been widely used in various settings, such as cross-lingual transfer, where a <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP) model</a> trained on one language is deployed to another language. While the cross-lingual transfer techniques are powerful, they carry <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> from the source to target languages. In this paper, we study <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> in multilingual embeddings and how it affects <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP applications</a>. We create a multilingual dataset for bias analysis and propose several ways for quantifying bias in multilingual representations from both the intrinsic and extrinsic perspectives. Experimental results show that the magnitude of bias in the multilingual representations changes differently when we align the embeddings to different target spaces and that the alignment direction can also have an influence on the bias in <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>. We further provide recommendations for using the multilingual word representations for <a href=https://en.wikipedia.org/wiki/Downstream_(networking)>downstream tasks</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.262.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--262 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.262 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928838 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.262/>Is Your Classifier Actually Biased? Measuring Fairness under Uncertainty with Bernstein Bounds</a></strong><br><a href=/people/k/kawin-ethayarajh/>Kawin Ethayarajh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--262><div class="card-body p-3 small">Most NLP datasets are not annotated with protected attributes such as gender, making it difficult to measure classification bias using standard measures of fairness (e.g., equal opportunity). However, manually annotating a large dataset with a protected attribute is slow and expensive. Instead of annotating all the examples, can we annotate a subset of them and use that sample to estimate the <a href=https://en.wikipedia.org/wiki/Bias_(statistics)>bias</a>? While it is possible to do so, the smaller this annotated sample is, the less certain we are that the <a href=https://en.wikipedia.org/wiki/Estimation_theory>estimate</a> is close to the true bias. In this work, we propose using Bernstein bounds to represent this uncertainty about the <a href=https://en.wikipedia.org/wiki/Bias_of_an_estimator>bias estimate</a> as a <a href=https://en.wikipedia.org/wiki/Confidence_interval>confidence interval</a>. We provide empirical evidence that a 95 % confidence interval derived this way consistently bounds the true <a href=https://en.wikipedia.org/wiki/Bias_(statistics)>bias</a>. In quantifying this uncertainty, our method, which we call Bernstein-bounded unfairness, helps prevent classifiers from being deemed biased or unbiased when there is insufficient evidence to make either claim. Our findings suggest that the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> currently used to measure specific biases are too small to conclusively identify <a href=https://en.wikipedia.org/wiki/Bias>bias</a> except in the most egregious cases. For example, consider a co-reference resolution system that is 5 % more accurate on gender-stereotypical sentences to claim it is biased with 95 % confidence, we need a bias-specific dataset that is 3.8 times larger than WinoBias, the largest available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.264.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--264 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.264 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928917 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.264" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.264/>Mitigating Gender Bias Amplification in Distribution by Posterior Regularization</a></strong><br><a href=/people/s/shengyu-jia/>Shengyu Jia</a>
|
<a href=/people/t/tao-meng/>Tao Meng</a>
|
<a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--264><div class="card-body p-3 small">Advanced machine learning techniques have boosted the performance of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. Nevertheless, recent studies, e.g., (CITATION) show that these techniques inadvertently capture the societal bias hidden in the corpus and further amplify it. However, their analysis is conducted only on models&#8217; top predictions. In this paper, we investigate the gender bias amplification issue from the distribution perspective and demonstrate that the bias is amplified in the view of predicted probability distribution over labels. We further propose a bias mitigation approach based on posterior regularization. With little performance loss, our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> can almost remove the bias amplification in the distribution. Our study sheds the light on understanding the bias amplification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.265.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--265 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.265 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.265.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929244 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.265/>Towards Understanding Gender Bias in Relation Extraction</a></strong><br><a href=/people/a/andrew-gaut/>Andrew Gaut</a>
|
<a href=/people/t/tony-sun/>Tony Sun</a>
|
<a href=/people/s/shirlyn-tang/>Shirlyn Tang</a>
|
<a href=/people/y/yuxin-huang/>Yuxin Huang</a>
|
<a href=/people/j/jing-qian/>Jing Qian</a>
|
<a href=/people/m/mai-elsherief/>Mai ElSherief</a>
|
<a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/d/diba-mirza/>Diba Mirza</a>
|
<a href=/people/e/elizabeth-belding/>Elizabeth Belding</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--265><div class="card-body p-3 small">Recent developments in Neural Relation Extraction (NRE) have made significant strides towards Automated Knowledge Base Construction. While much attention has been dedicated towards improvements in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, there have been no attempts in the literature to evaluate <a href=https://en.wikipedia.org/wiki/Bias>social biases</a> exhibited in NRE systems. In this paper, we create WikiGenderBias, a distantly supervised dataset composed of over 45,000 sentences including a 10 % human annotated test set for the purpose of analyzing gender bias in relation extraction systems. We find that when extracting spouse-of and hypernym (i.e., occupation) relations, an NRE system performs differently when the gender of the target entity is different. However, such disparity does not appear when extracting relations such as <a href=https://en.wikipedia.org/wiki/Birth_date>birthDate</a> or <a href=https://en.wikipedia.org/wiki/Place_of_birth>birthPlace</a>. We also analyze how existing bias mitigation techniques, such as name anonymization, word embedding debiasing, and <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> affect the NRE system in terms of maintaining the test performance and reducing biases. Unfortunately, due to NRE models rely heavily on surface level cues, we find that existing bias mitigation approaches have a negative effect on NRE. Our analysis lays groundwork for future quantifying and mitigating bias in NRE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.272.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--272 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.272 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929229 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.272/>Zero-shot Text Classification via Reinforced Self-training</a></strong><br><a href=/people/z/zhiquan-ye/>Zhiquan Ye</a>
|
<a href=/people/y/yuxia-geng/>Yuxia Geng</a>
|
<a href=/people/j/jiaoyan-chen/>Jiaoyan Chen</a>
|
<a href=/people/j/jingmin-chen/>Jingmin Chen</a>
|
<a href=/people/x/xiaoxiao-xu/>Xiaoxiao Xu</a>
|
<a href=/people/s/suhang-zheng/>SuHang Zheng</a>
|
<a href=/people/f/feng-wang/>Feng Wang</a>
|
<a href=/people/j/jun-zhang/>Jun Zhang</a>
|
<a href=/people/h/huajun-chen/>Huajun Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--272><div class="card-body p-3 small">Zero-shot learning has been a tough problem since no labeled data is available for unseen classes during training, especially for classes with low similarity. In this situation, transferring from seen classes to unseen classes is extremely hard. To tackle this problem, in this paper we propose a self-training based method to efficiently leverage unlabeled data. Traditional self-training methods use fixed heuristics to select instances from unlabeled data, whose performance varies among different datasets. We propose a reinforcement learning framework to learn data selection strategy automatically and provide more reliable selection. Experimental results on both benchmarks and a real-world e-commerce dataset show that our approach significantly outperforms previous methods in zero-shot text classification</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.274.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--274 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.274 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929428 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.274/>A Relaxed Matching Procedure for Unsupervised BLI<span class=acl-fixed-case>BLI</span></a></strong><br><a href=/people/x/xu-zhao/>Xu Zhao</a>
|
<a href=/people/z/zihao-wang/>Zihao Wang</a>
|
<a href=/people/y/yong-zhang/>Yong Zhang</a>
|
<a href=/people/h/hao-wu/>Hao Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--274><div class="card-body p-3 small">Recently unsupervised Bilingual Lexicon Induction(BLI) without any <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> has attracted much research interest. One of the crucial parts in <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> for the BLI task is the matching procedure. Previous works impose a too strong <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>constraint</a> on the <a href=https://en.wikipedia.org/wiki/Impedance_matching>matching</a> and lead to many counterintuitive translation pairings. Thus We propose a relaxed matching procedure to find a more precise matching between two languages. We also find that aligning source and target language embedding space bidirectionally will bring significant improvement. We follow the previous iterative framework to conduct experiments. Results on standard <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a> demonstrate the effectiveness of our proposed method, which substantially outperforms previous <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.275.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--275 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.275 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929282 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.275" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.275/>Dynamic Programming Encoding for Subword Segmentation in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/x/xuanli-he/>Xuanli He</a>
|
<a href=/people/g/gholamreza-haffari/>Gholamreza Haffari</a>
|
<a href=/people/m/mohammad-norouzi/>Mohammad Norouzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--275><div class="card-body p-3 small">This paper introduces Dynamic Programming Encoding (DPE), a new segmentation algorithm for tokenizing sentences into subword units. We view the subword segmentation of output sentences as a <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> that should be marginalized out for <a href=https://en.wikipedia.org/wiki/Machine_learning>learning</a> and <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a>. A mixed character-subword transformer is proposed, which enables exact log marginal likelihood estimation and exact MAP inference to find target segmentations with maximum posterior probability. DPE uses a lightweight mixed character-subword transformer as a means of pre-processing parallel data to segment output sentences using <a href=https://en.wikipedia.org/wiki/Dynamic_programming>dynamic programming</a>. Empirical results on <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> suggest that DPE is effective for segmenting output sentences and can be combined with BPE dropout for stochastic segmentation of source sentences. DPE achieves an average improvement of 0.9 BLEU over BPE (Sennrich et al., 2016) and an average improvement of 0.55 BLEU over BPE dropout (Provilkov et al., 2019) on several WMT datasets including English = (German, Romanian, Estonian, Finnish, Hungarian).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.276.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--276 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.276 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.276.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929319 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.276/>Geometry-aware domain adaptation for unsupervised alignment of word embeddings</a></strong><br><a href=/people/p/pratik-jawanpuria/>Pratik Jawanpuria</a>
|
<a href=/people/m/mayank-meghwanshi/>Mayank Meghwanshi</a>
|
<a href=/people/b/bamdev-mishra/>Bamdev Mishra</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--276><div class="card-body p-3 small">We propose a novel manifold based geometric approach for learning unsupervised alignment of word embeddings between the source and the target languages. Our approach formulates the alignment learning problem as a domain adaptation problem over the manifold of doubly stochastic matrices. This viewpoint arises from the aim to align the <a href=https://en.wikipedia.org/wiki/Second-order_logic>second order information</a> of the two language spaces. The rich geometry of the doubly stochastic manifold allows to employ efficient Riemannian conjugate gradient algorithm for the proposed formulation. Empirically, the proposed approach outperforms state-of-the-art optimal transport based approach on the bilingual lexicon induction task across several language pairs. The performance improvement is more significant for distant language pairs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.280.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--280 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.280 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928782 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.280" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.280/>Distinguish Confusing Law Articles for Legal Judgment Prediction</a></strong><br><a href=/people/n/nuo-xu/>Nuo Xu</a>
|
<a href=/people/p/pinghui-wang/>Pinghui Wang</a>
|
<a href=/people/l/long-chen/>Long Chen</a>
|
<a href=/people/l/li-pan/>Li Pan</a>
|
<a href=/people/x/xiaoyan-wang/>Xiaoyan Wang</a>
|
<a href=/people/j/junzhou-zhao/>Junzhou Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--280><div class="card-body p-3 small">Legal Judgement Prediction (LJP) is the task of automatically predicting a law case&#8217;s judgment results given a text describing the case&#8217;s facts, which has great prospects in judicial assistance systems and handy services for the public. In practice, confusing charges are often presented, because <a href=https://en.wikipedia.org/wiki/Legal_case>law cases</a> applicable to similar <a href=https://en.wikipedia.org/wiki/Legal_case>law articles</a> are easily misjudged. To address this issue, existing work relies heavily on <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain experts</a>, which hinders its application in different <a href=https://en.wikipedia.org/wiki/List_of_national_legal_systems>law systems</a>. In this paper, we present an <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end model</a>, LADAN, to solve the task of LJP. To distinguish confusing charges, we propose a novel graph neural network, GDL, to automatically learn subtle differences between confusing law articles, and also design a novel attention mechanism that fully exploits the learned differences to attentively extract effective discriminative features from fact descriptions. Experiments conducted on real-world datasets demonstrate the superiority of our LADAN.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.282.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--282 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.282 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928939 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.282/>HyperCore : Hyperbolic and Co-graph Representation for Automatic ICD Coding<span class=acl-fixed-case>H</span>yper<span class=acl-fixed-case>C</span>ore: Hyperbolic and Co-graph Representation for Automatic <span class=acl-fixed-case>ICD</span> Coding</a></strong><br><a href=/people/p/pengfei-cao/>Pengfei Cao</a>
|
<a href=/people/y/yubo-chen/>Yubo Chen</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a>
|
<a href=/people/s/shengping-liu/>Shengping Liu</a>
|
<a href=/people/w/weifeng-chong/>Weifeng Chong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--282><div class="card-body p-3 small">The International Classification of Diseases (ICD) provides a standardized way for <a href=https://en.wikipedia.org/wiki/Medical_classification>classifying diseases</a>, which endows each disease with a unique code. ICD coding aims to assign proper ICD codes to a <a href=https://en.wikipedia.org/wiki/Medical_record>medical record</a>. Since manual coding is very laborious and prone to errors, many methods have been proposed for the automatic ICD coding task. However, most of existing <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> independently predict each code, ignoring two important characteristics : Code Hierarchy and <a href=https://en.wikipedia.org/wiki/Co-occurrence>Code Co-occurrence</a>. In this paper, we propose a Hyperbolic and Co-graph Representation method (HyperCore) to address the above problem. Specifically, we propose a hyperbolic representation method to leverage the code hierarchy. Moreover, we propose a graph convolutional network to utilize the code co-occurrence. Experimental results on two widely used datasets demonstrate that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms previous state-of-the-art methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.289.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--289 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.289 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928827 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.289/>Effective Inter-Clause Modeling for End-to-End Emotion-Cause Pair Extraction</a></strong><br><a href=/people/p/penghui-wei/>Penghui Wei</a>
|
<a href=/people/j/jiahao-zhao/>Jiahao Zhao</a>
|
<a href=/people/w/wenji-mao/>Wenji Mao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--289><div class="card-body p-3 small">Emotion-cause pair extraction aims to extract all emotion clauses coupled with their cause clauses from a given document. Previous work employs two-step approaches, in which the first step extracts emotion clauses and cause clauses separately, and the second step trains a <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifier</a> to filter out negative pairs. However, such pipeline-style system for emotion-cause pair extraction is suboptimal because it suffers from <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a> and the two steps may not adapt to each other well. In this paper, we tackle emotion-cause pair extraction from a <a href=https://en.wikipedia.org/wiki/Ranking>ranking perspective</a>, i.e., ranking clause pair candidates in a document, and propose a one-step neural approach which emphasizes inter-clause modeling to perform end-to-end extraction. It models the interrelations between the clauses in a document to learn clause representations with graph attention, and enhances clause pair representations with kernel-based relative position embedding for effective ranking. Experimental results show that our approach significantly outperforms the current two-step systems, especially in the condition of extracting multiple pairs in one document.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.291.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--291 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.291 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929329 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.291/>Enhancing Cross-target Stance Detection with Transferable Semantic-Emotion Knowledge</a></strong><br><a href=/people/b/bowen-zhang/>Bowen Zhang</a>
|
<a href=/people/m/min-yang/>Min Yang</a>
|
<a href=/people/x/xutao-li/>Xutao Li</a>
|
<a href=/people/y/yunming-ye/>Yunming Ye</a>
|
<a href=/people/x/xiaofei-xu/>Xiaofei Xu</a>
|
<a href=/people/k/kuai-dai/>Kuai Dai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--291><div class="card-body p-3 small">Stance detection is an important task, which aims to classify the attitude of an opinionated text towards a given target. Remarkable success has been achieved when sufficient labeled training data is available. However, annotating sufficient data is labor-intensive, which establishes significant barriers for generalizing the stance classifier to the data with new targets. In this paper, we proposed a Semantic-Emotion Knowledge Transferring (SEKT) model for cross-target stance detection, which uses the external knowledge (semantic and emotion lexicons) as a bridge to enable knowledge transfer across different targets. Specifically, a semantic-emotion heterogeneous graph is constructed from external semantic and emotion lexicons, which is then fed into a graph convolutional network to learn multi-hop semantic connections between words and emotion tags. Then, the learned semantic-emotion graph representation, which serves as prior knowledge bridging the gap between the source and target domains, is fully integrated into the bidirectional long short-term memory (BiLSTM) stance classifier by adding a novel knowledge-aware memory unit to the BiLSTM cell. Extensive experiments on a large real-world dataset demonstrate the superiority of SEKT against the state-of-the-art baseline methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.292.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--292 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.292 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929234 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.292" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.292/>KinGDOM : Knowledge-Guided DOMain Adaptation for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a><span class=acl-fixed-case>K</span>in<span class=acl-fixed-case>GDOM</span>: <span class=acl-fixed-case>K</span>nowledge-<span class=acl-fixed-case>G</span>uided <span class=acl-fixed-case>DOM</span>ain <span class=acl-fixed-case>A</span>daptation for <span class=acl-fixed-case>S</span>entiment <span class=acl-fixed-case>A</span>nalysis</a></strong><br><a href=/people/d/deepanway-ghosal/>Deepanway Ghosal</a>
|
<a href=/people/d/devamanyu-hazarika/>Devamanyu Hazarika</a>
|
<a href=/people/a/abhinaba-roy/>Abhinaba Roy</a>
|
<a href=/people/n/navonil-majumder/>Navonil Majumder</a>
|
<a href=/people/r/rada-mihalcea/>Rada Mihalcea</a>
|
<a href=/people/s/soujanya-poria/>Soujanya Poria</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--292><div class="card-body p-3 small">Cross-domain sentiment analysis has received significant attention in recent years, prompted by the need to combat the domain gap between different <a href=https://en.wikipedia.org/wiki/Application_software>applications</a> that make use of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. In this paper, we take a novel perspective on this task by exploring the role of <a href=https://en.wikipedia.org/wiki/Common_knowledge_(logic)>external commonsense knowledge</a>. We introduce a new framework, KinGDOM, which utilizes the ConceptNet knowledge graph to enrich the semantics of a document by providing both domain-specific and domain-general background concepts. These <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> are learned by training a graph convolutional autoencoder that leverages inter-domain concepts in a domain-invariant manner. Conditioning a popular domain-adversarial baseline method with these learned concepts helps improve its performance over state-of-the-art approaches, demonstrating the efficacy of our proposed framework.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.294.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--294 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.294 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929365 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.294" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.294/>Parallel Data Augmentation for Formality Style Transfer</a></strong><br><a href=/people/y/yi-zhang/>Yi Zhang</a>
|
<a href=/people/t/tao-ge/>Tao Ge</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--294><div class="card-body p-3 small">The main barrier to progress in the task of Formality Style Transfer is the inadequacy of training data. In this paper, we study how to augment parallel data and propose novel and simple data augmentation methods for this task to obtain useful sentence pairs with easily accessible models and systems. Experiments demonstrate that our augmented parallel data largely helps improve formality style transfer when it is used to pre-train the model, leading to the state-of-the-art results in the GYAFC benchmark dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.299.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--299 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.299 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928752 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.299" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.299/>A Span-based Linearization for Constituent Trees</a></strong><br><a href=/people/y/yang-wei/>Yang Wei</a>
|
<a href=/people/y/yuanbin-wu/>Yuanbin Wu</a>
|
<a href=/people/m/man-lan/>Man Lan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--299><div class="card-body p-3 small">We propose a novel linearization of a constituent tree, together with a new locally normalized model. For each split point in a sentence, our model computes the <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalizer</a> on all spans ending with that split point, and then predicts a tree span from them. Compared with global models, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is fast and parallelizable. Different from previous local models, our linearization method is tied on the spans directly and considers more local features when performing span prediction, which is more interpretable and effective. Experiments on PTB (95.8 F1) and CTB (92.4 F1) show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> significantly outperforms existing local models and efficiently achieves competitive results with global models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.301.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--301 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.301 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928813 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.301/>Efficient Constituency Parsing by Pointing</a></strong><br><a href=/people/t/thanh-tung-nguyen/>Thanh-Tung Nguyen</a>
|
<a href=/people/x/xuan-phi-nguyen/>Xuan-Phi Nguyen</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/x/xiaoli-li/>Xiaoli Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--301><div class="card-body p-3 small">We propose a novel constituency parsing model that casts the parsing problem into a series of pointing tasks. Specifically, our model estimates the likelihood of a span being a legitimate tree constituent via the pointing score corresponding to the boundary words of the span. Our parsing model supports efficient <a href=https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design>top-down decoding</a> and our learning objective is able to enforce structural consistency without resorting to the expensive CKY inference. The experiments on the standard English Penn Treebank parsing task show that our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> achieves 92.78 F1 without using pre-trained models, which is higher than all the existing methods with similar <a href=https://en.wikipedia.org/wiki/Time_complexity>time complexity</a>. Using pre-trained BERT, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 95.48 <a href=https://en.wikipedia.org/wiki/F-number>F1</a>, which is competitive with the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> while being faster. Our approach also establishes new state-of-the-art in <a href=https://en.wikipedia.org/wiki/Basque_language>Basque</a> and <a href=https://en.wikipedia.org/wiki/Swedish_language>Swedish</a> in the SPMRL shared tasks on multilingual constituency parsing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.306.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--306 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.306 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929164 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.306/>Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer</a></strong><br><a href=/people/j/jianfei-yu/>Jianfei Yu</a>
|
<a href=/people/j/jing-jiang/>Jing Jiang</a>
|
<a href=/people/l/li-yang/>Li Yang</a>
|
<a href=/people/r/rui-xia/>Rui Xia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--306><div class="card-body p-3 small">In this paper, we study Multimodal Named Entity Recognition (MNER) for social media posts. Existing approaches for MNER mainly suffer from two drawbacks : (1) despite generating word-aware visual representations, their word representations are insensitive to the visual context ; (2) most of them ignore the bias brought by the visual context. To tackle the first issue, we propose a multimodal interaction module to obtain both image-aware word representations and word-aware visual representations. To alleviate the visual bias, we further propose to leverage purely text-based entity span detection as an auxiliary module, and design a Unified Multimodal Transformer to guide the final predictions with the entity span predictions. Experiments show that our unified approach achieves the new state-of-the-art performance on two <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.307.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--307 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.307 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928848 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.307/>Stock Embeddings Acquired from News Articles and Price History, and an Application to <a href=https://en.wikipedia.org/wiki/Portfolio_optimization>Portfolio Optimization</a></a></strong><br><a href=/people/x/xin-du/>Xin Du</a>
|
<a href=/people/k/kumiko-tanaka-ishii/>Kumiko Tanaka-Ishii</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--307><div class="card-body p-3 small">Previous works that integrated <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> to better process <a href=https://en.wikipedia.org/wiki/Stock_market>stock prices</a> used a variety of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> to predict <a href=https://en.wikipedia.org/wiki/Volatility_(finance)>price movements</a>. The textual and price information were both encoded in the <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a>, and it is therefore difficult to apply this approach in situations other than the original framework of the notoriously hard problem of price prediction. In contrast, this paper presents a method to encode the influence of news articles through a vector representation of stocks called a stock embedding. The stock embedding is acquired with a deep learning framework using both <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> and price history. Because the <a href=https://en.wikipedia.org/wiki/Embedding>embedding</a> takes the operational form of a <a href=https://en.wikipedia.org/wiki/Euclidean_vector>vector</a>, it is applicable to other financial problems besides <a href=https://en.wikipedia.org/wiki/Mathematical_finance>price prediction</a>. As one example application, we show the results of <a href=https://en.wikipedia.org/wiki/Portfolio_optimization>portfolio optimization</a> using Reuters & Bloomberg headlines, producing a <a href=https://en.wikipedia.org/wiki/Capital_gain>capital gain</a> 2.8 times larger than that obtained with a <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline method</a> using only stock price data. This suggests that the proposed stock embedding can leverage textual financial semantics to solve financial prediction problems.<i>stock embedding</i>. The stock embedding is acquired with a deep learning framework using both news articles and price history. Because the embedding takes the operational form of a vector, it is applicable to other financial problems besides price prediction. As one example application, we show the results of portfolio optimization using Reuters & Bloomberg headlines, producing a capital gain 2.8 times larger than that obtained with a baseline method using only stock price data. This suggests that the proposed stock embedding can leverage textual financial semantics to solve financial prediction problems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.308.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--308 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.308 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929381 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.308" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.308/>What Was Written vs. Who Read It : News Media Profiling Using <a href=https://en.wikipedia.org/wiki/Text_mining>Text Analysis</a> and Social Media Context</a></strong><br><a href=/people/r/ramy-baly/>Ramy Baly</a>
|
<a href=/people/g/georgi-karadzhov/>Georgi Karadzhov</a>
|
<a href=/people/j/jisun-an/>Jisun An</a>
|
<a href=/people/h/haewoon-kwak/>Haewoon Kwak</a>
|
<a href=/people/y/yoan-dinkov/>Yoan Dinkov</a>
|
<a href=/people/a/ahmed-ali/>Ahmed Ali</a>
|
<a href=/people/j/james-glass/>James Glass</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--308><div class="card-body p-3 small">Predicting the political bias and the factuality of reporting of entire news outlets are critical elements of media profiling, which is an understudied but an increasingly important research direction. The present level of proliferation of fake, biased, and propagandistic content online has made it impossible to fact-check every single suspicious claim, either manually or automatically. Thus, it has been proposed to profile entire <a href=https://en.wikipedia.org/wiki/News_media>news outlets</a> and to look for those that are likely to publish fake or biased content. This makes it possible to detect likely <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> the moment they are published, by simply checking the reliability of their source. From a practical perspective, political bias and factuality of reporting have a linguistic aspect but also a <a href=https://en.wikipedia.org/wiki/Social_environment>social context</a>. Here, we study the impact of both, namely (i) what was written (i.e., what was published by the target medium, and how it describes itself in Twitter) vs. (ii) who reads it (i.e., analyzing the target medium&#8217;s audience on social media). We further study (iii) what was written about the target medium (in Wikipedia). The evaluation results show that what was written matters most, and we further show that putting all information sources together yields huge improvements over the current state-of-the-art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.311.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--311 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.311 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928695 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.311/>Roles and Utilization of Attention Heads in Transformer-based Neural Language Models</a></strong><br><a href=/people/j/jae-young-jo/>Jae-young Jo</a>
|
<a href=/people/s/sung-hyon-myaeng/>Sung-Hyon Myaeng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--311><div class="card-body p-3 small">Sentence encoders based on the transformer architecture have shown promising results on various natural language tasks. The main impetus lies in the pre-trained neural language models that capture long-range dependencies among words, owing to multi-head attention that is unique in the architecture. However, little is known for how linguistic properties are processed, represented, and utilized for downstream tasks among hundreds of <a href=https://en.wikipedia.org/wiki/Attentional_control>attention heads</a> inside the pre-trained transformer-based model. For the initial goal of examining the roles of attention heads in handling a set of linguistic features, we conducted a set of experiments with ten probing tasks and three downstream tasks on four pre-trained transformer families (GPT, GPT2, BERT, and ELECTRA). Meaningful insights are shown through the lens of heat map visualization and utilized to propose a relatively simple sentence representation method that takes advantage of most influential attention heads, resulting in additional performance improvements on the downstream tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.312.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--312 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.312 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929360 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.312/>Understanding Attention for <a href=https://en.wikipedia.org/wiki/Text_classification>Text Classification</a></a></strong><br><a href=/people/x/xiaobing-sun/>Xiaobing Sun</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--312><div class="card-body p-3 small">Attention has been proven successful in many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP) tasks</a>. Recently, many researchers started to investigate the interpretability of <a href=https://en.wikipedia.org/wiki/Attention>attention</a> on NLP tasks. Many existing approaches focused on examining whether the local attention weights could reflect the importance of input representations. In this work, we present a study on understanding the internal mechanism of attention by looking into the gradient update process, checking its behavior when approaching a <a href=https://en.wikipedia.org/wiki/Maxima_and_minima>local minimum</a> during <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a>. We propose to analyze for each word token the following two quantities : its polarity score and its attention score, where the latter is a global assessment on the token&#8217;s significance. We discuss conditions under which the attention mechanism may become more (or less) interpretable, and show how the interplay between the two quantities can contribute towards model performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.315.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--315 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.315 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928721 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.315" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.315/>Enhancing Pre-trained Chinese Character Representation with Word-aligned Attention<span class=acl-fixed-case>C</span>hinese Character Representation with Word-aligned Attention</a></strong><br><a href=/people/y/yanzeng-li/>Yanzeng Li</a>
|
<a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/x/xue-mengge/>Xue Mengge</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--315><div class="card-body p-3 small">Most <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese pre-trained models</a> take <a href=https://en.wikipedia.org/wiki/Character_(symbol)>character</a> as the basic unit and learn representation according to <a href=https://en.wikipedia.org/wiki/Character_(symbol)>character&#8217;s external contexts</a>, ignoring the semantics expressed in the word, which is the smallest meaningful utterance in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. Hence, we propose a novel word-aligned attention to exploit explicit word information, which is complementary to various character-based Chinese pre-trained language models. Specifically, we devise a pooling mechanism to align the character-level attention to the word level and propose to alleviate the potential issue of segmentation error propagation by multi-source information fusion. As a result, word and character information are explicitly integrated at the <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning procedure</a>. Experimental results on five Chinese NLP benchmark tasks demonstrate that our method achieves significant improvements against BERT, <a href=https://en.wikipedia.org/wiki/ERNIE>ERNIE</a> and BERT-wwm.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.316.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--316 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.316 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928764 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.316" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.316/>On the Encoder-Decoder Incompatibility in Variational Text Modeling and Beyond</a></strong><br><a href=/people/c/chen-wu/>Chen Wu</a>
|
<a href=/people/p/prince-zizhuang-wang/>Prince Zizhuang Wang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--316><div class="card-body p-3 small">Variational autoencoders (VAEs) combine <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> with <a href=https://en.wikipedia.org/wiki/Amortized_analysis>amortized variational inference</a>, whose optimization usually converges into a trivial local optimum termed posterior collapse, especially in text modeling. By tracking the optimization dynamics, we observe the encoder-decoder incompatibility that leads to poor parameterizations of the <a href=https://en.wikipedia.org/wiki/Manifold>data manifold</a>. We argue that the trivial local optimum may be avoided by improving the encoder and decoder parameterizations since the posterior network is part of a transition map between them. To this end, we propose Coupled-VAE, which couples a VAE model with a deterministic autoencoder with the same structure and improves the encoder and decoder parameterizations via encoder weight sharing and decoder signal matching. We apply the proposed Coupled-VAE approach to various VAE models with different <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a>, <a href=https://en.wikipedia.org/wiki/Posterior_probability>posterior family</a>, decoder structure, and <a href=https://en.wikipedia.org/wiki/Mathematical_optimization>optimization strategy</a>. Experiments on <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark datasets</a> (i.e., PTB, <a href=https://en.wikipedia.org/wiki/Yelp>Yelp</a>, and Yahoo) show consistently improved results in terms of <a href=https://en.wikipedia.org/wiki/Probability_estimation>probability estimation</a> and richness of the latent space. We also generalize our method to conditional language modeling and propose Coupled-CVAE, which largely improves the diversity of dialogue generation on the Switchboard dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.321.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--321 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.321 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929020 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.321/>A Simple and Effective Unified Encoder for Document-Level Machine Translation</a></strong><br><a href=/people/s/shuming-ma/>Shuming Ma</a>
|
<a href=/people/d/dongdong-zhang/>Dongdong Zhang</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--321><div class="card-body p-3 small">Most of the existing <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> for document-level machine translation adopt dual-encoder structures. The representation of the source sentences and the document-level contexts are modeled with two separate <a href=https://en.wikipedia.org/wiki/Encoder>encoders</a>. Although these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> can make use of the document-level contexts, they do not fully model the interaction between the contexts and the source sentences, and can not directly adapt to the recent pre-training models (e.g., BERT) which encodes multiple sentences with a single <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a>. In this work, we propose a simple and effective unified encoder that can outperform the baseline models of dual-encoder models in terms of BLEU and METEOR scores. Moreover, the pre-training models can further boost the performance of our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.324.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--324 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.324 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928849 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.324/>Knowledge Distillation for Multilingual Unsupervised Neural Machine Translation</a></strong><br><a href=/people/h/haipeng-sun/>Haipeng Sun</a>
|
<a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/k/kehai-chen/>Kehai Chen</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichiro Sumita</a>
|
<a href=/people/t/tiejun-zhao/>Tiejun Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--324><div class="card-body p-3 small">Unsupervised neural machine translation (UNMT) has recently achieved remarkable results for several language pairs. However, it can only translate between a single language pair and can not produce <a href=https://en.wikipedia.org/wiki/Translation>translation</a> results for multiple language pairs at the same time. That is, research on multilingual UNMT has been limited. In this paper, we empirically introduce a simple method to translate between thirteen languages using a single encoder and a single decoder, making use of multilingual data to improve UNMT for all language pairs. On the basis of the empirical findings, we propose two knowledge distillation methods to further enhance multilingual UNMT performance. Our experiments on a dataset with English translated to and from twelve other languages (including three language families and six language branches) show remarkable results, surpassing strong unsupervised individual baselines while achieving promising performance between non-English language pairs in zero-shot translation scenarios and alleviating poor performance in low-resource language pairs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.333.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--333 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.333 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929412 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.333" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.333/>Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation</a></strong><br><a href=/people/b/bo-pang/>Bo Pang</a>
|
<a href=/people/e/erik-nijkamp/>Erik Nijkamp</a>
|
<a href=/people/w/wenjuan-han/>Wenjuan Han</a>
|
<a href=/people/l/linqi-zhou/>Linqi Zhou</a>
|
<a href=/people/y/yixian-liu/>Yixian Liu</a>
|
<a href=/people/k/kewei-tu/>Kewei Tu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--333><div class="card-body p-3 small">Open-domain dialogue generation has gained increasing attention in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>. Its evaluation requires a holistic means. Human ratings are deemed as the gold standard. As <a href=https://en.wikipedia.org/wiki/Evaluation>human evaluation</a> is inefficient and costly, an automated substitute is highly desirable. In this paper, we propose holistic evaluation metrics that capture different aspects of open-domain dialogues. Our metrics consist of (1) GPT-2 based context coherence between sentences in a dialogue, (2) GPT-2 based fluency in phrasing, (3) n-gram based diversity in responses to augmented queries, and (4) textual-entailment-inference based logical self-consistency. The empirical validity of our <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> is demonstrated by strong correlations with <a href=https://en.wikipedia.org/wiki/Judgement>human judgments</a>. We open source the code and relevant materials.<tex-math>n</tex-math>-gram based diversity in responses to augmented queries, and (4) textual-entailment-inference based logical self-consistency. The empirical validity of our metrics is demonstrated by strong correlations with human judgments. We open source the code and relevant materials.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.334.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--334 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.334 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929383 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.334/>BiRRE : Learning Bidirectional Residual Relation Embeddings for Supervised Hypernymy Detection<span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>RRE</span>: Learning Bidirectional Residual Relation Embeddings for Supervised Hypernymy Detection</a></strong><br><a href=/people/c/chengyu-wang/>Chengyu Wang</a>
|
<a href=/people/x/xiaofeng-he/>Xiaofeng He</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--334><div class="card-body p-3 small">The hypernymy detection task has been addressed under various <a href=https://en.wikipedia.org/wiki/Software_framework>frameworks</a>. Previously, the design of unsupervised hypernymy scores has been extensively studied. In contrast, <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised classifiers</a>, especially distributional models, leverage the global contexts of terms to make predictions, but are more likely to suffer from lexical memorization. In this work, we revisit <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised distributional models</a> for hypernymy detection. Rather than taking embeddings of two terms as classification inputs, we introduce a representation learning framework named Bidirectional Residual Relation Embeddings (BiRRE). In this model, a term pair is represented by a BiRRE vector as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> for hypernymy classification, which models the possibility of a term being mapped to another in the embedding space by hypernymy relations. A Latent Projection Model with Negative Regularization (LPMNR) is proposed to simulate how <a href=https://en.wikipedia.org/wiki/Hypernym>hypernyms</a> and <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponyms</a> are generated by neural language models, and to generate BiRRE vectors based on bidirectional residuals of projections. Experiments verify BiRRE outperforms strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> over various evaluation frameworks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.335.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--335 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.335 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929043 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.335" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.335/>Biomedical Entity Representations with Synonym Marginalization</a></strong><br><a href=/people/m/mujeen-sung/>Mujeen Sung</a>
|
<a href=/people/h/hwisang-jeon/>Hwisang Jeon</a>
|
<a href=/people/j/jinhyuk-lee/>Jinhyuk Lee</a>
|
<a href=/people/j/jaewoo-kang/>Jaewoo Kang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--335><div class="card-body p-3 small">Biomedical named entities often play important roles in many biomedical text mining tools. However, due to the incompleteness of provided synonyms and numerous variations in their surface forms, normalization of biomedical entities is very challenging. In this paper, we focus on learning representations of biomedical entities solely based on the <a href=https://en.wikipedia.org/wiki/Synonym>synonyms of entities</a>. To learn from the incomplete synonyms, we use a model-based candidate selection and maximize the marginal likelihood of the <a href=https://en.wikipedia.org/wiki/Synonym>synonyms</a> present in top candidates. Our model-based candidates are iteratively updated to contain more difficult negative samples as our model evolves. In this way, we avoid the explicit pre-selection of negative samples from more than 400 K candidates. On four biomedical entity normalization datasets having three different entity types (disease, chemical, adverse reaction), our model BioSyn consistently outperforms previous state-of-the-art models almost reaching the upper bound on each dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.341.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--341 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.341 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928884 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.341" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.341/>SentiBERT : A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics<span class=acl-fixed-case>S</span>enti<span class=acl-fixed-case>BERT</span>: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics</a></strong><br><a href=/people/d/da-yin/>Da Yin</a>
|
<a href=/people/t/tao-meng/>Tao Meng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--341><div class="card-body p-3 small">We propose SentiBERT, a variant of <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> that effectively captures compositional sentiment semantics. The model incorporates contextualized representation with binary constituency parse tree to capture semantic composition. Comprehensive experiments demonstrate that SentiBERT achieves competitive performance on phrase-level sentiment classification. We further demonstrate that the sentiment composition learned from the phrase-level annotations on <a href=https://en.wikipedia.org/wiki/Standard_score>SST</a> can be transferred to other sentiment analysis tasks as well as related tasks, such as emotion classification tasks. Moreover, we conduct <a href=https://en.wikipedia.org/wiki/Ablation>ablation studies</a> and design visualization methods to understand SentiBERT. We show that SentiBERT is better than baseline approaches in capturing <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a> and the <a href=https://en.wikipedia.org/wiki/Contrast_(linguistics)>contrastive relation</a> and model the compositional sentiment semantics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.343.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--343 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.343 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928933 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.343" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.343/>CH-SIMS : A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotation of Modality<span class=acl-fixed-case>CH</span>-<span class=acl-fixed-case>SIMS</span>: A <span class=acl-fixed-case>C</span>hinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotation of Modality</a></strong><br><a href=/people/w/wenmeng-yu/>Wenmeng Yu</a>
|
<a href=/people/h/hua-xu/>Hua Xu</a>
|
<a href=/people/f/fanyang-meng/>Fanyang Meng</a>
|
<a href=/people/y/yilin-zhu/>Yilin Zhu</a>
|
<a href=/people/y/yixiao-ma/>Yixiao Ma</a>
|
<a href=/people/j/jiele-wu/>Jiele Wu</a>
|
<a href=/people/j/jiyun-zou/>Jiyun Zou</a>
|
<a href=/people/k/kaicheng-yang/>Kaicheng Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--343><div class="card-body p-3 small">Previous studies in <a href=https://en.wikipedia.org/wiki/Multimodal_sentiment_analysis>multimodal sentiment analysis</a> have used limited datasets, which only contain unified multimodal annotations. However, the unified annotations do not always reflect the independent sentiment of single modalities and limit the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to capture the difference between modalities. In this paper, we introduce a Chinese single- and multi-modal sentiment analysis dataset, CH-SIMS, which contains 2,281 refined video segments in the wild with both multimodal and independent unimodal annotations. It allows researchers to study the interaction between modalities or use independent unimodal annotations for unimodal sentiment analysis. Furthermore, we propose a multi-task learning framework based on late fusion as the baseline. Extensive experiments on the CH-SIMS show that our methods achieve state-of-the-art performance and learn more distinctive unimodal representations. The full dataset and codes are available for use at https://github.com/thuiar/MMSA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.344.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--344 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.344 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928753 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.344/>Curriculum Pre-training for End-to-End Speech Translation</a></strong><br><a href=/people/c/chengyi-wang/>Chengyi Wang</a>
|
<a href=/people/y/yu-wu/>Yu Wu</a>
|
<a href=/people/s/shujie-liu/>Shujie Liu</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a>
|
<a href=/people/z/zhenglu-yang/>Zhenglu Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--344><div class="card-body p-3 small">End-to-end speech translation poses a heavy burden on the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> because it has to transcribe, understand, and learn cross-lingual semantics simultaneously. To obtain a powerful <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a>, traditional methods pre-train it on <a href=https://en.wikipedia.org/wiki/Speech_recognition>ASR data</a> to capture <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech features</a>. However, we argue that pre-training the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> only through simple <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a> is not enough, and high-level linguistic knowledge should be considered. Inspired by this, we propose a curriculum pre-training method that includes an elementary course for transcription learning and two advanced courses for understanding the utterance and mapping words in two languages. The difficulty of these <a href=https://en.wikipedia.org/wiki/Course_(education)>courses</a> is gradually increasing. Experiments show that our curriculum pre-training method leads to significant improvements on En-De and En-Fr speech translation benchmarks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.348.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--348 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.348 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928739 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.348" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.348/>Meta-Transfer Learning for Code-Switched Speech Recognition</a></strong><br><a href=/people/g/genta-indra-winata/>Genta Indra Winata</a>
|
<a href=/people/s/samuel-cahyawijaya/>Samuel Cahyawijaya</a>
|
<a href=/people/z/zhaojiang-lin/>Zhaojiang Lin</a>
|
<a href=/people/z/zihan-liu/>Zihan Liu</a>
|
<a href=/people/p/peng-xu/>Peng Xu</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--348><div class="card-body p-3 small">An increasing number of people in the world today speak a <a href=https://en.wikipedia.org/wiki/Mixed_language>mixed-language</a> as a result of being multilingual. However, building a <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition system</a> for <a href=https://en.wikipedia.org/wiki/Code-switching>code-switching</a> remains difficult due to the availability of limited resources and the expense and significant effort required to collect mixed-language data. We therefore propose a new learning method, meta-transfer learning, to transfer learn on a code-switched speech recognition system in a low-resource setting by judiciously extracting information from high-resource monolingual datasets. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> learns to recognize individual languages, and transfer them so as to better recognize mixed-language speech by conditioning the <a href=https://en.wikipedia.org/wiki/Mathematical_optimization>optimization</a> on the code-switching data. Based on experimental results, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms existing <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> on <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition and language modeling tasks</a>, and is faster to converge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.353.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--353 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.353 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928719 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.353/>It Takes Two to Lie : One to Lie, and One to Listen</a></strong><br><a href=/people/d/denis-peskov/>Denis Peskov</a>
|
<a href=/people/b/benny-cheng/>Benny Cheng</a>
|
<a href=/people/a/ahmed-elgohary/>Ahmed Elgohary</a>
|
<a href=/people/j/joe-barrow/>Joe Barrow</a>
|
<a href=/people/c/cristian-danescu-niculescu-mizil/>Cristian Danescu-Niculescu-Mizil</a>
|
<a href=/people/j/jordan-boyd-graber/>Jordan Boyd-Graber</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--353><div class="card-body p-3 small">Trust is implicit in many online text conversationsstriking up new friendships, or asking for tech support. But <a href=https://en.wikipedia.org/wiki/Trust_(social_science)>trust</a> can be betrayed through <a href=https://en.wikipedia.org/wiki/Deception>deception</a>. We study the language and dynamics of <a href=https://en.wikipedia.org/wiki/Deception>deception</a> in the negotiation-based game Diplomacy, where seven players compete for world domination by forging and breaking alliances with each other. Our study with players from the Diplomacy community gathers 17,289 messages annotated by the sender for their intended truthfulness and by the receiver for their perceived truthfulness. Unlike existing datasets, this captures <a href=https://en.wikipedia.org/wiki/Deception>deception</a> in long-lasting relationships, where the interlocutors strategically combine truth with lies to advance objectives. A <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that uses power dynamics and conversational contexts can predict when a lie occurs nearly as well as human players.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.357.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--357 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.357 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929054 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.357/>Pre-training Is (Almost) All You Need : An Application to Commonsense Reasoning</a></strong><br><a href=/people/a/alexandre-tamborrino/>Alexandre Tamborrino</a>
|
<a href=/people/n/nicola-pellicano/>Nicola Pellican</a>
|
<a href=/people/b/baptiste-pannier/>Baptiste Pannier</a>
|
<a href=/people/p/pascal-voitot/>Pascal Voitot</a>
|
<a href=/people/l/louise-naudin/>Louise Naudin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--357><div class="card-body p-3 small">Fine-tuning of pre-trained transformer models has become the standard approach for solving common NLP tasks. Most of the existing approaches rely on a randomly initialized classifier on top of such <a href=https://en.wikipedia.org/wiki/Flow_network>networks</a>. We argue that this fine-tuning procedure is sub-optimal as the pre-trained model has no prior on the specific classifier labels, while it might have already learned an intrinsic textual representation of the task. In this paper, we introduce a new scoring method that casts a plausibility ranking task in a full-text format and leverages the masked language modeling head tuned during the pre-training phase. We study commonsense reasoning tasks where the model must rank a set of hypotheses given a premise, focusing on the COPA, Swag, HellaSwag and CommonsenseQA datasets. By exploiting our scoring method without <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>, we are able to produce strong baselines (e.g. 80 % test accuracy on COPA) that are comparable to supervised approaches. Moreover, when fine-tuning directly on the proposed scoring function, we show that our method provides a much more stable training phase across random restarts (e.g x10 standard deviation reduction on COPA test accuracy) and requires less annotated data than the standard classifier approach to reach equivalent performances.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.360.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--360 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.360 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929399 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.360/>Successfully Applying the Stabilized Lottery Ticket Hypothesis to the Transformer Architecture</a></strong><br><a href=/people/c/christopher-brix/>Christopher Brix</a>
|
<a href=/people/p/parnia-bahar/>Parnia Bahar</a>
|
<a href=/people/h/hermann-ney/>Hermann Ney</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--360><div class="card-body p-3 small">Sparse models require less <a href=https://en.wikipedia.org/wiki/Computer_memory>memory</a> for storage and enable a faster <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a> by reducing the necessary number of FLOPs. This is relevant both for time-critical and on-device computations using <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. The stabilized lottery ticket hypothesis states that networks can be pruned after none or few training iterations, using a <a href=https://en.wikipedia.org/wiki/Mask_(computing)>mask</a> computed based on the unpruned converged model. On the transformer architecture and the WMT 2014 English-to-German and English-to-French tasks, we show that stabilized lottery ticket pruning performs similar to magnitude pruning for sparsity levels of up to 85 %, and propose a new combination of pruning techniques that outperforms all other techniques for even higher levels of sparsity. Furthermore, we confirm that the parameter&#8217;s initial sign and not its specific value is the primary factor for successful training, and show that magnitude pruning can not be used to find winning lottery tickets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.365.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--365 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.365 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929048 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.365" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.365/>Analysing Lexical Semantic Change with Contextualised Word Representations</a></strong><br><a href=/people/m/mario-giulianelli/>Mario Giulianelli</a>
|
<a href=/people/m/marco-del-tredici/>Marco Del Tredici</a>
|
<a href=/people/r/raquel-fernandez/>Raquel Fernndez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--365><div class="card-body p-3 small">This paper presents the first unsupervised approach to lexical semantic change that makes use of contextualised word representations. We propose a novel method that exploits the BERT neural language model to obtain <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations of word usages</a>, clusters these <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> into usage types, and measures change along time with three proposed metrics. We create a new evaluation dataset and show that the model representations and the detected semantic shifts are positively correlated with human judgements. Our extensive qualitative analysis demonstrates that our method captures a variety of synchronic and diachronic linguistic phenomena. We expect our work to inspire further research in this direction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.372.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--372 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.372 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929085 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.372" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.372/>GoEmotions : A Dataset of Fine-Grained Emotions<span class=acl-fixed-case>G</span>o<span class=acl-fixed-case>E</span>motions: A Dataset of Fine-Grained Emotions</a></strong><br><a href=/people/d/dorottya-demszky/>Dorottya Demszky</a>
|
<a href=/people/d/dana-movshovitz-attias/>Dana Movshovitz-Attias</a>
|
<a href=/people/j/jeongwoo-ko/>Jeongwoo Ko</a>
|
<a href=/people/a/alan-cowen/>Alan Cowen</a>
|
<a href=/people/g/gaurav-nemade/>Gaurav Nemade</a>
|
<a href=/people/s/sujith-ravi/>Sujith Ravi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--372><div class="card-body p-3 small">Understanding emotion expressed in language has a wide range of applications, from building empathetic chatbots to detecting harmful online behavior. Advancement in this area can be improved using <a href=https://en.wikipedia.org/wiki/Data_set>large-scale datasets</a> with a fine-grained typology, adaptable to multiple <a href=https://en.wikipedia.org/wiki/Downstream_(networking)>downstream tasks</a>. We introduce GoEmotions, the largest manually annotated dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. We demonstrate the high quality of the <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> via Principal Preserved Component Analysis. We conduct <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> experiments with existing emotion benchmarks to show that our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> generalizes well to other domains and different emotion taxonomies. Our BERT-based model achieves an average F1-score of.46 across our proposed taxonomy, leaving much room for improvement.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.374.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--374 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.374 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929227 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.374" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.374/>SKEP : Sentiment Knowledge Enhanced Pre-training for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a><span class=acl-fixed-case>SKEP</span>: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis</a></strong><br><a href=/people/h/hao-tian/>Hao Tian</a>
|
<a href=/people/c/can-gao/>Can Gao</a>
|
<a href=/people/x/xinyan-xiao/>Xinyan Xiao</a>
|
<a href=/people/h/hao-liu/>Hao Liu</a>
|
<a href=/people/b/bolei-he/>Bolei He</a>
|
<a href=/people/h/hua-wu/>Hua Wu</a>
|
<a href=/people/h/haifeng-wang/>Haifeng Wang</a>
|
<a href=/people/f/feng-wu/>Feng Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--374><div class="card-body p-3 small">Recently, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> has seen remarkable advance with the help of pre-training approaches. However, sentiment knowledge, such as sentiment words and aspect-sentiment pairs, is ignored in the process of pre-training, despite the fact that they are widely used in traditional sentiment analysis approaches. In this paper, we introduce Sentiment Knowledge Enhanced Pre-training (SKEP) in order to learn a unified sentiment representation for multiple sentiment analysis tasks. With the help of automatically-mined knowledge, SKEP conducts sentiment masking and constructs three sentiment knowledge prediction objectives, so as to embed sentiment information at the word, polarity and aspect level into pre-trained sentiment representation. In particular, the prediction of aspect-sentiment pairs is converted into <a href=https://en.wikipedia.org/wiki/Multi-label_classification>multi-label classification</a>, aiming to capture the dependency between words in a pair. Experiments on three kinds of sentiment tasks show that SKEP significantly outperforms strong pre-training baseline, and achieves new state-of-the-art results on most of the test datasets. We release our code at https://github.com/baidu/Senta.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.377.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--377 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.377 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.377.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929406 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.377/>Exact yet Efficient Graph Parsing, Bi-directional Locality and the Constructivist Hypothesis</a></strong><br><a href=/people/y/yajie-ye/>Yajie Ye</a>
|
<a href=/people/w/weiwei-sun/>Weiwei Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--377><div class="card-body p-3 small">A key problem in processing graph-based meaning representations is <a href=https://en.wikipedia.org/wiki/Graph_(abstract_data_type)>graph parsing</a>, i.e. computing all possible derivations of a given <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> according to a (competence) grammar. We demonstrate, for the first time, that exact <a href=https://en.wikipedia.org/wiki/Graph_parsing>graph parsing</a> can be efficient for large graphs and with large Hyperedge Replacement Grammars (HRGs). The advance is achieved by exploiting <a href=https://en.wikipedia.org/wiki/Locality_of_reference>locality</a> as terminal edge-adjacency in HRG rules. In particular, we highlight the importance of 1) a terminal edge-first parsing strategy, 2) a categorization of a subclass of HRG, i.e. what we call Weakly Regular Graph Grammar, and 3) distributing argument-structures to both lexical and phrasal rules.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.379.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--379 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.379 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929031 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.379/>Neural Reranking for Dependency Parsing : An Evaluation</a></strong><br><a href=/people/b/bich-ngoc-do/>Bich-Ngoc Do</a>
|
<a href=/people/i/ines-rehbein/>Ines Rehbein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--379><div class="card-body p-3 small">Recent work has shown that neural rerankers can improve results for dependency parsing over the top k trees produced by a base <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>. However, all neural rerankers so far have been evaluated on <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> only, both languages with a configurational word order and poor morphology. In the paper, we re-assess the potential of successful neural reranking models from the literature on <a href=https://en.wikipedia.org/wiki/English_language>English</a> and on two morphologically rich(er) languages, <a href=https://en.wikipedia.org/wiki/German_language>German</a> and <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a>. In addition, we introduce a new variation of a discriminative reranker based on graph convolutional networks (GCNs). We show that the GCN not only outperforms previous models on <a href=https://en.wikipedia.org/wiki/English_language>English</a> but is the only <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that is able to improve results over the baselines on <a href=https://en.wikipedia.org/wiki/German_language>German</a> and <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a>. We explain the differences in reranking performance based on an analysis of a) the gold tree ratio and b) the variety in the k-best lists.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.384.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--384 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.384 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929145 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.384/>Probing for Referential Information in Language Models</a></strong><br><a href=/people/i/ionut-sorodoc/>Ionut-Teodor Sorodoc</a>
|
<a href=/people/k/kristina-gulordava/>Kristina Gulordava</a>
|
<a href=/people/g/gemma-boleda/>Gemma Boleda</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--384><div class="card-body p-3 small">Language models keep track of complex information about the preceding context including, e.g., <a href=https://en.wikipedia.org/wiki/Syntax>syntactic relations</a> in a sentence. We investigate whether they also capture information beneficial for resolving pronominal anaphora in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We analyze two state of the art models with LSTM and Transformer architectures, via probe tasks and analysis on a coreference annotated corpus. The <a href=https://en.wikipedia.org/wiki/Transformer>Transformer</a> outperforms the LSTM in all analyses. Our results suggest that <a href=https://en.wikipedia.org/wiki/Language>language models</a> are more successful at learning grammatical constraints than they are at learning truly referential information, in the sense of capturing the fact that we use <a href=https://en.wikipedia.org/wiki/Language>language</a> to refer to entities in the world. However, we find traces of the latter aspect, too.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.387.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--387 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.387 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929301 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.387" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.387/>Towards Transparent and Explainable Attention Models</a></strong><br><a href=/people/a/akash-kumar-mohankumar/>Akash Kumar Mohankumar</a>
|
<a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/s/sharan-narasimhan/>Sharan Narasimhan</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/b/balaji-vasan-srinivasan/>Balaji Vasan Srinivasan</a>
|
<a href=/people/b/balaraman-ravindran/>Balaraman Ravindran</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--387><div class="card-body p-3 small">Recent studies on interpretability of <a href=https://en.wikipedia.org/wiki/Attentional_control>attention distributions</a> have led to notions of faithful and plausible explanations for a model&#8217;s predictions. Attention distributions can be considered a faithful explanation if a higher attention weight implies a greater impact on the model&#8217;s prediction. They can be considered a plausible explanation if they provide a human-understandable justification for the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions. In this work, we first explain why current <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanisms</a> in LSTM based encoders can neither provide a faithful nor a plausible explanation of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions. We observe that in LSTM based encoders the hidden representations at different time-steps are very similar to each other (high conicity) and attention weights in these situations do not carry much meaning because even a random permutation of the attention weights does not affect the model&#8217;s predictions. Based on experiments on a wide variety of tasks and datasets, we observe attention distributions often attribute the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions to unimportant words such as <a href=https://en.wikipedia.org/wiki/Punctuation>punctuation</a> and fail to offer a plausible explanation for the predictions. To make attention mechanisms more faithful and plausible, we propose a modified LSTM cell with a diversity-driven training objective that ensures that the hidden representations learned at different time steps are diverse. We show that the resulting attention distributions offer more transparency as they (i) provide a more precise importance ranking of the hidden states (ii) are better indicative of words important for the model&#8217;s predictions (iii) correlate better with gradient-based attribution methods. Human evaluations indicate that the attention distributions learned by our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> offer a plausible explanation of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.388.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--388 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.388 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.388.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928751 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.388/>Tchebycheff Procedure for Multi-task Text Classification</a></strong><br><a href=/people/y/yuren-mao/>Yuren Mao</a>
|
<a href=/people/s/shuang-yun/>Shuang Yun</a>
|
<a href=/people/w/weiwei-liu/>Weiwei Liu</a>
|
<a href=/people/b/bo-du/>Bo Du</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--388><div class="card-body p-3 small">Multi-task Learning methods have achieved great progress in <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a>. However, existing methods assume that multi-task text classification problems are convex multiobjective optimization problems, which is unrealistic in real-world applications. To address this issue, this paper presents a novel Tchebycheff procedure to optimize the multi-task classification problems without convex assumption. The extensive experiments back up our theoretical analysis and validate the superiority of our proposals.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.389.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--389 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.389 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929104 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.389/>Modeling Word Formation in EnglishGerman Neural Machine Translation<span class=acl-fixed-case>E</span>nglish<span class=acl-fixed-case>G</span>erman Neural Machine Translation</a></strong><br><a href=/people/m/marion-weller-di-marco/>Marion Weller-Di Marco</a>
|
<a href=/people/a/alexander-fraser/>Alexander Fraser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--389><div class="card-body p-3 small">This paper studies strategies to model <a href=https://en.wikipedia.org/wiki/Word_formation>word formation</a> in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NMT</a> using rich linguistic information, namely a word segmentation approach that goes beyond splitting into substrings by considering <a href=https://en.wikipedia.org/wiki/Fusional_language>fusional morphology</a>. Our linguistically sound segmentation is combined with a method for target-side inflection to accommodate modeling word formation. The best <a href=https://en.wikipedia.org/wiki/System>system variants</a> employ source-side morphological analysis and model complex target-side words, improving over a standard <a href=https://en.wikipedia.org/wiki/System>system</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.394.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--394 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.394 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929125 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.394/>Joint Modelling of Emotion and Abusive Language Detection</a></strong><br><a href=/people/s/santhosh-rajamanickam/>Santhosh Rajamanickam</a>
|
<a href=/people/p/pushkar-mishra/>Pushkar Mishra</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--394><div class="card-body p-3 small">The rise of online communication platforms has been accompanied by some undesirable effects, such as the proliferation of aggressive and abusive behaviour online. Aiming to tackle this problem, the natural language processing (NLP) community has experimented with a range of techniques for abuse detection. While achieving substantial success, these methods have so far only focused on modelling the linguistic properties of the comments and the online communities of users, disregarding the emotional state of the users and how this might affect their language. The latter is, however, inextricably linked to <a href=https://en.wikipedia.org/wiki/Abusive_power_and_control>abusive behaviour</a>. In this paper, we present the first joint model of emotion and abusive language detection, experimenting in a multi-task learning framework that allows one task to inform the other. Our results demonstrate that incorporating <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>affective features</a> leads to significant improvements in abuse detection performance across datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.399.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--399 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.399 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928990 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.399/>Target Inference in Argument Conclusion Generation</a></strong><br><a href=/people/m/milad-alshomary/>Milad Alshomary</a>
|
<a href=/people/s/shahbaz-syed/>Shahbaz Syed</a>
|
<a href=/people/m/martin-potthast/>Martin Potthast</a>
|
<a href=/people/h/henning-wachsmuth/>Henning Wachsmuth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--399><div class="card-body p-3 small">In <a href=https://en.wikipedia.org/wiki/Argumentation_theory>argumentation</a>, people state premises to reason towards a conclusion. The conclusion conveys a stance towards some target, such as a concept or statement. Often, the conclusion remains implicit, though, since it is self-evident in a discussion or left out for rhetorical reasons. However, the conclusion is key to understanding an <a href=https://en.wikipedia.org/wiki/Argument>argument</a> and, hence, to any application that processes <a href=https://en.wikipedia.org/wiki/Argumentation_theory>argumentation</a>. We thus study the question to what extent an argument&#8217;s conclusion can be reconstructed from its premises. In particular, we argue here that a decisive step is to infer a conclusion&#8217;s target, and we hypothesize that this target is related to the premises&#8217; targets. We develop two complementary target inference approaches : one ranks premise targets and selects the top-ranked target as the conclusion target, the other finds a new conclusion target in a learned embedding space using a triplet neural network. Our evaluation on corpora from two domains indicates that a <a href=https://en.wikipedia.org/wiki/Hybrid_(biology)>hybrid</a> of both approaches is best, outperforming several strong <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baselines</a>. According to human annotators, we infer a reasonably adequate conclusion target in 89 % of the cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--400 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.400 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929440 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.400/>Multimodal Transformer for Multimodal Machine Translation</a></strong><br><a href=/people/s/shaowei-yao/>Shaowei Yao</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--400><div class="card-body p-3 small">Multimodal Machine Translation (MMT) aims to introduce information from other modality, generally static images, to improve the translation quality. Previous works propose various incorporation methods, but most of them do not consider the relative importance of multiple modalities. Equally treating all modalities may encode too much useless information from less important modalities. In this paper, we introduce the multimodal self-attention in Transformer to solve the issues above in MMT. The proposed method learns the representation of images based on the text, which avoids encoding irrelevant information in <a href=https://en.wikipedia.org/wiki/Image>images</a>. Experiments and visualization analysis demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> benefits from <a href=https://en.wikipedia.org/wiki/Visual_system>visual information</a> and substantially outperforms previous works and competitive baselines in terms of various <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.402.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--402 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.402 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929394 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.402/>Towards Emotion-aided Multi-modal Dialogue Act Classification</a></strong><br><a href=/people/t/tulika-saha/>Tulika Saha</a>
|
<a href=/people/a/aditya-patra/>Aditya Patra</a>
|
<a href=/people/s/sriparna-saha/>Sriparna Saha</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--402><div class="card-body p-3 small">The task of Dialogue Act Classification (DAC) that purports to capture communicative intent has been studied extensively. But these studies limit themselves to text. Non-verbal features (change of tone, <a href=https://en.wikipedia.org/wiki/Facial_expression>facial expressions</a> etc.) can provide cues to identify DAs, thus stressing the benefit of incorporating multi-modal inputs in the task. Also, the emotional state of the speaker has a substantial effect on the choice of the dialogue act, since conversations are often influenced by <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a>. Hence, the effect of emotion too on automatic identification of DAs needs to be studied. In this work, we address the role of both multi-modality and emotion recognition (ER) in <a href=https://en.wikipedia.org/wiki/Digital-to-analog_converter>DAC</a>. DAC and ER help each other by way of <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>. One of the major contributions of this work is a new dataset- multimodal Emotion aware Dialogue Act dataset called EMOTyDA, collected from open-sourced dialogue datasets. To demonstrate the utility of EMOTyDA, we build an attention based (self, inter-modal, inter-task) multi-modal, multi-task Deep Neural Network (DNN) for joint learning of DAs and emotions. We show empirically that multi-modality and multi-tasking achieve better performance of <a href=https://en.wikipedia.org/wiki/Digital-to-analog_converter>DAC</a> compared to uni-modal and single task DAC variants.<i>both</i> multi-modality and emotion recognition (ER) in DAC. DAC and ER help each other by way of multi-task learning. One of the major contributions of this work is a new dataset- multimodal Emotion aware Dialogue Act dataset called EMOTyDA, collected from open-sourced dialogue datasets. To demonstrate the utility of EMOTyDA, we build an attention based (self, inter-modal, inter-task) multi-modal, multi-task Deep Neural Network (DNN) for joint learning of DAs and emotions. We show empirically that multi-modality and multi-tasking achieve better performance of DAC compared to uni-modal and single task DAC variants.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.409.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--409 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.409 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929220 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.409" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.409/>Learning to Faithfully Rationalize by Construction<span class=acl-fixed-case>L</span>earning to Faithfully Rationalize by Construction</a></strong><br><a href=/people/s/sarthak-jain/>Sarthak Jain</a>
|
<a href=/people/s/sarah-wiegreffe/>Sarah Wiegreffe</a>
|
<a href=/people/y/yuval-pinter/>Yuval Pinter</a>
|
<a href=/people/b/byron-c-wallace/>Byron C. Wallace</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--409><div class="card-body p-3 small">In many settings it is important for one to be able to understand why a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> made a particular prediction. In <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> this often entails extracting snippets of an input text &#8216;responsible for&#8217; corresponding model output ; when such a snippet comprises tokens that indeed informed the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s prediction, it is a faithful explanation. In some settings, <a href=https://en.wikipedia.org/wiki/Faithfulness>faithfulness</a> may be critical to ensure transparency. Lei et al. (2016) proposed a model to produce faithful rationales for neural text classification by defining independent snippet extraction and prediction modules. However, the discrete selection over input tokens performed by this method complicates training, leading to high variance and requiring careful <a href=https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)>hyperparameter tuning</a>. We propose a simpler variant of this approach that provides faithful explanations by construction. In our scheme, named FRESH, arbitrary feature importance scores (e.g., <a href=https://en.wikipedia.org/wiki/Gradient>gradients</a> from a trained model) are used to induce binary labels over token inputs, which an <a href=https://en.wikipedia.org/wiki/Linear_prediction>extractor</a> can be trained to predict. An independent classifier module is then trained exclusively on snippets provided by the extractor ; these snippets thus constitute faithful explanations, even if the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> is arbitrarily complex. In both automatic and manual evaluations we find that variants of this simple <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> yield predictive performance superior to &#8216;end-to-end&#8217; approaches, while being more general and easier to train. Code is available at https://github.com/successar/FRESH.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.411.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--411 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.411 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929429 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.411" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.411/>DeFormer : Decomposing Pre-trained Transformers for Faster Question Answering<span class=acl-fixed-case>D</span>e<span class=acl-fixed-case>F</span>ormer: Decomposing Pre-trained Transformers for Faster Question Answering</a></strong><br><a href=/people/q/qingqing-cao/>Qingqing Cao</a>
|
<a href=/people/h/harsh-trivedi/>Harsh Trivedi</a>
|
<a href=/people/a/aruna-balasubramanian/>Aruna Balasubramanian</a>
|
<a href=/people/n/niranjan-balasubramanian/>Niranjan Balasubramanian</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--411><div class="card-body p-3 small">Transformer-based QA models use input-wide self-attention i.e. across both the question and the input passage at all layers, causing them to be slow and memory-intensive. It turns out that we can get by without input-wide self-attention at all layers, especially in the lower layers. We introduce DeFormer, a decomposed transformer, which substitutes the full self-attention with question-wide and passage-wide self-attentions in the lower layers. This allows for question-independent processing of the input text representations, which in turn enables pre-computing passage representations reducing runtime compute drastically. Furthermore, because DeFormer is largely similar to the original model, we can initialize DeFormer with the pre-training weights of a standard transformer, and directly fine-tune on the target QA dataset. We show DeFormer versions of <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> and XLNet can be used to speed up <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a> by over 4.3x and with simple distillation-based losses they incur only a 1 % drop in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. We open source the code at https://github.com/StonyBrookNLP/deformer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.412.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--412 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.412 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929421 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.412" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.412/>Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings</a></strong><br><a href=/people/a/apoorv-saxena/>Apoorv Saxena</a>
|
<a href=/people/a/aditay-tripathi/>Aditay Tripathi</a>
|
<a href=/people/p/partha-talukdar/>Partha Talukdar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--412><div class="card-body p-3 small">Knowledge Graphs (KG) are multi-relational graphs consisting of entities as <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>nodes</a> and relations among them as typed edges. Goal of the Question Answering over KG (KGQA) task is to answer natural language queries posed over the KG. Multi-hop KGQA requires reasoning over multiple edges of the KG to arrive at the right answer. KGs are often incomplete with many missing links, posing additional challenges for KGQA, especially for multi-hop KGQA. Recent research on multi-hop KGQA has attempted to handle KG sparsity using relevant external text, which is n&#8217;t always readily available. In a separate line of research, KG embedding methods have been proposed to reduce KG sparsity by performing missing link prediction. Such KG embedding methods, even though highly relevant, have not been explored for multi-hop KGQA so far. We fill this gap in this paper and propose EmbedKGQA. EmbedKGQA is particularly effective in performing multi-hop KGQA over sparse KGs. EmbedKGQA also relaxes the requirement of answer selection from a pre-specified neighborhood, a sub-optimal constraint enforced by previous multi-hop KGQA methods. Through extensive experiments on multiple benchmark datasets, we demonstrate EmbedKGQA&#8217;s effectiveness over other state-of-the-art baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.417.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--417 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.417 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928733 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.417" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.417/>ParaCrawl : Web-Scale Acquisition of Parallel Corpora<span class=acl-fixed-case>P</span>ara<span class=acl-fixed-case>C</span>rawl: Web-Scale Acquisition of Parallel Corpora</a></strong><br><a href=/people/m/marta-banon/>Marta Ban</a>
|
<a href=/people/p/pinzhen-chen/>Pinzhen Chen</a>
|
<a href=/people/b/barry-haddow/>Barry Haddow</a>
|
<a href=/people/k/kenneth-heafield/>Kenneth Heafield</a>
|
<a href=/people/h/hieu-hoang/>Hieu Hoang</a>
|
<a href=/people/m/miquel-espla-gomis/>Miquel Espl-Gomis</a>
|
<a href=/people/m/mikel-l-forcada/>Mikel L. Forcada</a>
|
<a href=/people/a/amir-kamran/>Amir Kamran</a>
|
<a href=/people/f/faheem-kirefu/>Faheem Kirefu</a>
|
<a href=/people/p/philipp-koehn/>Philipp Koehn</a>
|
<a href=/people/s/sergio-ortiz-rojas/>Sergio Ortiz Rojas</a>
|
<a href=/people/l/leopoldo-pla-sempere/>Leopoldo Pla Sempere</a>
|
<a href=/people/g/gema-ramirez-sanchez/>Gema Ramrez-Snchez</a>
|
<a href=/people/e/elsa-sarrias/>Elsa Sarras</a>
|
<a href=/people/m/marek-strelec/>Marek Strelec</a>
|
<a href=/people/b/brian-thompson/>Brian Thompson</a>
|
<a href=/people/w/william-waites/>William Waites</a>
|
<a href=/people/d/dion-wiggins/>Dion Wiggins</a>
|
<a href=/people/j/jaume-zaragoza/>Jaume Zaragoza</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--417><div class="card-body p-3 small">We report on methods to create the largest publicly available parallel corpora by crawling the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a>, using <a href=https://en.wikipedia.org/wiki/Open-source_software>open source software</a>. We empirically compare alternative methods and publish benchmark data sets for sentence alignment and sentence pair filtering. We also describe the parallel corpora released and evaluate their quality and their usefulness to create machine translation systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.418.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--418 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.418 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929030 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.418" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.418/>Toward Gender-Inclusive Coreference Resolution</a></strong><br><a href=/people/y/yang-trista-cao/>Yang Trista Cao</a>
|
<a href=/people/h/hal-daume-iii/>Hal Daum III</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--418><div class="card-body p-3 small">Correctly resolving textual mentions of people fundamentally entails making inferences about those people. Such inferences raise the risk of systemic biases in coreference resolution systems, including biases that can harm binary and non-binary trans and cis stakeholders. To better understand such biases, we foreground nuanced conceptualizations of <a href=https://en.wikipedia.org/wiki/Gender>gender</a> from <a href=https://en.wikipedia.org/wiki/Sociology>sociology</a> and <a href=https://en.wikipedia.org/wiki/Sociolinguistics>sociolinguistics</a>, and develop two new datasets for interrogating bias in crowd annotations and in existing coreference resolution systems. Through these studies, conducted on <a href=https://en.wikipedia.org/wiki/English_language>English text</a>, we confirm that without acknowledging and building systems that recognize the complexity of gender, we build <a href=https://en.wikipedia.org/wiki/System>systems</a> that lead to many potential harms.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.420.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--420 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.420 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928922 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.420" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.420/>Information-Theoretic Probing for Linguistic Structure</a></strong><br><a href=/people/t/tiago-pimentel/>Tiago Pimentel</a>
|
<a href=/people/j/josef-valvoda/>Josef Valvoda</a>
|
<a href=/people/r/rowan-hall-maudslay/>Rowan Hall Maudslay</a>
|
<a href=/people/r/ran-zmigrod/>Ran Zmigrod</a>
|
<a href=/people/a/adina-williams/>Adina Williams</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--420><div class="card-body p-3 small">The success of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> on a diverse set of NLP tasks has led researchers to question how much these <a href=https://en.wikipedia.org/wiki/Neural_network>networks</a> actually know about <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Probes are a natural way of assessing this. When probing, a researcher chooses a <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic task</a> and trains a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised model</a> to predict annotations in that <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic task</a> from the network&#8217;s learned representations. If the probe does well, the researcher may conclude that the <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> encode knowledge related to the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. A commonly held belief is that using simpler <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> as probes is better ; the logic is that simpler models will identify linguistic structure, but not learn the task itself. We propose an information-theoretic operationalization of probing as estimating mutual information that contradicts this received wisdom : one should always select the highest performing probe one can, even if it is more complex, since it will result in a tighter estimate, and thus reveal more of the linguistic information inherent in the representation. The experimental portion of our paper focuses on empirically estimating the <a href=https://en.wikipedia.org/wiki/Mutual_information>mutual information</a> between a linguistic property and BERT, comparing these estimates to several baselines. We evaluate on a set of ten typologically diverse languages often underrepresented in NLP researchplus Englishtotalling eleven languages. Our implementation is available in https://github.com/rycolab/info-theoretic-probing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.422.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--422 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.422 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928932 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.422" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.422/>Similarity Analysis of Contextual Word Representation Models</a></strong><br><a href=/people/j/john-wu/>John Wu</a>
|
<a href=/people/y/yonatan-belinkov/>Yonatan Belinkov</a>
|
<a href=/people/h/hassan-sajjad/>Hassan Sajjad</a>
|
<a href=/people/n/nadir-durrani/>Nadir Durrani</a>
|
<a href=/people/f/fahim-dalvi/>Fahim Dalvi</a>
|
<a href=/people/j/james-glass/>James Glass</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--422><div class="card-body p-3 small">This paper investigates contextual word representation models from the lens of similarity analysis. Given a collection of trained <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a>, we measure the similarity of their <a href=https://en.wikipedia.org/wiki/Internal_representation>internal representations</a> and attention. Critically, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> come from vastly different architectures. We use existing and novel similarity measures that aim to gauge the level of localization of information in the deep models, and facilitate the investigation of which design factors affect model similarity, without requiring any external linguistic annotation. The analysis reveals that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> within the same <a href=https://en.wikipedia.org/wiki/Family_(biology)>family</a> are more similar to one another, as may be expected. Surprisingly, different <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> have rather similar representations, but different individual neurons. We also observed differences in information localization in lower and higher layers and found that higher layers are more affected by <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> on downstream tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.427.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--427 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.427 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.427.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929264 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.427/>CraftAssist Instruction Parsing : Semantic Parsing for a Voxel-World Assistant<span class=acl-fixed-case>C</span>raft<span class=acl-fixed-case>A</span>ssist Instruction Parsing: Semantic Parsing for a Voxel-World Assistant</a></strong><br><a href=/people/k/kavya-srinet/>Kavya Srinet</a>
|
<a href=/people/y/yacine-jernite/>Yacine Jernite</a>
|
<a href=/people/j/jonathan-gray/>Jonathan Gray</a>
|
<a href=/people/a/arthur-szlam/>Arthur Szlam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--427><div class="card-body p-3 small">We propose a semantic parsing dataset focused on instruction-driven communication with an agent in the game Minecraft. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consists of 7 K <a href=https://en.wikipedia.org/wiki/Utterance>human utterances</a> and their corresponding <a href=https://en.wikipedia.org/wiki/Parsing>parses</a>. Given proper <a href=https://en.wikipedia.org/wiki/State_(computer_science)>world state</a>, the <a href=https://en.wikipedia.org/wiki/Parsing>parses</a> can be interpreted and executed in game. We report the performance of <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline models</a>, and analyze their successes and failures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.429.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--429 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.429 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928830 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.429/>How does BERTs attention change when you fine-tune? An analysis methodology and a case study in negation scope<span class=acl-fixed-case>BERT</span>s attention change when you fine-tune? An analysis methodology and a case study in negation scope</a></strong><br><a href=/people/y/yiyun-zhao/>Yiyun Zhao</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--429><div class="card-body p-3 small">Large pretrained language models like BERT, after fine-tuning to a downstream task, have achieved high performance on a variety of NLP problems. Yet explaining their decisions is difficult despite recent work probing their internal representations. We propose a procedure and analysis methods that take a hypothesis of how a transformer-based model might encode a linguistic phenomenon, and test the validity of that hypothesis based on a comparison between knowledge-related downstream tasks with downstream control tasks, and measurement of cross-dataset consistency. We apply this methodology to test BERT and RoBERTa on a hypothesis that some attention heads will consistently attend from a word in negation scope to the negation cue. We find that after fine-tuning BERT and RoBERTa on a <a href=https://en.wikipedia.org/wiki/Negation>negation scope task</a>, the average attention head improves its sensitivity to <a href=https://en.wikipedia.org/wiki/Negation>negation</a> and its attention consistency across <a href=https://en.wikipedia.org/wiki/Negation>negation datasets</a> compared to the pre-trained models. However, only the <a href=https://en.wikipedia.org/wiki/Dependent_and_independent_variables>base models</a> (not the large models) improve compared to a <a href=https://en.wikipedia.org/wiki/Dependent_and_independent_variables>control task</a>, indicating there is evidence for a shallow encoding of negation only in the <a href=https://en.wikipedia.org/wiki/Dependent_and_independent_variables>base models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.439.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--439 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.439 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928972 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.439" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.439/>Pretraining with Contrastive Sentence Objectives Improves <a href=https://en.wikipedia.org/wiki/Discourse>Discourse</a> Performance of Language Models</a></strong><br><a href=/people/d/dan-iter/>Dan Iter</a>
|
<a href=/people/k/kelvin-guu/>Kelvin Guu</a>
|
<a href=/people/l/larry-lansing/>Larry Lansing</a>
|
<a href=/people/d/dan-jurafsky/>Dan Jurafsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--439><div class="card-body p-3 small">Recent models for unsupervised representation learning of text have employed a number of techniques to improve contextual word representations but have put little focus on discourse-level representations. We propose Conpono, an inter-sentence objective for pretraining language models that models discourse coherence and the distance between sentences. Given an anchor sentence, our model is trained to predict the text k sentences away using a sampled-softmax objective where the candidates consist of neighboring sentences and sentences randomly sampled from the corpus. On the discourse representation benchmark DiscoEval, our model improves over the previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> by up to 13 % and on average 4 % absolute across 7 tasks. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is the same size as BERT-Base, but outperforms the much larger BERT-Large model and other more recent approaches that incorporate <a href=https://en.wikipedia.org/wiki/Discourse>discourse</a>. We also show that Conpono yields gains of 2%-6 % absolute even for tasks that do not explicitly evaluate discourse : textual entailment (RTE), common sense reasoning (COPA) and reading comprehension (ReCoRD).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.442.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--442 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.442 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Best Overall Paper"><i class="fas fa-award"></i></span><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929272 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.442" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.442/>Beyond Accuracy : Behavioral Testing of NLP Models with CheckList<span class=acl-fixed-case>NLP</span> Models with <span class=acl-fixed-case>C</span>heck<span class=acl-fixed-case>L</span>ist</a></strong><br><a href=/people/m/marco-tulio-ribeiro/>Marco Tulio Ribeiro</a>
|
<a href=/people/t/tongshuang-wu/>Tongshuang Wu</a>
|
<a href=/people/c/carlos-guestrin/>Carlos Guestrin</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--442><div class="card-body p-3 small">Although measuring held-out accuracy has been the primary approach to evaluate <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a>, it often overestimates the performance of NLP models, while alternative approaches for evaluating <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in <a href=https://en.wikipedia.org/wiki/Software_engineering>software engineering</a>, we introduce <a href=https://en.wikipedia.org/wiki/CheckList>CheckList</a>, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of <a href=https://en.wikipedia.org/wiki/CheckList>CheckList</a> with <a href=https://en.wikipedia.org/wiki/Software_testing>tests</a> for three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, identifying <a href=https://en.wikipedia.org/wiki/Critical_failure>critical failures</a> in both commercial and state-of-art models. In a <a href=https://en.wikipedia.org/wiki/User_study>user study</a>, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. In another user study, NLP practitioners with <a href=https://en.wikipedia.org/wiki/CheckList>CheckList</a> created twice as many tests, and found almost three times as many bugs as users without it.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.446.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--446 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.446 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929100 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.446/>More Diverse Dialogue Datasets via Diversity-Informed Data Collection</a></strong><br><a href=/people/k/katherine-stasaski/>Katherine Stasaski</a>
|
<a href=/people/g/grace-hui-yang/>Grace Hui Yang</a>
|
<a href=/people/m/marti-a-hearst/>Marti A. Hearst</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--446><div class="card-body p-3 small">Automated generation of conversational dialogue using modern neural architectures has made notable advances. However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are known to have a drawback of often producing uninteresting, predictable responses ; this is known as the diversity problem. We introduce a new <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> to address this problem, called Diversity-Informed Data Collection. Unlike prior approaches, which modify model architectures to solve the problem, this method uses dynamically computed corpus-level statistics to determine which conversational participants to collect data from. Diversity-Informed Data Collection produces significantly more diverse data than baseline data collection methods, and better results on two downstream tasks : <a href=https://en.wikipedia.org/wiki/Emotion_classification>emotion classification</a> and dialogue generation. This method is generalizable and can be used with other corpus-level metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.447.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--447 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.447 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929131 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.447" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.447/>S2ORC : The Semantic Scholar Open Research Corpus<span class=acl-fixed-case>S</span>2<span class=acl-fixed-case>ORC</span>: The Semantic Scholar Open Research Corpus</a></strong><br><a href=/people/k/kyle-lo/>Kyle Lo</a>
|
<a href=/people/l/lucy-lu-wang/>Lucy Lu Wang</a>
|
<a href=/people/m/mark-neumann/>Mark Neumann</a>
|
<a href=/people/r/rodney-kinney/>Rodney Kinney</a>
|
<a href=/people/d/daniel-s-weld/>Daniel Weld</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--447><div class="card-body p-3 small">We introduce S2ORC, a large corpus of 81.1 M English-language academic papers spanning many academic disciplines. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> consists of <a href=https://en.wikipedia.org/wiki/Metadata>rich metadata</a>, <a href=https://en.wikipedia.org/wiki/Abstract_(summary)>paper abstracts</a>, resolved bibliographic references, as well as <a href=https://en.wikipedia.org/wiki/Structured_text>structured full text</a> for 8.1 M open access papers. Full text is annotated with automatically-detected inline mentions of <a href=https://en.wikipedia.org/wiki/Citation>citations</a>, figures, and tables, each linked to their corresponding paper objects. In S2ORC, we aggregate papers from hundreds of academic publishers and digital archives into a unified source, and create the largest publicly-available collection of machine-readable academic text to date. We hope this resource will facilitate research and development of tools and tasks for <a href=https://en.wikipedia.org/wiki/Text_mining>text mining</a> over <a href=https://en.wikipedia.org/wiki/Academic_publishing>academic text</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.449.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--449 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.449 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929076 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.449" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.449/>A Transformer-based Approach for Source Code Summarization</a></strong><br><a href=/people/w/wasi-ahmad/>Wasi Ahmad</a>
|
<a href=/people/s/saikat-chakraborty/>Saikat Chakraborty</a>
|
<a href=/people/b/baishakhi-ray/>Baishakhi Ray</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--449><div class="card-body p-3 small">Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens&#8217; position hinders, while relative encoding significantly improves the <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> performance. We have made our code publicly available to facilitate future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.452.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--452 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.452 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.452.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929184 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.452" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.452/>Discrete Optimization for Unsupervised Sentence Summarization with Word-Level Extraction</a></strong><br><a href=/people/r/raphael-schumann/>Raphael Schumann</a>
|
<a href=/people/l/lili-mou/>Lili Mou</a>
|
<a href=/people/y/yao-lu/>Yao Lu</a>
|
<a href=/people/o/olga-vechtomova/>Olga Vechtomova</a>
|
<a href=/people/k/katja-markert/>Katja Markert</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--452><div class="card-body p-3 small">Automatic sentence summarization produces a shorter version of a sentence, while preserving its most important information. A good summary is characterized by <a href=https://en.wikipedia.org/wiki/Fluency>language fluency</a> and high information overlap with the source sentence. We model these two aspects in an unsupervised objective function, consisting of <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> and semantic similarity metrics. We search for a high-scoring summary by <a href=https://en.wikipedia.org/wiki/Discrete_optimization>discrete optimization</a>. Our proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> achieves a new state-of-the art for unsupervised sentence summarization according to ROUGE scores. Additionally, we demonstrate that the commonly reported ROUGE F1 metric is sensitive to summary length. Since this is unwillingly exploited in recent work, we emphasize that future evaluation should explicitly group summarization systems by output length brackets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.454.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--454 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.454 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929353 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.454" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.454/>FEQA : A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization<span class=acl-fixed-case>FEQA</span>: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization</a></strong><br><a href=/people/e/esin-durmus/>Esin Durmus</a>
|
<a href=/people/h/he-he/>He He</a>
|
<a href=/people/m/mona-diab/>Mona Diab</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--454><div class="card-body p-3 small">Neural abstractive summarization models are prone to generate content inconsistent with the source document, i.e. unfaithful. Existing <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automatic metrics</a> do not capture such mistakes effectively. We tackle the problem of evaluating faithfulness of a generated summary given its source document. We first collected human annotations of faithfulness for outputs from numerous <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on two datasets. We find that current models exhibit a trade-off between <a href=https://en.wikipedia.org/wiki/Abstraction>abstractiveness</a> and <a href=https://en.wikipedia.org/wiki/Faithfulness>faithfulness</a> : outputs with less word overlap with the source document are more likely to be unfaithful. Next, we propose an automatic question answering (QA) based metric for <a href=https://en.wikipedia.org/wiki/Faithfulness>faithfulness</a>, FEQA, which leverages recent advances in <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>. Given question-answer pairs generated from the summary, a QA model extracts answers from the document ; non-matched answers indicate unfaithful information in the summary. Among metrics based on word overlap, embedding similarity, and learned language understanding models, our QA-based metric has significantly higher correlation with human faithfulness scores, especially on highly abstractive summaries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.461.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--461 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.461 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928963 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.461" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.461/>Unsupervised Opinion Summarization as Copycat-Review Generation</a></strong><br><a href=/people/a/arthur-brazinskas/>Arthur Brainskas</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--461><div class="card-body p-3 small">Opinion summarization is the task of automatically creating summaries that reflect <a href=https://en.wikipedia.org/wiki/Subjectivity>subjective information</a> expressed in multiple documents, such as <a href=https://en.wikipedia.org/wiki/Review>product reviews</a>. While the majority of previous work has focused on the extractive setting, i.e., selecting fragments from input reviews to produce a summary, we let the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> generate novel sentences and hence produce abstractive summaries. Recent progress in <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> has seen the development of <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> which rely on large quantities of <a href=https://en.wikipedia.org/wiki/Abstract_(summary)>document-summary pairs</a>. Since such training data is expensive to acquire, we instead consider the <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised setting</a>, in other words, we do not use any summaries in training. We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the amount of novelty going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, when generating summaries, we force the <a href=https://en.wikipedia.org/wiki/Novelty_(patent)>novelty</a> to be minimal, and produce a text reflecting consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder model. Both individual reviews and the products they correspond to are associated with stochastic latent codes, and the review generator (decoder) has direct access to the text of input reviews through the pointer-generator mechanism. Experiments on Amazon and Yelp datasets, show that setting at test time the review&#8217;s latent code to its mean, allows the model to produce fluent and coherent summaries reflecting common opinions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.464.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--464 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.464 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929236 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.464/>Examining Citations of Natural Language Processing Literature</a></strong><br><a href=/people/s/saif-mohammad/>Saif M. Mohammad</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--464><div class="card-body p-3 small">We extracted information from the ACL Anthology (AA) and Google Scholar (GS) to examine trends in citations of NLP papers. We explore questions such as : how well cited are papers of different types (journal articles, <a href=https://en.wikipedia.org/wiki/Academic_conference>conference papers</a>, <a href=https://en.wikipedia.org/wiki/Demoscene>demo papers</a>, etc.)? how well cited are papers from different areas of within <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>? etc. Notably, we show that only about 56 % of the papers in <a href=https://en.wikipedia.org/wiki/American_Association_for_the_Advancement_of_Science>AA</a> are cited ten or more times. CL Journal has the most cited papers, but its citation dominance has lessened in recent years. On average, long papers get almost three times as many citations as short papers ; and papers on sentiment classification, <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora resolution</a>, and entity recognition have the highest median citations. The analyses presented here, and the associated <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of NLP papers mapped to <a href=https://en.wikipedia.org/wiki/Citation>citations</a>, have a number of uses including : understanding how the field is growing and quantifying the impact of different types of papers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.465.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--465 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.465 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Honorable Mention for Best Theme Paper"><i class="fas fa-award"></i></span><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929098 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.465/>How Can We Accelerate Progress Towards Human-like Linguistic Generalization?</a></strong><br><a href=/people/t/tal-linzen/>Tal Linzen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--465><div class="card-body p-3 small">This position paper describes and critiques the Pretraining-Agnostic Identically Distributed (PAID) evaluation paradigm, which has become a central tool for measuring progress in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. This paradigm consists of three stages : (1) pre-training of a word prediction model on a corpus of arbitrary size ; (2) fine-tuning (transfer learning) on a training set representing a classification task ; (3) evaluation on a test set drawn from the same distribution as that training set. This paradigm favors simple, low-bias architectures, which, first, can be scaled to process vast amounts of data, and second, can capture the fine-grained statistical properties of a particular data set, regardless of whether those properties are likely to generalize to examples of the task outside the data set. This contrasts with <a href=https://en.wikipedia.org/wiki/Human>humans</a>, who learn language from several orders of magnitude less data than the <a href=https://en.wikipedia.org/wiki/System>systems</a> favored by this evaluation paradigm, and generalize to new tasks in a consistent way. We advocate for supplementing or replacing PAID with <a href=https://en.wikipedia.org/wiki/Paradigm>paradigms</a> that reward architectures that generalize as quickly and robustly as humans.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.470.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--470 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.470 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928806 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.470/>Balancing Objectives in Counseling Conversations : Advancing Forwards or Looking Backwards</a></strong><br><a href=/people/j/justine-zhang/>Justine Zhang</a>
|
<a href=/people/c/cristian-danescu-niculescu-mizil/>Cristian Danescu-Niculescu-Mizil</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--470><div class="card-body p-3 small">Throughout a conversation, participants make choices that can orient the flow of the interaction. Such choices are particularly salient in the consequential domain of crisis counseling, where a difficulty for counselors is balancing between two key objectives : advancing the conversation towards a resolution, and empathetically addressing the crisis situation. In this work, we develop an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methodology</a> to quantify how counselors manage this balance. Our main intuition is that if an utterance can only receive a narrow range of appropriate replies, then its likely aim is to advance the conversation forwards, towards a target within that range. Likewise, an utterance that can only appropriately follow a narrow range of possible utterances is likely aimed backwards at addressing a specific situation within that range. By applying this intuition, we can map each utterance to a continuous orientation axis that captures the degree to which it is intended to direct the flow of the conversation forwards or backwards. This unsupervised method allows us to characterize counselor behaviors in a large dataset of crisis counseling conversations, where we show that known counseling strategies intuitively align with this axis. We also illustrate how our <a href=https://en.wikipedia.org/wiki/Measurement>measure</a> can be indicative of a conversation&#8217;s progress, as well as its effectiveness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.471.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--471 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.471 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929226 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.471" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.471/>Detecting Perceived Emotions in Hurricane Disasters</a></strong><br><a href=/people/s/shrey-desai/>Shrey Desai</a>
|
<a href=/people/c/cornelia-caragea/>Cornelia Caragea</a>
|
<a href=/people/j/junyi-jessy-li/>Junyi Jessy Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--471><div class="card-body p-3 small">Natural disasters (e.g., hurricanes) affect millions of people each year, causing widespread destruction in their wake. People have recently taken to social media websites (e.g., <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>) to share their sentiments and feelings with the larger community. Consequently, these <a href=https://en.wikipedia.org/wiki/Computing_platform>platforms</a> have become instrumental in understanding and perceiving emotions at scale. In this paper, we introduce HurricaneEmo, an emotion dataset of 15,000 English tweets spanning three hurricanes : <a href=https://en.wikipedia.org/wiki/Hurricane_Harvey>Harvey</a>, <a href=https://en.wikipedia.org/wiki/Hurricane_Irma>Irma</a>, and <a href=https://en.wikipedia.org/wiki/Hurricane_Maria>Maria</a>. We present a comprehensive study of fine-grained emotions and propose classification tasks to discriminate between coarse-grained emotion groups. Our best BERT model, even after task-guided pre-training which leverages unlabeled Twitter data, achieves only 68 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> (averaged across all groups). HurricaneEmo serves not only as a challenging benchmark for <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a> but also as a valuable resource for analyzing <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> in disaster-centric domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.473.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--473 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.473 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929057 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.473" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.473/>Measuring Forecasting Skill from Text</a></strong><br><a href=/people/s/shi-zong/>Shi Zong</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--473><div class="card-body p-3 small">People vary in their ability to make accurate predictions about the future. Prior studies have shown that some individuals can predict the outcome of future events with consistently better <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. This leads to a natural question : what makes some forecasters better than others? In this paper we explore connections between the language people use to describe their predictions and their forecasting skill. Datasets from two different forecasting domains are explored : (1) geopolitical forecasts from Good Judgment Open, an online prediction forum and (2) a corpus of company earnings forecasts made by financial analysts. We present a number of linguistic metrics which are computed over text associated with people&#8217;s predictions about the future including : <a href=https://en.wikipedia.org/wiki/Uncertainty>uncertainty</a>, <a href=https://en.wikipedia.org/wiki/Readability>readability</a>, and <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a>. By studying <a href=https://en.wikipedia.org/wiki/Linguistics>linguistic factors</a> associated with predictions, we are able to shed some light on the approach taken by skilled forecasters. Furthermore, we demonstrate that it is possible to accurately predict forecasting skill using a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that is based solely on <a href=https://en.wikipedia.org/wiki/Language>language</a>. This could potentially be useful for identifying accurate predictions or potentially skilled forecasters earlier.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.475.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--475 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.475 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929238 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.475" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.475/>Text-Based Ideal Points</a></strong><br><a href=/people/k/keyon-vafa/>Keyon Vafa</a>
|
<a href=/people/s/suresh-naidu/>Suresh Naidu</a>
|
<a href=/people/d/david-blei/>David Blei</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--475><div class="card-body p-3 small">Ideal point models analyze lawmakers&#8217; votes to quantify their <a href=https://en.wikipedia.org/wiki/Political_party>political positions</a>, or ideal points. But <a href=https://en.wikipedia.org/wiki/Voting>votes</a> are not the only way to express a political position. Lawmakers also give speeches, release press statements, and post tweets. In this paper, we introduce the text-based ideal point model (TBIP), an unsupervised probabilistic topic model that analyzes texts to quantify the political positions of its authors. We demonstrate the TBIP with two types of politicized text data : <a href=https://en.wikipedia.org/wiki/United_States_Senate>U.S. Senate speeches</a> and <a href=https://en.wikipedia.org/wiki/United_States_Senate>senator tweets</a>. Though the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> does not analyze their votes or political affiliations, the TBIP separates lawmakers by party, learns interpretable politicized topics, and infers ideal points close to the classical vote-based ideal points. One benefit of analyzing texts, as opposed to votes, is that the TBIP can estimate ideal points of anyone who authors political texts, including non-voting actors. To this end, we use <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> to study tweets from the 2020 Democratic presidential candidates. Using only the texts of their tweets, it identifies them along an interpretable progressive-to-moderate spectrum.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.478.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--478 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.478 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.478.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928770 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.478/>Discourse as a Function of Event : Profiling Discourse Structure in News Articles around the Main Event</a></strong><br><a href=/people/p/prafulla-kumar-choubey/>Prafulla Kumar Choubey</a>
|
<a href=/people/a/aaron-lee/>Aaron Lee</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--478><div class="card-body p-3 small">Understanding discourse structures of <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> is vital to effectively contextualize the occurrence of a news event. To enable computational modeling of news structures, we apply an existing theory of functional discourse structure for news articles that revolves around the main event and create a human-annotated corpus of 802 documents spanning over four domains and three media sources. Next, we propose several document-level neural-network models to automatically construct news content structures. Finally, we demonstrate that incorporating system predicted news structures yields new state-of-the-art performance for event coreference resolution. The news documents we annotated are openly available and the annotations are publicly released for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.480.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--480 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.480 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929324 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.480/>Implicit Discourse Relation Classification : We Need to Talk about Evaluation</a></strong><br><a href=/people/n/najoung-kim/>Najoung Kim</a>
|
<a href=/people/s/song-feng/>Song Feng</a>
|
<a href=/people/c/chulaka-gunasekara/>Chulaka Gunasekara</a>
|
<a href=/people/l/luis-lastras/>Luis Lastras</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--480><div class="card-body p-3 small">Implicit relation classification on Penn Discourse TreeBank (PDTB) 2.0 is a common benchmark task for evaluating the understanding of discourse relations. However, the lack of consistency in preprocessing and <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> poses challenges to fair comparison of results in the literature. In this work, we highlight these inconsistencies and propose an improved evaluation protocol. Paired with this <a href=https://en.wikipedia.org/wiki/Communication_protocol>protocol</a>, we report strong baseline results from pretrained sentence encoders, which set the new state-of-the-art for PDTB 2.0. Furthermore, this work is the first to explore fine-grained relation classification on PDTB 3.0. We expect our work to serve as a point of comparison for future work, and also as an initiative to discuss models of larger context and possible data augmentations for downstream transferability.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.482.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--482 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.482 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928741 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.482/>ZPR2 : Joint Zero Pronoun Recovery and Resolution using Multi-Task Learning and BERT<span class=acl-fixed-case>ZPR</span>2: Joint Zero Pronoun Recovery and Resolution using Multi-Task Learning and <span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/l/linfeng-song/>Linfeng Song</a>
|
<a href=/people/k/kun-xu/>Kun Xu</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/j/jianshu-chen/>Jianshu Chen</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--482><div class="card-body p-3 small">Zero pronoun recovery and resolution aim at recovering the dropped pronoun and pointing out its <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphoric mentions</a>, respectively. We propose to better explore their interaction by solving both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> together, while the previous work treats them separately. For zero pronoun resolution, we study this task in a more realistic setting, where no <a href=https://en.wikipedia.org/wiki/Parsing_tree>parsing trees</a> or only <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>automatic trees</a> are available, while most previous work assumes gold trees. Experiments on two <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmarks</a> show that joint modeling significantly outperforms our <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> that already beats the previous state of the arts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.484.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--484 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.484 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929050 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.484" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.484/>Double-Hard Debias : Tailoring Word Embeddings for Gender Bias Mitigation</a></strong><br><a href=/people/t/tianlu-wang/>Tianlu Wang</a>
|
<a href=/people/x/xi-victoria-lin/>Xi Victoria Lin</a>
|
<a href=/people/n/nazneen-fatema-rajani/>Nazneen Fatema Rajani</a>
|
<a href=/people/b/bryan-mccann/>Bryan McCann</a>
|
<a href=/people/v/vicente-ordonez/>Vicente Ordonez</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--484><div class="card-body p-3 small">Word embeddings derived from human-generated corpora inherit strong gender bias which can be further amplified by downstream models. Some commonly adopted debiasing approaches, including the seminal Hard Debias algorithm, apply post-processing procedures that project pre-trained word embeddings into a subspace orthogonal to an inferred gender subspace. We discover that semantic-agnostic corpus regularities such as <a href=https://en.wikipedia.org/wiki/Word_frequency>word frequency</a> captured by the <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> negatively impact the performance of these algorithms. We propose a simple but effective technique, Double Hard Debias, which purifies the word embeddings against such corpus regularities prior to inferring and removing the gender subspace. Experiments on three bias mitigation benchmarks show that our approach preserves the distributional semantics of the pre-trained word embeddings while reducing gender bias to a significantly larger degree than prior approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.486.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--486 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.486 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.486.Dataset.tgz data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928840 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.486/>Social Bias Frames : Reasoning about Social and Power Implications of Language</a></strong><br><a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/s/saadia-gabriel/>Saadia Gabriel</a>
|
<a href=/people/l/lianhui-qin/>Lianhui Qin</a>
|
<a href=/people/d/dan-jurafsky/>Dan Jurafsky</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--486><div class="card-body p-3 small">Warning : this paper contains content that may be offensive or upsetting. Language has the power to reinforce <a href=https://en.wikipedia.org/wiki/Stereotype>stereotypes</a> and project <a href=https://en.wikipedia.org/wiki/Bias>social biases</a> onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people&#8217;s judgments about others. For example, given a statement that we should n&#8217;t lower our standards to hire more women, most listeners will infer the implicature intended by the speaker-that women (candidates) are less qualified. Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce Social Bias Frames, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover Social Bias Frames from <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured text</a>. We find that while state-of-the-art neural models are effective at high-level categorization of whether a given statement projects unwanted social bias (80 % F1), they are not effective at spelling out more detailed explanations in terms of Social Bias Frames. Our study motivates future work that combines structured pragmatic inference with <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a> on social implications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.489.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--489 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.489 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929034 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.489" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.489/>A Re-evaluation of Knowledge Graph Completion Methods</a></strong><br><a href=/people/z/zhiqing-sun/>Zhiqing Sun</a>
|
<a href=/people/s/shikhar-vashishth/>Shikhar Vashishth</a>
|
<a href=/people/s/soumya-sanyal/>Soumya Sanyal</a>
|
<a href=/people/p/partha-talukdar/>Partha Talukdar</a>
|
<a href=/people/y/yiming-yang/>Yiming Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--489><div class="card-body p-3 small">Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including <a href=https://en.wikipedia.org/wiki/Data_mining>data mining</a>, <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a>, and <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed <a href=https://en.wikipedia.org/wiki/Communication_protocol>protocol</a> is robust to handle bias in the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, which can substantially affect the final results. We conduct extensive experiments and report performance of several existing <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> using our <a href=https://en.wikipedia.org/wiki/Protocol_(science)>protocol</a>. The reproducible code has been made publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.491.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--491 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.491 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929036 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.491" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.491/>Evaluating Explainable AI : Which Algorithmic Explanations Help Users Predict Model Behavior?<span class=acl-fixed-case>AI</span>: Which Algorithmic Explanations Help Users Predict Model Behavior?</a></strong><br><a href=/people/p/peter-hase/>Peter Hase</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--491><div class="card-body p-3 small">Algorithmic approaches to interpreting machine learning models have proliferated in recent years. We carry out human subject tests that are the first of their kind to isolate the effect of algorithmic explanations on a key aspect of model interpretability, simulatability, while avoiding important confounding experimental factors. A <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is simulatable when a person can predict its behavior on new inputs. Through two kinds of simulation tests involving text and tabular data, we evaluate five explanations methods : (1) LIME, (2) Anchor, (3) Decision Boundary, (4) a Prototype model, and (5) a Composite approach that combines explanations from each method. Clear evidence of method effectiveness is found in very few cases : LIME improves simulatability in tabular classification, and our Prototype method is effective in counterfactual simulation tests. We also collect subjective ratings of explanations, but we do not find that ratings are predictive of how helpful explanations are. Our results provide the first reliable and comprehensive estimates of how <a href=https://en.wikipedia.org/wiki/Explanation>explanations</a> influence simulatability across a variety of explanation methods and <a href=https://en.wikipedia.org/wiki/Data_domain>data domains</a>. We show that (1) we need to be careful about the metrics we use to evaluate explanation methods, and (2) there is significant room for improvement in current <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.492.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--492 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.492 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929233 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.492" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.492/>Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions</a></strong><br><a href=/people/x/xiaochuang-han/>Xiaochuang Han</a>
|
<a href=/people/b/byron-c-wallace/>Byron C. Wallace</a>
|
<a href=/people/y/yulia-tsvetkov/>Yulia Tsvetkov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--492><div class="card-body p-3 small">Modern deep learning models for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> are notoriously opaque. This has motivated the development of methods for interpreting such <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>, e.g., via gradient-based saliency maps or the visualization of attention weights. Such approaches aim to provide explanations for a particular model prediction by highlighting important words in the corresponding input text. While this might be useful for tasks where decisions are explicitly influenced by individual tokens in the input, we suspect that such highlighting is not suitable for tasks where model decisions should be driven by more complex reasoning. In this work, we investigate the use of influence functions for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, providing an alternative approach to interpreting neural text classifiers. Influence functions explain the decisions of a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> by identifying influential training examples. Despite the promise of this approach, influence functions have not yet been extensively evaluated in the context of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, a gap addressed by this work. We conduct a comparison between <a href=https://en.wikipedia.org/wiki/Influence_function>influence functions</a> and common word-saliency methods on representative tasks. As suspected, we find that influence functions are particularly useful for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language inference</a>, a task in which &#8216;saliency maps&#8217; may not have clear interpretation. Furthermore, we develop a new quantitative measure based on <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>influence functions</a> that can reveal artifacts in training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.493.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--493 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.493 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929418 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.493" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.493/>Finding <a href=https://en.wikipedia.org/wiki/Universal_grammar>Universal Grammatical Relations</a> in Multilingual BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/e/ethan-a-chi/>Ethan A. Chi</a>
|
<a href=/people/j/john-hewitt/>John Hewitt</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--493><div class="card-body p-3 small">Recent work has found evidence that Multilingual BERT (mBERT), a transformer-based multilingual masked language model, is capable of zero-shot cross-lingual transfer, suggesting that some aspects of its representations are shared cross-lingually. To better understand this overlap, we extend recent work on finding syntactic trees in neural networks&#8217; internal representations to the multilingual setting. We show that subspaces of mBERT representations recover syntactic tree distances in languages other than English, and that these <a href=https://en.wikipedia.org/wiki/Linear_subspace>subspaces</a> are approximately shared across languages. Motivated by these results, we present an unsupervised analysis method that provides evidence mBERT learns representations of syntactic dependency labels, in the form of clusters which largely agree with the Universal Dependencies taxonomy. This evidence suggests that even without explicit <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a>, multilingual masked language models learn certain <a href=https://en.wikipedia.org/wiki/Linguistic_universal>linguistic universals</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.496.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--496 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.496 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.496.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929403 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.496" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.496/>Rationalizing Text Matching : Learning Sparse Alignments via Optimal Transport<span class=acl-fixed-case>L</span>earning Sparse Alignments via Optimal Transport</a></strong><br><a href=/people/k/kyle-swanson/>Kyle Swanson</a>
|
<a href=/people/l/lili-yu/>Lili Yu</a>
|
<a href=/people/t/tao-lei/>Tao Lei</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--496><div class="card-body p-3 small">Selecting input <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> of top relevance has become a popular method for building self-explaining models. In this work, we extend this selective rationalization approach to text matching, where the goal is to jointly select and align text pieces, such as tokens or sentences, as a justification for the downstream prediction. Our approach employs optimal transport (OT) to find a minimal cost alignment between the inputs. However, directly applying OT often produces dense and therefore uninterpretable alignments. To overcome this limitation, we introduce novel constrained variants of the OT problem that result in highly sparse alignments with controllable sparsity. Our model is end-to-end differentiable using the Sinkhorn algorithm for OT and can be trained without any alignment annotations. We evaluate our model on the <a href=https://en.wikipedia.org/wiki/StackExchange>StackExchange</a>, MultiNews, e-SNLI, and MultiRC datasets. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves very sparse rationale selections with high fidelity while preserving prediction accuracy compared to strong attention baseline models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.500.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--500 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.500 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929093 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.500/>On the Importance of Diversity in Question Generation for QA<span class=acl-fixed-case>QA</span></a></strong><br><a href=/people/m/md-arafat-sultan/>Md Arafat Sultan</a>
|
<a href=/people/s/shubham-chandel/>Shubham Chandel</a>
|
<a href=/people/r/ramon-fernandez-astudillo/>Ramn Fernandez Astudillo</a>
|
<a href=/people/v/vittorio-castelli/>Vittorio Castelli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--500><div class="card-body p-3 small">Automatic question generation (QG) has shown promise as a source of <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>synthetic training data</a> for question answering (QA). In this paper we ask : Is textual diversity in QG beneficial for downstream QA? Using top-p nucleus sampling to derive samples from a transformer-based question generator, we show that diversity-promoting QG indeed provides better QA training than likelihood maximization approaches such as <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a>. We also show that standard QG evaluation metrics such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, ROUGE and <a href=https://en.wikipedia.org/wiki/METEOR>METEOR</a> are inversely correlated with diversity, and propose a diversity-aware intrinsic measure of overall QG quality that correlates well with extrinsic evaluation on <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.503.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--503 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.503 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929409 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.503" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.503/>Selective Question Answering under Domain Shift</a></strong><br><a href=/people/a/amita-kamath/>Amita Kamath</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--503><div class="card-body p-3 small">To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>&#8217;s training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model&#8217;s softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a <a href=https://en.wikipedia.org/wiki/Calibration>calibrator</a> to identify inputs on which the <a href=https://en.wikipedia.org/wiki/Quantitative_analysis_(finance)>QA model</a> errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuAD-trained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56 % of questions while maintaining 80 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> ; in contrast, directly using the model&#8217;s probabilities only answers 48 % at 80 % accuracy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.504.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--504 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.504 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929221 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.504" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.504/>The Cascade Transformer : an Application for Efficient Answer Sentence Selection</a></strong><br><a href=/people/l/luca-soldaini/>Luca Soldaini</a>
|
<a href=/people/a/alessandro-moschitti/>Alessandro Moschitti</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--504><div class="card-body p-3 small">Large transformer-based language models have been shown to be very effective in many <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification tasks</a>. However, their <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>computational complexity</a> prevents their use in applications requiring the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> of a large set of candidates. While previous works have investigated approaches to reduce model size, relatively little attention has been paid to techniques to improve <a href=https://en.wikipedia.org/wiki/Batch_processing>batch throughput</a> during <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a>. In this paper, we introduce the Cascade Transformer, a simple yet effective technique to adapt transformer-based models into a cascade of rankers. Each <a href=https://en.wikipedia.org/wiki/Ranker>ranker</a> is used to prune a subset of candidates in a batch, thus dramatically increasing <a href=https://en.wikipedia.org/wiki/Throughput>throughput</a> at <a href=https://en.wikipedia.org/wiki/Time_complexity>inference time</a>. Partial encodings from the transformer model are shared among <a href=https://en.wikipedia.org/wiki/Rank_(linear_algebra)>rerankers</a>, providing further speed-up. When compared to a state-of-the-art transformer model, our approach reduces <a href=https://en.wikipedia.org/wiki/Computation>computation</a> by 37 % with almost no impact on <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, as measured on two English Question Answering datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.507.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--507 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.507 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928901 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.507" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.507/>STARC : Structured Annotations for Reading Comprehension<span class=acl-fixed-case>STARC</span>: Structured Annotations for Reading Comprehension</a></strong><br><a href=/people/y/yevgeni-berzak/>Yevgeni Berzak</a>
|
<a href=/people/j/jonathan-malmaud/>Jonathan Malmaud</a>
|
<a href=/people/r/roger-levy/>Roger Levy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--507><div class="card-body p-3 small">We present STARC (Structured Annotations for Reading Comprehension), a new annotation framework for assessing reading comprehension with multiple choice questions. Our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> introduces a principled structure for the answer choices and ties them to textual span annotations. The <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is implemented in OneStopQA, a new high-quality dataset for evaluation and analysis of reading comprehension in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We use this dataset to demonstrate that STARC can be leveraged for a key new application for the development of SAT-like reading comprehension materials : automatic annotation quality probing via span ablation experiments. We further show that it enables in-depth analyses and comparisons between machine and human reading comprehension behavior, including error distributions and guessing ability. Our experiments also reveal that the standard multiple choice dataset in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, RACE, is limited in its ability to measure <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>. 47 % of its questions can be guessed by machines without accessing the passage, and 18 % are unanimously judged by humans as not having a unique correct answer. OneStopQA provides an alternative <a href=https://en.wikipedia.org/wiki/Test_(assessment)>test set</a> for <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> which alleviates these shortcomings and has a substantially higher human ceiling performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.514.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--514 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.514 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929338 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.514/>A Comprehensive Analysis of Preprocessing for Word Representation Learning in Affective Tasks</a></strong><br><a href=/people/n/nastaran-babanejad/>Nastaran Babanejad</a>
|
<a href=/people/a/ameeta-agrawal/>Ameeta Agrawal</a>
|
<a href=/people/a/aijun-an/>Aijun An</a>
|
<a href=/people/m/manos-papagelis/>Manos Papagelis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--514><div class="card-body p-3 small">Affective tasks such as <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, <a href=https://en.wikipedia.org/wiki/Emotion_classification>emotion classification</a>, and sarcasm detection have been popular in recent years due to an abundance of user-generated data, accurate computational linguistic models, and a broad range of relevant applications in various domains. At the same time, many studies have highlighted the importance of text preprocessing, as an integral step to any natural language processing prediction model and downstream task. While <a href=https://en.wikipedia.org/wiki/Preprocessing>preprocessing</a> in <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective systems</a> is well-studied, preprocessing in word vector-based models applied to <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective systems</a>, is not. To address this limitation, we conduct a comprehensive analysis of the role of preprocessing techniques in affective analysis based on word vector models. Our analysis is the first of its kind and provides useful insights of the importance of each preprocessing technique when applied at the training phase, commonly ignored in pretrained word vector models, and/or at the downstream task phase.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.515.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--515 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.515 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928749 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.515/>Diverse and Informative Dialogue Generation with Context-Specific Commonsense Knowledge Awareness</a></strong><br><a href=/people/s/sixing-wu/>Sixing Wu</a>
|
<a href=/people/y/ying-li/>Ying Li</a>
|
<a href=/people/d/dawei-zhang/>Dawei Zhang</a>
|
<a href=/people/y/yang-zhou/>Yang Zhou</a>
|
<a href=/people/z/zhonghai-wu/>Zhonghai Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--515><div class="card-body p-3 small">Generative dialogue systems tend to produce generic responses, which often leads to boring conversations. For alleviating this issue, Recent studies proposed to retrieve and introduce knowledge facts from <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a>. While this <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a> works to a certain extent, it usually retrieves knowledge facts only based on the entity word itself, without considering the specific dialogue context. Thus, the introduction of the context-irrelevant knowledge facts can impact the quality of generations. To this end, this paper proposes a novel commonsense knowledge-aware dialogue generation model, ConKADI. We design a Felicitous Fact mechanism to help the model focus on the knowledge facts that are highly relevant to the context ; furthermore, two techniques, Context-Knowledge Fusion and Flexible Mode Fusion are proposed to facilitate the integration of the knowledge in the ConKADI. We collect and build a large-scale Chinese dataset aligned with the <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> for dialogue generation. Extensive evaluations over both an open-released English dataset and our Chinese dataset demonstrate that our approach ConKADI outperforms the state-of-the-art approach CCM, in most experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.520.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--520 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.520 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928958 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.520" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.520/>An Effective Transition-based Model for Discontinuous NER<span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/x/xiang-dai/>Xiang Dai</a>
|
<a href=/people/s/sarvnaz-karimi/>Sarvnaz Karimi</a>
|
<a href=/people/b/ben-hachey/>Ben Hachey</a>
|
<a href=/people/c/cecile-paris/>Cecile Paris</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--520><div class="card-body p-3 small">Unlike widely used Named Entity Recognition (NER) data sets in generic domains, biomedical NER data sets often contain mentions consisting of discontinuous spans. Conventional sequence tagging techniques encode <a href=https://en.wikipedia.org/wiki/Markov_assumption>Markov assumptions</a> that are efficient but preclude recovery of these mentions. We propose a simple, effective transition-based model with generic neural encoding for discontinuous NER. Through extensive experiments on three biomedical data sets, we show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can effectively recognize discontinuous mentions without sacrificing the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on continuous mentions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.527.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--527 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.527 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928879 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.527/>Relabel the Noise : Joint Extraction of Entities and Relations via Cooperative Multiagents</a></strong><br><a href=/people/d/daoyuan-chen/>Daoyuan Chen</a>
|
<a href=/people/y/yaliang-li/>Yaliang Li</a>
|
<a href=/people/k/kai-lei/>Kai Lei</a>
|
<a href=/people/y/ying-shen/>Ying Shen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--527><div class="card-body p-3 small">Distant supervision based methods for entity and relation extraction have received increasing popularity due to the fact that these methods require light human annotation efforts. In this paper, we consider the problem of shifted label distribution, which is caused by the inconsistency between the noisy-labeled training set subject to external knowledge graph and the human-annotated test set, and exacerbated by the pipelined entity-then-relation extraction manner with noise propagation. We propose a joint extraction approach to address this problem by re-labeling noisy instances with a group of cooperative multiagents. To handle noisy instances in a fine-grained manner, each agent in the cooperative group evaluates the instance by calculating a continuous confidence score from its own perspective ; To leverage the correlations between these two extraction tasks, a confidence consensus module is designed to gather the wisdom of all agents and re-distribute the noisy training set with confidence-scored labels. Further, the <a href=https://en.wikipedia.org/wiki/Confidence_interval>confidences</a> are used to adjust the training losses of extractors. Experimental results on two real-world datasets verify the benefits of re-labeling noisy instance, and show that the proposed model significantly outperforms the state-of-the-art entity and relation extraction methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.528.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--528 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.528 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928863 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.528" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.528/>Simplify the Usage of Lexicon in Chinese NER<span class=acl-fixed-case>C</span>hinese <span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/r/ruotian-ma/>Ruotian Ma</a>
|
<a href=/people/m/minlong-peng/>Minlong Peng</a>
|
<a href=/people/q/qi-zhang/>Qi Zhang</a>
|
<a href=/people/z/zhongyu-wei/>Zhongyu Wei</a>
|
<a href=/people/x/xuan-jing-huang/>Xuanjing Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--528><div class="card-body p-3 small">Recently, many works have tried to augment the performance of Chinese named entity recognition (NER) using word lexicons. As a representative, Lattice-LSTM has achieved new benchmark results on several public Chinese NER datasets. However, Lattice-LSTM has a complex model architecture. This limits its application in many industrial areas where real-time NER responses are needed. In this work, we propose a simple but effective <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for incorporating the <a href=https://en.wikipedia.org/wiki/Lexicon>word lexicon</a> into the <a href=https://en.wikipedia.org/wiki/Character_(symbol)>character representations</a>. This method avoids designing a complicated sequence modeling architecture, and for any neural NER model, it requires only subtle adjustment of the character representation layer to introduce the lexicon information. Experimental studies on four benchmark Chinese NER datasets show that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> achieves an inference speed up to 6.15 times faster than those of state-of-the-art methods, along with a better performance. The experimental results also show that the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> can be easily incorporated with pre-trained models like BERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.529.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--529 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.529 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929269 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.529/>AdvAug : Robust Adversarial Augmentation for Neural Machine Translation<span class=acl-fixed-case>A</span>dv<span class=acl-fixed-case>A</span>ug: Robust Adversarial Augmentation for Neural Machine Translation</a></strong><br><a href=/people/y/yong-cheng/>Yong Cheng</a>
|
<a href=/people/l/lu-jiang/>Lu Jiang</a>
|
<a href=/people/w/wolfgang-macherey/>Wolfgang Macherey</a>
|
<a href=/people/j/jacob-eisenstein/>Jacob Eisenstein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--529><div class="card-body p-3 small">In this paper, we propose a new adversarial augmentation method for Neural Machine Translation (NMT). The main idea is to minimize the vicinal risk over virtual sentences sampled from two vicinity distributions, in which the crucial one is a novel vicinity distribution for adversarial sentences that describes a smooth interpolated embedding space centered around observed training sentence pairs. We then discuss our approach, AdvAug, to train NMT models using the embeddings of virtual sentences in sequence-to-sequence learning. Experiments on Chinese-English, English-French, and English-German translation benchmarks show that AdvAug achieves significant improvements over theTransformer (up to 4.9 BLEU points), and substantially outperforms other data augmentation techniques (e.g.back-translation) without using extra corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.536.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--536 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.536 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928831 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.536/>Emerging Cross-lingual Structure in Pretrained Language Models</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/h/haoran-li/>Haoran Li</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/v/veselin-stoyanov/>Veselin Stoyanov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--536><div class="card-body p-3 small">We study the problem of multilingual masked language modeling, i.e. the training of a single <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on concatenated text from multiple languages, and present a detailed study of several factors that influence why these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from monolingual BERT models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these <a href=https://en.wikipedia.org/wiki/Symmetry>symmetries</a> are automatically discovered and aligned during the joint training process.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.538.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--538 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.538 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928800 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.538" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.538/>Incorporating External Knowledge through Pre-training for <a href=https://en.wikipedia.org/wiki/Natural_language>Natural Language</a> to Code Generation</a></strong><br><a href=/people/f/frank-f-xu/>Frank F. Xu</a>
|
<a href=/people/z/zhengbao-jiang/>Zhengbao Jiang</a>
|
<a href=/people/p/pengcheng-yin/>Pengcheng Yin</a>
|
<a href=/people/b/bogdan-vasilescu/>Bogdan Vasilescu</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--538><div class="card-body p-3 small">Open-domain code generation aims to generate code in a general-purpose programming language (such as Python) from natural language (NL) intents. Motivated by the intuition that developers usually retrieve resources on the web when writing code, we explore the effectiveness of incorporating two varieties of external knowledge into NL-to-code generation : automatically mined NL-code pairs from the online programming QA forum StackOverflow and programming language API documentation. Our evaluations show that combining the two sources with data augmentation and retrieval-based data re-sampling improves the current state-of-the-art by up to 2.2 % absolute BLEU score on the code generation testbed CoNaLa. The code and resources are available at https://github.com/neulab/external-knowledge-codegen.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.540.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--540 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.540 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928950 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.540" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.540/>Word-level Textual Adversarial Attacking as <a href=https://en.wikipedia.org/wiki/Combinatorial_optimization>Combinatorial Optimization</a></a></strong><br><a href=/people/y/yuan-zang/>Yuan Zang</a>
|
<a href=/people/f/fanchao-qi/>Fanchao Qi</a>
|
<a href=/people/c/chenghao-yang/>Chenghao Yang</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/m/meng-zhang/>Meng Zhang</a>
|
<a href=/people/q/qun-liu/>Qun Liu</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--540><div class="card-body p-3 small">Adversarial attacks are carried out to reveal the vulnerability of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a>. Textual adversarial attacking is challenging because text is discrete and a small perturbation can bring significant change to the original input. Word-level attacking, which can be regarded as a <a href=https://en.wikipedia.org/wiki/Combinatorial_optimization>combinatorial optimization problem</a>, is a well-studied class of textual attack methods. However, existing word-level attack models are far from perfect, largely because unsuitable search space reduction methods and inefficient <a href=https://en.wikipedia.org/wiki/Mathematical_optimization>optimization algorithms</a> are employed. In this paper, we propose a novel attack model, which incorporates the sememe-based word substitution method and particle swarm optimization-based search algorithm to solve the two problems separately. We conduct exhaustive experiments to evaluate our attack model by attacking BiLSTM and <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> on three benchmark datasets. Experimental results demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> consistently achieves much higher attack success rates and crafts more high-quality adversarial examples as compared to baseline methods. Also, further experiments show our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has higher transferability and can bring more robustness enhancement to victim models by adversarial training. All the code and data of this paper can be obtained on https://github.com/thunlp/SememePSO-Attack.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.549.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--549 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.549 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928866 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.549/>Reasoning Over Semantic-Level Graph for Fact Checking</a></strong><br><a href=/people/w/wanjun-zhong/>Wanjun Zhong</a>
|
<a href=/people/j/jingjing-xu/>Jingjing Xu</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/z/zenan-xu/>Zenan Xu</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a>
|
<a href=/people/j/jiahai-wang/>Jiahai Wang</a>
|
<a href=/people/j/jian-yin/>Jian Yin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--549><div class="card-body p-3 small">Fact checking is a challenging task because verifying the truthfulness of a claim requires reasoning about multiple retrievable evidence. In this work, we present a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> suitable for reasoning about the semantic-level structure of evidence. Unlike most previous works, which typically represent evidence sentences with either string concatenation or fusing the features of isolated evidence sentences, our approach operates on rich semantic structures of evidence obtained by semantic role labeling. We propose two mechanisms to exploit the structure of evidence while leveraging the advances of pre-trained models like BERT, GPT or XLNet. Specifically, using XLNet as the backbone, we first utilize the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> to re-define the relative distances of words, with the intuition that semantically related words should have short distances. Then, we adopt graph convolutional network and graph attention network to propagate and aggregate information from neighboring nodes on the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>. We evaluate our system on FEVER, a benchmark dataset for <a href=https://en.wikipedia.org/wiki/Fact-checking>fact checking</a>, and find that rich structural information is helpful and both our graph-based mechanisms improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. Our model is the state-of-the-art system in terms of both official evaluation metrics, namely claim verification accuracy and FEVER score.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.552.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--552 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.552 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929382 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.552" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.552/>Extractive Summarization as Text Matching</a></strong><br><a href=/people/m/ming-zhong/>Ming Zhong</a>
|
<a href=/people/p/pengfei-liu/>Pengfei Liu</a>
|
<a href=/people/y/yiran-chen/>Yiran Chen</a>
|
<a href=/people/d/danqing-wang/>Danqing Wang</a>
|
<a href=/people/x/xipeng-qiu/>Xipeng Qiu</a>
|
<a href=/people/x/xuan-jing-huang/>Xuanjing Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--552><div class="card-body p-3 small">This paper creates a paradigm shift with regard to the way we build neural extractive summarization systems. Instead of following the commonly used framework of extracting sentences individually and modeling the relationship between sentences, we formulate the extractive summarization task as a semantic text matching problem, in which a source document and candidate summaries will be (extracted from the original text) matched in a <a href=https://en.wikipedia.org/wiki/Semantic_space>semantic space</a>. Notably, this paradigm shift to semantic matching framework is well-grounded in our comprehensive analysis of the inherent gap between sentence-level and summary-level extractors based on the property of the dataset. Besides, even instantiating the <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> with a simple form of a <a href=https://en.wikipedia.org/wiki/Matching_model>matching model</a>, we have driven the state-of-the-art extractive result on CNN / DailyMail to a new level (44.41 in ROUGE-1). Experiments on the other five <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> also show the effectiveness of the matching framework. We believe the power of this matching-based summarization framework has not been fully exploited. To encourage more instantiations in the future, we have released our codes, processed dataset, as well as generated summaries in.<url>https://github.com/maszhongming/MatchSum</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.556.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--556 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.556 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929014 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.556/>Multi-Granularity Interaction Network for Extractive and Abstractive Multi-Document Summarization</a></strong><br><a href=/people/h/hanqi-jin/>Hanqi Jin</a>
|
<a href=/people/t/tianming-wang/>Tianming Wang</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--556><div class="card-body p-3 small">In this paper, we propose a multi-granularity interaction network for extractive and abstractive multi-document summarization, which jointly learn semantic representations for words, sentences, and documents. The word representations are used to generate an abstractive summary while the sentence representations are used to produce an extractive summary. We employ attention mechanisms to interact between different granularity of semantic representations, which helps to capture multi-granularity key information and improves the performance of both abstractive and extractive summarization. Experiment results show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> substantially outperforms all strong baseline methods and achieves the best results on the Multi-News dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.559.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--559 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.559 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929397 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.559/>Language (Re)modelling : Towards Embodied Language Understanding<span class=acl-fixed-case>L</span>anguage (Re)modelling: <span class=acl-fixed-case>T</span>owards Embodied Language Understanding</a></strong><br><a href=/people/r/ronen-tamari/>Ronen Tamari</a>
|
<a href=/people/c/chen-shani/>Chen Shani</a>
|
<a href=/people/t/tom-hope/>Tom Hope</a>
|
<a href=/people/m/miriam-r-l-petruck/>Miriam R L Petruck</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a>
|
<a href=/people/d/dafna-shahaf/>Dafna Shahaf</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--559><div class="card-body p-3 small">While natural language understanding (NLU) is advancing rapidly, today&#8217;s technology differs from human-like language understanding in fundamental ways, notably in its inferior efficiency, <a href=https://en.wikipedia.org/wiki/Interpretability>interpretability</a>, and <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a>. This work proposes an approach to representation and learning based on the tenets of embodied cognitive linguistics (ECL). According to ECL, <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> is inherently executable (like programming languages), driven by mental simulation and metaphoric mappings over hierarchical compositions of structures and schemata learned through embodied interaction. This position paper argues that the use of grounding by metaphoric reasoning and <a href=https://en.wikipedia.org/wiki/Simulation>simulation</a> will greatly benefit NLU systems, and proposes a <a href=https://en.wikipedia.org/wiki/Systems_architecture>system architecture</a> along with a roadmap towards realizing this vision.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.560.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--560 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.560 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929069 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.560/>The State and Fate of <a href=https://en.wikipedia.org/wiki/Linguistic_diversity>Linguistic Diversity</a> and Inclusion in the NLP World<span class=acl-fixed-case>NLP</span> World</a></strong><br><a href=/people/p/pratik-joshi/>Pratik Joshi</a>
|
<a href=/people/s/sebastin-santy/>Sebastin Santy</a>
|
<a href=/people/a/amar-budhiraja/>Amar Budhiraja</a>
|
<a href=/people/k/kalika-bali/>Kalika Bali</a>
|
<a href=/people/m/monojit-choudhury/>Monojit Choudhury</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--560><div class="card-body p-3 small">Language technologies contribute to promoting <a href=https://en.wikipedia.org/wiki/Multilingualism>multilingualism</a> and <a href=https://en.wikipedia.org/wiki/Language>linguistic diversity</a> around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving <a href=https://en.wikipedia.org/wiki/Language_technology>language technologies</a> and <a href=https://en.wikipedia.org/wiki/Application_software>applications</a>. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the language agnostic status of current <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> and <a href=https://en.wikipedia.org/wiki/System>systems</a>. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.561.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--561 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.561 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929007 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.561/>The Unstoppable Rise of <a href=https://en.wikipedia.org/wiki/Computational_linguistics>Computational Linguistics</a> in Deep Learning</a></strong><br><a href=/people/j/james-henderson/>James Henderson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--561><div class="card-body p-3 small">In this paper, we trace the history of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> applied to natural language understanding tasks, and identify key contributions which the nature of language has made to the development of neural network architectures. We focus on the importance of variable binding and its instantiation in attention-based models, and argue that Transformer is not a sequence model but an induced-structure model. This perspective leads to predictions of the challenges facing research in deep learning architectures for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.563.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--563 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.563 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929047 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block style=text-decoration:line-through><strong><a class=align-middle href=/2020.acl-main.563/>A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking</a></strong><br><a href=/people/y/yong-shan/>Yong Shan</a>
|
<a href=/people/z/zekang-li/>Zekang Li</a>
|
<a href=/people/j/jinchao-zhang/>Jinchao Zhang</a>
|
<a href=/people/f/fandong-meng/>Fandong Meng</a>
|
<a href=/people/y/yang-feng/>Yang Feng</a>
|
<a href=/people/c/cheng-niu/>Cheng Niu</a>
|
<a href=/people/j/jie-zhou/>Jie Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--563><div class="card-body p-3 small">Recent studies in dialogue state tracking (DST) leverage historical information to determine states which are generally represented as slot-value pairs. However, most of them have limitations to efficiently exploit relevant context due to the lack of a powerful mechanism for modeling interactions between the slot and the dialogue history. Besides, existing methods usually ignore the slot imbalance problem and treat all slots indiscriminately, which limits the learning of hard slots and eventually hurts overall performance. In this paper, we propose to enhance the DST through employing a contextual hierarchical attention network to not only discern relevant information at both word level and turn level but also learn contextual representations. We further propose an adaptive objective to alleviate the slot imbalance problem by dynamically adjust weights of different slots during training. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Methodology>approach</a> reaches 52.68 % and 58.55 % joint accuracy on MultiWOZ 2.0 and MultiWOZ 2.1 datasets respectively and achieves new state-of-the-art performance with considerable improvements (+1.24 % and +5.98 %).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.564.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--564 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.564 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928992 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.564/>Data Manipulation : Towards Effective Instance Learning for Neural Dialogue Generation via Learning to Augment and Reweight</a></strong><br><a href=/people/h/hengyi-cai/>Hengyi Cai</a>
|
<a href=/people/h/hongshen-chen/>Hongshen Chen</a>
|
<a href=/people/y/yonghao-song/>Yonghao Song</a>
|
<a href=/people/c/cheng-zhang/>Cheng Zhang</a>
|
<a href=/people/x/xiaofang-zhao/>Xiaofang Zhao</a>
|
<a href=/people/d/dawei-yin/>Dawei Yin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--564><div class="card-body p-3 small">Current state-of-the-art neural dialogue models learn from <a href=https://en.wikipedia.org/wiki/Conversation>human conversations</a> following the data-driven paradigm. As such, a reliable <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training corpus</a> is the crux of building a robust and well-behaved dialogue model. However, due to the open-ended nature of human conversations, the quality of user-generated training data varies greatly, and effective training samples are typically insufficient while noisy samples frequently appear. This impedes the learning of those data-driven neural dialogue models. Therefore, effective dialogue learning requires not only more reliable learning samples, but also fewer noisy samples. In this paper, we propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and highlighting effective learning samples as well as reducing the effect of inefficient samples simultaneously. In particular, the data manipulation model selectively augments the training samples and assigns an importance weight to each instance to reform the training data. Note that, the proposed data manipulation framework is fully data-driven and learnable. It not only manipulates training samples to optimize the dialogue generation model, but also learns to increase its manipulation skills through <a href=https://en.wikipedia.org/wiki/Gradient_descent>gradient descent</a> with validation samples. Extensive experiments show that our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> can improve the dialogue generation performance with respect to various automatic evaluation metrics and <a href=https://en.wikipedia.org/wiki/Judgement>human judgments</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.567.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--567 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.567 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929216 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.567/>SAS : Dialogue State Tracking via Slot Attention and Slot Information Sharing<span class=acl-fixed-case>SAS</span>: Dialogue State Tracking via Slot Attention and Slot Information Sharing</a></strong><br><a href=/people/j/jiaying-hu/>Jiaying Hu</a>
|
<a href=/people/y/yan-yang/>Yan Yang</a>
|
<a href=/people/c/chencai-chen/>Chencai Chen</a>
|
<a href=/people/l/liang-he/>Liang He</a>
|
<a href=/people/z/zhou-yu/>Zhou Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--567><div class="card-body p-3 small">Dialogue state tracker is responsible for inferring user intentions through dialogue history. Previous methods have difficulties in handling <a href=https://en.wikipedia.org/wiki/Dialogue>dialogues</a> with <a href=https://en.wikipedia.org/wiki/Context_(language_use)>long interaction context</a>, due to the excessive information. We propose a Dialogue State Tracker with Slot Attention and Slot Information Sharing (SAS) to reduce redundant information&#8217;s interference and improve long dialogue context tracking. Specially, we first apply a Slot Attention to learn a set of slot-specific features from the original dialogue and then integrate them using a slot information sharing module. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> yields a significantly improved performance compared to previous state-of the-art models on the MultiWOZ dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.576.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--576 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.576 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929356 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.576/>MIE : A Medical Information Extractor towards Medical Dialogues<span class=acl-fixed-case>MIE</span>: A Medical Information Extractor towards Medical Dialogues</a></strong><br><a href=/people/y/yuanzhe-zhang/>Yuanzhe Zhang</a>
|
<a href=/people/z/zhongtao-jiang/>Zhongtao Jiang</a>
|
<a href=/people/t/tao-zhang/>Tao Zhang</a>
|
<a href=/people/s/shiwan-liu/>Shiwan Liu</a>
|
<a href=/people/j/jiarun-cao/>Jiarun Cao</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/s/shengping-liu/>Shengping Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--576><div class="card-body p-3 small">Electronic Medical Records (EMRs) have become key components of modern <a href=https://en.wikipedia.org/wiki/Health_system>medical care systems</a>. Despite the merits of <a href=https://en.wikipedia.org/wiki/Electronic_health_record>EMRs</a>, many doctors suffer from writing them, which is time-consuming and tedious. We believe that automatically converting medical dialogues to <a href=https://en.wikipedia.org/wiki/Electronic_health_record>EMRs</a> can greatly reduce the burdens of doctors, and extracting information from medical dialogues is an essential step. To this end, we annotate online medical consultation dialogues in a window-sliding style, which is much easier than the sequential labeling annotation. We then propose a Medical Information Extractor (MIE) towards medical dialogues. MIE is able to extract mentioned symptoms, <a href=https://en.wikipedia.org/wiki/Surgery>surgeries</a>, <a href=https://en.wikipedia.org/wiki/Medical_test>tests</a>, other information and their corresponding status. To tackle the particular challenges of the task, MIE uses a deep matching architecture, taking dialogue turn-interaction into account. The experimental results demonstrate MIE is a promising solution to extract <a href=https://en.wikipedia.org/wiki/Medical_record>medical information</a> from doctor-patient dialogues.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.585.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--585 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.585 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929045 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.585" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.585/>Span-based Localizing Network for Natural Language Video Localization</a></strong><br><a href=/people/h/hao-zhang/>Hao Zhang</a>
|
<a href=/people/a/aixin-sun/>Aixin Sun</a>
|
<a href=/people/w/wei-jing/>Wei Jing</a>
|
<a href=/people/j/joey-tianyi-zhou/>Joey Tianyi Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--585><div class="card-body p-3 small">Given an untrimmed video and a text query, natural language video localization (NLVL) is to locate a matching span from the video that semantically corresponds to the query. Existing solutions formulate NLVL either as a ranking task and apply multimodal matching architecture, or as a regression task to directly regress the target video span. In this work, we address NLVL task with a span-based QA approach by treating the input video as text passage. We propose a video span localizing network (VSLNet), on top of the standard span-based QA framework, to address NLVL. The proposed VSLNet tackles the differences between NLVL and span-based QA through a simple and yet effective query-guided highlighting (QGH) strategy. The QGH guides VSLNet to search for matching video span within a highlighted region. Through extensive experiments on three benchmark datasets, we show that the proposed VSLNet outperforms the state-of-the-art methods ; and adopting span-based QA framework is a promising direction to solve NLVL.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.586.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--586 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.586 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929224 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.586" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.586/>Words Are nt Enough, Their Order Matters : On the Robustness of Grounding Visual Referring Expressions</a></strong><br><a href=/people/a/arjun-akula/>Arjun Akula</a>
|
<a href=/people/s/spandana-gella/>Spandana Gella</a>
|
<a href=/people/y/yaser-al-onaizan/>Yaser Al-Onaizan</a>
|
<a href=/people/s/song-chun-zhu/>Song-Chun Zhu</a>
|
<a href=/people/s/siva-reddy/>Siva Reddy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--586><div class="card-body p-3 small">Visual referring expression recognition is a challenging task that requires <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a> in the context of an <a href=https://en.wikipedia.org/wiki/Image>image</a>. We critically examine RefCOCOg, a standard <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a> for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, using a human study and show that 83.7 % of test instances do not require reasoning on linguistic structure, i.e., words are enough to identify the target object, the <a href=https://en.wikipedia.org/wiki/Word_order>word order</a> does n&#8217;t matter. To measure the true progress of existing <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>, we split the test set into two sets, one which requires reasoning on linguistic structure and the other which does n&#8217;t. Additionally, we create an out-of-distribution dataset Ref-Adv by asking crowdworkers to perturb in-domain examples such that the target object changes. Using these datasets, we empirically show that existing methods fail to exploit linguistic structure and are 12 % to 23 % lower in performance than the established progress for this task. We also propose two methods, one based on contrastive learning and the other based on <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>, to increase the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of ViLBERT, the current state-of-the-art model for this task. Our datasets are publicly available at https://github.com/aws/aws-refcocog-adv.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.589.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--589 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.589 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928814 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.589/>Differentiable Window for Dynamic Local Attention</a></strong><br><a href=/people/t/thanh-tung-nguyen/>Thanh-Tung Nguyen</a>
|
<a href=/people/x/xuan-phi-nguyen/>Xuan-Phi Nguyen</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/x/xiaoli-li/>Xiaoli Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--589><div class="card-body p-3 small">We propose Differentiable Window, a new neural module and general purpose component for dynamic window selection. While universally applicable, we demonstrate a compelling use case of utilizing Differentiable Window to improve standard attention modules by enabling more focused attentions over the input regions. We propose two variants of Differentiable Window, and integrate them within the Transformer architecture in two novel ways. We evaluate our proposed approach on a myriad of NLP tasks, including <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>subject-verb agreement</a> and <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. Our experimental results demonstrate consistent and sizable improvements across all <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.593.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--593 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.593 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929251 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.593" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.593/>The Right Tool for the Job : <a href=https://en.wikipedia.org/wiki/Matching_model>Matching Model</a> and Instance Complexities</a></strong><br><a href=/people/r/roy-schwartz/>Roy Schwartz</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/s/swabha-swayamdipta/>Swabha Swayamdipta</a>
|
<a href=/people/j/jesse-dodge/>Jesse Dodge</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--593><div class="card-body p-3 small">As NLP models become larger, executing a trained <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> requires significant computational resources incurring monetary and environmental costs. To better respect a given <a href=https://en.wikipedia.org/wiki/Inference>inference budget</a>, we propose a modification to contextual representation fine-tuning which, during <a href=https://en.wikipedia.org/wiki/Inference>inference</a>, allows for an early (and fast) exit from neural network calculations for simple instances, and late (and accurate) exit for hard instances. To achieve this, we add <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> to different layers of BERT and use their calibrated confidence scores to make early exit decisions. We test our proposed modification on five different <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> in two tasks : three text classification datasets and two natural language inference benchmarks. Our method presents a favorable speed / accuracy tradeoff in almost all cases, producing models which are up to five times faster than the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state of the art</a>, while preserving their <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. Our method also requires almost no additional <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training resources</a> (in either time or parameters) compared to the baseline BERT model. Finally, our method alleviates the need for costly retraining of multiple models at different levels of efficiency ; we allow users to control the inference speed / accuracy tradeoff using a single trained model, by setting a single variable at inference time. We publicly release our code.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.595.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--595 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.595 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928996 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.595" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.595/>Coupling Distant Annotation and Adversarial Training for Cross-Domain Chinese Word Segmentation<span class=acl-fixed-case>C</span>hinese Word Segmentation</a></strong><br><a href=/people/n/ning-ding/>Ning Ding</a>
|
<a href=/people/d/dingkun-long/>Dingkun Long</a>
|
<a href=/people/g/guangwei-xu/>Guangwei Xu</a>
|
<a href=/people/m/muhua-zhu/>Muhua Zhu</a>
|
<a href=/people/p/pengjun-xie/>Pengjun Xie</a>
|
<a href=/people/x/xiaobin-wang/>Xiaobin Wang</a>
|
<a href=/people/h/haitao-zheng/>Haitao Zheng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--595><div class="card-body p-3 small">Fully supervised neural approaches have achieved significant progress in the task of Chinese word segmentation (CWS). Nevertheless, the performance of <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> always drops gravely if the domain shifts due to the distribution gap across domains and the out of vocabulary (OOV) problem. In order to simultaneously alleviate the issues, this paper intuitively couples distant annotation and adversarial training for cross-domain CWS. 1) We rethink the essence of Chinese words and design an automatic distant annotation mechanism, which does not need any supervision or pre-defined dictionaries on the target domain. The <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> could effectively explore domain-specific words and distantly annotate the raw texts for the target domain. 2) We further develop a sentence-level adversarial training procedure to perform <a href=https://en.wikipedia.org/wiki/Noise_reduction>noise reduction</a> and maximum utilization of the source domain information. Experiments on multiple real-world datasets across various domains show the superiority and robustness of our model, significantly outperforming previous state-of-the-arts cross-domain CWS methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.598.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--598 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.598 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929159 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.598" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.598/>Unsupervised Morphological Paradigm Completion</a></strong><br><a href=/people/h/huiming-jin/>Huiming Jin</a>
|
<a href=/people/l/liwei-cai/>Liwei Cai</a>
|
<a href=/people/y/yihui-peng/>Yihui Peng</a>
|
<a href=/people/c/chen-xia/>Chen Xia</a>
|
<a href=/people/a/arya-d-mccarthy/>Arya McCarthy</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--598><div class="card-body p-3 small">We propose the task of unsupervised morphological paradigm completion. Given only raw text and a <a href=https://en.wikipedia.org/wiki/Lemma_(morphology)>lemma list</a>, the task consists of generating the morphological paradigms, i.e., all inflected forms, of the lemmas. From a natural language processing (NLP) perspective, this is a challenging <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised task</a>, and high-performing systems have the potential to improve tools for low-resource languages or to assist linguistic annotators. From a cognitive science perspective, this can shed light on how children acquire <a href=https://en.wikipedia.org/wiki/Morphology_(biology)>morphological knowledge</a>. We further introduce a system for the task, which generates morphological paradigms via the following steps : (i) EDIT TREE retrieval, (ii) additional lemma retrieval, (iii) paradigm size discovery, and (iv) inflection generation. We perform an evaluation on 14 typologically diverse languages. Our <a href=https://en.wikipedia.org/wiki/System>system</a> outperforms trivial baselines with ease and, for some languages, even obtains a higher <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> than minimally supervised systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.599.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--599 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.599 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928861 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.599" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.599/>Document Modeling with Graph Attention Networks for Multi-grained Machine Reading Comprehension</a></strong><br><a href=/people/b/bo-zheng/>Bo Zheng</a>
|
<a href=/people/h/haoyang-wen/>Haoyang Wen</a>
|
<a href=/people/y/yaobo-liang/>Yaobo Liang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/d/daxin-jiang/>Daxin Jiang</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--599><div class="card-body p-3 small">Natural Questions is a new challenging machine reading comprehension benchmark with two-grained answers, which are a long answer (typically a paragraph) and a short answer (one or more entities inside the long answer). Despite the effectiveness of existing methods on this <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a>, they treat these two sub-tasks individually during training while ignoring their dependencies. To address this issue, we present a novel multi-grained machine reading comprehension framework that focuses on modeling documents at their hierarchical nature, which are different levels of granularity : documents, paragraphs, sentences, and tokens. We utilize graph attention networks to obtain different levels of <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> so that they can be learned simultaneously. The long and short answers can be extracted from paragraph-level representation and token-level representation, respectively. In this way, we can model the dependencies between the two-grained answers to provide evidence for each other. We jointly train the two sub-tasks, and our experiments show that our approach significantly outperforms previous systems at both long and short answer criteria.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.604.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--604 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.604 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928913 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.604/>RikiNet : Reading Wikipedia Pages for Natural Question Answering<span class=acl-fixed-case>R</span>iki<span class=acl-fixed-case>N</span>et: Reading <span class=acl-fixed-case>W</span>ikipedia Pages for Natural Question Answering</a></strong><br><a href=/people/d/dayiheng-liu/>Dayiheng Liu</a>
|
<a href=/people/y/yeyun-gong/>Yeyun Gong</a>
|
<a href=/people/j/jie-fu/>Jie Fu</a>
|
<a href=/people/y/yu-yan/>Yu Yan</a>
|
<a href=/people/j/jiusheng-chen/>Jiusheng Chen</a>
|
<a href=/people/d/daxin-jiang/>Daxin Jiang</a>
|
<a href=/people/j/jiancheng-lv/>Jiancheng Lv</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--604><div class="card-body p-3 small">Reading long documents to answer open-domain questions remains challenging in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. In this paper, we introduce a new <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, called RikiNet, which reads <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia pages</a> for natural question answering. RikiNet contains a dynamic paragraph dual-attention reader and a multi-level cascaded answer predictor. The reader dynamically represents the document and question by utilizing a set of complementary attention mechanisms. The representations are then fed into the predictor to obtain the span of the short answer, the paragraph of the long answer, and the answer type in a cascaded manner. On the Natural Questions (NQ) dataset, a single RikiNet achieves 74.3 F1 and 57.9 F1 on long-answer and short-answer tasks. To our best knowledge, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is the first single <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that outperforms the single human performance. Furthermore, an ensemble RikiNet obtains 76.1 F1 and 61.3 F1 on long-answer and short-answer tasks, achieving the best performance on the official NQ leaderboard.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.606.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--606 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.606 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929300 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.606/>Semantic Parsing for <a href=https://en.wikipedia.org/wiki/English_language>English</a> as a Second Language<span class=acl-fixed-case>E</span>nglish as a Second Language</a></strong><br><a href=/people/y/yuanyuan-zhao/>Yuanyuan Zhao</a>
|
<a href=/people/w/weiwei-sun/>Weiwei Sun</a>
|
<a href=/people/j/junjie-cao/>Junjie Cao</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--606><div class="card-body p-3 small">This paper is concerned with <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> for <a href=https://en.wikipedia.org/wiki/English_language>English</a> as a second language (ESL). Motivated by the theoretical emphasis on the learning challenges that occur at the syntax-semantics interface during second language acquisition, we formulate the task based on the divergence between literal and intended meanings. We combine the complementary strengths of English Resource Grammar, a linguistically-precise hand-crafted deep grammar, and TLE, an existing manually annotated ESL UD-TreeBank with a novel reranking model. Experiments demonstrate that in comparison to human annotations, our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> can obtain a very promising SemBanking quality. By means of the newly created <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, we evaluate state-of-the-art semantic parsing as well as grammatical error correction models. The evaluation profiles the performance of neural NLP techniques for handling <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>ESL data</a> and suggests some research directions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.608.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--608 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.608 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929390 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.608/>Unsupervised Dual Paraphrasing for Two-stage Semantic Parsing</a></strong><br><a href=/people/r/ruisheng-cao/>Ruisheng Cao</a>
|
<a href=/people/s/su-zhu/>Su Zhu</a>
|
<a href=/people/c/chenyu-yang/>Chenyu Yang</a>
|
<a href=/people/c/chen-liu/>Chen Liu</a>
|
<a href=/people/r/rao-ma/>Rao Ma</a>
|
<a href=/people/y/yanbin-zhao/>Yanbin Zhao</a>
|
<a href=/people/l/lu-chen/>Lu Chen</a>
|
<a href=/people/k/kai-yu/>Kai Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--608><div class="card-body p-3 small">One daunting problem for <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> is the scarcity of <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>. Aiming to reduce nontrivial human labor, we propose a two-stage semantic parsing framework, where the first stage utilizes an unsupervised paraphrase model to convert an unlabeled natural language utterance into the canonical utterance. The downstream naive semantic parser accepts the intermediate output and returns the target <a href=https://en.wikipedia.org/wiki/Logical_form>logical form</a>. Furthermore, the entire training process is split into two phases : pre-training and cycle learning. Three tailored self-supervised tasks are introduced throughout training to activate the unsupervised paraphrase model. Experimental results on benchmarks <a href=https://en.wikipedia.org/wiki/Overnight>Overnight</a> and GeoGranno demonstrate that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is effective and compatible with supervised training.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.609.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--609 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.609 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929443 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.609/>DRTS Parsing with Structure-Aware Encoding and Decoding<span class=acl-fixed-case>DRTS</span> Parsing with Structure-Aware Encoding and Decoding</a></strong><br><a href=/people/q/qiankun-fu/>Qiankun Fu</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/j/jiangming-liu/>Jiangming Liu</a>
|
<a href=/people/m/meishan-zhang/>Meishan Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--609><div class="card-body p-3 small">Discourse representation tree structure (DRTS) parsing is a novel semantic parsing task which has been concerned most recently. State-of-the-art performance can be achieved by a neural sequence-to-sequence model, treating the tree construction as an incremental sequence generation problem. Structural information such as input syntax and the intermediate skeleton of the partial output has been ignored in the model, which could be potentially useful for the DRTS parsing. In this work, we propose a structural-aware model at both the encoder and decoder phase to integrate the structural information, where graph attention network (GAT) is exploited for effectively modeling. Experimental results on a benchmark dataset show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is effective and can obtain the best performance in the literature.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.613.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--613 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.613 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929450 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.613/>Document Translation vs. Query Translation for Cross-Lingual Information Retrieval in the Medical Domain</a></strong><br><a href=/people/s/shadi-saleh/>Shadi Saleh</a>
|
<a href=/people/p/pavel-pecina/>Pavel Pecina</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--613><div class="card-body p-3 small">We present a thorough comparison of two principal approaches to <a href=https://en.wikipedia.org/wiki/Cross-lingual_information_retrieval>Cross-Lingual Information Retrieval</a> : document translation (DT) and query translation (QT). Our experiments are conducted using the cross-lingual test collection produced within the CLEF eHealth information retrieval tasks in 20132015 containing English documents and queries in several European languages. We exploit the Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) paradigms and train several domain-specific and task-specific machine translation systems to translate the non-English queries into English (for the QT approach) and the English documents to all the query languages (for the DT approach). The results show that the quality of <a href=https://en.wikipedia.org/wiki/Quantitative_trait_locus>QT</a> by <a href=https://en.wikipedia.org/wiki/Satisfiability_modulo_theories>SMT</a> is sufficient enough to outperform the retrieval results of the DT approach for all the languages. NMT then further boosts translation quality and retrieval quality for both QT and DT for most languages, but still, QT provides generally better retrieval results than DT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.619.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--619 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.619 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929196 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.619/>Gender in Danger? Evaluating Speech Translation Technology on the MuST-SHE Corpus<span class=acl-fixed-case>M</span>u<span class=acl-fixed-case>ST</span>-<span class=acl-fixed-case>SHE</span> Corpus</a></strong><br><a href=/people/l/luisa-bentivogli/>Luisa Bentivogli</a>
|
<a href=/people/b/beatrice-savoldi/>Beatrice Savoldi</a>
|
<a href=/people/m/matteo-negri/>Matteo Negri</a>
|
<a href=/people/m/mattia-a-di-gangi/>Mattia A. Di Gangi</a>
|
<a href=/people/r/roldano-cattoni/>Roldano Cattoni</a>
|
<a href=/people/m/marco-turchi/>Marco Turchi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--619><div class="card-body p-3 small">Translating from languages without productive <a href=https://en.wikipedia.org/wiki/Grammatical_gender>grammatical gender</a> like <a href=https://en.wikipedia.org/wiki/English_language>English</a> into gender-marked languages is a well-known difficulty for <a href=https://en.wikipedia.org/wiki/Machine_translation>machines</a>. This difficulty is also due to the fact that the training data on which <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> are built typically reflect the asymmetries of natural languages, <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> included. Exclusively fed with textual data, <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> is intrinsically constrained by the fact that the input sentence does not always contain clues about the gender identity of the referred human entities. But what happens with <a href=https://en.wikipedia.org/wiki/Speech_translation>speech translation</a>, where the input is an <a href=https://en.wikipedia.org/wiki/Audio_signal>audio signal</a>? Can <a href=https://en.wikipedia.org/wiki/Sound>audio</a> provide additional information to reduce gender bias? We present the first thorough investigation of gender bias in speech translation, contributing with : i) the release of a benchmark useful for future studies, and ii) the comparison of different technologies (cascade and end-to-end) on two language directions (English-Italian / French).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.621.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--621 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.621 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928788 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.621" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.621/>Closing the Gap : Joint De-Identification and Concept Extraction in the Clinical Domain</a></strong><br><a href=/people/l/lukas-lange/>Lukas Lange</a>
|
<a href=/people/h/heike-adel/>Heike Adel</a>
|
<a href=/people/j/jannik-strotgen/>Jannik Strtgen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--621><div class="card-body p-3 small">Exploiting <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> in the <a href=https://en.wikipedia.org/wiki/Medicine>clinical domain</a> requires de-identification, i.e., <a href=https://en.wikipedia.org/wiki/Data_anonymization>anonymization of personal information</a> in texts. However, current research considers <a href=https://en.wikipedia.org/wiki/De-identification>de-identification</a> and downstream tasks, such as concept extraction, only in isolation and does not study the effects of <a href=https://en.wikipedia.org/wiki/De-identification>de-identification</a> on other tasks. In this paper, we close this gap by reporting concept extraction performance on automatically anonymized data and investigating joint models for <a href=https://en.wikipedia.org/wiki/De-identification>de-identification</a> and concept extraction. In particular, we propose a stacked model with restricted access to <a href=https://en.wikipedia.org/wiki/Information_privacy>privacy sensitive information</a> and a multitask model. We set the new state of the art on <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a> in English (96.1 % F1 for <a href=https://en.wikipedia.org/wiki/De-identification>de-identification</a> and 88.9 % F1 for concept extraction) and Spanish (91.4 % F1 for concept extraction).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.623.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--623 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.623 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929128 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.623" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.623/>Estimating predictive uncertainty for rumour verification models</a></strong><br><a href=/people/e/elena-kochkina/>Elena Kochkina</a>
|
<a href=/people/m/maria-liakata/>Maria Liakata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--623><div class="card-body p-3 small">The inability to correctly resolve rumours circulating online can have harmful real-world consequences. We present a method for incorporating model and data uncertainty estimates into <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing models</a> for automatic rumour verification. We show that these estimates can be used to filter out model predictions likely to be erroneous so that these difficult instances can be prioritised by a human fact-checker. We propose two <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for uncertainty-based instance rejection, supervised and unsupervised. We also show how uncertainty estimates can be used to interpret <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance as a rumour unfolds.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.625.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--625 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.625 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928907 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.625/>Language to Network : Conditional Parameter Adaptation with Natural Language Descriptions</a></strong><br><a href=/people/t/tian-jin/>Tian Jin</a>
|
<a href=/people/z/zhun-liu/>Zhun Liu</a>
|
<a href=/people/s/shengjia-yan/>Shengjia Yan</a>
|
<a href=/people/a/alexandre-eichenberger/>Alexandre Eichenberger</a>
|
<a href=/people/l/louis-philippe-morency/>Louis-Philippe Morency</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--625><div class="card-body p-3 small">Transfer learning using ImageNet pre-trained models has been the de facto approach in a wide range of <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision tasks</a>. However, <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> still requires task-specific training data. In this paper, we propose N3 (Neural Networks from Natural Language)-a new paradigm of synthesizing task-specific neural networks from language descriptions and a generic pre-trained model. N3 leverages <a href=https://en.wikipedia.org/wiki/Linguistic_description>language descriptions</a> to generate parameter adaptations as well as a new task-specific classification layer for a pre-trained neural network, effectively fine-tuning the network for a new task using only <a href=https://en.wikipedia.org/wiki/Linguistic_description>language descriptions</a> as input. To the best of our knowledge, N3 is the first method to synthesize entire <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> from <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Experimental results show that N3 can out-perform previous natural-language based zero-shot learning methods across 4 different zero-shot image classification benchmarks. We also demonstrate a simple method to help identify keywords in <a href=https://en.wikipedia.org/wiki/Linguistic_description>language descriptions</a> leveraged by N3 when synthesizing <a href=https://en.wikipedia.org/wiki/Parameter_(computer_programming)>model parameters</a>.<b>N3</b> (<b>N</b>eural <b>N</b>etworks from <b>N</b>atural Language) - a new paradigm of synthesizing task-specific neural networks from language descriptions and a generic pre-trained model. <b>N3</b> leverages language descriptions to generate parameter adaptations as well as a new task-specific classification layer for a pre-trained neural network, effectively &#8220;fine-tuning&#8221; the network for a new task using only language descriptions as input. To the best of our knowledge, <b>N3</b> is the first method to synthesize entire neural networks from natural language. Experimental results show that <b>N3</b> can out-perform previous natural-language based zero-shot learning methods across 4 different zero-shot image classification benchmarks. We also demonstrate a simple method to help identify keywords in language descriptions leveraged by <b>N3</b> when synthesizing model parameters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.630.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--630 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.630 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928734 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.630" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.630/>tBERT : Topic Models and BERT Joining Forces for Semantic Similarity Detection<span class=acl-fixed-case>BERT</span>: Topic Models and <span class=acl-fixed-case>BERT</span> Joining Forces for Semantic Similarity Detection</a></strong><br><a href=/people/n/nicole-peinelt/>Nicole Peinelt</a>
|
<a href=/people/d/dong-nguyen/>Dong Nguyen</a>
|
<a href=/people/m/maria-liakata/>Maria Liakata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--630><div class="card-body p-3 small">Semantic similarity detection is a fundamental task in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. Adding <a href=https://en.wikipedia.org/wiki/Topic_and_comment>topic information</a> has been useful for previous feature-engineered semantic similarity models as well as neural models for other tasks. There is currently no standard way of combining topics with pretrained contextual representations such as BERT. We propose a novel topic-informed BERT-based architecture for pairwise semantic similarity detection and show that our model improves performance over strong neural baselines across a variety of English language datasets. We find that the addition of topics to BERT helps particularly with resolving domain-specific cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.633.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--633 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.633 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928964 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.633/>Out of the Echo Chamber : Detecting Countering Debate Speeches<span class=acl-fixed-case>D</span>etecting Countering Debate Speeches</a></strong><br><a href=/people/m/matan-orbach/>Matan Orbach</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/a/assaf-toledo/>Assaf Toledo</a>
|
<a href=/people/d/dan-lahav/>Dan Lahav</a>
|
<a href=/people/m/michal-jacovi/>Michal Jacovi</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--633><div class="card-body p-3 small">An educated and informed consumption of media content has become a challenge in modern times. With the shift from traditional news outlets to <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and similar venues, a major concern is that readers are becoming encapsulated in echo chambers and may fall prey to fake news and disinformation, lacking easy access to dissenting views. We suggest a novel task aiming to alleviate some of these concerns that of detecting articles that most effectively counter the arguments and not just the stance made in a given text. We study this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> in the context of <a href=https://en.wikipedia.org/wiki/Public_speaking>debate speeches</a>. Given such a <a href=https://en.wikipedia.org/wiki/Public_speaking>speech</a>, we aim to identify, from among a set of <a href=https://en.wikipedia.org/wiki/Public_speaking>speeches</a> on the same topic and with an opposing stance, the ones that directly counter it. We provide a large dataset of 3,685 such speeches (in English), annotated for this relation, which hopefully would be of general interest to the NLP community. We explore several <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> addressing this task, and while some are successful, all fall short of expert human performance, suggesting room for further research. All data collected during this work is freely available for research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.635.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--635 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.635 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928880 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.635" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.635/>KdConv : A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation<span class=acl-fixed-case>K</span>d<span class=acl-fixed-case>C</span>onv: A <span class=acl-fixed-case>C</span>hinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation</a></strong><br><a href=/people/h/hao-zhou/>Hao Zhou</a>
|
<a href=/people/c/chujie-zheng/>Chujie Zheng</a>
|
<a href=/people/k/kaili-huang/>Kaili Huang</a>
|
<a href=/people/m/minlie-huang/>Minlie Huang</a>
|
<a href=/people/x/xiaoyan-zhu/>Xiaoyan Zhu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--635><div class="card-body p-3 small">The research of knowledge-driven conversational systems is largely limited due to the lack of dialog data which consists of multi-turn conversations on multiple topics and with knowledge annotations. In this paper, we propose a Chinese multi-domain knowledge-driven conversation dataset, KdConv, which grounds the topics in multi-turn conversations to <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a>. Our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> contains 4.5 K conversations from three domains (film, <a href=https://en.wikipedia.org/wiki/Music>music</a>, and travel), and 86 K utterances with an <a href=https://en.wikipedia.org/wiki/Arithmetic_mean>average turn number</a> of 19.0. These <a href=https://en.wikipedia.org/wiki/Conversation>conversations</a> contain in-depth discussions on related topics and natural transition between multiple topics. To facilitate the following research on this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, we provide several benchmark models. Comparative results show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can be enhanced by introducing background knowledge, yet there is still a large space for leveraging <a href=https://en.wikipedia.org/wiki/Knowledge>knowledge</a> to model multi-turn conversations for further research. Results also show that there are obvious performance differences between different domains, indicating that it is worth further explore <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> and domain adaptation. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark models</a> are publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.638.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--638 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.638 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928730 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.638" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.638/>Multi-Domain Dialogue Acts and Response Co-Generation</a></strong><br><a href=/people/k/kai-wang/>Kai Wang</a>
|
<a href=/people/j/junfeng-tian/>Junfeng Tian</a>
|
<a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/x/xiaojun-quan/>Xiaojun Quan</a>
|
<a href=/people/j/jianxing-yu/>Jianxing Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--638><div class="card-body p-3 small">Generating fluent and informative responses is of critical importance for task-oriented dialogue systems. Existing pipeline approaches generally predict multiple dialogue acts first and use them to assist response generation. There are at least two shortcomings with such <a href=https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets>approaches</a>. First, the inherent structures of multi-domain dialogue acts are neglected. Second, the semantic associations between <a href=https://en.wikipedia.org/wiki/Action_(philosophy)>acts</a> and responses are not taken into account for response generation. To address these issues, we propose a neural co-generation model that generates dialogue acts and responses concurrently. Unlike those pipeline approaches, our act generation module preserves the semantic structures of multi-domain dialogue acts and our response generation module dynamically attends to different <a href=https://en.wikipedia.org/wiki/Action_(philosophy)>acts</a> as needed. We train the two <a href=https://en.wikipedia.org/wiki/Modular_programming>modules</a> jointly using an uncertainty loss to adjust their task weights adaptively. Extensive experiments are conducted on the large-scale MultiWOZ dataset and the results show that our model achieves very favorable improvement over several state-of-the-art models in both automatic and human evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.641.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--641 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.641 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929190 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.641/>Neural Data-to-Text Generation via Jointly Learning the Segmentation and Correspondence</a></strong><br><a href=/people/x/xiaoyu-shen/>Xiaoyu Shen</a>
|
<a href=/people/e/ernie-chang/>Ernie Chang</a>
|
<a href=/people/h/hui-su/>Hui Su</a>
|
<a href=/people/c/cheng-niu/>Cheng Niu</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--641><div class="card-body p-3 small">The neural attention model has achieved great success in data-to-text generation tasks. Though usually excelling at producing fluent text, it suffers from the problem of information missing, <a href=https://en.wikipedia.org/wiki/Repetition_(rhetorical_device)>repetition</a> and <a href=https://en.wikipedia.org/wiki/Hallucination>hallucination</a>. Due to the black-box nature of the neural attention architecture, avoiding these problems in a systematic way is non-trivial. To address this concern, we propose to explicitly segment target text into fragment units and align them with their data correspondences. The segmentation and correspondence are jointly learned as <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> without any human annotations. We further impose a soft statistical constraint to regularize the segmental granularity. The resulting architecture maintains the same <a href=https://en.wikipedia.org/wiki/Expressive_power_(computer_science)>expressive power</a> as neural attention models, while being able to generate fully interpretable outputs with several times less <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a>. On both E2E and WebNLG benchmarks, we show the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> consistently outperforms its neural attention counterparts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.647.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--647 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.647 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929453 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.647" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.647/>Null It Out : Guarding Protected Attributes by Iterative Nullspace Projection</a></strong><br><a href=/people/s/shauli-ravfogel/>Shauli Ravfogel</a>
|
<a href=/people/y/yanai-elazar/>Yanai Elazar</a>
|
<a href=/people/h/hila-gonen/>Hila Gonen</a>
|
<a href=/people/m/michael-twiton/>Michael Twiton</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--647><div class="card-body p-3 small">The ability to control for the kinds of information encoded in <a href=https://en.wikipedia.org/wiki/Neural_coding>neural representation</a> has a variety of use cases, especially in light of the challenge of interpreting these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. We present Iterative Null-space Projection (INLP), a novel method for removing information from neural representations. Our method is based on repeated training of linear classifiers that predict a certain property we aim to remove, followed by projection of the <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> on their null-space. By doing so, the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> become oblivious to that target property, making it hard to linearly separate the data according to it. While applicable for multiple uses, we evaluate our method on bias and fairness use-cases, and show that our method is able to mitigate bias in word embeddings, as well as to increase fairness in a setting of multi-class classification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.654.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--654 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.654 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929127 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.654/>Multi-source Meta Transfer for Low Resource Multiple-Choice Question Answering</a></strong><br><a href=/people/m/ming-yan/>Ming Yan</a>
|
<a href=/people/h/hao-zhang/>Hao Zhang</a>
|
<a href=/people/d/di-jin/>Di Jin</a>
|
<a href=/people/j/joey-tianyi-zhou/>Joey Tianyi Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--654><div class="card-body p-3 small">Multiple-choice question answering (MCQA) is one of the most challenging tasks in machine reading comprehension since it requires more advanced reading comprehension skills such as <a href=https://en.wikipedia.org/wiki/Logical_reasoning>logical reasoning</a>, <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, and <a href=https://en.wikipedia.org/wiki/Arithmetic>arithmetic operations</a>. Unfortunately, most existing MCQA datasets are small in size, which increases the difficulty of <a href=https://en.wikipedia.org/wiki/Machine_learning>model learning</a> and <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a>. To address this challenge, we propose a multi-source meta transfer (MMT) for low-resource MCQA. In this <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a>, we first extend <a href=https://en.wikipedia.org/wiki/Meta_learning_(computer_science)>meta learning</a> by incorporating multiple training sources to learn a generalized feature representation across domains. To bridge the distribution gap between training sources and the target, we further introduce the meta transfer that can be integrated into the multi-source meta training. More importantly, the proposed <a href=https://en.wikipedia.org/wiki/Model-driven_architecture>MMT</a> is independent of <a href=https://en.wikipedia.org/wiki/Backbone_network>backbone language models</a>. Extensive experiments demonstrate the superiority of MMT over <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-arts</a>, and continuous improvements can be achieved on different backbone networks on both supervised and unsupervised domain adaptation settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.657.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--657 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.657 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929402 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.657/>Premise Selection in Natural Language Mathematical Texts</a></strong><br><a href=/people/d/deborah-ferreira/>Deborah Ferreira</a>
|
<a href=/people/a/andre-freitas/>Andr Freitas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--657><div class="card-body p-3 small">The discovery of supporting evidence for addressing complex mathematical problems is a semantically challenging task, which is still unexplored in the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> for mathematical text. The <a href=https://en.wikipedia.org/wiki/Natural_language>natural language premise selection task</a> consists in using conjectures written in both <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> and mathematical formulae to recommend premises that most likely will be useful to prove a particular statement. We propose an approach to solve this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> as a link prediction problem, using <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Convolutional Graph Neural Networks</a>. This paper also analyses how different baselines perform in this task and shows that a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> can provide higher <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a>, especially when considering multi-hop premise selection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.658.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--658 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.658 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929161 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.658/>A Call for More Rigor in Unsupervised Cross-lingual Learning</a></strong><br><a href=/people/m/mikel-artetxe/>Mikel Artetxe</a>
|
<a href=/people/s/sebastian-ruder/>Sebastian Ruder</a>
|
<a href=/people/d/dani-yogatama/>Dani Yogatama</a>
|
<a href=/people/g/gorka-labaka/>Gorka Labaka</a>
|
<a href=/people/e/eneko-agirre/>Eneko Agirre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--658><div class="card-body p-3 small">We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world&#8217;s languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.665.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--665 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.665 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929432 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.665" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.665/>Shape of Synth to Come : Why We Should Use Synthetic Data for English Surface Realization<span class=acl-fixed-case>S</span>hape of Synth to Come: <span class=acl-fixed-case>W</span>hy We Should Use Synthetic Data for <span class=acl-fixed-case>E</span>nglish Surface Realization</a></strong><br><a href=/people/h/henry-elder/>Henry Elder</a>
|
<a href=/people/r/robert-burke/>Robert Burke</a>
|
<a href=/people/a/alexander-oconnor/>Alexander OConnor</a>
|
<a href=/people/j/jennifer-foster/>Jennifer Foster</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--665><div class="card-body p-3 small">The Surface Realization Shared Tasks of 2018 and 2019 were Natural Language Generation shared tasks with the goal of exploring approaches to surface realization from Universal-Dependency-like trees to surface strings for several languages. In the 2018 shared task there was very little difference in the absolute performance of systems trained with and without additional, synthetically created data, and a new rule prohibiting the use of synthetic data was introduced for the 2019 shared task. Contrary to the findings of the 2018 shared task, we show, in experiments on the English 2018 dataset, that the use of synthetic data can have a substantial positive effect an improvement of almost 8 BLEU points for a previously state-of-the-art system. We analyse the effects of synthetic data, and we argue that its use should be encouraged rather than prohibited so that future research efforts continue to explore <a href=https://en.wikipedia.org/wiki/System>systems</a> that can take advantage of such <a href=https://en.wikipedia.org/wiki/Data>data</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.666.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--666 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.666 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928916 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.666" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.666/>Toward Better Storylines with Sentence-Level Language Models</a></strong><br><a href=/people/d/daphne-ippolito/>Daphne Ippolito</a>
|
<a href=/people/d/david-grangier/>David Grangier</a>
|
<a href=/people/d/douglas-eck/>Douglas Eck</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--666><div class="card-body p-3 small">We propose a sentence-level language model which selects the next sentence in a story from a finite set of fluent alternatives. Since it does not need to model <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>, the sentence-level language model can focus on longer range dependencies, which are crucial for <a href=https://en.wikipedia.org/wiki/Coherence_(linguistics)>multi-sentence coherence</a>. Rather than dealing with individual words, our method treats the story so far as a list of pre-trained sentence embeddings and predicts an embedding for the next sentence, which is more efficient than predicting word embeddings. Notably this allows us to consider a large number of candidates for the next sentence during training. We demonstrate the effectiveness of our approach with state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on the unsupervised Story Cloze task and with promising results on larger-scale next sentence prediction tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.667.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--667 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.667 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928918 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.667/>A Two-Step Approach for Implicit Event Argument Detection</a></strong><br><a href=/people/z/zhisong-zhang/>Zhisong Zhang</a>
|
<a href=/people/x/xiang-kong/>Xiang Kong</a>
|
<a href=/people/z/zhengzhong-liu/>Zhengzhong Liu</a>
|
<a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--667><div class="card-body p-3 small">In this work, we explore the implicit event argument detection task, which studies <a href=https://en.wikipedia.org/wiki/Argument_(linguistics)>event arguments</a> beyond <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence boundaries</a>. The addition of cross-sentence argument candidates imposes great challenges for <a href=https://en.wikipedia.org/wiki/Mathematical_model>modeling</a>. To reduce the number of candidates, we adopt a two-step approach, decomposing the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> into two sub-problems : argument head-word detection and head-to-span expansion. Evaluated on the recent RAMS dataset (Ebner et al., 2020), our model achieves overall better performance than a strong sequence labeling baseline. We further provide detailed error analysis, presenting where the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> mainly makes errors and indicating directions for future improvements. It remains a challenge to detect implicit arguments, calling for more future work of document-level modeling for this task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.668.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--668 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.668 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929364 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.668" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.668/>Machine Reading of Historical Events</a></strong><br><a href=/people/o/or-honovich/>Or Honovich</a>
|
<a href=/people/l/lucas-torroba-hennigen/>Lucas Torroba Hennigen</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--668><div class="card-body p-3 small">Machine reading is an ambitious goal in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> that subsumes a wide range of text understanding capabilities. Within this broad framework, we address the task of machine reading the time of historical events, compile datasets for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, and develop a model for tackling it. Given a brief textual description of an event, we show that good performance can be achieved by extracting relevant sentences from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, and applying a combination of task-specific and general-purpose feature embeddings for the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>. Furthermore, we establish a link between the historical event ordering task and the event focus time task from the information retrieval literature, showing they also provide a challenging test case for machine reading algorithms.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.673.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--673 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.673 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929080 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.673/>Improving Disentangled Text Representation Learning with Information-Theoretic Guidance</a></strong><br><a href=/people/p/pengyu-cheng/>Pengyu Cheng</a>
|
<a href=/people/m/martin-renqiang-min/>Martin Renqiang Min</a>
|
<a href=/people/d/dinghan-shen/>Dinghan Shen</a>
|
<a href=/people/c/christopher-malon/>Christopher Malon</a>
|
<a href=/people/y/yizhe-zhang/>Yizhe Zhang</a>
|
<a href=/people/y/yitong-li/>Yitong Li</a>
|
<a href=/people/l/lawrence-carin/>Lawrence Carin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--673><div class="card-body p-3 small">Learning disentangled representations of natural language is essential for many NLP tasks, e.g., <a href=https://en.wikipedia.org/wiki/Conditional_(computer_programming)>conditional text generation</a>, style transfer, personalized dialogue systems, etc. Similar problems have been studied extensively for other forms of <a href=https://en.wikipedia.org/wiki/Data>data</a>, such as <a href=https://en.wikipedia.org/wiki/Image>images</a> and <a href=https://en.wikipedia.org/wiki/Video>videos</a>. However, the discrete nature of <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> makes the disentangling of <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual representations</a> more challenging (e.g., the manipulation over the data space can not be easily achieved). Inspired by <a href=https://en.wikipedia.org/wiki/Information_theory>information theory</a>, we propose a novel method that effectively manifests disentangled representations of text, without any supervision on semantics. A new mutual information upper bound is derived and leveraged to measure dependence between style and content. By minimizing this <a href=https://en.wikipedia.org/wiki/Upper_and_lower_bounds>upper bound</a>, the proposed method induces style and content embeddings into two independent low-dimensional spaces. Experiments on both conditional text generation and text-style transfer demonstrate the high quality of our disentangled representation in terms of content and style preservation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.676.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--676 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.676 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928687 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.676" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.676/>Good-Enough Compositional Data Augmentation</a></strong><br><a href=/people/j/jacob-andreas/>Jacob Andreas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--676><div class="card-body p-3 small">We propose a simple data augmentation protocol aimed at providing a compositional inductive bias in conditional and unconditional sequence models. Under this protocol, synthetic training examples are constructed by taking real training examples and replacing (possibly discontinuous) fragments with other fragments that appear in at least one similar environment. The <a href=https://en.wikipedia.org/wiki/Communication_protocol>protocol</a> is model-agnostic and useful for a variety of <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a>. Applied to neural sequence-to-sequence models, it reduces error rate by as much as 87 % on diagnostic tasks from the SCAN dataset and 16 % on a semantic parsing task. Applied to n-gram language models, it reduces perplexity by roughly 1 % on small corpora in several languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.681.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--681 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.681 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929304 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.681" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.681/>Towards Open Domain Event Trigger Identification using Adversarial Domain Adaptation</a></strong><br><a href=/people/a/aakanksha-naik/>Aakanksha Naik</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rose</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--681><div class="card-body p-3 small">We tackle the task of building supervised event trigger identification models which can generalize better across domains. Our work leverages the adversarial domain adaptation (ADA) framework to introduce domain-invariance. ADA uses adversarial training to construct representations that are predictive for trigger identification, but not predictive of the example&#8217;s domain. It requires no labeled data from the target domain, making <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> completely unsupervised. Experiments with two domains (English literature and news) show that ADA leads to an average F1 score improvement of 3.9 on out-of-domain data. Our best performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> (BERT-A) reaches 44-49 <a href=https://en.wikipedia.org/wiki/F-number>F1</a> across both domains, using no labeled target data. Preliminary experiments reveal that <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a> on 1 % labeled data, followed by self-training leads to substantial improvement, reaching 51.5 and 67.2 F1 on <a href=https://en.wikipedia.org/wiki/Literature>literature</a> and <a href=https://en.wikipedia.org/wiki/News>news</a> respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.684.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--684 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.684 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929361 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.684/>Learning Web-based Procedures by Reasoning over Explanations and Demonstrations in Context</a></strong><br><a href=/people/s/shashank-srivastava/>Shashank Srivastava</a>
|
<a href=/people/o/oleksandr-polozov/>Oleksandr Polozov</a>
|
<a href=/people/n/nebojsa-jojic/>Nebojsa Jojic</a>
|
<a href=/people/c/christopher-meek/>Christopher Meek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--684><div class="card-body p-3 small">We explore learning web-based tasks from a human teacher through <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language explanations</a> and a single demonstration. Our approach investigates a new direction for semantic parsing that models explaining a demonstration in a context, rather than mapping explanations to demonstrations. By leveraging the idea of inverse semantics from <a href=https://en.wikipedia.org/wiki/Program_synthesis>program synthesis</a> to reason backwards from observed demonstrations, we ensure that all considered interpretations are consistent with executable actions in any context, thus simplifying the problem of search over logical forms. We present a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of <a href=https://en.wikipedia.org/wiki/Explanation>explanations</a> paired with <a href=https://en.wikipedia.org/wiki/Demonstration_(teaching)>demonstrations</a> for <a href=https://en.wikipedia.org/wiki/Web_application>web-based tasks</a>. Our methods show better task completion rates than a supervised semantic parsing baseline (40 % relative improvement on average), and are competitive with simple exploration-and-demonstration based methods, while requiring no exploration of the environment. In learning to align explanations with demonstrations, basic properties of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language syntax</a> emerge as <a href=https://en.wikipedia.org/wiki/Learning>learned behavior</a>. This is an interesting example of pragmatic language acquisition without any linguistic annotation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.688.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--688 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.688 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929410 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.688/>In <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a>, What Does Transfer Learning Transfer?</a></strong><br><a href=/people/a/alham-fikri-aji/>Alham Fikri Aji</a>
|
<a href=/people/n/nikolay-bogoychev/>Nikolay Bogoychev</a>
|
<a href=/people/k/kenneth-heafield/>Kenneth Heafield</a>
|
<a href=/people/r/rico-sennrich/>Rico Sennrich</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--688><div class="card-body p-3 small">Transfer learning improves <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a> for low-resource machine translation, but it is unclear what exactly it transfers. We perform several <a href=https://en.wikipedia.org/wiki/Ablation>ablation studies</a> that limit <a href=https://en.wikipedia.org/wiki/Information_transfer>information transfer</a>, then measure the quality impact across three language pairs to gain a black-box understanding of <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>. Word embeddings play an important role in <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, particularly if they are properly aligned. Although <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> can be performed without <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>, results are sub-optimal. In contrast, transferring only the <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> but nothing else yields catastrophic results. We then investigate diagonal alignments with <a href=https://en.wikipedia.org/wiki/Auto-encoder>auto-encoders</a> over real languages and <a href=https://en.wikipedia.org/wiki/Random_sequence>randomly generated sequences</a>, finding even <a href=https://en.wikipedia.org/wiki/Random_sequence>randomly generated sequences</a> as parents yield noticeable but smaller gains. Finally, <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> can eliminate the need for a warm-up phase when training transformer models in high resource language pairs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.689.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--689 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.689 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929116 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.689/>Learning a Multi-Domain Curriculum for Neural Machine Translation</a></strong><br><a href=/people/w/wei-wang/>Wei Wang</a>
|
<a href=/people/y/ye-tian/>Ye Tian</a>
|
<a href=/people/j/jiquan-ngiam/>Jiquan Ngiam</a>
|
<a href=/people/y/yinfei-yang/>Yinfei Yang</a>
|
<a href=/people/i/isaac-caswell/>Isaac Caswell</a>
|
<a href=/people/z/zarana-parekh/>Zarana Parekh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--689><div class="card-body p-3 small">Most data selection research in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> focuses on improving a single domain. We perform data selection for multiple domains at once. This is achieved by carefully introducing instance-level domain-relevance features and automatically constructing a training curriculum to gradually concentrate on multi-domain relevant and noise-reduced data batches. Both the choice of <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> and the use of <a href=https://en.wikipedia.org/wiki/Curriculum>curriculum</a> are crucial for balancing and improving all domains, including out-of-domain. In large-scale experiments, the multi-domain curriculum simultaneously reaches or outperforms the individual performance and brings solid gains over no-curriculum training.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.690.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--690 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.690 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928755 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.690" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.690/>Reducing Gender Bias in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> as a Domain Adaptation Problem</a></strong><br><a href=/people/d/danielle-saunders/>Danielle Saunders</a>
|
<a href=/people/b/bill-byrne/>Bill Byrne</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--690><div class="card-body p-3 small">Training data for NLP tasks often exhibits <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> in that fewer sentences refer to women than to men. In Neural Machine Translation (NMT) <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> has been shown to reduce translation quality, particularly when the target language has <a href=https://en.wikipedia.org/wiki/Grammatical_gender>grammatical gender</a>. The recent WinoMT challenge set allows us to measure this effect directly (Stanovsky et al, 2019) Ideally we would reduce system bias by simply debiasing all data prior to training, but achieving this effectively is itself a challenge. Rather than attempt to create a &#8216;balanced&#8217; dataset, we use <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> on a small set of trusted, gender-balanced examples. This approach gives strong and consistent improvements in gender debiasing with much less <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a> than training from scratch. A known pitfall of <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> on new domains is &#8216;catastrophic forgetting&#8217;, which we address at <a href=https://en.wikipedia.org/wiki/Adaptation>adaptation</a> and inference time. During <a href=https://en.wikipedia.org/wiki/Adaptation>adaptation</a> we show that Elastic Weight Consolidation allows a performance trade-off between general translation quality and bias reduction. At inference time we propose a lattice-rescoring scheme which outperforms all systems evaluated in Stanovsky et al, 2019 on WinoMT with no degradation of general test set BLEU. We demonstrate our approach translating from <a href=https://en.wikipedia.org/wiki/English_language>English</a> into three languages with varied linguistic properties and data availability.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.694.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--694 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.694 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928909 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.694/>Variational Neural Machine Translation with Normalizing Flows</a></strong><br><a href=/people/h/hendra-setiawan/>Hendra Setiawan</a>
|
<a href=/people/m/matthias-sperber/>Matthias Sperber</a>
|
<a href=/people/u/udhyakumar-nallasamy/>Udhyakumar Nallasamy</a>
|
<a href=/people/m/matthias-paulik/>Matthias Paulik</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--694><div class="card-body p-3 small">Variational Neural Machine Translation (VNMT) is an attractive framework for modeling the generation of target translations, conditioned not only on the source sentence but also on some <a href=https://en.wikipedia.org/wiki/Latent_variable>latent random variables</a>. The latent variable modeling may introduce useful <a href=https://en.wikipedia.org/wiki/Dependent_and_independent_variables>statistical dependencies</a> that can improve translation accuracy. Unfortunately, learning informative latent variables is non-trivial, as the <a href=https://en.wikipedia.org/wiki/Latent_variable>latent space</a> can be prohibitively large, and the latent codes are prone to be ignored by many translation models at training time. Previous works impose strong assumptions on the distribution of the latent code and limit the choice of the NMT architecture. In this paper, we propose to apply the VNMT framework to the state-of-the-art Transformer and introduce a more flexible approximate posterior based on normalizing flows. We demonstrate the efficacy of our proposal under both in-domain and out-of-domain conditions, significantly outperforming strong baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.695.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--695 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.695 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928868 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.695" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.695/>The Paradigm Discovery Problem</a></strong><br><a href=/people/a/alexander-erdmann/>Alexander Erdmann</a>
|
<a href=/people/m/micha-elsner/>Micha Elsner</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--695><div class="card-body p-3 small">This work treats the paradigm discovery problem (PDP), the task of learning an inflectional morphological system from unannotated sentences. We formalize the <a href=https://en.wikipedia.org/wiki/Programmable_Data_Processor>PDP</a> and develop evaluation metrics for judging systems. Using currently available resources, we construct datasets for the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. We also devise a heuristic benchmark for the <a href=https://en.wikipedia.org/wiki/Programmed_Data_Processor>PDP</a> and report empirical results on five diverse languages. Our benchmark system first makes use of <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and <a href=https://en.wikipedia.org/wiki/String_similarity>string similarity</a> to cluster forms by cell and by <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a>. Then, we bootstrap a neural transducer on top of the clustered data to predict words to realize the empty paradigm slots. An error analysis of our <a href=https://en.wikipedia.org/wiki/System>system</a> suggests clustering by cell across different inflection classes is the most pressing challenge for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.697.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--697 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.697 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929122 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.697/>Automated Evaluation of Writing 50 Years and Counting</a></strong><br><a href=/people/b/beata-beigman-klebanov/>Beata Beigman Klebanov</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--697><div class="card-body p-3 small">In this theme paper, we focus on Automated Writing Evaluation (AWE), using Ellis Page&#8217;s seminal 1966 paper to frame the presentation. We discuss some of the current frontiers in the field and offer some thoughts on the emergent uses of this <a href=https://en.wikipedia.org/wiki/Technology>technology</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--700 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.700 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929062 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.700/>Returning the N to NLP : Towards Contextually Personalized Classification Models<span class=acl-fixed-case>N</span> to <span class=acl-fixed-case>NLP</span>: <span class=acl-fixed-case>T</span>owards Contextually Personalized Classification Models</a></strong><br><a href=/people/l/lucie-flek/>Lucie Flek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--700><div class="card-body p-3 small">Most NLP models today treat <a href=https://en.wikipedia.org/wiki/Language>language</a> as universal, even though socio- and psycholingustic research shows that the communicated message is influenced by the characteristics of the speaker as well as the target audience. This paper surveys the landscape of <a href=https://en.wikipedia.org/wiki/Personalization>personalization</a> in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and related fields, and offers a path forward to mitigate the decades of deviation of the NLP tools from sociolingustic findings, allowing to flexibly process the natural language of each user rather than enforcing a uniform NLP treatment. It outlines a possible direction to incorporate these aspects into neural NLP models by means of socially contextual personalization, and proposes to shift the focus of our evaluation strategies accordingly.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.701.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--701 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.701 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.701.Dataset.tgz data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928793 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.701/>To Test <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Comprehension</a>, Start by Defining Comprehension</a></strong><br><a href=/people/j/jesse-dunietz/>Jesse Dunietz</a>
|
<a href=/people/g/greg-burnham/>Greg Burnham</a>
|
<a href=/people/a/akash-bharadwaj/>Akash Bharadwaj</a>
|
<a href=/people/o/owen-rambow/>Owen Rambow</a>
|
<a href=/people/j/jennifer-chu-carroll/>Jennifer Chu-Carroll</a>
|
<a href=/people/d/dave-ferrucci/>Dave Ferrucci</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--701><div class="card-body p-3 small">Many <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> aim to measure machine reading comprehension (MRC), often focusing on question types presumed to be difficult. Rarely, however, do task designers start by considering what systems should in fact comprehend. In this paper we make two key contributions. First, we argue that existing approaches do not adequately define <a href=https://en.wikipedia.org/wiki/Comprehension_(logic)>comprehension</a> ; they are too unsystematic about what content is tested. Second, we present a detailed definition of comprehensiona Template of Understandingfor a widely useful class of texts, namely short narratives. We then conduct an experiment that strongly suggests existing <a href=https://en.wikipedia.org/wiki/System>systems</a> are not up to the task of <a href=https://en.wikipedia.org/wiki/Narrative>narrative understanding</a> as we define <a href=https://en.wikipedia.org/wiki/Information_technology>it</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.710.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--710 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.710 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929166 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.710" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.710/>One Size Does Not Fit All : Generating and Evaluating Variable Number of Keyphrases</a></strong><br><a href=/people/x/xingdi-yuan/>Xingdi Yuan</a>
|
<a href=/people/t/tong-wang/>Tong Wang</a>
|
<a href=/people/r/rui-meng/>Rui Meng</a>
|
<a href=/people/k/khushboo-thaker/>Khushboo Thaker</a>
|
<a href=/people/p/peter-brusilovsky/>Peter Brusilovsky</a>
|
<a href=/people/d/daqing-he/>Daqing He</a>
|
<a href=/people/a/adam-trischler/>Adam Trischler</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--710><div class="card-body p-3 small">Different texts shall by nature correspond to different number of keyphrases. This desideratum is largely missing from existing neural keyphrase generation models. In this study, we address this problem from both modeling and evaluation perspectives. We first propose a recurrent generative model that generates multiple <a href=https://en.wikipedia.org/wiki/Phrase>keyphrases</a> as delimiter-separated sequences. Generation diversity is further enhanced with two novel techniques by manipulating decoder hidden states. In contrast to previous approaches, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is capable of generating diverse <a href=https://en.wikipedia.org/wiki/Phrase>keyphrases</a> and controlling number of outputs. We further propose two evaluation metrics tailored towards the variable-number generation. We also introduce a new dataset StackEx that expands beyond the only existing genre (i.e., academic writing) in keyphrase generation tasks. With both previous and new evaluation metrics, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> on all datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.712.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--712 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.712 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928740 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.712" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.712/>Structural Information Preserving for Graph-to-Text Generation</a></strong><br><a href=/people/l/linfeng-song/>Linfeng Song</a>
|
<a href=/people/a/ante-wang/>Ante Wang</a>
|
<a href=/people/j/jinsong-su/>Jinsong Su</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/k/kun-xu/>Kun Xu</a>
|
<a href=/people/y/yubin-ge/>Yubin Ge</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--712><div class="card-body p-3 small">The task of graph-to-text generation aims at producing sentences that preserve the meaning of input graphs. As a crucial defect, the current state-of-the-art models may mess up or even drop the core structural information of input graphs when generating outputs. We propose to tackle this problem by leveraging richer training signals that can guide our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for preserving input information. In particular, we introduce two types of autoencoding losses, each individually focusing on different aspects (a.k.a. views) of input graphs. The losses are then back-propagated to better calibrate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> via multi-task training. Experiments on two <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a> for graph-to-text generation show the effectiveness of our approach over a state-of-the-art baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.713.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--713 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.713 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929257 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.713/>A Joint Neural Model for <a href=https://en.wikipedia.org/wiki/Information_extraction>Information Extraction</a> with Global Features</a></strong><br><a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/f/fei-huang/>Fei Huang</a>
|
<a href=/people/l/lingfei-wu/>Lingfei Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--713><div class="card-body p-3 small">Most existing joint neural models for Information Extraction (IE) use local task-specific classifiers to predict labels for individual instances (e.g., trigger, relation) regardless of their interactions. For example, a victim of a die event is likely to be a victim of an attack event in the same sentence. In order to capture such cross-subtask and cross-instance inter-dependencies, we propose a joint neural framework, OneIE, that aims to extract the globally optimal IE result as a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> from an input sentence. OneIE performs end-to-end IE in four stages : (1) Encoding a given sentence as contextualized word representations ; (2) Identifying entity mentions and event triggers as <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>nodes</a> ; (3) Computing label scores for all <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>nodes</a> and their pairwise links using local classifiers ; (4) Searching for the globally optimal graph with a beam decoder. At the decoding stage, we incorporate global features to capture the cross-subtask and cross-instance interactions. Experiments show that adding global features improves the performance of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and achieves new state of-the-art on all subtasks. In addition, as OneIE does not use any language-specific feature, we prove it can be easily applied to new languages or trained in a multilingual manner.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.716.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--716 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.716 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929261 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.716" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.716/>From English to <a href=https://en.wikipedia.org/wiki/Code-switching>Code-Switching</a> : <a href=https://en.wikipedia.org/wiki/Transfer_learning>Transfer Learning</a> with Strong Morphological Clues<span class=acl-fixed-case>E</span>nglish to Code-Switching: Transfer Learning with Strong Morphological Clues</a></strong><br><a href=/people/g/gustavo-aguilar/>Gustavo Aguilar</a>
|
<a href=/people/t/thamar-solorio/>Thamar Solorio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--716><div class="card-body p-3 small">Linguistic Code-switching (CS) is still an understudied phenomenon in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. The NLP community has mostly focused on monolingual and multi-lingual scenarios, but little attention has been given to CS in particular. This is partly because of the lack of resources and annotated data, despite its increasing occurrence in <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a>. In this paper, we aim at adapting <a href=https://en.wikipedia.org/wiki/Monolingualism>monolingual models</a> to code-switched text in various tasks. Specifically, we transfer English knowledge from a pre-trained ELMo model to different <a href=https://en.wikipedia.org/wiki/Code-switching>code-switched language pairs</a> (i.e., <a href=https://en.wikipedia.org/wiki/Nepali_language>Nepali-English</a>, Spanish-English, and Hindi-English) using the task of <a href=https://en.wikipedia.org/wiki/Language_identification>language identification</a>. Our method, CS-ELMo, is an extension of ELMo with a simple yet effective position-aware attention mechanism inside its character convolutions. We show the effectiveness of this transfer learning step by outperforming multilingual BERT and homologous CS-unaware ELMo models and establishing a new state of the art in CS tasks, such as NER and POS tagging. Our technique can be expanded to more English-paired code-switched languages, providing more resources to the CS community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.717.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--717 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.717 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928762 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.717/>Learning Interpretable Relationships between Entities, Relations and Concepts via Bayesian Structure Learning on Open Domain Facts<span class=acl-fixed-case>B</span>ayesian Structure Learning on Open Domain Facts</a></strong><br><a href=/people/j/jingyuan-zhang/>Jingyuan Zhang</a>
|
<a href=/people/m/mingming-sun/>Mingming Sun</a>
|
<a href=/people/y/yue-feng/>Yue Feng</a>
|
<a href=/people/p/ping-li/>Ping Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--717><div class="card-body p-3 small">Concept graphs are created as universal taxonomies for text understanding in the open-domain knowledge. The <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>nodes</a> in concept graphs include both <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entities</a> and concepts. The <a href=https://en.wikipedia.org/wiki/Edge_(geometry)>edges</a> are from entities to concepts, showing that an entity is an instance of a concept. In this paper, we propose the task of learning interpretable relationships from open-domain facts to enrich and refine concept graphs. The Bayesian network structures are learned from open-domain facts as the interpretable relationships between relations of facts and concepts of entities. We conduct extensive experiments on public English and Chinese datasets. Compared to the state-of-the-art methods, the learned network structures help improving the identification of concepts for <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entities</a> based on the relations of entities on both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.720.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--720 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.720 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.720.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.720.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929424 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.720" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.720/>Sources of Transfer in Multilingual Named Entity Recognition</a></strong><br><a href=/people/d/david-mueller/>David Mueller</a>
|
<a href=/people/n/nicholas-andrews/>Nicholas Andrews</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--720><div class="card-body p-3 small">Named-entities are inherently multilingual, and <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> in any given language may be limited. This motivates us to consider polyglot named-entity recognition (NER), where one model is trained using annotated data drawn from more than one language. However, a straightforward implementation of this simple idea does not always work in practice : naive training of NER models using annotated data drawn from multiple languages consistently underperforms <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on monolingual data alone, despite having access to more training data. The starting point of this paper is a simple solution to this problem, in which polyglot models are fine-tuned on monolingual data to consistently and significantly outperform their monolingual counterparts. To explain this phenomena, we explore the sources of multilingual transfer in polyglot NER models and examine the weight structure of polyglot models compared to their monolingual counterparts. We find that polyglot models efficiently share many parameters across languages and that <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> may utilize a large number of those parameters.<i>polyglot</i> named-entity recognition (NER), where one model is trained using annotated data drawn from more than one language. However, a straightforward implementation of this simple idea does not always work in practice: naive training of NER models using annotated data drawn from multiple languages consistently underperforms models trained on monolingual data alone, despite having access to more training data. The starting point of this paper is a simple solution to this problem, in which polyglot models are <i>fine-tuned</i> on monolingual data to consistently and significantly outperform their monolingual counterparts. To explain this phenomena, we explore the sources of multilingual transfer in polyglot NER models and examine the weight structure of polyglot models compared to their monolingual counterparts. We find that polyglot models efficiently share many parameters across languages and that fine-tuning may utilize a large number of those parameters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.721.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--721 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.721 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929243 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.721/>ZeroShotCeres : Zero-Shot Relation Extraction from Semi-Structured Webpages<span class=acl-fixed-case>Z</span>ero<span class=acl-fixed-case>S</span>hot<span class=acl-fixed-case>C</span>eres: Zero-Shot Relation Extraction from Semi-Structured Webpages</a></strong><br><a href=/people/c/colin-lockard/>Colin Lockard</a>
|
<a href=/people/p/prashant-shiralkar/>Prashant Shiralkar</a>
|
<a href=/people/x/xin-luna-dong/>Xin Luna Dong</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--721><div class="card-body p-3 small">In many documents, such as semi-structured webpages, textual semantics are augmented with additional information conveyed using visual elements including <a href=https://en.wikipedia.org/wiki/Page_layout>layout</a>, <a href=https://en.wikipedia.org/wiki/Typeface>font size</a>, and <a href=https://en.wikipedia.org/wiki/Color>color</a>. Prior work on <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a> from semi-structured websites has required learning an extraction model specific to a given <a href=https://en.wikipedia.org/wiki/Web_template_system>template</a> via either manually labeled or distantly supervised data from that template. In this work, we propose a solution for zero-shot open-domain relation extraction from webpages with a previously unseen template, including from websites with little overlap with existing sources of knowledge for distant supervision and websites in entirely new subject verticals. Our model uses a graph neural network-based approach to build a rich representation of text fields on a <a href=https://en.wikipedia.org/wiki/Web_page>webpage</a> and the relationships between them, enabling generalization to new templates. Experiments show this approach provides a 31 % F1 gain over a baseline for zero-shot extraction in a new subject vertical.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.723.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--723 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.723 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929150 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.723/>A Prioritization Model for Suicidality Risk Assessment</a></strong><br><a href=/people/h/han-chin-shing/>Han-Chin Shing</a>
|
<a href=/people/p/philip-resnik/>Philip Resnik</a>
|
<a href=/people/d/douglas-w-oard/>Douglas Oard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--723><div class="card-body p-3 small">We reframe <a href=https://en.wikipedia.org/wiki/Suicide_risk_assessment>suicide risk assessment</a> from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> as a ranking problem whose goal is maximizing detection of severely at-risk individuals given the time available. Building on measures developed for resource-bounded document retrieval, we introduce a well founded evaluation paradigm, and demonstrate using an expert-annotated test collection that meaningful improvements over plausible cascade model baselines can be achieved using an approach that jointly ranks individuals and their social media posts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.728.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--728 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.728 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928892 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.728" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.728/>History for Visual Dialog : Do we really need it?</a></strong><br><a href=/people/s/shubham-agarwal/>Shubham Agarwal</a>
|
<a href=/people/t/trung-bui/>Trung Bui</a>
|
<a href=/people/j/joon-young-lee/>Joon-Young Lee</a>
|
<a href=/people/i/ioannis-konstas/>Ioannis Konstas</a>
|
<a href=/people/v/verena-rieser/>Verena Rieser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--728><div class="card-body p-3 small">Visual Dialogue involves understanding the dialogue history (what has been discussed previously) and the current question (what is asked), in addition to grounding information in the image, to accurately generate the correct response. In this paper, we show that co-attention models which explicitly encode dialoh history outperform <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that do n&#8217;t, achieving state-of-the-art performance (72 % NDCG on val set). However, we also expose shortcomings of the crowdsourcing dataset collection procedure, by showing that dialogue history is indeed only required for a small amount of the data, and that the current evaluation metric encourages generic replies. To that end, we propose a challenging subset (VisdialConv) of the VisdialVal set and the benchmark NDCG of 63 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.733.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--733 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.733 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928759 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.733/>Frugal Paradigm Completion</a></strong><br><a href=/people/a/alexander-erdmann/>Alexander Erdmann</a>
|
<a href=/people/t/tom-kenter/>Tom Kenter</a>
|
<a href=/people/m/markus-becker/>Markus Becker</a>
|
<a href=/people/c/christian-schallhart/>Christian Schallhart</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--733><div class="card-body p-3 small">Lexica distinguishing all morphologically related forms of each <a href=https://en.wikipedia.org/wiki/Lexeme>lexeme</a> are crucial to many language technologies, yet building them is expensive. We propose a frugal paradigm completion approach that predicts all related forms in a morphological paradigm from as few manually provided forms as possible. It induces <a href=https://en.wikipedia.org/wiki/Typology_(linguistics)>typological information</a> during training which <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> uses to determine the best sources at test time. We evaluate our language-agnostic approach on 7 diverse languages. Compared to popular alternative approaches, ours reduces <a href=https://en.wikipedia.org/wiki/Manual_labour>manual labor</a> by 16-63 % and is the most robust to typological variation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.734.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--734 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.734 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928921 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.734" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.734/>Improving Chinese Word Segmentation with Wordhood Memory Networks<span class=acl-fixed-case>C</span>hinese Word Segmentation with Wordhood Memory Networks</a></strong><br><a href=/people/y/yuanhe-tian/>Yuanhe Tian</a>
|
<a href=/people/y/yan-song/>Yan Song</a>
|
<a href=/people/f/fei-xia/>Fei Xia</a>
|
<a href=/people/t/tong-zhang/>Tong Zhang</a>
|
<a href=/people/y/yonggang-wang/>Yonggang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--734><div class="card-body p-3 small">Contextual features always play an important role in Chinese word segmentation (CWS). Wordhood information, being one of the contextual features, is proved to be useful in many conventional character-based segmenters. However, this feature receives less attention in recent neural models and it is also challenging to design a framework that can properly integrate wordhood information from different wordhood measures to existing neural frameworks. In this paper, we therefore propose a neural framework, WMSeg, which uses memory networks to incorporate wordhood information with several popular encoder-decoder combinations for CWS. Experimental results on five benchmark datasets indicate the memory mechanism successfully models wordhood information for neural segmenters and helps WMSeg achieve state-of-the-art performance on all those <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. Further experiments and analyses also demonstrate the robustness of our proposed framework with respect to different wordhood measures and the efficiency of wordhood information in cross-domain experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.737.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--737 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.737 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929400 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.737" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.737/>Phonetic and Visual Priors for Decipherment of Informal Romanization<span class=acl-fixed-case>R</span>omanization</a></strong><br><a href=/people/m/maria-ryskina/>Maria Ryskina</a>
|
<a href=/people/m/matthew-r-gormley/>Matthew R. Gormley</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--737><div class="card-body p-3 small">Informal romanization is an idiosyncratic process used by humans in informal digital communication to encode non-Latin script languages into <a href=https://en.wikipedia.org/wiki/Latin_script>Latin character sets</a> found on common keyboards. Character substitution choices differ between users but have been shown to be governed by the same main principles observed across a variety of languagesnamely, character pairs are often associated through phonetic or visual similarity. We propose a noisy-channel WFST cascade model for deciphering the original non-Latin script from observed romanized text in an unsupervised fashion. We train our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> directly on romanized data from two languages : <a href=https://en.wikipedia.org/wiki/Egyptian_Arabic>Egyptian Arabic</a> and <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>. We demonstrate that adding <a href=https://en.wikipedia.org/wiki/Inductive_bias>inductive bias</a> through phonetic and visual priors on character mappings substantially improves the model&#8217;s performance on both languages, yielding results much closer to the supervised skyline. Finally, we introduce a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of <a href=https://en.wikipedia.org/wiki/Romanization_of_Russian>romanized Russian</a>, collected from a Russian social network website and partially annotated for our experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.738.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--738 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.738 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928722 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.738" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.738/>Active Learning for <a href=https://en.wikipedia.org/wiki/Coreference_resolution>Coreference Resolution</a> using Discrete Annotation</a></strong><br><a href=/people/b/belinda-z-li/>Belinda Z. Li</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--738><div class="card-body p-3 small">We improve upon pairwise annotation for active learning in <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>, by asking annotators to identify mention antecedents if a presented mention pair is deemed not coreferent. This simple modification, when combined with a novel mention clustering algorithm for selecting which examples to label, is much more efficient in terms of the performance obtained per annotation budget. In experiments with existing benchmark coreference datasets, we show that the signal from this additional question leads to significant performance gains per human-annotation hour. Future work can use our annotation protocol to effectively develop coreference models for new domains. Our code is publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.739.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--739 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.739 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928887 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.739/>Beyond Possession Existence : Duration and Co-Possession</a></strong><br><a href=/people/d/dhivya-chinnappa/>Dhivya Chinnappa</a>
|
<a href=/people/s/srikala-murugan/>Srikala Murugan</a>
|
<a href=/people/e/eduardo-blanco/>Eduardo Blanco</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--739><div class="card-body p-3 small">This paper introduces two tasks : determining (a) the duration of possession relations and (b) co-possessions, i.e., whether multiple possessors possess a possessee at the same time. We present new <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> on top of corpora annotating possession existence and experimental results. Regarding possession duration, we derive the time spans we work with empirically from <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> indicating lower and upper bounds. Regarding co-possessions, we use a binary label. Cohen&#8217;s kappa coefficients indicate substantial agreement, and experimental results show that <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> is more useful than the <a href=https://en.wikipedia.org/wiki/Image>image</a> for solving these tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.740.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--740 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.740 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Honorable Mention for Best Overall Paper"><i class="fas fa-award"></i></span><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929123 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.740" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.740/>Do nt Stop Pretraining : Adapt Language Models to Domains and Tasks</a></strong><br><a href=/people/s/suchin-gururangan/>Suchin Gururangan</a>
|
<a href=/people/a/ana-marasovic/>Ana Marasovi</a>
|
<a href=/people/s/swabha-swayamdipta/>Swabha Swayamdipta</a>
|
<a href=/people/k/kyle-lo/>Kyle Lo</a>
|
<a href=/people/i/iz-beltagy/>Iz Beltagy</a>
|
<a href=/people/d/doug-downey/>Doug Downey</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--740><div class="card-body p-3 small">Language models pretrained on text from a wide variety of sources form the foundation of today&#8217;s <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. In light of the success of these broad-coverage models, we investigate whether it is still helpful to tailor a pretrained <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to the domain of a target task. We present a study across four domains (biomedical and computer science publications, news, and reviews) and eight classification tasks, showing that a second phase of pretraining in-domain (domain-adaptive pretraining) leads to performance gains, under both high- and low-resource settings. Moreover, adapting to the task&#8217;s unlabeled data (task-adaptive pretraining) improves performance even after domain-adaptive pretraining. Finally, we show that adapting to a task corpus augmented using simple data selection strategies is an effective alternative, especially when resources for domain-adaptive pretraining might be unavailable. Overall, we consistently find that multi-phase adaptive pretraining offers large gains in task performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.742.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--742 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.742 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929266 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.742/>Exploring Unexplored Generalization Challenges for Cross-Database Semantic Parsing</a></strong><br><a href=/people/a/alane-suhr/>Alane Suhr</a>
|
<a href=/people/m/ming-wei-chang/>Ming-Wei Chang</a>
|
<a href=/people/p/peter-shaw/>Peter Shaw</a>
|
<a href=/people/k/kenton-lee/>Kenton Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--742><div class="card-body p-3 small">We study the task of cross-database semantic parsing (XSP), where a system that maps natural language utterances to executable SQL queries is evaluated on databases unseen during training. Recently, several <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, including Spider, were proposed to support development of XSP systems. We propose a challenging evaluation setup for cross-database semantic parsing, focusing on variation across <a href=https://en.wikipedia.org/wiki/Database_schema>database schemas</a> and in-domain language use. We re-purpose eight semantic parsing datasets that have been well-studied in the setting where in-domain training data is available, and instead use them as additional evaluation data for XSP systems instead. We build a <a href=https://en.wikipedia.org/wiki/System>system</a> that performs well on Spider, and find that it struggles to generalize to our re-purposed set. Our setup uncovers several generalization challenges for cross-database semantic parsing, demonstrating the need to use and develop diverse training and evaluation datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.743.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--743 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.743 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929211 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.743/>Predicting the Focus of Negation : Model and Error Analysis</a></strong><br><a href=/people/m/md-mosharaf-hossain/>Md Mosharaf Hossain</a>
|
<a href=/people/k/kathleen-hamilton/>Kathleen Hamilton</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a>
|
<a href=/people/e/eduardo-blanco/>Eduardo Blanco</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--743><div class="card-body p-3 small">The focus of a <a href=https://en.wikipedia.org/wiki/Negation>negation</a> is the set of tokens intended to be negated, and a key component for revealing affirmative alternatives to negated utterances. In this paper, we experiment with <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> to predict the focus of negation. Our main novelty is leveraging a scope detector to introduce the scope of negation as an additional input to the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a>. Experimental results show that doing so obtains the best results to date. Additionally, we perform a detailed error analysis providing insights into the main error categories, and analyze errors depending on whether the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> takes into account scope and context information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.744.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--744 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.744 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929153 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.744" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.744/>Structured Tuning for Semantic Role Labeling</a></strong><br><a href=/people/t/tao-li/>Tao Li</a>
|
<a href=/people/p/parth-anand-jawale/>Parth Anand Jawale</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--744><div class="card-body p-3 small">Recent neural network-driven semantic role labeling (SRL) systems have shown impressive improvements in F1 scores. These improvements are due to expressive input representations, which, at least at the surface, are orthogonal to knowledge-rich constrained decoding mechanisms that helped linear SRL models. Introducing the benefits of <a href=https://en.wikipedia.org/wiki/Mathematical_structure>structure</a> to inform neural models presents a methodological challenge. In this paper, we present a structured tuning framework to improve <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using softened constraints only at training time. Our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> leverages the expressiveness of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> and provides <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a> with structured loss components. We start with a strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> (RoBERTa) to validate the impact of our approach, and show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> outperforms the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> by learning to comply with declarative constraints. Additionally, our experiments with smaller training sizes show that we can achieve consistent improvements under low-resource scenarios.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.746.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--746 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.746 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929022 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.746/>Universal Decompositional Semantic Parsing</a></strong><br><a href=/people/e/elias-stengel-eskin/>Elias Stengel-Eskin</a>
|
<a href=/people/a/aaron-steven-white/>Aaron Steven White</a>
|
<a href=/people/s/sheng-zhang/>Sheng Zhang</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--746><div class="card-body p-3 small">We introduce a transductive model for parsing into Universal Decompositional Semantics (UDS) representations, which jointly learns to map natural language utterances into UDS graph structures and annotate the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> with decompositional semantic attribute scores. We also introduce a strong <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline model</a> for <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> into the UDS graph structure, and show that our transductive parser performs comparably while additionally performing attribute prediction. By analyzing the attribute prediction errors, we find the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> captures natural relationships between attribute groups.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.747.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--747 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.747 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928776 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.747" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.747/>Unsupervised Cross-lingual Representation Learning at Scale</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/k/kartikay-khandelwal/>Kartikay Khandelwal</a>
|
<a href=/people/n/naman-goyal/>Naman Goyal</a>
|
<a href=/people/v/vishrav-chaudhary/>Vishrav Chaudhary</a>
|
<a href=/people/g/guillaume-wenzek/>Guillaume Wenzek</a>
|
<a href=/people/f/francisco-guzman/>Francisco Guzmn</a>
|
<a href=/people/e/edouard-grave/>Edouard Grave</a>
|
<a href=/people/m/myle-ott/>Myle Ott</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/v/veselin-stoyanov/>Veselin Stoyanov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--747><div class="card-body p-3 small">This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6 % average accuracy on XNLI, +13 % average F1 score on MLQA, and +2.4 % F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7 % in XNLI accuracy for <a href=https://en.wikipedia.org/wiki/Swahili_language>Swahili</a> and 11.4 % for <a href=https://en.wikipedia.org/wiki/Urdu>Urdu</a> over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance ; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code and models publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.750.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--750 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.750 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929187 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.750/>Multi-Domain Named Entity Recognition with Genre-Aware and Agnostic Inference</a></strong><br><a href=/people/j/jing-wang/>Jing Wang</a>
|
<a href=/people/m/mayank-kulkarni/>Mayank Kulkarni</a>
|
<a href=/people/d/daniel-preotiuc-pietro/>Daniel Preotiuc-Pietro</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--750><div class="card-body p-3 small">Named entity recognition is a key component of many text processing pipelines and it is thus essential for this component to be robust to different types of input. However, domain transfer of NER models with data from multiple genres has not been widely studied. To this end, we conduct NER experiments in three predictive setups on data from : a) multiple domains ; b) multiple domains where the genre label is unknown at inference time ; c) domains not encountered in training. We introduce a new <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> tailored to this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> by using shared and private domain parameters and <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>. This consistently outperforms all other baseline and competitive methods on all three experimental setups, with differences ranging between +1.95 to +3.11 average F1 across multiple genres when compared to standard approaches. These results illustrate the challenges that need to be taken into account when building real-world NLP applications that are robust to various types of text and the methods that can help, at least partially, alleviate these issues.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.753.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--753 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.753 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929049 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.753/>Addressing Posterior Collapse with <a href=https://en.wikipedia.org/wiki/Mutual_information>Mutual Information</a> for Improved Variational Neural Machine Translation</a></strong><br><a href=/people/a/arya-d-mccarthy/>Arya D. McCarthy</a>
|
<a href=/people/x/xian-li/>Xian Li</a>
|
<a href=/people/j/jiatao-gu/>Jiatao Gu</a>
|
<a href=/people/n/ning-dong/>Ning Dong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--753><div class="card-body p-3 small">This paper proposes a simple and effective approach to address the problem of posterior collapse in conditional variational autoencoders (CVAEs). It thus improves performance of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation models</a> that use noisy or monolingual data, as well as in conventional settings. Extending Transformer and conditional VAEs, our proposed <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable model</a> measurably prevents posterior collapse by (1) using a modified evidence lower bound (ELBO) objective which promotes mutual information between the <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> and the target, and (2) guiding the <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> with an auxiliary bag-of-words prediction task. As a result, the proposed model yields improved translation quality compared to existing variational NMT models on WMT RoEn and DeEn. With <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> being effectively utilized, our model demonstrates improved <a href=https://en.wikipedia.org/wiki/Robust_statistics>robustness</a> over non-latent Transformer in handling uncertainty : exploiting noisy source-side monolingual data (up to +3.2 BLEU), and training with weakly aligned web-mined parallel data (up to +4.7 BLEU).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.755.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--755 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.755 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929225 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.755/>Evaluating Robustness to Input Perturbations for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/x/xing-niu/>Xing Niu</a>
|
<a href=/people/p/prashant-mathur/>Prashant Mathur</a>
|
<a href=/people/g/georgiana-dinu/>Georgiana Dinu</a>
|
<a href=/people/y/yaser-al-onaizan/>Yaser Al-Onaizan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--755><div class="card-body p-3 small">Neural Machine Translation (NMT) models are sensitive to <a href=https://en.wikipedia.org/wiki/Perturbation_theory_(quantum_mechanics)>small perturbations</a> in the input. Robustness to such perturbations is typically measured using translation quality metrics such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> on the noisy input. This paper proposes additional <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> which measure the relative degradation and changes in translation when small perturbations are added to the input. We focus on a class of models employing subword regularization to address <a href=https://en.wikipedia.org/wiki/Robust_statistics>robustness</a> and perform extensive evaluations of these models using the <a href=https://en.wikipedia.org/wiki/Robust_statistics>robustness measures</a> proposed. Results show that our proposed <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> reveal a clear trend of improved robustness to perturbations when subword regularization methods are used.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.760.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--760 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.760 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929026 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.760/>Clinical Concept Linking with Contextualized Neural Representations</a></strong><br><a href=/people/e/elliot-schumacher/>Elliot Schumacher</a>
|
<a href=/people/a/andriy-mulyar/>Andriy Mulyar</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--760><div class="card-body p-3 small">In traditional approaches to <a href=https://en.wikipedia.org/wiki/Entity_linking>entity linking</a>, linking decisions are based on three sources of information the similarity of the mention string to an entity&#8217;s name, the similarity of the context of the document to the entity, and broader information about the knowledge base (KB). In some domains, there is little contextual information present in the KB and thus we rely more heavily on mention string similarity. We consider one example of this, concept linking, which seeks to link mentions of medical concepts to a medical concept ontology. We propose an approach to concept linking that leverages recent work in contextualized neural models, such as ELMo (Peters et al. 2018), which create a token representation that integrates the surrounding context of the mention and concept name. We find a neural ranking approach paired with contextualized embeddings provides gains over a competitive baseline (Leaman et al. Additionally, we find that a pre-training step using <a href=https://en.wikipedia.org/wiki/Synonym>synonyms</a> from the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> offers a useful initialization for the ranker.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.771.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--771 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.771 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929362 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.771" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.771/>NILE : <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Inference</a> with Faithful Natural Language Explanations<span class=acl-fixed-case>NILE</span> : Natural Language Inference with Faithful Natural Language Explanations</a></strong><br><a href=/people/s/sawan-kumar/>Sawan Kumar</a>
|
<a href=/people/p/partha-talukdar/>Partha Talukdar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--771><div class="card-body p-3 small">The recent growth in the popularity and success of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a> on NLP classification tasks has accompanied the need for generating some form of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language explanation</a> of the predicted labels. Such generated <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language (NL) explanations</a> are expected to be faithful, i.e., they should correlate well with the model&#8217;s internal decision making. In this work, we focus on the task of natural language inference (NLI) and address the following question : can we build NLI systems which produce labels with high accuracy, while also generating faithful explanations of its decisions? We propose Natural-language Inference over Label-specific Explanations (NILE), a novel NLI method which utilizes auto-generated label-specific NL explanations to produce labels along with its faithful explanation. We demonstrate NILE&#8217;s effectiveness over previously reported methods through automated and human evaluation of the produced labels and explanations. Our evaluation of NILE also supports the claim that accurate <a href=https://en.wikipedia.org/wiki/System>systems</a> capable of providing testable explanations of their decisions can be designed. We discuss the faithfulness of NILE&#8217;s explanations in terms of sensitivity of the decisions to the corresponding explanations. We argue that explicit evaluation of faithfulness, in addition to label and explanation accuracy, is an important step in evaluating model&#8217;s explanations. Further, we demonstrate that task-specific probes are necessary to establish such sensitivity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.774.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--774 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.774 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929141 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.774/>Uncertain Natural Language Inference</a></strong><br><a href=/people/t/tongfei-chen/>Tongfei Chen</a>
|
<a href=/people/z/zheng-ping-jiang/>Zhengping Jiang</a>
|
<a href=/people/a/adam-poliak/>Adam Poliak</a>
|
<a href=/people/k/keisuke-sakaguchi/>Keisuke Sakaguchi</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--774><div class="card-body p-3 small">We introduce Uncertain Natural Language Inference (UNLI), a refinement of Natural Language Inference (NLI) that shifts away from categorical labels, targeting instead the direct prediction of subjective probability assessments. We demonstrate the feasibility of collecting annotations for UNLI by relabeling a portion of the SNLI dataset under a probabilistic scale, where items even with the same categorical label differ in how likely people judge them to be true given a premise. We describe a direct scalar regression modeling approach, and find that existing categorically-labeled NLI data can be used in pre-training. Our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> correlate well with humans, demonstrating <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are capable of more subtle inferences than the categorical bin assignment employed in current NLI tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.776.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--776 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.776 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929446 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.776/>Revisiting Higher-Order Dependency Parsers</a></strong><br><a href=/people/e/erick-fonseca/>Erick Fonseca</a>
|
<a href=/people/a/andre-f-t-martins/>Andr F. T. Martins</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--776><div class="card-body p-3 small">Neural encoders have allowed dependency parsers to shift from higher-order structured models to simpler first-order ones, making decoding faster and still achieving better accuracy than non-neural parsers. This has led to a belief that neural encoders can implicitly encode structural constraints, such as <a href=https://en.wikipedia.org/wiki/Sibling>siblings</a> and grandparents in a <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>tree</a>. We tested this hypothesis and found that <a href=https://en.wikipedia.org/wiki/Parsing>neural parsers</a> may benefit from higher-order features, even when employing a powerful pre-trained encoder, such as BERT. While the gains of higher-order features are small in the presence of a powerful <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a>, they are consistent for long-range dependencies and long sentences. In particular, higher-order models are more accurate on full sentence parses and on the exact match of modifier lists, indicating that they deal better with larger, more complex structures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.778.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--778 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.778 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929016 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.778" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.778/>Treebank Embedding Vectors for Out-of-Domain Dependency Parsing</a></strong><br><a href=/people/j/joachim-wagner/>Joachim Wagner</a>
|
<a href=/people/j/james-barry/>James Barry</a>
|
<a href=/people/j/jennifer-foster/>Jennifer Foster</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--778><div class="card-body p-3 small">A recent advance in monolingual dependency parsing is the idea of a <a href=https://en.wikipedia.org/wiki/Treebank>treebank embedding vector</a>, which allows all treebanks for a particular language to be used as training data while at the same time allowing the model to prefer training data from one treebank over others and to select the preferred <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a> at test time. We build on this idea by 1) introducing a method to predict a <a href=https://en.wikipedia.org/wiki/Treebank>treebank vector</a> for sentences that do not come from a <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a> used in training, and 2) exploring what happens when we move away from predefined treebank embedding vectors during test time and instead devise tailored interpolations. We show that 1) there are interpolated vectors that are superior to the predefined ones, and 2) treebank vectors can be predicted with sufficient accuracy, for nine out of ten test languages, to match the performance of an oracle approach that knows the most suitable predefined treebank embedding for the test set.</div></div></div><hr><div id=2020acl-demos><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.acl-demos/>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.acl-demos.0/>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</a></strong><br><a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928588 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.1/>Xiaomingbot : A Multilingual Robot News Reporter<span class=acl-fixed-case>X</span>iaomingbot: <span class=acl-fixed-case>A</span> <span class=acl-fixed-case>M</span>ultilingual <span class=acl-fixed-case>R</span>obot <span class=acl-fixed-case>N</span>ews <span class=acl-fixed-case>R</span>eporter</a></strong><br><a href=/people/r/runxin-xu/>Runxin Xu</a>
|
<a href=/people/j/jun-cao/>Jun Cao</a>
|
<a href=/people/m/mingxuan-wang/>Mingxuan Wang</a>
|
<a href=/people/j/jiaze-chen/>Jiaze Chen</a>
|
<a href=/people/h/hao-zhou/>Hao Zhou</a>
|
<a href=/people/y/ying-zeng/>Ying Zeng</a>
|
<a href=/people/y/yuping-wang/>Yuping Wang</a>
|
<a href=/people/l/li-chen/>Li Chen</a>
|
<a href=/people/x/xiang-yin/>Xiang Yin</a>
|
<a href=/people/x/xijin-zhang/>Xijin Zhang</a>
|
<a href=/people/s/songcheng-jiang/>Songcheng Jiang</a>
|
<a href=/people/y/yuxuan-wang/>Yuxuan Wang</a>
|
<a href=/people/l/lei-li/>Lei Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--1><div class="card-body p-3 small">This paper proposes the building of Xiaomingbot, an intelligent, multilingual and multimodal software robot equipped with four inte- gral capabilities : news generation, news translation, news reading and avatar animation. Its <a href=https://en.wikipedia.org/wiki/System>system</a> summarizes <a href=https://en.wikipedia.org/wiki/Media_of_China>Chinese news</a> that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> automatically generates from data tables. Next, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> translates the summary or the full article into multiple languages, and reads the multi- lingual rendition through <a href=https://en.wikipedia.org/wiki/Speech_synthesis>synthesized speech</a>. Notably, Xiaomingbot utilizes a voice cloning technology to synthesize the speech trained from a real person&#8217;s voice data in one input language. The proposed <a href=https://en.wikipedia.org/wiki/System>system</a> enjoys several merits : it has an <a href=https://en.wikipedia.org/wiki/Avatar_(computing)>animated avatar</a>, and is able to generate and read multilingual news. Since <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> was put into practice, Xiaomingbot has written over 600,000 articles, and gained over 150,000 followers on <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928594 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-demos.2" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.2/>TextBrewer : An Open-Source Knowledge Distillation Toolkit for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a><span class=acl-fixed-case>T</span>ext<span class=acl-fixed-case>B</span>rewer: <span class=acl-fixed-case>A</span>n <span class=acl-fixed-case>O</span>pen-<span class=acl-fixed-case>S</span>ource <span class=acl-fixed-case>K</span>nowledge <span class=acl-fixed-case>D</span>istillation <span class=acl-fixed-case>T</span>oolkit for <span class=acl-fixed-case>N</span>atural <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>P</span>rocessing</a></strong><br><a href=/people/z/ziqing-yang/>Ziqing Yang</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/z/zhipeng-chen/>Zhipeng Chen</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--2><div class="card-body p-3 small">In this paper, we introduce TextBrewer, an open-source knowledge distillation toolkit designed for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. It works with different neural network models and supports various kinds of supervised learning tasks, such as <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a>, <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>, <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a>. TextBrewer provides a simple and uniform workflow that enables quick setting up of <a href=https://en.wikipedia.org/wiki/Distillation>distillation</a> experiments with highly flexible configurations. It offers a set of predefined distillation methods and can be extended with custom code. As a case study, we use TextBrewer to distill BERT on several typical NLP tasks. With simple configurations, we achieve results that are comparable with or even higher than the public distilled BERT models with similar numbers of parameters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928604 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.6/>Personalized PageRank with Syntagmatic Information for Multilingual Word Sense Disambiguation<span class=acl-fixed-case>P</span>age<span class=acl-fixed-case>R</span>ank with Syntagmatic Information for Multilingual Word Sense Disambiguation</a></strong><br><a href=/people/f/federico-scozzafava/>Federico Scozzafava</a>
|
<a href=/people/m/marco-maru/>Marco Maru</a>
|
<a href=/people/f/fabrizio-brignone/>Fabrizio Brignone</a>
|
<a href=/people/g/giovanni-torrisi/>Giovanni Torrisi</a>
|
<a href=/people/r/roberto-navigli/>Roberto Navigli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--6><div class="card-body p-3 small">Exploiting syntagmatic information is an encouraging research focus to be pursued in an effort to close the gap between knowledge-based and supervised Word Sense Disambiguation (WSD) performance. We follow this direction in our next-generation knowledge-based WSD system, SyntagRank, which we make available via a Web interface and a RESTful API. SyntagRank leverages the disambiguated pairs of co-occurring words included in SyntagNet, a lexical-semantic combination resource, to perform state-of-the-art knowledge-based WSD in a multilingual setting. Our <a href=https://en.wikipedia.org/wiki/Service_(systems_architecture)>service</a> provides both a user-friendly interface, available at http://syntagnet.org/, and a RESTful endpoint to query the system programmatically (accessible at http://api.syntagnet.org/).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928620 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-demos.14" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.14/>Stanza : A Python Natural Language Processing Toolkit for Many Human Languages<span class=acl-fixed-case>S</span>tanza: A Python Natural Language Processing Toolkit for Many Human Languages</a></strong><br><a href=/people/p/peng-qi/>Peng Qi</a>
|
<a href=/people/y/yuhao-zhang/>Yuhao Zhang</a>
|
<a href=/people/y/yuhui-zhang/>Yuhui Zhang</a>
|
<a href=/people/j/jason-bolton/>Jason Bolton</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--14><div class="card-body p-3 small">We introduce Stanza, an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Stanza features a language-agnostic fully neural pipeline for text analysis, including <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a>, multi-word token expansion, <a href=https://en.wikipedia.org/wiki/Lemmatization>lemmatization</a>, part-of-speech and morphological feature tagging, dependency parsing, and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>. We have trained Stanza on a total of 112 datasets, including the Universal Dependencies treebanks and other multilingual corpora, and show that the same neural architecture generalizes well and achieves competitive performance on all languages tested. Additionally, Stanza includes a native Python interface to the widely used Java Stanford CoreNLP software, which further extends its functionality to cover other tasks such as <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> and <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a>. Source code, documentation, and pretrained models for 66 languages are available at https://stanfordnlp.github.io/stanza/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928595 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-demos.15" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.15/>jiant : A Software Toolkit for Research on General-Purpose Text Understanding Models</a></strong><br><a href=/people/y/yada-pruksachatkun/>Yada Pruksachatkun</a>
|
<a href=/people/p/phil-yeres/>Phil Yeres</a>
|
<a href=/people/h/haokun-liu/>Haokun Liu</a>
|
<a href=/people/j/jason-phang/>Jason Phang</a>
|
<a href=/people/p/phu-mon-htut/>Phu Mon Htut</a>
|
<a href=/people/a/alex-wang/>Alex Wang</a>
|
<a href=/people/i/ian-tenney/>Ian Tenney</a>
|
<a href=/people/s/samuel-bowman/>Samuel R. Bowman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--15><div class="card-body p-3 small">We introduce <a href=https://en.wikipedia.org/wiki/Jiant>jiant</a>, an open source toolkit for conducting multitask and transfer learning experiments on English NLU tasks. jiant enables modular and configuration driven experimentation with state-of-the-art models and a broad set of tasks for probing, <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, and multitask training experiments. jiant implements over 50 NLU tasks, including all GLUE and SuperGLUE benchmark tasks. We demonstrate that <a href=https://en.wikipedia.org/wiki/Jiant>jiant</a> reproduces published performance on a variety of <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> and models, e.g., RoBERTa and <a href=https://en.wikipedia.org/wiki/BERT>BERT</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928611 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-demos.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.16/>The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding<span class=acl-fixed-case>M</span>icrosoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding</a></strong><br><a href=/people/x/xiaodong-liu/>Xiaodong Liu</a>
|
<a href=/people/y/yu-wang/>Yu Wang</a>
|
<a href=/people/j/jianshu-ji/>Jianshu Ji</a>
|
<a href=/people/h/hao-cheng/>Hao Cheng</a>
|
<a href=/people/x/xueyun-zhu/>Xueyun Zhu</a>
|
<a href=/people/e/emmanuel-awa/>Emmanuel Awa</a>
|
<a href=/people/p/pengcheng-he/>Pengcheng He</a>
|
<a href=/people/w/weizhu-chen/>Weizhu Chen</a>
|
<a href=/people/h/hoifung-poon/>Hoifung Poon</a>
|
<a href=/people/g/guihong-cao/>Guihong Cao</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--16><div class="card-body p-3 small">We present MT-DNN, an open-source natural language understanding (NLU) toolkit that makes it easy for researchers and developers to train customized deep learning models. Built upon <a href=https://en.wikipedia.org/wiki/PyTorch>PyTorch</a> and Transformers, MT-DNN is designed to facilitate rapid customization for a broad spectrum of NLU tasks, using a variety of objectives (classification, regression, structured prediction) and <a href=https://en.wikipedia.org/wiki/Character_encoding>text encoders</a> (e.g., <a href=https://en.wikipedia.org/wiki/Random-access_memory>RNNs</a>, BERT, RoBERTa, UniLM). A unique feature of MT-DNN is its built-in support for robust and transferable learning using the adversarial multi-task learning paradigm. To enable efficient production deployment, MT-DNN supports multi-task knowledge distillation, which can substantially compress a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural model</a> without significant performance drop. We demonstrate the effectiveness of MT-DNN on a wide range of NLU applications across general and biomedical domains. The software and pre-trained models will be publicly available at https://github.com/namisan/mt-dnn.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928597 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-demos.19" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.19/>ConvLab-2 : An Open-Source Toolkit for Building, Evaluating, and Diagnosing Dialogue Systems<span class=acl-fixed-case>C</span>onv<span class=acl-fixed-case>L</span>ab-2: An Open-Source Toolkit for Building, Evaluating, and Diagnosing Dialogue Systems</a></strong><br><a href=/people/q/qi-zhu/>Qi Zhu</a>
|
<a href=/people/z/zheng-zhang/>Zheng Zhang</a>
|
<a href=/people/y/yan-fang/>Yan Fang</a>
|
<a href=/people/x/xiang-li/>Xiang Li</a>
|
<a href=/people/r/ryuichi-takanobu/>Ryuichi Takanobu</a>
|
<a href=/people/j/jinchao-li/>Jinchao Li</a>
|
<a href=/people/b/baolin-peng/>Baolin Peng</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a>
|
<a href=/people/x/xiaoyan-zhu/>Xiaoyan Zhu</a>
|
<a href=/people/m/minlie-huang/>Minlie Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--19><div class="card-body p-3 small">We present ConvLab-2, an open-source toolkit that enables researchers to build task-oriented dialogue systems with state-of-the-art models, perform an end-to-end evaluation, and diagnose the weakness of systems. As the successor of ConvLab, ConvLab-2 inherits ConvLab&#8217;s framework but integrates more powerful dialogue models and supports more datasets. Besides, we have developed an <a href=https://en.wikipedia.org/wiki/Analysis>analysis tool</a> and an <a href=https://en.wikipedia.org/wiki/Interactive_computing>interactive tool</a> to assist researchers in diagnosing <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a>. The analysis tool presents rich statistics and summarizes common mistakes from simulated dialogues, which facilitates error analysis and <a href=https://en.wikipedia.org/wiki/Systems_engineering>system improvement</a>. The interactive tool provides an <a href=https://en.wikipedia.org/wiki/User_interface>user interface</a> that allows developers to diagnose an assembled dialogue system by interacting with the <a href=https://en.wikipedia.org/wiki/System>system</a> and modifying the output of each system component.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928609 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.21/>Label Noise in Context</a></strong><br><a href=/people/m/michael-desmond/>Michael Desmond</a>
|
<a href=/people/c/catherine-finegan-dollak/>Catherine Finegan-Dollak</a>
|
<a href=/people/j/jeff-boston/>Jeff Boston</a>
|
<a href=/people/m/matt-arnold/>Matt Arnold</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--21><div class="card-body p-3 small">Label noiseincorrectly or ambiguously labeled training examplescan negatively impact model performance. Although noise detection techniques have been around for decades, practitioners rarely apply them, as manual noise remediation is a tedious process. Examples incorrectly flagged as <a href=https://en.wikipedia.org/wiki/Noise_(electronics)>noise</a> waste reviewers&#8217; time, and correcting label noise without guidance can be difficult. We propose LNIC, a noise-detection method that uses an example&#8217;s neighborhood within the training set to (a) reduce <a href=https://en.wikipedia.org/wiki/False_positives_and_false_negatives>false positives</a> and (b) provide an explanation as to why the ex- ample was flagged as noise. We demonstrate on several short-text classification datasets that LNIC outperforms the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state of the art</a> on measures of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> and <a href=https://en.wikipedia.org/wiki/F-number>F0.5-score</a>. We also show how LNIC&#8217;s training set context helps a reviewer to understand and correct label noise in a dataset. The LNIC tool lowers the barriers to label noise remediation, increasing its utility for NLP practitioners.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928624 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.24/>Photon : A Robust Cross-Domain Text-to-SQL System<span class=acl-fixed-case>P</span>hoton: A Robust Cross-Domain Text-to-<span class=acl-fixed-case>SQL</span> System</a></strong><br><a href=/people/j/jichuan-zeng/>Jichuan Zeng</a>
|
<a href=/people/x/xi-victoria-lin/>Xi Victoria Lin</a>
|
<a href=/people/s/steven-c-h-hoi/>Steven C.H. Hoi</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a>
|
<a href=/people/m/michael-lyu/>Michael Lyu</a>
|
<a href=/people/i/irwin-king/>Irwin King</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--24><div class="card-body p-3 small">Natural language interfaces to databases(NLIDB) democratize end user access to <a href=https://en.wikipedia.org/wiki/Relational_model>relational data</a>. Due to fundamental differences between <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language communication</a> and <a href=https://en.wikipedia.org/wiki/Computer_programming>programming</a>, it is common for end users to issue questions that are ambiguous to the system or fall outside the semantic scope of its underlying <a href=https://en.wikipedia.org/wiki/Query_language>query language</a>. We present PHOTON, a robust, modular, cross-domain NLIDB that can flag natural language input to which a SQL mapping can not be immediately determined. PHOTON consists of a strong neural semantic parser (63.2 % structure accuracy on the Spider dev benchmark), a human-in-the-loop question corrector, a <a href=https://en.wikipedia.org/wiki/Executable>SQL executor</a> and a response generator. The question corrector isa discriminative neural sequence editor which detects confusion span(s) in the input question and suggests rephrasing until a translatable input is given by the user or a maximum number of iterations are conducted. Experiments on simulated data show that the proposed method effectively improves the robustness of text-to-SQL system against untranslatable user input. The live demo of our system is available at http://www.naturalsql.com</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928590 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.27/>NLP Scholar : An Interactive Visual Explorer for Natural Language Processing Literature<span class=acl-fixed-case>NLP</span> Scholar: An Interactive Visual Explorer for Natural Language Processing Literature</a></strong><br><a href=/people/s/saif-mohammad/>Saif M. Mohammad</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--27><div class="card-body p-3 small">As part of the NLP Scholar project, we created a single unified dataset of NLP papers and their meta-information (including citation numbers), by extracting and aligning information from the <a href=https://en.wikipedia.org/wiki/ACL_Anthology>ACL Anthology</a> and <a href=https://en.wikipedia.org/wiki/Google_Scholar>Google Scholar</a>. In this paper, we describe several interconnected interactive visualizations (dashboards) that present various aspects of the data. Clicking on an item within a <a href=https://en.wikipedia.org/wiki/Data_visualization>visualization</a> or entering query terms in the search boxes filters the data in all visualizations in the <a href=https://en.wikipedia.org/wiki/Dashboard_(business)>dashboard</a>. This allows users to search for papers in the area of their interest, published within specific time periods, published by specified authors, etc. The interactive visualizations presented here, and the associated dataset of papers mapped to citations, have additional uses as well including understanding how the field is growing (both overall and across sub-areas), as well as quantifying the impact of different types of papers on subsequent publications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Honorable Mention for Best Demonstration Paper"><i class="fas fa-award"></i></span><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928622 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.32/>Prta : A System to Support the Analysis of Propaganda Techniques in the News<span class=acl-fixed-case>P</span>rta: A System to Support the Analysis of Propaganda Techniques in the News</a></strong><br><a href=/people/g/giovanni-da-san-martino/>Giovanni Da San Martino</a>
|
<a href=/people/s/shaden-shaar/>Shaden Shaar</a>
|
<a href=/people/y/yifan-zhang/>Yifan Zhang</a>
|
<a href=/people/s/seunghak-yu/>Seunghak Yu</a>
|
<a href=/people/a/alberto-barron-cedeno/>Alberto Barrn-Cedeo</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--32><div class="card-body p-3 small">Recent events, such as the 2016 US Presidential Campaign, <a href=https://en.wikipedia.org/wiki/Brexit>Brexit</a> and the COVID-19 infodemic, have brought into the spotlight the dangers of online disinformation. There has been a lot of research focusing on <a href=https://en.wikipedia.org/wiki/Fact-checking>fact-checking</a> and disinformation detection. However, little attention has been paid to the specific <a href=https://en.wikipedia.org/wiki/Rhetorical_techniques>rhetorical and psychological techniques</a> used to convey <a href=https://en.wikipedia.org/wiki/Propaganda>propaganda messages</a>. Revealing the use of such techniques can help promote <a href=https://en.wikipedia.org/wiki/Media_literacy>media literacy</a> and <a href=https://en.wikipedia.org/wiki/Critical_thinking>critical thinking</a>, and eventually contribute to limiting the impact of fake news and <a href=https://en.wikipedia.org/wiki/Disinformation>disinformation campaigns</a>. Prta (Propaganda Persuasion Techniques Analyzer) allows users to explore the articles crawled on a regular basis by highlighting the spans in which propaganda techniques occur and to compare them on the basis of their use of propaganda techniques. The system further reports statistics about the use of such techniques, overall and over time, or according to filtering criteria specified by the user based on time interval, <a href=https://en.wikipedia.org/wiki/Index_term>keywords</a>, and/or political orientation of the media. Moreover, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> allows users to analyze any text or URL through a dedicated interface or via an API. The <a href=https://en.wikipedia.org/wiki/System>system</a> is available online : https://www.tanbih.org/prta.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.37.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--37 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.37 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928587 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.37/>MMPE : A Multi-Modal Interface using Handwriting, Touch Reordering, and Speech Commands for Post-Editing Machine Translation<span class=acl-fixed-case>MMPE</span>: <span class=acl-fixed-case>A</span> <span class=acl-fixed-case>M</span>ulti-<span class=acl-fixed-case>M</span>odal <span class=acl-fixed-case>I</span>nterface using <span class=acl-fixed-case>H</span>andwriting, <span class=acl-fixed-case>T</span>ouch <span class=acl-fixed-case>R</span>eordering, and <span class=acl-fixed-case>S</span>peech <span class=acl-fixed-case>C</span>ommands for <span class=acl-fixed-case>P</span>ost-<span class=acl-fixed-case>E</span>diting <span class=acl-fixed-case>M</span>achine <span class=acl-fixed-case>T</span>ranslation</a></strong><br><a href=/people/n/nico-herbig/>Nico Herbig</a>
|
<a href=/people/s/santanu-pal/>Santanu Pal</a>
|
<a href=/people/t/tim-duwel/>Tim Dwel</a>
|
<a href=/people/k/kalliopi-meladaki/>Kalliopi Meladaki</a>
|
<a href=/people/m/mahsa-monshizadeh/>Mahsa Monshizadeh</a>
|
<a href=/people/v/vladislav-hnatovskiy/>Vladislav Hnatovskiy</a>
|
<a href=/people/a/antonio-kruger/>Antonio Krger</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--37><div class="card-body p-3 small">The shift from traditional <a href=https://en.wikipedia.org/wiki/Translation>translation</a> to post-editing (PE) of machine-translated (MT) text can save time and reduce errors, but it also affects the design of <a href=https://en.wikipedia.org/wiki/Translation>translation interfaces</a>, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Since this paradigm shift offers potential for modalities other than <a href=https://en.wikipedia.org/wiki/Computer_mouse>mouse</a> and <a href=https://en.wikipedia.org/wiki/Computer_keyboard>keyboard</a>, we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT. Users can directly cross out or hand-write new text, drag and drop words for reordering, or use spoken commands to update the text in place. All text manipulations are logged in an easily interpretable format to simplify subsequent translation process research. The results of an evaluation with professional translators suggest that pen and touch interaction are suitable for deletion and reordering tasks, while speech and multi-modal combinations of select & speech are considered suitable for replacements and insertions. Overall, experiment participants were enthusiastic about the new modalities and saw them as useful extensions to mouse & keyboard, but not as a complete substitute.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.39.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--39 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.39 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928605 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.39/>Conversation Learner-A Machine Teaching Tool for Building Dialog Managers for Task-Oriented Dialog Systems<span class=acl-fixed-case>C</span>onversation <span class=acl-fixed-case>L</span>earner - A Machine Teaching Tool for Building Dialog Managers for Task-Oriented Dialog Systems</a></strong><br><a href=/people/s/swadheen-shukla/>Swadheen Shukla</a>
|
<a href=/people/l/lars-liden/>Lars Liden</a>
|
<a href=/people/s/shahin-shayandeh/>Shahin Shayandeh</a>
|
<a href=/people/e/eslam-kamal/>Eslam Kamal</a>
|
<a href=/people/j/jinchao-li/>Jinchao Li</a>
|
<a href=/people/m/matt-mazzola/>Matt Mazzola</a>
|
<a href=/people/t/thomas-park/>Thomas Park</a>
|
<a href=/people/b/baolin-peng/>Baolin Peng</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--39><div class="card-body p-3 small">Traditionally, industry solutions for building a task-oriented dialog system have relied on helping dialog authors define rule-based dialog managers, represented as dialog flows. While dialog flows are intuitively interpretable and good for simple scenarios, they fall short of performance in terms of the flexibility needed to handle complex dialogs. On the other hand, purely machine-learned models can handle complex dialogs, but they are considered to be black boxes and require large amounts of training data. In this demonstration, we showcase Conversation Learner, a machine teaching tool for building dialog managers. It combines the best of both approaches by enabling dialog authors to create a dialog flow using familiar tools, converting the dialog flow into a parametric model (e.g., neural networks), and allowing dialog authors to improve the <a href=https://en.wikipedia.org/wiki/Dialog_manager>dialog manager</a> (i.e., the parametric model) over time by leveraging user-system dialog logs as training data through a machine teaching interface.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-demos.41.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-demos--41 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-demos.41 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928607 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-demos.41" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-demos.41/>SUPP.AI : finding evidence for supplement-drug interactions<span class=acl-fixed-case>SUPP</span>.<span class=acl-fixed-case>AI</span>: finding evidence for supplement-drug interactions</a></strong><br><a href=/people/l/lucy-wang/>Lucy Wang</a>
|
<a href=/people/o/oyvind-tafjord/>Oyvind Tafjord</a>
|
<a href=/people/a/arman-cohan/>Arman Cohan</a>
|
<a href=/people/s/sarthak-jain/>Sarthak Jain</a>
|
<a href=/people/s/sam-skjonsberg/>Sam Skjonsberg</a>
|
<a href=/people/c/carissa-schoenick/>Carissa Schoenick</a>
|
<a href=/people/n/nick-botner/>Nick Botner</a>
|
<a href=/people/w/waleed-ammar/>Waleed Ammar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-demos--41><div class="card-body p-3 small">Dietary supplements are used by a large portion of the population, but information on their <a href=https://en.wikipedia.org/wiki/Drug_interaction>pharmacologic interactions</a> is incomplete. To address this challenge, we present SUPP.AI, an <a href=https://en.wikipedia.org/wiki/Application_software>application</a> for browsing evidence of supplement-drug interactions (SDIs) extracted from the <a href=https://en.wikipedia.org/wiki/Medical_literature>biomedical literature</a>. We train a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to automatically extract <a href=https://en.wikipedia.org/wiki/Supplement_(publishing)>supplement information</a> and identify such <a href=https://en.wikipedia.org/wiki/Interaction_(statistics)>interactions</a> from the <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific literature</a>. To address the lack of labeled data for SDI identification, we use labels of the closely related task of identifying drug-drug interactions (DDIs) for supervision. We fine-tune the contextualized word representations of the RoBERTa language model using labeled DDI data, and apply the fine-tuned <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to identify supplement interactions. We extract 195k evidence sentences from 22 M articles (P=0.82, R=0.58, F1=0.68) for 60k interactions. We create the SUPP.AI application for users to search evidence sentences extracted by our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. SUPP.AI is an attempt to close the information gap on <a href=https://en.wikipedia.org/wiki/Dietary_supplement>dietary supplements</a> by making up-to-date evidence on SDIs more discoverable for researchers, clinicians, and consumers. An informational video on how to use SUPP.AI is available at : https://youtu.be/dR0ucKdORwc</div></div></div><hr><div id=2020acl-srw><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.acl-srw/>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.acl-srw.0/>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></strong><br><a href=/people/s/shruti-rijhwani/>Shruti Rijhwani</a>
|
<a href=/people/j/jiangming-liu/>Jiangming Liu</a>
|
<a href=/people/y/yizhong-wang/>Yizhong Wang</a>
|
<a href=/people/r/rotem-dror/>Rotem Dror</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928637 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-srw.1" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.1/>Adaptive Transformers for Learning Multimodal Representations</a></strong><br><a href=/people/p/prajjwal-bhargava/>Prajjwal Bhargava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--1><div class="card-body p-3 small">The usage of <a href=https://en.wikipedia.org/wiki/Transformer>transformers</a> has grown from learning about <a href=https://en.wikipedia.org/wiki/Semantics>language semantics</a> to forming meaningful visiolinguistic representations. These <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> are often over-parametrized, requiring large amounts of computation. In this work, we extend adaptive approaches to learn more about <a href=https://en.wikipedia.org/wiki/Interpretability>model interpretability</a> and computational efficiency. Specifically, we study <a href=https://en.wikipedia.org/wiki/Attention_span>attention spans</a>, sparse, and structured dropout methods to help understand how their <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a> extends for vision and language tasks. We further show that these approaches can help us learn more about how the <a href=https://en.wikipedia.org/wiki/Neural_network>network</a> perceives the complexity of input sequences, sparsity preferences for different modalities, and other related phenomena.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928640 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.3/>Unsupervised Paraphasia Classification in <a href=https://en.wikipedia.org/wiki/Aphasia>Aphasic Speech</a></a></strong><br><a href=/people/s/sharan-pai/>Sharan Pai</a>
|
<a href=/people/n/nikhil-sachdeva/>Nikhil Sachdeva</a>
|
<a href=/people/p/prince-sachdeva/>Prince Sachdeva</a>
|
<a href=/people/r/rajiv-shah/>Rajiv Ratn Shah</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--3><div class="card-body p-3 small">Aphasia is a <a href=https://en.wikipedia.org/wiki/Speech-language_pathology>speech and language disorder</a> which results from <a href=https://en.wikipedia.org/wiki/Brain_damage>brain damage</a>, often characterized by word retrieval deficit (anomia) resulting in naming errors (paraphasia). Automatic paraphasia detection has many benefits for both treatment and diagnosis of Aphasia and its type. But supervised learning methods ca nt be properly utilized as there is a lack of aphasic speech data. In this paper, we describe our novel <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised method</a> which can be implemented without the need for labeled paraphasia data. Our evaluations show that our method outperforms previous work based on <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning</a> and transfer learning approaches for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We demonstrate the utility of our method as an essential first step in developing augmentative and alternative communication (AAC) devices for patients suffering from <a href=https://en.wikipedia.org/wiki/Aphasia>aphasia</a> in any language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928636 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.5/>Grammatical Error Correction Using Pseudo Learner Corpus Considering Learners Error Tendency</a></strong><br><a href=/people/y/yujin-takahashi/>Yujin Takahashi</a>
|
<a href=/people/s/satoru-katsumata/>Satoru Katsumata</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--5><div class="card-body p-3 small">Recently, several studies have focused on improving the performance of grammatical error correction (GEC) tasks using pseudo data. However, a large amount of pseudo data are required to train an accurate GEC model. To address the limitations of language and computational resources, we assume that introducing pseudo errors into sentences similar to those written by the language learners is more efficient, rather than incorporating random pseudo errors into monolingual data. In this regard, we study the effect of pseudo data on GEC task performance using two approaches. First, we extract sentences that are similar to the learners&#8217; sentences from monolingual data. Second, we generate realistic pseudo errors by considering error types that learners often make. Based on our comparative results, we observe that <a href=https://en.wikipedia.org/wiki/F-number>F0.5 scores</a> for the Russian GEC task are significantly improved.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928639 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.12/>Media Bias, the <a href=https://en.wikipedia.org/wiki/Social_science>Social Sciences</a>, and <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> : Automating Frame Analyses to Identify Bias by Word Choice and Labeling<span class=acl-fixed-case>NLP</span>: Automating Frame Analyses to Identify Bias by Word Choice and Labeling</a></strong><br><a href=/people/f/felix-hamborg/>Felix Hamborg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--12><div class="card-body p-3 small">Media bias can strongly impact the public perception of topics reported in the news. A difficult to detect, yet powerful form of slanted news coverage is called bias by word choice and labeling (WCL). WCL bias can occur, for example, when journalists refer to the same semantic concept by using different terms that frame the concept differently and consequently may lead to different assessments by readers, such as the terms <a href=https://en.wikipedia.org/wiki/Resistance_movement>freedom fighters</a> and <a href=https://en.wikipedia.org/wiki/Terrorism>terrorists</a>, or <a href=https://en.wikipedia.org/wiki/Gun_politics_in_the_United_States>gun rights</a> and <a href=https://en.wikipedia.org/wiki/Gun_control>gun control</a>. In this research project, I aim to devise methods that identify instances of WCL bias and estimate the frames they induce, e.g., not only is terrorists of negative polarity but also ascribes to <a href=https://en.wikipedia.org/wiki/Aggression>aggression</a> and <a href=https://en.wikipedia.org/wiki/Fear>fear</a>. To achieve this, I plan to research methods using <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> while employing models and using analysis concepts from the <a href=https://en.wikipedia.org/wiki/Social_science>social sciences</a>, where researchers have studied <a href=https://en.wikipedia.org/wiki/Media_bias>media bias</a> for decades. The first results indicate the effectiveness of this <a href=https://en.wikipedia.org/wiki/Interdisciplinarity>interdisciplinary research approach</a>. My vision is to devise a system that helps news readers to become aware of the differences in media coverage caused by bias.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928649 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.13/>SCAR : Sentence Compression using Autoencoders for Reconstruction<span class=acl-fixed-case>SCAR</span>: Sentence Compression using Autoencoders for Reconstruction</a></strong><br><a href=/people/c/chanakya-malireddy/>Chanakya Malireddy</a>
|
<a href=/people/t/tirth-maniar/>Tirth Maniar</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--13><div class="card-body p-3 small">Sentence compression is the task of shortening a sentence while retaining its meaning. Most methods proposed for this task rely on labeled or paired corpora (containing pairs of verbose and compressed sentences), which is often expensive to collect. To overcome this limitation, we present a novel unsupervised deep learning framework (SCAR) for deletion-based sentence compression. SCAR is primarily composed of two encoder-decoder pairs : a <a href=https://en.wikipedia.org/wiki/Dynamic_range_compression>compressor</a> and a <a href=https://en.wikipedia.org/wiki/Reconstructor>reconstructor</a>. The <a href=https://en.wikipedia.org/wiki/Dynamic_range_compression>compressor</a> masks the input, and the <a href=https://en.wikipedia.org/wiki/Reconstructor>reconstructor</a> tries to regenerate it. The <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> is entirely trained on unlabeled data and does not require additional inputs such as explicit syntactic information or optimal compression length. SCAR&#8217;s merit lies in the novel Linkage Loss function, which correlates the compressor and its effect on reconstruction, guiding it to drop inferable tokens. SCAR achieves higher ROUGE scores on benchmark datasets than the existing state-of-the-art methods and baselines. We also conduct a <a href=https://en.wikipedia.org/wiki/User_study>user study</a> to demonstrate the application of our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> as a text highlighting system. Using our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to underscore salient information facilitates speed-reading and reduces the time required to skim a document.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928652 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.15/>Multi-Task Neural Model for Agglutinative Language Translation</a></strong><br><a href=/people/y/yirong-pan/>Yirong Pan</a>
|
<a href=/people/x/xiao-li/>Xiao Li</a>
|
<a href=/people/y/yating-yang/>Yating Yang</a>
|
<a href=/people/r/rui-dong/>Rui Dong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--15><div class="card-body p-3 small">Neural machine translation (NMT) has achieved impressive performance recently by using large-scale parallel corpora. However, it struggles in the low-resource and morphologically-rich scenarios of agglutinative language translation task. Inspired by the finding that monolingual data can greatly improve the NMT performance, we propose a multi-task neural model that jointly learns to perform <a href=https://en.wikipedia.org/wiki/Bi-directional_translation>bi-directional translation</a> and <a href=https://en.wikipedia.org/wiki/Stemming>agglutinative language stemming</a>. Our approach employs the shared encoder and decoder to train a single model without changing the standard NMT architecture but instead adding a token before each source-side sentence to specify the desired target outputs of the two different tasks. Experimental results on Turkish-English and Uyghur-Chinese show that our proposed approach can significantly improve the <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance on agglutinative languages by using a small amount of monolingual data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928655 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.18/>Why is penguin more similar to <a href=https://en.wikipedia.org/wiki/Polar_bear>polar bear</a> than to <a href=https://en.wikipedia.org/wiki/Sea_gull>sea gull</a>? Analyzing conceptual knowledge in distributional models</a></strong><br><a href=/people/p/pia-sommerauer/>Pia Sommerauer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--18><div class="card-body p-3 small">What do powerful <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> of word mean- ing created from <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional data</a> (e.g. Word2vec (Mikolov et al., 2013) BERT (Devlin et al., 2019) and ELMO (Peters et al., 2018)) represent? What causes words to be similar in the <a href=https://en.wikipedia.org/wiki/Semantic_space>semantic space</a>? What type of information is lacking? This thesis proposal presents a <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> for investigating the information encoded in distributional semantic models. Several <a href=https://en.wikipedia.org/wiki/Mathematical_analysis>analysis methods</a> have been suggested, but they have been shown to be limited and are not well understood. This approach pairs observations made on actual corpora with insights obtained from data manipulation experiments. The expected outcome is a better understanding of (1) the semantic information we can infer purely based on linguistic co-occurrence patterns and (2) the potential of distributional semantic models to pick up linguistic evidence.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-srw.22.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-srw.22.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928675 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.22/>Efficient <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> for Low-Resource Languages via Exploiting Related Languages</a></strong><br><a href=/people/v/vikrant-goyal/>Vikrant Goyal</a>
|
<a href=/people/s/sourav-kumar/>Sourav Kumar</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Misra Sharma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--22><div class="card-body p-3 small">A large percentage of the world&#8217;s population speaks a language of the Indian subcontinent, comprising languages from both Indo-Aryan (e.g. Hindi, Punjabi, <a href=https://en.wikipedia.org/wiki/Gujarati_language>Gujarati</a>, etc.) and Dravidian (e.g. Tamil, <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, etc.) families. A universal characteristic of <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a> is their <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>complex morphology</a>, which, when combined with the general lack of sufficient quantities of high-quality parallel data, can make developing <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT) systems</a> for these languages difficult. Neural Machine Translation (NMT) is a rapidly advancing MT paradigm and has shown promising results for many language pairs, especially in large training data scenarios. Since the condition of large parallel corpora is not met for Indian-English language pairs, we present our efforts towards building efficient NMT systems between <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a> (specifically Indo-Aryan languages) and English via efficiently exploiting parallel data from the related languages. We propose a technique called Unified Transliteration and Subword Segmentation to leverage language similarity while exploiting parallel data from related language pairs. We also propose a Multilingual Transfer Learning technique to leverage parallel data from multiple related languages to assist <a href=https://en.wikipedia.org/wiki/Translation>translation</a> for low resource language pair of interest. Our experiments demonstrate an overall average improvement of 5 BLEU points over the standard Transformer-based NMT baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928664 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.24/>Crossing the Line : Where do Demographic Variables Fit into Humor Detection?</a></strong><br><a href=/people/j/j-a-meaney/>J. A. Meaney</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--24><div class="card-body p-3 small">Recent <a href=https://en.wikipedia.org/wiki/Humour>humor classification shared tasks</a> have struggled with two issues : either the data comprises a highly constrained genre of humor which does not broadly represent <a href=https://en.wikipedia.org/wiki/Humour>humor</a>, or the data is so indiscriminate that the inter-annotator agreement on its <a href=https://en.wikipedia.org/wiki/Humour>humor content</a> is drastically low. These tasks typically average over all annotators&#8217; judgments, in spite of the fact that <a href=https://en.wikipedia.org/wiki/Humour>humor</a> is a highly subjective phenomenon. We argue that <a href=https://en.wikipedia.org/wiki/Demography>demographic factors</a> influence whether a text is perceived as humorous or not. We propose the addition of <a href=https://en.wikipedia.org/wiki/Demography>demographic information</a> about the humor annotators in order to bin ratings more sensibly. We also suggest the addition of an &#8216;offensive&#8217; label to distinguish between different generations, in terms of <a href=https://en.wikipedia.org/wiki/Humour>humor</a>. This would allow for more nuanced shared tasks and could lead to better performance on downstream <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a>, such as <a href=https://en.wikipedia.org/wiki/Content-control_software>content moderation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928654 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.27/>uBLEU : Uncertainty-Aware Automatic Evaluation Method for Open-Domain Dialogue Systems<span class=acl-fixed-case>BLEU</span>: Uncertainty-Aware Automatic Evaluation Method for Open-Domain Dialogue Systems</a></strong><br><a href=/people/y/yuma-tsuta/>Yuma Tsuta</a>
|
<a href=/people/n/naoki-yoshinaga/>Naoki Yoshinaga</a>
|
<a href=/people/m/masashi-toyoda/>Masashi Toyoda</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--27><div class="card-body p-3 small">Because open-domain dialogues allow diverse responses, basic reference-based metrics such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> do not work well unless we prepare a massive reference set of high-quality responses for input utterances. To reduce this burden, a human-aided, uncertainty-aware metric, <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, has been proposed ; it embeds human judgment on the quality of reference outputs into the computation of multiple-reference BLEU. In this study, we instead propose a fully automatic, uncertainty-aware evaluation method for open-domain dialogue systems, <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>. This method first collects diverse reference responses from massive dialogue data and then annotates their quality judgments by using a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> trained on automatically collected training data. Experimental results on massive Twitter data confirmed that <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> is comparable to <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> in terms of its correlation with human judgment and that the state of the art automatic evaluation method, RUBER, is improved by integrating <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.30.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--30 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.30 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928673 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-srw.30" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.30/>Embeddings of Label Components for Sequence Labeling : A Case Study of Fine-grained Named Entity Recognition</a></strong><br><a href=/people/t/takuma-kato/>Takuma Kato</a>
|
<a href=/people/k/kaori-abe/>Kaori Abe</a>
|
<a href=/people/h/hiroki-ouchi/>Hiroki Ouchi</a>
|
<a href=/people/s/shumpei-miyawaki/>Shumpei Miyawaki</a>
|
<a href=/people/j/jun-suzuki/>Jun Suzuki</a>
|
<a href=/people/k/kentaro-inui/>Kentaro Inui</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--30><div class="card-body p-3 small">In general, the labels used in <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a> consist of different types of elements. For example, IOB-format entity labels, such as B-Person and I-Person, can be decomposed into span (B and I) and type information (Person). However, while most sequence labeling models do not consider such label components, the shared components across labels, such as <a href=https://en.wikipedia.org/wiki/Person_(disambiguation)>Person</a>, can be beneficial for label prediction. In this work, we propose to integrate label component information as <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> into <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Through experiments on English and Japanese fine-grained named entity recognition, we demonstrate that the proposed method improves performance, especially for instances with low-frequency labels.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.38.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--38 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.38 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-srw.38.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928632 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.38/>Checkpoint Reranking : An Approach to Select Better Hypothesis for Neural Machine Translation Systems</a></strong><br><a href=/people/v/vinay-pandramish/>Vinay Pandramish</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Misra Sharma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--38><div class="card-body p-3 small">In this paper, we propose a method of <a href=https://en.wikipedia.org/wiki/Ranking>re-ranking</a> the outputs of Neural Machine Translation (NMT) systems. After the decoding process, we select a few last iteration outputs in the training process as the N-best list. After training a Neural Machine Translation (NMT) baseline system, it has been observed that these iteration outputs have an oracle score higher than <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> up to 1.01 BLEU points compared to the last iteration of the trained system. We come up with a ranking mechanism by solely focusing on the decoder&#8217;s ability to generate distinct tokens and without the usage of any <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> or data. With this <a href=https://en.wikipedia.org/wiki/Methodology>method</a>, we achieved a translation improvement up to +0.16 BLEU points over baseline. We also evaluate our approach by applying the coverage penalty to the training process. In cases of moderate coverage penalty, the oracle scores are higher than the final iteration up to +0.99 BLEU points, and our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> gives an improvement up to +0.17 BLEU points. With excessive penalty, there is a decrease in translation quality compared to the baseline system. Still, an increase in <a href=https://en.wikipedia.org/wiki/Oracle_machine>oracle scores</a> up to +1.30 is observed with the re-ranking algorithm giving an improvement up to +0.15 BLEU points is found in case of excessive penalty. The proposed re-ranking method is a generic one and can be extended to other language pairs as well.<tex-math>N</tex-math>-best list. After training a Neural Machine Translation (NMT) baseline system, it has been observed that these iteration outputs have an oracle score higher than baseline up to 1.01 BLEU points compared to the last iteration of the trained system.We come up with a ranking mechanism by solely focusing on the decoder&#8217;s ability to generate distinct tokens and without the usage of any language model or data. With this method, we achieved a translation improvement up to +0.16 BLEU points over baseline.We also evaluate our approach by applying the coverage penalty to the training process.In cases of moderate coverage penalty, the oracle scores are higher than the final iteration up to +0.99 BLEU points, and our algorithm gives an improvement up to +0.17 BLEU points.With excessive penalty, there is a decrease in translation quality compared to the baseline system. Still, an increase in oracle scores up to +1.30 is observed with the re-ranking algorithm giving an improvement up to +0.15 BLEU points is found in case of excessive penalty.The proposed re-ranking method is a generic one and can be extended to other language pairs as well.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.39.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--39 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.39 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928661 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-srw.39" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.39/>Cross-Lingual Disaster-related Multi-label Tweet Classification with Manifold Mixup</a></strong><br><a href=/people/j/jishnu-ray-chowdhury/>Jishnu Ray Chowdhury</a>
|
<a href=/people/c/cornelia-caragea/>Cornelia Caragea</a>
|
<a href=/people/d/doina-caragea/>Doina Caragea</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--39><div class="card-body p-3 small">Distinguishing informative and actionable messages from a <a href=https://en.wikipedia.org/wiki/Social_media>social media platform</a> like <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> is critical for facilitating <a href=https://en.wikipedia.org/wiki/Emergency_management>disaster management</a>. For this purpose, we compile a multilingual dataset of over 130 K samples for multi-label classification of disaster-related tweets. We present a masking-based loss function for partially labelled samples and demonstrate the effectiveness of Manifold Mixup in the text domain. Our main <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is based on Multilingual BERT, which we further improve with Manifold Mixup. We show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> generalizes to unseen disasters in the test set. Furthermore, we analyze the capability of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for zero-shot generalization to new languages. Our code, dataset, and other resources are available on Github.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.41.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--41 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.41 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928672 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.41/>Exploring the Role of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>Context</a> to Distinguish Rhetorical and Information-Seeking Questions</a></strong><br><a href=/people/y/yuan-zhuang/>Yuan Zhuang</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--41><div class="card-body p-3 small">Social media posts often contain questions, but many of the questions are rhetorical and do not seek information. Our work studies the problem of distinguishing rhetorical and information-seeking questions on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. Most work has focused on <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> of the question itself, but we hypothesize that the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>prior context</a> plays a role too. This paper introduces a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> containing questions in tweets paired with their prior tweets to provide context. We create classification models to assess the difficulty of distinguishing rhetorical and information-seeking questions, and experiment with different properties of the prior context. Our results show that the prior tweet and topic features can improve performance on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div></div><hr><div id=2020acl-tutorials><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-tutorials.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.acl-tutorials/>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-tutorials.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.acl-tutorials.0/>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</a></strong><br><a href=/people/a/agata-savary/>Agata Savary</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-tutorials.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-tutorials--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-tutorials.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.acl-tutorials.2/>Integrating <a href=https://en.wikipedia.org/wiki/Ethics>Ethics</a> into the NLP Curriculum<span class=acl-fixed-case>NLP</span> Curriculum</a></strong><br><a href=/people/e/emily-m-bender/>Emily M. Bender</a>
|
<a href=/people/d/dirk-hovy/>Dirk Hovy</a>
|
<a href=/people/a/alexandra-schofield/>Alexandra Schofield</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-tutorials--2><div class="card-body p-3 small">To raise awareness among future NLP practitioners and prevent inertia in the field, we need to place <a href=https://en.wikipedia.org/wiki/Ethics>ethics</a> in the curriculum for all NLP studentsnot as an elective, but as a core part of their education. Our goal in this tutorial is to empower NLP researchers and practitioners with tools and resources to teach others about how to ethically apply NLP techniques. We will present both high-level strategies for developing an ethics-oriented curriculum, based on experience and best practices, as well as specific sample exercises that can be brought to a classroom. This highly interactive work session will culminate in a shared online resource page that pools lesson plans, assignments, exercise ideas, reading suggestions, and ideas from the attendees. Though the tutorial will focus particularly on examples for university classrooms, we believe these ideas can extend to company-internal workshops or tutorials in a variety of organizations. In this setting, a key lesson is that there is no single approach to ethical NLP : each project requires thoughtful consideration about what steps can be taken to best support people affected by that project. However, we can learn (and teach) what issues to be aware of, what questions to ask, and what strategies are available to mitigate harm.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-tutorials.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-tutorials--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-tutorials.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.acl-tutorials.5/>Stylized Text Generation : Approaches and Applications</a></strong><br><a href=/people/l/lili-mou/>Lili Mou</a>
|
<a href=/people/o/olga-vechtomova/>Olga Vechtomova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-tutorials--5><div class="card-body p-3 small">Text generation has played an important role in various applications of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>, and kn recent studies, researchers are paying increasing attention to modeling and manipulating the style of the generation text, which we call stylized text generation. In this tutorial, we will provide a comprehensive literature review in this direction. We start from the definition of <a href=https://en.wikipedia.org/wiki/Style_(visual_arts)>style</a> and different settings of stylized text generation, illustrated with various applications. Then, we present different settings of stylized generation, such as style-conditioned generation, style-transfer generation, and style-adversarial generation. In each setting, we delve deep into machine learning methods, including embedding learning techniques to represent style, <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning</a>, and <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> with cycle consistency to match content but to distinguish different styles. We also introduce current approaches to evaluating stylized text generation systems. We conclude our tutorial by presenting the challenges of stylized text generation and discussing future directions, such as small-data training, non-categorical style modeling, and a generalized scope of style transfer (e.g., controlling the syntax as a style).</div></div></div><hr><div id=2020alvr-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.alvr-1/>Proceedings of the First Workshop on Advances in Language and Vision Research</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.alvr-1.0/>Proceedings of the First Workshop on Advances in Language and Vision Research</a></strong><br><a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/j/jesse-thomason/>Jesse Thomason</a>
|
<a href=/people/r/ronghang-hu/>Ronghang Hu</a>
|
<a href=/people/x/xinlei-chen/>Xinlei Chen</a>
|
<a href=/people/p/peter-anderson/>Peter Anderson</a>
|
<a href=/people/q/qi-wu/>Qi Wu</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/j/jason-baldridge/>Jason Baldridge</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--alvr-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.alvr-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929760 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.alvr-1.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.alvr-1.3/>Visual Question Generation from Radiology Images</a></strong><br><a href=/people/m/mourad-sarrouti/>Mourad Sarrouti</a>
|
<a href=/people/a/asma-ben-abacha/>Asma Ben Abacha</a>
|
<a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--alvr-1--3><div class="card-body p-3 small">Visual Question Generation (VQG), the task of generating a question based on image contents, is an increasingly important area that combines <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a>. Although there are some recent works that have attempted to generate questions from images in the <a href=https://en.wikipedia.org/wiki/Open_domain>open domain</a>, the task of VQG in the <a href=https://en.wikipedia.org/wiki/Medical_imaging>medical domain</a> has not been explored so far. In this paper, we introduce an approach to generation of visual questions about radiology images called VQGR, i.e. an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> that is able to ask a question when shown an image. VQGR first generates new training data from the existing examples, based on contextual word embeddings and image augmentation techniques. It then uses the variational auto-encoders model to encode images into a latent space and decode natural language questions. Experimental automatic evaluations performed on the VQA-RAD dataset of clinical visual questions show that VQGR achieves good performances compared with the baseline system. The source code is available at https://github.com/sarrouti/vqgr.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--alvr-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.alvr-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.alvr-1.4/>On the role of effective and referring questions in GuessWhat? !<span class=acl-fixed-case>G</span>uess<span class=acl-fixed-case>W</span>hat?!</a></strong><br><a href=/people/m/mauricio-mazuecos/>Mauricio Mazuecos</a>
|
<a href=/people/a/alberto-testoni/>Alberto Testoni</a>
|
<a href=/people/r/raffaella-bernardi/>Raffaella Bernardi</a>
|
<a href=/people/l/luciana-benotti/>Luciana Benotti</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--alvr-1--4><div class="card-body p-3 small">Task success is the standard <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> used to evaluate referential visual dialogue systems. In this paper we propose two new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> that evaluate how each question contributes to the goal. First, we measure how effective each question is by evaluating whether the question discards objects that are not the referent. Second, we define referring questions as those that univocally identify one object in the image. We report the new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> for human dialogues and for state of the art publicly available <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on GuessWhat? !. Regarding our first <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, we find that successful dialogues do not have a higher percentage of effective questions for most <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. With respect to the second <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, humans make questions at the end of the dialogue that are referring, confirming their guess before guessing. Human dialogues that use this <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> have a higher task success but models do not seem to learn it.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--alvr-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.alvr-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929759 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.alvr-1.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.alvr-1.5/>Latent Alignment of Procedural Concepts in Multimodal Recipes</a></strong><br><a href=/people/h/hossein-rajaby-faghihi/>Hossein Rajaby Faghihi</a>
|
<a href=/people/r/roshanak-mirzaee/>Roshanak Mirzaee</a>
|
<a href=/people/s/sudarshan-paliwal/>Sudarshan Paliwal</a>
|
<a href=/people/p/parisa-kordjamshidi/>Parisa Kordjamshidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--alvr-1--5><div class="card-body p-3 small">We propose a novel alignment mechanism to deal with procedural reasoning on a newly released multimodal QA dataset, named RecipeQA. Our model is solving the textual cloze task which is a <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> on a <a href=https://en.wikipedia.org/wiki/Recipe>recipe</a> containing images and instructions. We exploit the power of attention networks, cross-modal representations, and a latent alignment space between instructions and candidate answers to solve the problem. We introduce constrained max-pooling which refines the max pooling operation on the alignment matrix to impose disjoint constraints among the outputs of the model. Our evaluation result indicates a 19 % improvement over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>.</div></div></div><hr><div id=2020autosimtrans-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.autosimtrans-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.autosimtrans-1/>Proceedings of the First Workshop on Automatic Simultaneous Translation</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.autosimtrans-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.autosimtrans-1.0/>Proceedings of the First Workshop on Automatic Simultaneous Translation</a></strong><br><a href=/people/h/hua-wu/>Hua Wu</a>
|
<a href=/people/c/collin-cherry/>Collin Cherry</a>
|
<a href=/people/l/liang-huang/>Liang Huang</a>
|
<a href=/people/z/zhongjun-he/>Zhongjun He</a>
|
<a href=/people/m/mark-liberman/>Mark Liberman</a>
|
<a href=/people/j/james-cross/>James Cross</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.autosimtrans-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--autosimtrans-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.autosimtrans-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929921 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.autosimtrans-1.5/>Modeling Discourse Structure for Document-level Neural Machine Translation</a></strong><br><a href=/people/j/junxuan-chen/>Junxuan Chen</a>
|
<a href=/people/x/xiang-li/>Xiang Li</a>
|
<a href=/people/j/jiarui-zhang/>Jiarui Zhang</a>
|
<a href=/people/c/chulun-zhou/>Chulun Zhou</a>
|
<a href=/people/j/jianwei-cui/>Jianwei Cui</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/j/jinsong-su/>Jinsong Su</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--autosimtrans-1--5><div class="card-body p-3 small">Recently, document-level neural machine translation (NMT) has become a hot topic in the community of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Despite its success, most of existing studies ignored the discourse structure information of the input document to be translated, which has shown effective in other tasks. In this paper, we propose to improve document-level NMT with the aid of discourse structure information. Our <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> is based on a hierarchical attention network (HAN) (Miculicich et al., 2018). Specifically, we first parse the input document to obtain its discourse structure. Then, we introduce a Transformer-based path encoder to embed the discourse structure information of each word. Finally, we combine the discourse structure information with the <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> before it is fed into the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a>. Experimental results on the English-to-German dataset show that our model can significantly outperform both Transformer and Transformer+HAN.</div></div></div><hr><div id=2020bea-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.bea-1/>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.0/>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></strong><br><a href=/people/j/jill-burstein/>Jill Burstein</a>
|
<a href=/people/e/ekaterina-kochmar/>Ekaterina Kochmar</a>
|
<a href=/people/c/claudia-leacock/>Claudia Leacock</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a>
|
<a href=/people/i/ildiko-pilan/>Ildik Piln</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.4/>Complementary Systems for Off-Topic Spoken Response Detection</a></strong><br><a href=/people/v/vatsal-raina/>Vatsal Raina</a>
|
<a href=/people/m/mark-gales/>Mark Gales</a>
|
<a href=/people/k/kate-knill/>Kate Knill</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--4><div class="card-body p-3 small">Increased demand to learn English for business and education has led to growing interest in automatic spoken language assessment and teaching systems. With this shift to automated approaches it is important that systems reliably assess all aspects of a candidate&#8217;s responses. This paper examines one form of spoken language assessment ; whether the response from the candidate is relevant to the prompt provided. This will be referred to as off-topic spoken response detection. Two forms of previously proposed approaches are examined in this work : the hierarchical attention-based topic model (HATM) ; and the similarity grid model (SGM). The work focuses on the scenario when the prompt, and associated responses, have not been seen in the training data, enabling the <a href=https://en.wikipedia.org/wiki/System>system</a> to be applied to new test scripts without the need to collect data or retrain the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. To improve the performance of the systems for unseen prompts, <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> based on easy data augmentation (EDA) and translation based approaches are applied. Additionally for the HATM, a form of prompt dropout is described. The <a href=https://en.wikipedia.org/wiki/System>systems</a> were evaluated on both seen and unseen prompts from Linguaskill Business and General English tests. For unseen data the performance of the HATM was improved using <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a>, in contrast to the <a href=https://en.wikipedia.org/wiki/SGM>SGM</a> where no gains were obtained. The two <a href=https://en.wikipedia.org/wiki/Computer_simulation>approaches</a> were found to be complementary to one another, yielding a combined <a href=https://en.wikipedia.org/wiki/F-number>F0.5 score</a> of 0.814 for off-topic response detection where the prompts have not been seen in training.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.5/>CIMA : A Large Open Access Dialogue Dataset for Tutoring<span class=acl-fixed-case>CIMA</span>: A Large Open Access Dialogue Dataset for Tutoring</a></strong><br><a href=/people/k/katherine-stasaski/>Katherine Stasaski</a>
|
<a href=/people/k/kimberly-kao/>Kimberly Kao</a>
|
<a href=/people/m/marti-a-hearst/>Marti A. Hearst</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--5><div class="card-body p-3 small">One-to-one tutoring is often an effective means to help students learn, and recent experiments with neural conversation systems are promising. However, large open datasets of tutoring conversations are lacking. To remedy this, we propose a novel asynchronous method for collecting tutoring dialogue via crowdworkers that is both amenable to the needs of deep learning algorithms and reflective of pedagogical concerns. In this approach, extended conversations are obtained between crowdworkers role-playing as both students and tutors. The CIMA collection, which we make publicly available, is novel in that students are exposed to overlapping grounded concepts between exercises and multiple relevant tutoring responses are collected for the same input. CIMA contains several compelling properties from an educational perspective : student role-players complete exercises in fewer turns during the course of the conversation and tutor players adopt strategies that conform with some educational conversational norms, such as providing hints versus asking questions in appropriate contexts. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> enables a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> to be trained to generate the next tutoring utterance in a conversation, conditioned on a provided action strategy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.bea-1.6.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.bea-1.6/>Becoming Linguistically Mature : Modeling English and German Childrens Writing Development Across School Grades<span class=acl-fixed-case>E</span>nglish and <span class=acl-fixed-case>G</span>erman Childrens Writing Development Across School Grades</a></strong><br><a href=/people/e/elma-kerz/>Elma Kerz</a>
|
<a href=/people/y/yu-qiao/>Yu Qiao</a>
|
<a href=/people/d/daniel-wiechmann/>Daniel Wiechmann</a>
|
<a href=/people/m/marcus-strobel/>Marcus Strbel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--6><div class="card-body p-3 small">In this paper we employ a novel approach to advancing our understanding of the development of writing in English and German children across school grades using classification tasks. The <a href=https://en.wikipedia.org/wiki/Data>data</a> used come from two recently compiled corpora : The English data come from the the GiC corpus (983 school children in second-, sixth-, ninth- and eleventh-grade) and the German data are from the FD-LEX corpus (930 school children in fifth- and ninth-grade). The key to this paper is the combined use of what we refer to as &#8216;complexity contours&#8217;, i.e. series of measurements that capture the progression of linguistic complexity within a text, and Recurrent Neural Network (RNN) classifiers that adequately capture the sequential information in those contours. Our experiments demonstrate that RNN classifiers trained on complexity contours achieve higher classification accuracy than one trained on text-average complexity scores. In a second step, we determine the relative importance of the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> from four distinct categories through a Sensitivity-Based Pruning approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.8/>Can <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a> Automatically Score Essay Traits?</a></strong><br><a href=/people/s/sandeep-mathias/>Sandeep Mathias</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--8><div class="card-body p-3 small">Essay traits are attributes of an essay that can help explain how well written (or badly written) the essay is. Examples of traits include <a href=https://en.wikipedia.org/wiki/Content_(media)>Content</a>, Organization, <a href=https://en.wikipedia.org/wiki/Language>Language</a>, Sentence Fluency, <a href=https://en.wikipedia.org/wiki/Word_choice>Word Choice</a>, etc. A lot of research in the last decade has dealt with automatic holistic essay scoring-where a machine rates an essay and gives a score for the essay. However, writers need feedback, especially if they want to improve their writing-which is why trait-scoring is important. In this paper, we show how a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep-learning based system</a> can outperform feature-based machine learning systems, as well as a string kernel system in scoring <a href=https://en.wikipedia.org/wiki/Essay>essay traits</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.12/>Applications of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> in Bilingual Language Teaching : An Indonesian-English Case Study<span class=acl-fixed-case>I</span>ndonesian-<span class=acl-fixed-case>E</span>nglish Case Study</a></strong><br><a href=/people/z/zara-maxwelll-smith/>Zara Maxwelll-Smith</a>
|
<a href=/people/s/simon-gonzalez-ochoa/>Simn Gonzlez Ochoa</a>
|
<a href=/people/b/ben-foley/>Ben Foley</a>
|
<a href=/people/h/hanna-suominen/>Hanna Suominen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--12><div class="card-body p-3 small">Multilingual corpora are difficult to compile and a classroom setting adds pedagogy to the mix of factors which make this <a href=https://en.wikipedia.org/wiki/Data>data</a> so rich and problematic to classify. In this paper, we set out methodological considerations of using <a href=https://en.wikipedia.org/wiki/Speech_recognition>automated speech recognition</a> to build a <a href=https://en.wikipedia.org/wiki/Speech_corpus>corpus of teacher speech</a> in an Indonesian language classroom. Our preliminary results (64 % word error rate) suggest these tools have the potential to speed <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a> in this context. We provide practical examples of our data structure, details of our piloted computer-assisted processes, and fine-grained error analysis. Our study is informed and directed by genuine research questions and discussion in both the education and computational linguistics fields. We highlight some of the benefits and risks of using these emerging <a href=https://en.wikipedia.org/wiki/Technology>technologies</a> to analyze the complex work of <a href=https://en.wikipedia.org/wiki/Language_education>language teachers</a> and in <a href=https://en.wikipedia.org/wiki/Education>education</a> more generally.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.13/>An empirical investigation of neural methods for content scoring of science explanations</a></strong><br><a href=/people/b/brian-riordan/>Brian Riordan</a>
|
<a href=/people/s/sarah-bichler/>Sarah Bichler</a>
|
<a href=/people/a/allison-bradford/>Allison Bradford</a>
|
<a href=/people/j/jennifer-king-chen/>Jennifer King Chen</a>
|
<a href=/people/k/korah-wiley/>Korah Wiley</a>
|
<a href=/people/l/libby-gerard/>Libby Gerard</a>
|
<a href=/people/m/marcia-c-linn/>Marcia C. Linn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--13><div class="card-body p-3 small">With the widespread adoption of the Next Generation Science Standards (NGSS), science teachers and online learning environments face the challenge of evaluating students&#8217; integration of different dimensions of <a href=https://en.wikipedia.org/wiki/Science_education>science learning</a>. Recent advances in representation learning in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> have proven effective across many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing tasks</a>, but a rigorous evaluation of the relative merits of these methods for scoring complex constructed response formative assessments has not previously been carried out. We present a detailed empirical investigation of feature-based, recurrent neural network, and pre-trained transformer models on scoring content in real-world formative assessment data. We demonstrate that recent <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural methods</a> can rival or exceed the performance of feature-based methods. We also provide evidence that different classes of neural models take advantage of different learning cues, and pre-trained transformer models may be more robust to spurious, dataset-specific learning cues, better reflecting scoring rubrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.bea-1.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.16/>GECToR Grammatical Error Correction : Tag, Not Rewrite<span class=acl-fixed-case>GECT</span>o<span class=acl-fixed-case>R</span>  Grammatical Error Correction: Tag, Not Rewrite</a></strong><br><a href=/people/k/kostiantyn-omelianchuk/>Kostiantyn Omelianchuk</a>
|
<a href=/people/v/vitaliy-atrasevych/>Vitaliy Atrasevych</a>
|
<a href=/people/a/artem-chernodub/>Artem Chernodub</a>
|
<a href=/people/o/oleksandr-skurzhanskyi/>Oleksandr Skurzhanskyi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--16><div class="card-body p-3 small">In this paper, we present a simple and efficient GEC sequence tagger using a Transformer encoder. Our system is pre-trained on synthetic data and then fine-tuned in two stages : first on errorful corpora, and second on a combination of errorful and error-free parallel corpora. We design custom token-level transformations to map input tokens to target corrections. Our best single-model / ensemble GEC tagger achieves an F_0.5 of 65.3/66.5 on CONLL-2014 (test) and F_0.5 of 72.4/73.6 on BEA-2019 (test). Its inference speed is up to 10 times as fast as a Transformer-based seq2seq GEC system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.bea-1.17.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.bea-1.17/>Interpreting Neural CWI Classifiers Weights as Vocabulary Size<span class=acl-fixed-case>CWI</span> Classifiers Weights as Vocabulary Size</a></strong><br><a href=/people/y/yo-ehara/>Yo Ehara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--17><div class="card-body p-3 small">Complex Word Identification (CWI) is a task for the identification of words that are challenging for <a href=https://en.wikipedia.org/wiki/Second-language_acquisition>second-language learners</a> to read. Even though the use of neural classifiers is now common in CWI, the interpretation of their parameters remains difficult. This paper analyzes neural CWI classifiers and shows that some of their parameters can be interpreted as <a href=https://en.wikipedia.org/wiki/Vocabulary_size>vocabulary size</a>. We present a novel formalization of vocabulary size measurement methods that are practiced in the applied linguistics field as a kind of neural classifier. We also contribute to building a novel <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for validating vocabulary testing and readability via <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.20/>Predicting the Difficulty and Response Time of Multiple Choice Questions Using Transfer Learning</a></strong><br><a href=/people/k/kang-xue/>Kang Xue</a>
|
<a href=/people/v/victoria-yaneva/>Victoria Yaneva</a>
|
<a href=/people/c/christopher-runyon/>Christopher Runyon</a>
|
<a href=/people/p/peter-baldwin/>Peter Baldwin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--20><div class="card-body p-3 small">This paper investigates whether <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> can improve the prediction of the difficulty and response time parameters for 18,000 multiple-choice questions from a high-stakes medical exam. The type the signal that best predicts difficulty and <a href=https://en.wikipedia.org/wiki/Response_time_(technology)>response time</a> is also explored, both in terms of <a href=https://en.wikipedia.org/wiki/Abstraction_(computer_science)>representation abstraction</a> and item component used as input (e.g., whole item, answer options only, etc.). The results indicate that, for our sample, <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> can improve the prediction of item difficulty when <a href=https://en.wikipedia.org/wiki/Mental_chronometry>response time</a> is used as an auxiliary task but not the other way around. In addition, difficulty was best predicted using signal from the item stem (the description of the clinical case), while all parts of the item were important for predicting the response time.</div></div></div><hr><div id=2020bionlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.bionlp-1/>Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.0/>Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing</a></strong><br><a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a>
|
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929643 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.3/>Interactive Extractive Search over Biomedical Corpora</a></strong><br><a href=/people/h/hillel-taub-tabib/>Hillel Taub Tabib</a>
|
<a href=/people/m/micah-shlain/>Micah Shlain</a>
|
<a href=/people/s/shoval-sadde/>Shoval Sadde</a>
|
<a href=/people/d/dan-lahav/>Dan Lahav</a>
|
<a href=/people/m/matan-eyal/>Matan Eyal</a>
|
<a href=/people/y/yaara-cohen/>Yaara Cohen</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--3><div class="card-body p-3 small">We present a system that allows life-science researchers to search a linguistically annotated corpus of scientific texts using patterns over dependency graphs, as well as using patterns over token sequences and a powerful variant of boolean keyword queries. In contrast to previous attempts to dependency-based search, we introduce a light-weight query language that does not require the user to know the details of the underlying linguistic representations, and instead to query the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> by providing an example sentence coupled with simple markup. Search is performed at an interactive speed due to efficient linguistic graph-indexing and retrieval engine. This allows for rapid exploration, development and refinement of <a href=https://en.wikipedia.org/wiki/User_(computing)>user queries</a>. We demonstrate the system using example workflows over two <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpora</a> : the PubMed corpus including 14,446,243 PubMed abstracts and the CORD-19 dataset, a collection of over 45,000 research papers focused on COVID-19 research. The <a href=https://en.wikipedia.org/wiki/System>system</a> is publicly available at https://allenai.github.io/spike</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.4/>Improving Biomedical Analogical Retrieval with Embedding of Structural Dependencies</a></strong><br><a href=/people/a/amandalynne-paullada/>Amandalynne Paullada</a>
|
<a href=/people/b/bethany-percha/>Bethany Percha</a>
|
<a href=/people/t/trevor-cohen/>Trevor Cohen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--4><div class="card-body p-3 small">Inferring the nature of the relationships between biomedical entities from <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> is an important problem due to the difficulty of maintaining human-curated knowledge bases in rapidly evolving fields. Neural word embeddings have earned attention for an apparent ability to encode relational information. However, word embedding models that disregard <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> during training are limited in their ability to encode the structural relationships fundamental to <a href=https://en.wikipedia.org/wiki/Analogy>cognitive theories of analogy</a>. In this paper, we demonstrate the utility of encoding dependency structure in word embeddings in a model we call Embedding of Structural Dependencies (ESD) as a way to represent biomedical relationships in two analogical retrieval tasks : a relationship retrieval (RR) task, and a literature-based discovery (LBD) task meant to hypothesize plausible relationships between pairs of entities unseen in training. We compare our model to skip-gram with negative sampling (SGNS), using 19 databases of biomedical relationships as our evaluation data, with improvements in performance on 17 (LBD) and 18 (RR) of these sets. These results suggest embeddings encoding dependency path information are of value for biomedical analogy retrieval.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.7/>A BERT-based One-Pass Multi-Task Model for Clinical Temporal Relation Extraction<span class=acl-fixed-case>BERT</span>-based One-Pass Multi-Task Model for Clinical Temporal Relation Extraction</a></strong><br><a href=/people/c/chen-lin/>Chen Lin</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a>
|
<a href=/people/d/dmitriy-dligach/>Dmitriy Dligach</a>
|
<a href=/people/f/farig-sadeque/>Farig Sadeque</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a>
|
<a href=/people/g/guergana-savova/>Guergana Savova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--7><div class="card-body p-3 small">Recently BERT has achieved a state-of-the-art performance in temporal relation extraction from clinical Electronic Medical Records text. However, the current approach is inefficient as <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> requires multiple passes through each input sequence. We extend a recently-proposed one-pass model for relation classification to a one-pass model for relation extraction. We augment this framework by introducing global embeddings to help with long-distance relation inference, and by <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> to increase model performance and generalizability. Our proposed model produces results on par with the state-of-the-art in temporal relation extraction on the THYME corpus and is much greener in <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.16/>Neural Transduction of Letter Position Dyslexia using an Anagram Matrix Representation</a></strong><br><a href=/people/a/avi-bleiweiss/>Avi Bleiweiss</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--16><div class="card-body p-3 small">Research on analyzing reading patterns of dyslectic children has mainly been driven by classifying dyslexia types offline. We contend that a framework to remedy reading errors inline is more far-reaching and will help to further advance our understanding of this impairment. In this paper, we propose a simple and intuitive neural model to reinstate migrating words that transpire in letter position dyslexia, a visual analysis deficit to the encoding of character order within a word. Introduced by the anagram matrix representation of an input verse, the novelty of our work lies in the expansion from one to a two dimensional context window for training. This warrants words that only differ in the disposition of letters to remain interpreted semantically similar in the <a href=https://en.wikipedia.org/wiki/Embedding>embedding space</a>. Subject to the apparent constraints of the self-attention transformer architecture, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved a unigram BLEU score of 40.6 on our reconstructed dataset of the <a href=https://en.wikipedia.org/wiki/Shakespeare&#8217;s_sonnets>Shakespeare sonnets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.bionlp-1.19" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.19/>Extensive Error Analysis and a Learning-Based Evaluation of Medical Entity Recognition Systems to Approximate User Experience</a></strong><br><a href=/people/i/isar-nejadgholi/>Isar Nejadgholi</a>
|
<a href=/people/k/kathleen-c-fraser/>Kathleen C. Fraser</a>
|
<a href=/people/b/berry-de-bruijn/>Berry de Bruijn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--19><div class="card-body p-3 small">When comparing entities extracted by a medical entity recognition system with gold standard annotations over a test set, two types of mismatches might occur, label mismatch or span mismatch. Here we focus on span mismatch and show that its severity can vary from a serious error to a fully acceptable entity extraction due to the subjectivity of span annotations. For a domain-specific BERT-based NER system, we showed that 25 % of the errors have the same labels and overlapping span with gold standard entities. We collected expert judgement which shows more than 90 % of these mismatches are accepted or partially accepted by the user. Using the training set of the NER system, we built a fast and lightweight <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity classifier</a> to approximate the <a href=https://en.wikipedia.org/wiki/User_experience>user experience</a> of such mismatches through accepting or rejecting them. The decisions made by this <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> are used to calculate a learning-based F-score which is shown to be a better approximation of a forgiving user&#8217;s experience than the relaxed F-score. We demonstrated the results of applying the proposed evaluation metric for a variety of deep learning medical entity recognition models trained with two datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.21/>Global Locality in Biomedical Relation and Event Extraction</a></strong><br><a href=/people/e/elaheh-shafieibavani/>Elaheh ShafieiBavani</a>
|
<a href=/people/a/antonio-jimeno-yepes/>Antonio Jimeno Yepes</a>
|
<a href=/people/x/xu-zhong/>Xu Zhong</a>
|
<a href=/people/d/david-martinez-iraola/>David Martinez Iraola</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--21><div class="card-body p-3 small">Due to the exponential growth of <a href=https://en.wikipedia.org/wiki/Medical_literature>biomedical literature</a>, event and relation extraction are important tasks in <a href=https://en.wikipedia.org/wiki/Biomedical_text_mining>biomedical text mining</a>. Most work only focus on relation extraction, and detect a single entity pair mention on a short span of text, which is not ideal due to long sentences that appear in biomedical contexts. We propose an approach to both relation and event extraction, for simultaneously predicting relationships between all mention pairs in a text. We also perform an empirical study to discuss different network setups for this purpose. The best performing model includes a set of multi-head attentions and convolutions, an adaptation of the transformer architecture, which offers self-attention the ability to strengthen dependencies among related elements, and models the interaction between features extracted by multiple attention heads. Experiment results demonstrate that our approach outperforms the state of the art on a set of benchmark biomedical corpora including BioNLP 2009, 2011, 2013 and BioCreative 2017 shared tasks.</div></div></div><hr><div id=2020challengehml-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.challengehml-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.challengehml-1/>Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.challengehml-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.challengehml-1.0/>Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)</a></strong><br><a href=/people/a/amir-zadeh/>Amir Zadeh</a>
|
<a href=/people/l/louis-philippe-morency/>Louis-Philippe Morency</a>
|
<a href=/people/p/paul-pu-liang/>Paul Pu Liang</a>
|
<a href=/people/s/soujanya-poria/>Soujanya Poria</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.challengehml-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--challengehml-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.challengehml-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38931259 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.challengehml-1.2/>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews</a></strong><br><a href=/people/e/edison-marrese-taylor/>Edison Marrese-Taylor</a>
|
<a href=/people/c/cristian-rodriguez/>Cristian Rodriguez</a>
|
<a href=/people/j/jorge-balazs/>Jorge Balazs</a>
|
<a href=/people/s/stephen-gould/>Stephen Gould</a>
|
<a href=/people/y/yutaka-matsuo/>Yutaka Matsuo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--challengehml-1--2><div class="card-body p-3 small">Despite the recent advances in <a href=https://en.wikipedia.org/wiki/Opinion_mining>opinion mining</a> for written reviews, few works have tackled the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> on other sources of reviews. In light of this issue, we propose a multi-modal approach for mining fine-grained opinions from video reviews that is able to determine the aspects of the item under review that are being discussed and the sentiment orientation towards them. Our approach works at the sentence level without the need for time annotations and uses features derived from the audio, video and language transcriptions of its contents. We evaluate our approach on two datasets and show that leveraging the video and audio modalities consistently provides increased performance over text-only baselines, providing evidence these extra modalities are key in better understanding video reviews.</div></div></div><hr><div id=2020ecnlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.ecnlp-1/>Proceedings of The 3rd Workshop on e-Commerce and NLP</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ecnlp-1.0/>Proceedings of The 3rd Workshop on e-Commerce and NLP</a></strong><br><a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/s/surya-kallumadi/>Surya Kallumadi</a>
|
<a href=/people/n/nicola-ueffing/>Nicola Ueffing</a>
|
<a href=/people/o/oleg-rokhlenko/>Oleg Rokhlenko</a>
|
<a href=/people/e/eugene-agichtein/>Eugene Agichtein</a>
|
<a href=/people/i/ido-guy/>Ido Guy</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ecnlp-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ecnlp-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38931239 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ecnlp-1.1/>Bootstrapping Named Entity Recognition in E-Commerce with Positive Unlabeled Learning<span class=acl-fixed-case>E</span>-Commerce with Positive Unlabeled Learning</a></strong><br><a href=/people/h/hanchu-zhang/>Hanchu Zhang</a>
|
<a href=/people/l/leonhard-hennig/>Leonhard Hennig</a>
|
<a href=/people/c/christoph-alt/>Christoph Alt</a>
|
<a href=/people/c/changjian-hu/>Changjian Hu</a>
|
<a href=/people/y/yao-meng/>Yao Meng</a>
|
<a href=/people/c/chao-wang/>Chao Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ecnlp-1--1><div class="card-body p-3 small">In this work, we introduce a bootstrapped, iterative NER model that integrates a PU learning algorithm for recognizing <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entities</a> in a low-resource setting. Our approach combines dictionary-based labeling with syntactically-informed label expansion to efficiently enrich the seed dictionaries. Experimental results on a dataset of manually annotated e-commerce product descriptions demonstrate the effectiveness of the proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ecnlp-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ecnlp-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38931243 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ecnlp-1.4/>A <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning System</a> for Sentiment Analysis of Service Calls</a></strong><br><a href=/people/y/yanan-jia/>Yanan Jia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ecnlp-1--4><div class="card-body p-3 small">Sentiment analysis is crucial for the advancement of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence (AI)</a>. Sentiment understanding can help <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI</a> to replicate <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human language and discourse</a>. Studying the formation and response of sentiment state from well-trained Customer Service Representatives (CSRs) can help make the interaction between humans and AI more intelligent. In this paper, a sentiment analysis pipeline is first carried out with respect to real-world multi-party conversations-that is, <a href=https://en.wikipedia.org/wiki/Service_(systems_architecture)>service calls</a>. Based on the acoustic and linguistic features extracted from the source information, a novel aggregated method for voice sentiment recognition framework is built. Each party&#8217;s sentiment pattern during the communication is investigated along with the interaction sentiment pattern between all parties.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ecnlp-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ecnlp-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ecnlp-1.11/>SimsterQ : A Similarity based Clustering Approach to Opinion Question Answering<span class=acl-fixed-case>S</span>imster<span class=acl-fixed-case>Q</span>: <span class=acl-fixed-case>A</span> Similarity based Clustering Approach to Opinion Question Answering</a></strong><br><a href=/people/a/aishwarya-ashok/>Aishwarya Ashok</a>
|
<a href=/people/g/ganapathy-natarajan/>Ganapathy Natarajan</a>
|
<a href=/people/r/ramez-elmasri/>Ramez Elmasri</a>
|
<a href=/people/l/laurel-smith-stvan/>Laurel Smith-Stvan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ecnlp-1--11><div class="card-body p-3 small">In recent years, there has been an increase in <a href=https://en.wikipedia.org/wiki/Online_shopping>online shopping</a> resulting in an increased number of <a href=https://en.wikipedia.org/wiki/Review_site>online reviews</a>. Customers can not delve into the huge amount of data when they are looking for specific aspects of a product. Some of these aspects can be extracted from the <a href=https://en.wikipedia.org/wiki/Product_review>product reviews</a>. In this paper we introduced SimsterQ-a clustering based system for answering questions that makes use of word vectors. Clustering was performed using cosine similarity scores between sentence vectors of reviews and questions. Two variants (Sim and Median) with and without <a href=https://en.wikipedia.org/wiki/Stopword>stopwords</a> were evaluated against traditional methods that use <a href=https://en.wikipedia.org/wiki/Term_frequency>term frequency</a>. We also used an n-gram approach to study the effect of <a href=https://en.wikipedia.org/wiki/Noise>noise</a>. We used the reviews in the Amazon Reviews dataset to pick the answers. Evaluation was performed both at the individual sentence level using the top sentence from <a href=https://en.wikipedia.org/wiki/Okapi_BM25>Okapi BM25</a> as the gold standard and at the whole answer level using review snippets as the gold standard. At the <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence level</a> our <a href=https://en.wikipedia.org/wiki/System>system</a> performed slightly better than a more complicated <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning method</a>. Our system returned answers similar to the review snippets from the Amazon QA Dataset as measured by the <a href=https://en.wikipedia.org/wiki/Cosine_similarity>cosine similarity</a>. Analysis was also performed on the quality of the <a href=https://en.wikipedia.org/wiki/Cluster_analysis>clusters</a> generated by our <a href=https://en.wikipedia.org/wiki/System>system</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ecnlp-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ecnlp-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38931245 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ecnlp-1.13/>On Application of Bayesian Parametric and Non-parametric Methods for User Cohorting in Product Search<span class=acl-fixed-case>B</span>ayesian Parametric and Non-parametric Methods for User Cohorting in Product Search</a></strong><br><a href=/people/s/shashank-gupta/>Shashank Gupta</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ecnlp-1--13><div class="card-body p-3 small">In this paper, we study the applicability of Bayesian Parametric and Non-parametric methods for user clustering in an E-commerce search setting. To the best of our knowledge, this is the first work that presents a comparative study of various Bayesian clustering methods in the context of product search. Specifically, we cluster users based on their topical patterns from their respective product search queries. To evaluate the quality of the <a href=https://en.wikipedia.org/wiki/Cluster_analysis>clusters</a> formed, we perform a collaborative query recommendation task. Our findings indicate that simple parametric model like Latent Dirichlet Allocation (LDA) outperforms more sophisticated non-parametric methods like Distance Dependent Chinese Restaurant Process and Dirichlet Process-based clustering in both tasks.</div></div></div><hr><div id=2020fever-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.fever-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.fever-1/>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.fever-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.fever-1.0/>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</a></strong><br><a href=/people/c/christos-christodoulopoulos/>Christos Christodoulopoulos</a>
|
<a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/o/oana-cocarascu/>Oana Cocarascu</a>
|
<a href=/people/a/arpit-mittal/>Arpit Mittal</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.fever-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--fever-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.fever-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929663 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.fever-1.1/>Simple Compounded-Label Training for Fact Extraction and Verification</a></strong><br><a href=/people/y/yixin-nie/>Yixin Nie</a>
|
<a href=/people/l/lisa-bauer/>Lisa Bauer</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--fever-1--1><div class="card-body p-3 small">Automatic fact checking is an important task motivated by the need for detecting and preventing the spread of misinformation across the web. The recently released FEVER challenge provides a benchmark task that assesses systems&#8217; capability for both the retrieval of required evidence and the identification of authentic claims. Previous approaches share a similar pipeline training paradigm that decomposes the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> into three subtasks, with each component built and trained separately. Although achieving acceptable scores, these <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> induce difficulty for practical application development due to <a href=https://en.wikipedia.org/wiki/Complexity>unnecessary complexity</a> and expensive computation. In this paper, we explore the potential of simplifying the system design and reducing training computation by proposing a joint training setup in which a single sequence matching model is trained with compounded labels that give supervision for both sentence selection and claim verification subtasks, eliminating the duplicate computation that occurs when models are designed and trained separately. Empirical results on FEVER indicate that our method : (1) outperforms the typical multi-task learning approach, and (2) gets comparable results to top performing systems with a much simpler training setup and less training computation (in terms of the amount of data consumed and the number of model parameters), facilitating future works on the automatic fact checking task and its practical usage.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.fever-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--fever-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.fever-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929662 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.fever-1.5/>Language Models as Fact Checkers?</a></strong><br><a href=/people/n/nayeon-lee/>Nayeon Lee</a>
|
<a href=/people/b/belinda-z-li/>Belinda Z. Li</a>
|
<a href=/people/s/sinong-wang/>Sinong Wang</a>
|
<a href=/people/w/wen-tau-yih/>Wen-tau Yih</a>
|
<a href=/people/h/hao-ma/>Hao Ma</a>
|
<a href=/people/m/madian-khabsa/>Madian Khabsa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--fever-1--5><div class="card-body p-3 small">Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data. In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>, without any external knowledge or explicit retrieval components. While previous work on extracting knowledge from LMs have focused on the task of open-domain question answering, to the best of our knowledge, this is the first work to examine the use of language models as <a href=https://en.wikipedia.org/wiki/Fact-checking>fact checkers</a>. In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines. Though we do not ultimately outperform methods which use explicit knowledge bases, we believe our exploration shows that this method is viable and has much room for exploration.</div></div></div><hr><div id=2020figlang-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.figlang-1/>Proceedings of the Second Workshop on Figurative Language Processing</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.0/>Proceedings of the Second Workshop on Figurative Language Processing</a></strong><br><a href=/people/b/beata-beigman-klebanov/>Beata Beigman Klebanov</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/p/patricia-lichtenstein/>Patricia Lichtenstein</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/c/chee-wee/>Chee Wee</a>
|
<a href=/people/a/anna-feldman/>Anna Feldman</a>
|
<a href=/people/d/debanjan-ghosh/>Debanjan Ghosh</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929697 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.7/>Sarcasm Detection in Tweets with BERT and GloVe Embeddings<span class=acl-fixed-case>BERT</span> and <span class=acl-fixed-case>G</span>lo<span class=acl-fixed-case>V</span>e Embeddings</a></strong><br><a href=/people/a/akshay-khatri/>Akshay Khatri</a>
|
<a href=/people/p/pranav-p/>Pranav P</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--7><div class="card-body p-3 small">Sarcasm is a form of communication in which the person states opposite of what he actually means. In this paper, we propose using machine learning techniques with BERT and GloVe embeddings to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is preprocessed before extracting the <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>. The proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> also uses all of the context provided in the dataset to which the user is reacting along with his actual response.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929698 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.8/>C-Net : Contextual Network for Sarcasm Detection<span class=acl-fixed-case>C</span>-Net: Contextual Network for Sarcasm Detection</a></strong><br><a href=/people/a/amit-kumar-jena/>Amit Kumar Jena</a>
|
<a href=/people/a/aman-sinha/>Aman Sinha</a>
|
<a href=/people/r/rohit-agarwal/>Rohit Agarwal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--8><div class="card-body p-3 small">Automatic Sarcasm Detection in <a href=https://en.wikipedia.org/wiki/Conversation>conversations</a> is a difficult and tricky task. Classifying an utterance as sarcastic or not in isolation can be futile since most of the time the sarcastic nature of a sentence heavily relies on its context. This paper presents our proposed model, <a href=https://en.wikipedia.org/wiki/C-Net>C-Net</a>, which takes contextual information of a sentence in a sequential manner to classify it as sarcastic or non-sarcastic. Our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> showcases competitive performance in the Sarcasm Detection shared task organised on CodaLab and achieved 75.0 % <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> on the Twitter dataset and 66.3 % <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> on Reddit dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929700 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.10/>Sarcasm Identification and Detection in Conversion Context using BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/k/kalaivani-a/>Kalaivani A.</a>
|
<a href=/people/t/thenmozhi-d/>Thenmozhi D.</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--10><div class="card-body p-3 small">Sarcasm analysis in user conversion text is automatic detection of any irony, insult, hurting, painful, caustic, <a href=https://en.wikipedia.org/wiki/Humour>humour</a>, vulgarity that degrades an individual. It is helpful in the field of sentimental analysis and <a href=https://en.wikipedia.org/wiki/Cyberbullying>cyberbullying</a>. As an immense growth of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, sarcasm analysis helps to avoid insult, hurts and <a href=https://en.wikipedia.org/wiki/Humour>humour</a> to affect someone. In this paper, we present traditional machine learning approaches, deep learning approach (LSTM -RNN) and BERT (Bidirectional Encoder Representations from Transformers) for identifying <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a>. We have used the approaches to build the model, to identify and categorize how much conversion context or response is needed for sarcasm detection and evaluated on the two social media forums that is twitter conversation dataset and reddit conversion dataset. We compare the performance based on the approaches and obtained the best F1 scores as 0.722, 0.679 for the <a href=https://en.wikipedia.org/wiki/Twitter>twitter forums</a> and <a href=https://en.wikipedia.org/wiki/Reddit>reddit forums</a> respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929701 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.11/>Neural Sarcasm Detection using Conversation Context</a></strong><br><a href=/people/n/nikhil-jaiswal/>Nikhil Jaiswal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--11><div class="card-body p-3 small">Social media platforms and <a href=https://en.wikipedia.org/wiki/Internet_forum>discussion forums</a> such as <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>, <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>, etc. are filled with <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>figurative languages</a>. Sarcasm is one such category of <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>figurative language</a> whose presence in a conversation makes <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> a challenging task. In this paper, we present a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural architecture</a> for sarcasm detection. We investigate various pre-trained language representation models (PLRMs) like BERT, RoBERTa, etc. and fine-tune it on the Twitter dataset. We experiment with a variety of PLRMs either on the twitter utterance in isolation or utilizing the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a> along with the utterance. Our findings indicate that by taking into consideration the previous three most recent utterances, the model is more accurately able to classify a conversation as being sarcastic or not. Our best performing <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble model</a> achieves an overall <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> of 0.790, which ranks us second on the leaderboard of the Sarcasm Shared Task 2020.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929704 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.14/>A Novel Hierarchical BERT Architecture for Sarcasm Detection<span class=acl-fixed-case>BERT</span> Architecture for Sarcasm Detection</a></strong><br><a href=/people/h/himani-srivastava/>Himani Srivastava</a>
|
<a href=/people/v/vaibhav-varshney/>Vaibhav Varshney</a>
|
<a href=/people/s/surabhi-kumari/>Surabhi Kumari</a>
|
<a href=/people/s/saurabh-srivastava/>Saurabh Srivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--14><div class="card-body p-3 small">Online discussion platforms are often flooded with opinions from users across the world on a variety of topics. Many such posts, comments, or utterances are often sarcastic in nature, i.e., the actual intent is hidden in the sentence and is different from its literal meaning, making the detection of such utterances challenging without additional context. In this paper, we propose a novel deep learning-based approach to detect whether an utterance is sarcastic or non-sarcastic by utilizing the given contexts ina hierarchical manner. We have used <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> from two online discussion platforms-Twitter and Reddit1for our experiments. Experimental and error analysis shows that the hierarchical models can make full use of history to obtain a better representation of contexts and thus, in turn, can outperform their sequential counterparts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.15/>Detecting Sarcasm in Conversation Context Using Transformer-Based Models<span class=acl-fixed-case>D</span>etecting <span class=acl-fixed-case>S</span>arcasm in <span class=acl-fixed-case>C</span>onversation <span class=acl-fixed-case>C</span>ontext <span class=acl-fixed-case>U</span>sing <span class=acl-fixed-case>T</span>ransformer-<span class=acl-fixed-case>B</span>ased <span class=acl-fixed-case>M</span>odels</a></strong><br><a href=/people/a/adithya-avvaru/>Adithya Avvaru</a>
|
<a href=/people/s/sanath-vobilisetty/>Sanath Vobilisetty</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--15><div class="card-body p-3 small">Sarcasm detection, regarded as one of the sub-problems of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, is a very typical task because the introduction of sarcastic words can flip the sentiment of the sentence itself. To date, many research works revolve around detecting <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in one single sentence and there is very limited research to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> resulting from multiple sentences. Current models used Long Short Term Memory (LSTM) variants with or without <a href=https://en.wikipedia.org/wiki/Attention>attention</a> to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in conversations. We showed that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using state-of-the-art Bidirectional Encoder Representations from Transformers (BERT), to capture syntactic and semantic information across conversation sentences, performed better than the current <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Based on the data analysis, we estimated that the number of sentences in the conversation that can contribute to the <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> and the results agrees to this estimation. We also perform a comparative study of our different versions of BERT-based model with other variants of LSTM model and XLNet (both using the estimated number of conversation sentences) and find out that BERT-based models outperformed them.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929723 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.16/>Using Conceptual Norms for Metaphor Detection</a></strong><br><a href=/people/m/mingyu-wan/>Mingyu Wan</a>
|
<a href=/people/k/kathleen-ahrens/>Kathleen Ahrens</a>
|
<a href=/people/e/emmanuele-chersoni/>Emmanuele Chersoni</a>
|
<a href=/people/m/menghan-jiang/>Menghan Jiang</a>
|
<a href=/people/q/qi-su/>Qi Su</a>
|
<a href=/people/r/rong-xiang/>Rong Xiang</a>
|
<a href=/people/c/chu-ren-huang/>Chu-Ren Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--16><div class="card-body p-3 small">This paper reports a linguistically-enriched method of detecting token-level metaphors for the second shared task on Metaphor Detection. We participate in all four phases of competition with both <a href=https://en.wikipedia.org/wiki/Digital_data>datasets</a>, i.e. Verbs and AllPOS on the VUA and the TOFEL datasets. We use the modality exclusivity and embodiment norms for constructing a conceptual representation of the nodes and the context. Our <a href=https://en.wikipedia.org/wiki/System>system</a> obtains an <a href=https://en.wikipedia.org/wiki/International_Federation_of_the_Phonographic_Industry>F-score</a> of 0.652 for the VUA Verbs track, which is 5 % higher than the strong baselines. The experimental results across models and datasets indicate the salient contribution of using modality exclusivity and modality shift information for predicting <a href=https://en.wikipedia.org/wiki/Metaphor>metaphoricity</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929724 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.18/>Character aware models with <a href=https://en.wikipedia.org/wiki/Similarity_learning>similarity learning</a> for metaphor detection</a></strong><br><a href=/people/t/tarun-kumar/>Tarun Kumar</a>
|
<a href=/people/y/yashvardhan-sharma/>Yashvardhan Sharma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--18><div class="card-body p-3 small">Recent work on automatic sequential metaphor detection has involved <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a> initialized with different pre-trained word embeddings and which are sometimes combined with hand engineered features. To capture lexical and orthographic information automatically, in this paper we propose to add character based word representation. Also, to contrast the difference between <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>literal and contextual meaning</a>, we utilize a similarity network. We explore these components via two different architectures-a BiLSTM model and a Transformer Encoder model similar to BERT to perform metaphor identification. We participate in the Second Shared Task on Metaphor Detection on both the VUA and TOFEL datasets with the above models. The experimental results demonstrate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> as it outperforms all the <a href=https://en.wikipedia.org/wiki/System>systems</a> which participated in the previous shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929717 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.20/>Recognizing Euphemisms and Dysphemisms Using <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a></a></strong><br><a href=/people/c/christian-felt/>Christian Felt</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--20><div class="card-body p-3 small">This paper presents the first research aimed at recognizing euphemistic and dysphemistic phrases with <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. Euphemisms soften references to topics that are sensitive, disagreeable, or taboo. Conversely, <a href=https://en.wikipedia.org/wiki/Dysphemism>dysphemisms</a> refer to sensitive topics in a harsh or rude way. For example, passed away and departed are <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> for death, while croaked and six feet under are <a href=https://en.wikipedia.org/wiki/Dysphemism>dysphemisms</a> for death. Our work explores the use of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> to recognize euphemistic and dysphemistic language. First, we identify near-synonym phrases for three topics (firing, lying, and stealing) using a bootstrapping algorithm for semantic lexicon induction. Next, we classify phrases as <a href=https://en.wikipedia.org/wiki/Euphemism>euphemistic</a>, dysphemistic, or neutral using <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical sentiment cues</a> and contextual sentiment analysis. We introduce a new gold standard data set and present our experimental results for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.figlang-1.23.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.figlang-1.23.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929711 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.23/>Generating Ethnographic Models from Communities Online Data</a></strong><br><a href=/people/t/tomek-strzalkowski/>Tomek Strzalkowski</a>
|
<a href=/people/a/anna-newheiser/>Anna Newheiser</a>
|
<a href=/people/n/nathan-kemper/>Nathan Kemper</a>
|
<a href=/people/n/ning-sa/>Ning Sa</a>
|
<a href=/people/b/bharvee-acharya/>Bharvee Acharya</a>
|
<a href=/people/g/gregorios-katsios/>Gregorios Katsios</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--23><div class="card-body p-3 small">In this paper we describe computational ethnography study to demonstrate how machine learning techniques can be utilized to exploit bias resident in language data produced by communities with online presence. Specifically, we leverage the use of <a href=https://en.wikipedia.org/wiki/Figurative_language>figurative language</a> (i.e., the choice of metaphors) in <a href=https://en.wikipedia.org/wiki/Online_and_offline>online text</a> (e.g., <a href=https://en.wikipedia.org/wiki/News_media>news media</a>, blogs) produced by distinct communities to obtain models of community worldviews that can be shown to be distinctly biased and thus different from other communities&#8217; models. We automatically construct metaphor-based community models for two distinct scenarios : <a href=https://en.wikipedia.org/wiki/Gun_politics_in_the_United_States>gun rights</a> and <a href=https://en.wikipedia.org/wiki/Same-sex_marriage_in_the_United_States>marriage equality</a>. We then conduct a series of experiments to validate the hypothesis that the <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a> found in each community&#8217;s online language convey the bias in the community&#8217;s worldview.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.28/>Augmenting Neural Metaphor Detection with Concreteness</a></strong><br><a href=/people/g/ghadi-alnafesah/>Ghadi Alnafesah</a>
|
<a href=/people/h/harish-tayyar-madabushi/>Harish Tayyar Madabushi</a>
|
<a href=/people/m/mark-lee/>Mark Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--28><div class="card-body p-3 small">The idea that a shift in <a href=https://en.wikipedia.org/wiki/Concreteness>concreteness</a> within a sentence indicates the presence of a <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> has been around for a while. However, recent methods of detecting metaphor that have relied on <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural models</a> have ignored <a href=https://en.wikipedia.org/wiki/Concreteness>concreteness</a> and related psycholinguistic information. We hypothesis that this <a href=https://en.wikipedia.org/wiki/Information>information</a> is not available to these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> and that their addition will boost the performance of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> in detecting <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a>. We test this hypothesis on the Metaphor Detection Shared Task 2020 and find that the addition of concreteness information does in fact boost <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural models</a>. We also run tests on data from a previous <a href=https://en.wikipedia.org/wiki/Task_(computing)>shared task</a> and show similar results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.33.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--33 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.33 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929728 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.33/>Metaphor Detection using Ensembles of Bidirectional Recurrent Neural Networks</a></strong><br><a href=/people/j/jennifer-brooks/>Jennifer Brooks</a>
|
<a href=/people/a/abdou-youssef/>Abdou Youssef</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--33><div class="card-body p-3 small">In this paper we present our results from the Second Shared Task on Metaphor Detection, hosted by the Second Workshop on Figurative Language Processing. We use an ensemble of RNN models with bidirectional LSTMs and bidirectional attention mechanisms. Some of the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> were trained on all parts of speech. Each of the other models was trained on one of four categories for <a href=https://en.wikipedia.org/wiki/Part_of_speech>parts of speech</a> : <a href=https://en.wikipedia.org/wiki/Noun>nouns</a>, <a href=https://en.wikipedia.org/wiki/Verb>verbs</a>, <a href=https://en.wikipedia.org/wiki/Adjective>adverbs / adjectives</a>, or other. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> were combined into voting pools and the voting pools were combined using the logical OR operator.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.35.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--35 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.35 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929730 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.35/>Testing the role of <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> in metaphor identification</a></strong><br><a href=/people/e/egon-stemle/>Egon Stemle</a>
|
<a href=/people/a/alexander-onysko/>Alexander Onysko</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--35><div class="card-body p-3 small">This paper describes the adaptation and application of a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network system</a> for the automatic detection of metaphors. The LSTM BiRNN system participated in the shared task of metaphor identification that was part of the Second Workshop of Figurative Language Processing (FigLang2020) held at the Annual Conference of the Association for Computational Linguistics (ACL2020). The particular focus of our approach is on the potential influence that the <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> given in the ETS Corpus of Non-Native Written English might have on the automatic detection of metaphors in this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. The article first discusses the annotated ETS learner data, highlighting some of its peculiarities and inherent biases of metaphor use. A series of evaluations follow in order to test whether specific <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> influence the <a href=https://en.wikipedia.org/wiki/System>system</a> performance in the task of automatic metaphor identification. The <a href=https://en.wikipedia.org/wiki/System>system</a> is available under the APLv2 open-source license.</div></div></div><hr><div id=2020iwpt-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.iwpt-1/>Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.0/>Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies</a></strong><br><a href=/people/g/gosse-bouma/>Gosse Bouma</a>
|
<a href=/people/y/yuji-matsumoto/>Yuji Matsumoto</a>
|
<a href=/people/s/stephan-oepen/>Stephan Oepen</a>
|
<a href=/people/k/kenji-sagae/>Kenji Sagae</a>
|
<a href=/people/d/djame-seddah/>Djam Seddah</a>
|
<a href=/people/w/weiwei-sun/>Weiwei Sun</a>
|
<a href=/people/a/anders-sogaard/>Anders Sgaard</a>
|
<a href=/people/r/reut-tsarfaty/>Reut Tsarfaty</a>
|
<a href=/people/d/daniel-zeman/>Dan Zeman</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929668 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.1/>Syntactic Parsing in Humans and Machines</a></strong><br><a href=/people/p/paola-merlo/>Paola Merlo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--1><div class="card-body p-3 small">To process the syntactic structures of a language in ways that are compatible with human expectations, we need computational representations of lexical and syntactic properties that form the basis of human knowledge of words and sentences. Recent neural-network-based and distributed semantics techniques have developed systems of considerable practical success and impressive performance. As has been advocated by many, however, such <a href=https://en.wikipedia.org/wiki/System>systems</a> still lack human-like properties. In particular, linguistic, psycholinguistic and neuroscientific investigations have shown that human processing of sentences is sensitive to structure and unbounded relations. In the spirit of better understanding the structure building and long-distance properties of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, I will present an overview of recent results on agreement and island effects in <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> in several languages. While certain sets of results in the literature indicate that neural language models exhibit long-distance agreement abilities, other finer-grained investigation of how these effects are calculated indicates that that the similarity spaces they define do not correlate with human experimental results on intervention similarity in long-distance dependencies. This opens the way to reflections on how to better match the <a href=https://en.wikipedia.org/wiki/Syntax>syntactic properties</a> of <a href=https://en.wikipedia.org/wiki/Natural_language>natural languages</a> in the representations of neural models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929672 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.5/>Semi-supervised Parsing with a Variational Autoencoding Parser</a></strong><br><a href=/people/x/xiao-zhang/>Xiao Zhang</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--5><div class="card-body p-3 small">We propose an end-to-end variational autoencoding parsing (VAP) model for semi-supervised graph-based projective dependency parsing. It encodes the input using <a href=https://en.wikipedia.org/wiki/Latent_variable_model>continuous latent variables</a> in a sequential manner by <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks (DNN)</a> that can utilize the contextual information, and reconstruct the input using a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a>. The VAP model admits a unified structure with different <a href=https://en.wikipedia.org/wiki/Loss_function>loss functions</a> for labeled and unlabeled data with shared parameters. We conducted experiments on the WSJ data sets, showing the proposed model can use the unlabeled data to increase the performance on a limited amount of labeled data, on a par with a recently proposed semi-supervised parser with faster inference.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929674 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.iwpt-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.7/>Obfuscation for Privacy-preserving Syntactic Parsing</a></strong><br><a href=/people/z/zhifeng-hu/>Zhifeng Hu</a>
|
<a href=/people/s/serhii-havrylov/>Serhii Havrylov</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--7><div class="card-body p-3 small">The goal of <a href=https://en.wikipedia.org/wiki/Homomorphic_encryption>homomorphic encryption</a> is to encrypt data such that another party can operate on it without being explicitly exposed to the content of the original data. We introduce an idea for a privacy-preserving transformation on <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language data</a>, inspired by <a href=https://en.wikipedia.org/wiki/Homomorphic_encryption>homomorphic encryption</a>. Our primary tool is <a href=https://en.wikipedia.org/wiki/Obfuscation>obfuscation</a>, relying on the properties of <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Specifically, a given English text is obfuscated using a neural model that aims to preserve the syntactic relationships of the original sentence so that the obfuscated sentence can be parsed instead of the original one. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> works at the word level, and learns to obfuscate each word separately by changing it into a new word that has a similar syntactic role. The text obfuscated by our model leads to better performance on three syntactic parsers (two dependency and one constituency parsers) in comparison to an upper-bound random substitution baseline. More specifically, the results demonstrate that as more terms are obfuscated (by their part of speech), the substitution upper bound significantly degrades, while the neural model maintains a relatively high performing <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>. All of this is done without much sacrifice of <a href=https://en.wikipedia.org/wiki/Privacy>privacy</a> compared to the random substitution upper bound. We also further analyze the results, and discover that the substituted words have similar <a href=https://en.wikipedia.org/wiki/Syntax>syntactic properties</a>, but different <a href=https://en.wikipedia.org/wiki/Semantics>semantic content</a>, compared to the original words.<i>obfuscation</i>, relying on the properties of natural language. Specifically, a given English text is obfuscated using a neural model that aims to preserve the syntactic relationships of the original sentence so that the obfuscated sentence can be parsed instead of the original one. The model works at the word level, and learns to obfuscate each word separately by changing it into a new word that has a similar syntactic role. The text obfuscated by our model leads to better performance on three syntactic parsers (two dependency and one constituency parsers) in comparison to an upper-bound random substitution baseline. More specifically, the results demonstrate that as more terms are obfuscated (by their part of speech), the substitution upper bound significantly degrades, while the neural model maintains a relatively high performing parser. All of this is done without much sacrifice of privacy compared to the random substitution upper bound. We also further analyze the results, and discover that the substituted words have similar syntactic properties, but different semantic content, compared to the original words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.iwpt-1.8.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929675 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.8/>Tensors over Semirings for Latent-Variable Weighted Logic Programs</a></strong><br><a href=/people/e/esma-balkir/>Esma Balkir</a>
|
<a href=/people/d/daniel-gildea/>Daniel Gildea</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--8><div class="card-body p-3 small">Semiring parsing is an elegant <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for describing <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> by using semiring weighted logic programs. In this paper we present a generalization of this <a href=https://en.wikipedia.org/wiki/Concept>concept</a> : latent-variable semiring parsing. With our framework, any <a href=https://en.wikipedia.org/wiki/Semiring>semiring weighted logic program</a> can be latentified by transforming weights from scalar values of a <a href=https://en.wikipedia.org/wiki/Semiring>semiring</a> to rank-n arrays, or tensors, of <a href=https://en.wikipedia.org/wiki/Semiring>semiring values</a>, allowing the modelling of latent-variable models within the <a href=https://en.wikipedia.org/wiki/Semiring>semiring parsing framework</a>. Semiring is too strong a notion when dealing with <a href=https://en.wikipedia.org/wiki/Tensor>tensors</a>, and we have to resort to a weaker structure : a partial semiring. We prove that this <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> preserves all the desired properties of the original semiring framework while strictly increasing its expressiveness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929678 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.11/>Self-Training for Unsupervised Parsing with PRPN<span class=acl-fixed-case>PRPN</span></a></strong><br><a href=/people/a/anhad-mohananey/>Anhad Mohananey</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a>
|
<a href=/people/s/samuel-bowman/>Samuel R. Bowman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--11><div class="card-body p-3 small">Neural unsupervised parsing (UP) models learn to parse without access to syntactic annotations, while being optimized for another task like <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. In this work, we propose self-training for neural UP models : we leverage aggregated annotations predicted by copies of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> as supervision for future copies. To be able to use our model&#8217;s predictions during training, we extend a recent neural UP architecture, the PRPN (Shen et al., 2018a), such that it can be trained in a semi-supervised fashion. We then add examples with <a href=https://en.wikipedia.org/wiki/Parsing>parses</a> predicted by our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to our unlabeled UP training data. Our self-trained model outperforms the PRPN by 8.1 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> and the previous state of the art by 1.6 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a>. In addition, we show that our <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> can also be helpful for semi-supervised parsing in ultra-low-resource settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929686 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.19/>Adaptation of Multilingual Transformer Encoder for Robust Enhanced Universal Dependency Parsing<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependency Parsing</a></strong><br><a href=/people/h/han-he/>Han He</a>
|
<a href=/people/j/jinho-d-choi/>Jinho D. Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--19><div class="card-body p-3 small">This paper presents our enhanced dependency parsing approach using transformer encoders, coupled with a simple yet powerful ensemble algorithm that takes advantage of both tree and graph dependency parsing. Two types of transformer encoders are compared, a multilingual encoder and language-specific encoders. Our dependency tree parsing (DTP) approach generates only primary dependencies to form trees whereas our dependency graph parsing (DGP) approach handles both primary and secondary dependencies to form graphs. Since DGP does not guarantee the generated graphs are acyclic, the ensemble algorithm is designed to add secondary arcs predicted by DGP to primary arcs predicted by DTP. Our results show that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using the multilingual encoder outperform ones using the language specific encoders for most languages. The ensemble models generally show higher labeled attachment score on enhanced dependencies (ELAS) than the DTP and DGP models. As the result, our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> rank the third place on the macro-average ELAS over 17 languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929688 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.21/>Linear Neural Parsing and Hybrid Enhancement for Enhanced Universal Dependencies<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/g/giuseppe-attardi/>Giuseppe Attardi</a>
|
<a href=/people/d/daniele-sartiano/>Daniele Sartiano</a>
|
<a href=/people/m/maria-simi/>Maria Simi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--21><div class="card-body p-3 small">To accomplish the shared task on <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parsing</a> we explore the use of a linear transition-based neural dependency parser as well as a combination of three of them by means of a linear tree combination algorithm. We train separate <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for each language on the shared task data. We compare our base <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> with two biaffine parsers and also present an ensemble combination of all five <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a>, which achieves an average UAS 1.88 point lower than the top official submission. For producing the enhanced dependencies, we exploit a hybrid approach, coupling an algorithmic graph transformation of the dependency tree with predictions made by a multitask machine learning model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929690 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.23/>How Much of Enhanced UD Is Contained in UD?<span class=acl-fixed-case>UD</span> Is Contained in <span class=acl-fixed-case>UD</span>?</a></strong><br><a href=/people/a/adam-ek/>Adam Ek</a>
|
<a href=/people/j/jean-philippe-bernardy/>Jean-Philippe Bernardy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--23><div class="card-body p-3 small">In this paper, we present the submission of team CLASP to the IWPT 2020 Shared Task on parsing enhanced universal dependencies. We develop a tree-to-graph transformation algorithm based on dependency patterns. This <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> can transform gold UD trees to EUD graphs with an ELAS score of 81.55 and a EULAS score of 96.70. These results show that much of the information needed to construct EUD graphs from UD trees are present in the UD trees. Coupled with a standard UD parser, the method applies to the official test data and yields and ELAS score of 67.85 and a EULAS score is 80.18.</div></div></div><hr><div id=2020iwslt-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.iwslt-1/>Proceedings of the 17th International Conference on Spoken Language Translation</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.0/>Proceedings of the 17th International Conference on Spoken Language Translation</a></strong><br><a href=/people/m/marcello-federico/>Marcello Federico</a>
|
<a href=/people/a/alex-waibel/>Alex Waibel</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a>
|
<a href=/people/h/hermann-ney/>Hermann Ney</a>
|
<a href=/people/j/jan-niehues/>Jan Niehues</a>
|
<a href=/people/s/sebastian-stuker/>Sebastian Stker</a>
|
<a href=/people/d/dekai-wu/>Dekai Wu</a>
|
<a href=/people/j/joseph-mariani/>Joseph Mariani</a>
|
<a href=/people/f/francois-yvon/>Francois Yvon</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.9/>SRPOLs System for the IWSLT 2020 End-to-End Speech Translation Task<span class=acl-fixed-case>SRPOL</span>s System for the <span class=acl-fixed-case>IWSLT</span> 2020 End-to-End Speech Translation Task</a></strong><br><a href=/people/t/tomasz-potapczyk/>Tomasz Potapczyk</a>
|
<a href=/people/p/pawel-przybysz/>Pawel Przybysz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--9><div class="card-body p-3 small">We took part in the offline End-to-End English to German TED lectures translation task. We based our <a href=https://en.wikipedia.org/wiki/Solution>solution</a> on our last year&#8217;s submission. We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder. To improve the model&#8217;s quality of translation we introduced two regularization techniques and trained on machine translated Librispeech corpus in addition to iwslt-corpus, TEDLIUM2 andMust_C corpora. Our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> scored almost 3 BLEU higher than last year&#8217;s model. To segment 2020 test set we used exactly the same procedure as last year.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929617 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.10/>The University of Helsinki Submission to the IWSLT2020 Offline SpeechTranslation Task<span class=acl-fixed-case>U</span>niversity of <span class=acl-fixed-case>H</span>elsinki Submission to the <span class=acl-fixed-case>IWSLT</span>2020 Offline <span class=acl-fixed-case>S</span>peech<span class=acl-fixed-case>T</span>ranslation Task</a></strong><br><a href=/people/r/raul-vazquez/>Ral Vzquez</a>
|
<a href=/people/m/mikko-aulamo/>Mikko Aulamo</a>
|
<a href=/people/u/umut-sulubacak/>Umut Sulubacak</a>
|
<a href=/people/j/jorg-tiedemann/>Jrg Tiedemann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--10><div class="card-body p-3 small">This paper describes the University of Helsinki Language Technology group&#8217;s participation in the IWSLT 2020 offline speech translation task, addressing the translation of English audio into German text. In line with this year&#8217;s task objective, we train both cascade and end-to-end systems for spoken language translation. We opt for an end-to-end multitasking architecture with shared internal representations and a cascade approach that follows a standard procedure consisting of ASR, correction, and MT stages. We also describe the experiments that served as a basis for the submitted <a href=https://en.wikipedia.org/wiki/System>systems</a>. Our experiments reveal that multitasking training with shared internal representations is not only possible but allows for <a href=https://en.wikipedia.org/wiki/Knowledge_transfer>knowledge-transfer</a> across modalities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929615 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.11/>The AFRL IWSLT 2020 Systems : Work-From-Home Edition<span class=acl-fixed-case>AFRL</span> <span class=acl-fixed-case>IWSLT</span> 2020 Systems: Work-From-Home Edition</a></strong><br><a href=/people/b/brian-ore/>Brian Ore</a>
|
<a href=/people/e/eric-hansen/>Eric Hansen</a>
|
<a href=/people/t/tim-anderson/>Tim Anderson</a>
|
<a href=/people/j/jeremy-gwinnup/>Jeremy Gwinnup</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--11><div class="card-body p-3 small">This report summarizes the Air Force Research Laboratory (AFRL) submission to the offline spoken language translation (SLT) task as part of the IWSLT 2020 evaluation campaign. As in previous years, we chose to adopt the cascade approach of using separate systems to perform <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech activity detection</a>, <a href=https://en.wikipedia.org/wiki/Speech_recognition>automatic speech recognition</a>, <a href=https://en.wikipedia.org/wiki/Sentence_segmentation>sentence segmentation</a>, and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. All systems were neural based, including a fully-connected neural network for speech activity detection, a Kaldi factorized time delay neural network with recurrent neural network (RNN) language model rescoring for speech recognition, a bidirectional RNN with attention mechanism for sentence segmentation, and transformer networks trained with OpenNMT and Marian for machine translation. Our primary submission yielded BLEU scores of 21.28 on tst2019 and 23.33 on tst2020.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929611 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.13/>OPPOs Machine Translation System for the IWSLT 2020 Open Domain Translation Task<span class=acl-fixed-case>OPPO</span>s Machine Translation System for the <span class=acl-fixed-case>IWSLT</span> 2020 Open Domain Translation Task</a></strong><br><a href=/people/q/qian-zhang/>Qian Zhang</a>
|
<a href=/people/x/xiaopu-li/>Xiaopu Li</a>
|
<a href=/people/d/dawei-dang/>Dawei Dang</a>
|
<a href=/people/t/tingxun-shi/>Tingxun Shi</a>
|
<a href=/people/d/di-ai/>Di Ai</a>
|
<a href=/people/z/zhengshan-xue/>Zhengshan Xue</a>
|
<a href=/people/j/jie-hao/>Jie Hao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--13><div class="card-body p-3 small">In this paper, we demonstrate our <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation system</a> applied for the Chinese-Japanese bidirectional translation task (aka. open domain translation task) for the IWSLT 2020. Our model is based on Transformer (Vaswani et al., 2017), with the help of many popular, widely proved effective data preprocessing and augmentation methods. Experiments show that these <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> can improve the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline model</a> steadily and significantly.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929590 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.iwslt-1.14" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.14/>Character Mapping and Ad-hoc Adaptation : Edinburghs IWSLT 2020 Open Domain Translation System<span class=acl-fixed-case>E</span>dinburghs <span class=acl-fixed-case>IWSLT</span> 2020 Open Domain Translation System</a></strong><br><a href=/people/p/pinzhen-chen/>Pinzhen Chen</a>
|
<a href=/people/n/nikolay-bogoychev/>Nikolay Bogoychev</a>
|
<a href=/people/u/ulrich-germann/>Ulrich Germann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--14><div class="card-body p-3 small">This paper describes the University of Edinburgh&#8217;s neural machine translation systems submitted to the IWSLT 2020 open domain JapaneseChinese translation task. On top of commonplace techniques like <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenisation</a> and corpus cleaning, we explore character mapping and unsupervised decoding-time adaptation. Our techniques focus on leveraging the provided data, and we show the positive impact of each technique through the gradual improvement of BLEU.<tex-math>\\leftrightarrow</tex-math>Chinese translation task. On top of commonplace techniques like tokenisation and corpus cleaning, we explore character mapping and unsupervised decoding-time adaptation. Our techniques focus on leveraging the provided data, and we show the positive impact of each technique through the gradual improvement of BLEU.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929589 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.15/>CASIAs System for IWSLT 2020 Open Domain Translation<span class=acl-fixed-case>CASIA</span>s System for <span class=acl-fixed-case>IWSLT</span> 2020 Open Domain Translation</a></strong><br><a href=/people/q/qian-wang/>Qian Wang</a>
|
<a href=/people/y/yuchen-liu/>Yuchen Liu</a>
|
<a href=/people/c/cong-ma/>Cong Ma</a>
|
<a href=/people/y/yu-lu/>Yu Lu</a>
|
<a href=/people/y/yining-wang/>Yining Wang</a>
|
<a href=/people/l/long-zhou/>Long Zhou</a>
|
<a href=/people/y/yang-zhao/>Yang Zhao</a>
|
<a href=/people/j/jiajun-zhang/>Jiajun Zhang</a>
|
<a href=/people/c/chengqing-zong/>Chengqing Zong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--15><div class="card-body p-3 small">This paper describes the CASIA&#8217;s system for the IWSLT 2020 open domain translation task. This year we participate in both ChineseJapanese and JapaneseChinese translation tasks. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is neural machine translation system based on Transformer model. We augment the training data with knowledge distillation and back translation to improve the <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance. Domain data classification and weighted domain model ensemble are introduced to generate the final translation result. We compare and analyze the performance on <a href=https://en.wikipedia.org/wiki/Software_development_process>development data</a> with different model settings and different <a href=https://en.wikipedia.org/wiki/Data_processing>data processing techniques</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929592 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.16/>Deep Blue Sonics Submission to IWSLT 2020 Open Domain Translation Task<span class=acl-fixed-case>IWSLT</span> 2020 Open Domain Translation Task</a></strong><br><a href=/people/e/enmin-su/>Enmin Su</a>
|
<a href=/people/y/yi-ren/>Yi Ren</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--16><div class="card-body p-3 small">We present in this report our submission to IWSLT 2020 Open Domain Translation Task. We built a data pre-processing pipeline to efficiently handle large noisy web-crawled corpora, which boosts the BLEU score of a widely used transformer model in this translation task. To tackle the open-domain nature of this task, back- translation is applied to further improve the <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.19/>ISTICs Neural Machine Translation System for IWSLT2020<span class=acl-fixed-case>ISTIC</span>s Neural Machine Translation System for <span class=acl-fixed-case>IWSLT</span>2020</a></strong><br><a href=/people/j/jiaze-wei/>Jiaze Wei</a>
|
<a href=/people/w/wenbin-liu/>Wenbin Liu</a>
|
<a href=/people/z/zhenfeng-wu/>Zhenfeng Wu</a>
|
<a href=/people/y/you-pan/>You Pan</a>
|
<a href=/people/y/yanqing-he/>Yanqing He</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--19><div class="card-body p-3 small">This paper introduces technical details of machine translation system of Institute of Scientific and Technical Information of China (ISTIC) for the 17th International Conference on Spoken Language Translation (IWSLT 2020). ISTIC participated in both translation tasks of the Open Domain Translation track : Japanese-to-Chinese MT task and Chinese-to-Japanese MT task. The paper mainly elaborates on the <a href=https://en.wikipedia.org/wiki/Model-driven_architecture>model framework</a>, <a href=https://en.wikipedia.org/wiki/Data_preprocessing>data preprocessing methods</a> and decoding strategies adopted in our <a href=https://en.wikipedia.org/wiki/System>system</a>. In addition, the <a href=https://en.wikipedia.org/wiki/System>system</a> performance on the development set are given under different settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929616 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.23/>The HW-TSC Video Speech Translation System at IWSLT 2020<span class=acl-fixed-case>HW</span>-<span class=acl-fixed-case>TSC</span> Video Speech Translation System at <span class=acl-fixed-case>IWSLT</span> 2020</a></strong><br><a href=/people/m/minghan-wang/>Minghan Wang</a>
|
<a href=/people/h/hao-yang/>Hao Yang</a>
|
<a href=/people/y/yao-deng/>Yao Deng</a>
|
<a href=/people/y/ying-qin/>Ying Qin</a>
|
<a href=/people/l/lizhi-lei/>Lizhi Lei</a>
|
<a href=/people/d/daimeng-wei/>Daimeng Wei</a>
|
<a href=/people/h/hengchao-shang/>Hengchao Shang</a>
|
<a href=/people/n/ning-xie/>Ning Xie</a>
|
<a href=/people/x/xiaochun-li/>Xiaochun Li</a>
|
<a href=/people/j/jiaxian-guo/>Jiaxian Guo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--23><div class="card-body p-3 small">The paper presents details of our <a href=https://en.wikipedia.org/wiki/System>system</a> in the IWSLT Video Speech Translation evaluation. The <a href=https://en.wikipedia.org/wiki/System>system</a> works in a cascade form, which contains three <a href=https://en.wikipedia.org/wiki/Modular_programming>modules</a> : 1) A proprietary ASR system. 2) A disfluency correction system aims to remove interregnums or other disfluent expressions with a fine-tuned BERT and a series of rule-based algorithms. 3) An NMT System based on the Transformer and trained with massive publicly available corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.24/>CUNI Neural ASR with Phoneme-Level Intermediate Step for ~ Non-Native ~ SLT at IWSLT 2020<span class=acl-fixed-case>CUNI</span> Neural <span class=acl-fixed-case>ASR</span> with Phoneme-Level Intermediate Step for~<span class=acl-fixed-case>N</span>on-<span class=acl-fixed-case>N</span>ative~<span class=acl-fixed-case>SLT</span> at <span class=acl-fixed-case>IWSLT</span> 2020</a></strong><br><a href=/people/p/peter-polak/>Peter Polk</a>
|
<a href=/people/s/sangeet-sagar/>Sangeet Sagar</a>
|
<a href=/people/d/dominik-machacek/>Dominik Machek</a>
|
<a href=/people/o/ondrej-bojar/>Ondej Bojar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--24><div class="card-body p-3 small">In this paper, we present our submission to the Non-Native Speech Translation Task for IWSLT 2020. Our main contribution is a proposed speech recognition pipeline that consists of an <a href=https://en.wikipedia.org/wiki/Acoustic_model>acoustic model</a> and a phoneme-to-grapheme model. As an <a href=https://en.wikipedia.org/wiki/Intermediate_representation>intermediate representation</a>, we utilize <a href=https://en.wikipedia.org/wiki/Phoneme>phonemes</a>. We demonstrate that the proposed <a href=https://en.wikipedia.org/wiki/Pipeline_transport>pipeline</a> surpasses commercially used automatic speech recognition (ASR) and submit it into the ASR track. We complement this ASR with off-the-shelf MT systems to take part also in the speech translation track.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929595 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.25/>ELITR Non-Native Speech Translation at IWSLT 2020<span class=acl-fixed-case>ELITR</span> Non-Native Speech Translation at <span class=acl-fixed-case>IWSLT</span> 2020</a></strong><br><a href=/people/d/dominik-machacek/>Dominik Machek</a>
|
<a href=/people/j/jonas-kratochvil/>Jon Kratochvl</a>
|
<a href=/people/s/sangeet-sagar/>Sangeet Sagar</a>
|
<a href=/people/m/matus-zilinec/>Mat ilinec</a>
|
<a href=/people/o/ondrej-bojar/>Ondej Bojar</a>
|
<a href=/people/t/thai-son-nguyen/>Thai-Son Nguyen</a>
|
<a href=/people/f/felix-schneider/>Felix Schneider</a>
|
<a href=/people/p/philip-williams/>Philip Williams</a>
|
<a href=/people/y/yuekun-yao/>Yuekun Yao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--25><div class="card-body p-3 small">This paper is an ELITR system submission for the non-native speech translation task at IWSLT 2020. We describe systems for offline ASR, real-time ASR, and our cascaded approach to offline SLT and real-time SLT. We select our primary candidates from a pool of pre-existing systems, develop a new end-to-end general ASR system, and a hybrid ASR trained on non-native speech. The provided small validation set prevents us from carrying out a complex validation, but we submit all the unselected candidates for contrastive evaluation on the test set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.29.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--29 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.29 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929608 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.29/>Neural Simultaneous Speech Translation Using Alignment-Based Chunking</a></strong><br><a href=/people/p/patrick-wilken/>Patrick Wilken</a>
|
<a href=/people/t/tamer-alkhouli/>Tamer Alkhouli</a>
|
<a href=/people/e/evgeny-matusov/>Evgeny Matusov</a>
|
<a href=/people/p/pavel-golik/>Pavel Golik</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--29><div class="card-body p-3 small">In simultaneous machine translation, the objective is to determine when to produce a partial translation given a continuous stream of source words, with a trade-off between <a href=https://en.wikipedia.org/wiki/Latency_(engineering)>latency</a> and <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a>. We propose a neural machine translation (NMT) model that makes dynamic decisions when to continue feeding on input or generate output words. The model is composed of two main <a href=https://en.wikipedia.org/wiki/Component-based_software_engineering>components</a> : one to dynamically decide on ending a source chunk, and another that translates the consumed chunk. We train the components jointly and in a manner consistent with the <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference conditions</a>. To generate chunked training data, we propose a method that utilizes <a href=https://en.wikipedia.org/wiki/Word_alignment>word alignment</a> while also preserving enough context. We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input. Our results on the IWSLT 2020 English-to-German task outperform a wait-k baseline by 2.6 to 3.7 % BLEU absolute.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwslt-1.33.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwslt-1--33 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwslt-1.33 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929594 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwslt-1.33/>Efficient Automatic Punctuation Restoration Using Bidirectional Transformers with Robust Inference</a></strong><br><a href=/people/m/maury-courtland/>Maury Courtland</a>
|
<a href=/people/a/adam-faulkner/>Adam Faulkner</a>
|
<a href=/people/g/gayle-mcelvain/>Gayle McElvain</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwslt-1--33><div class="card-body p-3 small">Though people rarely speak in complete sentences, <a href=https://en.wikipedia.org/wiki/Punctuation>punctuation</a> confers many benefits to the readers of <a href=https://en.wikipedia.org/wiki/Transcription_(linguistics)>transcribed speech</a>. Unfortunately, most ASR systems do not produce punctuated output. To address this, we propose a <a href=https://en.wikipedia.org/wiki/Solution>solution</a> for automatic punctuation that is both cost efficient and easy to train. Our <a href=https://en.wikipedia.org/wiki/Solution>solution</a> benefits from the recent trend in fine-tuning transformer-based language models. We also modify the typical framing of this task by predicting <a href=https://en.wikipedia.org/wiki/Punctuation>punctuation</a> for sequences rather than individual tokens, which makes for more efficient <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> and <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a>. Finally, we find that aggregating predictions across multiple context windows improves accuracy even further. Our best model achieves a new state of the art on benchmark data (TED Talks) with a combined F1 of 83.9, representing a 48.7 % relative improvement (15.3 absolute) over the previous state of the art.</div></div></div><hr><div id=2020ngt-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.ngt-1/>Proceedings of the Fourth Workshop on Neural Generation and Translation</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ngt-1.0/>Proceedings of the Fourth Workshop on Neural Generation and Translation</a></strong><br><a href=/people/a/alexandra-birch/>Alexandra Birch</a>
|
<a href=/people/a/andrew-finch/>Andrew Finch</a>
|
<a href=/people/h/hiroaki-hayashi/>Hiroaki Hayashi</a>
|
<a href=/people/k/kenneth-heafield/>Kenneth Heafield</a>
|
<a href=/people/m/marcin-junczys-dowmunt/>Marcin Junczys-Dowmunt</a>
|
<a href=/people/i/ioannis-konstas/>Ioannis Konstas</a>
|
<a href=/people/x/xian-li/>Xian Li</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/y/yusuke-oda/>Yusuke Oda</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929815 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.2/>Learning to Generate Multiple Style Transfer Outputs for an Input Sentence</a></strong><br><a href=/people/k/kevin-lin/>Kevin Lin</a>
|
<a href=/people/m/ming-yu-liu/>Ming-Yu Liu</a>
|
<a href=/people/m/ming-ting-sun/>Ming-Ting Sun</a>
|
<a href=/people/j/jan-kautz/>Jan Kautz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--2><div class="card-body p-3 small">Text style transfer refers to the task of rephrasing a given text in a different style. While various methods have been proposed to advance the state of the art, they often assume the transfer output follows a <a href=https://en.wikipedia.org/wiki/Delta_distribution>delta distribution</a>, and thus their <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can not generate different style transfer results for a given input text. To address the limitation, we propose a one-to-many text style transfer framework. In contrast to prior works that learn a <a href=https://en.wikipedia.org/wiki/One-to-one_mapping>one-to-one mapping</a> that converts an input sentence to one output sentence, our approach learns a one-to-many mapping that can convert an input sentence to multiple different output sentences, while preserving the input content. This is achieved by applying <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversarial training</a> with a latent decomposition scheme. Specifically, we decompose the latent representation of the input sentence to a style code that captures the language style variation and a content code that encodes the language style-independent content. We then combine the <a href=https://en.wikipedia.org/wiki/Content_(media)>content code</a> with the <a href=https://en.wikipedia.org/wiki/Style_sheet_(web_development)>style code</a> for generating a style transfer output. By combining the same <a href=https://en.wikipedia.org/wiki/Content_(media)>content code</a> with a different <a href=https://en.wikipedia.org/wiki/Style_sheet_(web_development)>style code</a>, we generate a different style transfer output. Extensive experimental results with comparisons to several text style transfer approaches on multiple public datasets using a diverse set of performance metrics validate effectiveness of the proposed approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929819 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.6/>Automatically Ranked Russian Paraphrase Corpus for Text Generation<span class=acl-fixed-case>R</span>ussian Paraphrase Corpus for Text Generation</a></strong><br><a href=/people/v/vadim-gudkov/>Vadim Gudkov</a>
|
<a href=/people/o/olga-mitrofanova/>Olga Mitrofanova</a>
|
<a href=/people/e/elizaveta-filippskikh/>Elizaveta Filippskikh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--6><div class="card-body p-3 small">The article is focused on automatic development and ranking of a large corpus for Russian paraphrase generation which proves to be the first <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of such type in Russian computational linguistics. Existing manually annotated paraphrase datasets for Russian are limited to small-sized ParaPhraser corpus and ParaPlag which are suitable for a set of NLP tasks, such as paraphrase and plagiarism detection, sentence similarity and relatedness estimation, etc. Due to size restrictions, these <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> can hardly be applied in end-to-end text generation solutions. Meanwhile, <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> requires a large amount of training data. In our study we propose a solution to the problem : we collect, rank and evaluate a new publicly available headline paraphrase corpus (ParaPhraser Plus), and then perform text generation experiments with manual evaluation on automatically ranked corpora using the Universal Transformer architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929825 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.12/>Distill, Adapt, Distill : Training Small, In-Domain Models for Neural Machine Translation</a></strong><br><a href=/people/m/mitchell-gordon/>Mitchell Gordon</a>
|
<a href=/people/k/kevin-duh/>Kevin Duh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--12><div class="card-body p-3 small">We explore best practices for training small, memory efficient <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation models</a> with sequence-level knowledge distillation in the domain adaptation setting. While both <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> and knowledge distillation are widely-used, their interaction remains little understood. Our large-scale empirical results in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> (on three language pairs with three domains each) suggest distilling twice for best performance : once using general-domain data and again using in-domain data with an adapted teacher.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929831 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.17/>The ADAPT System Description for the STAPLE 2020 English-to-Portuguese Translation Task<span class=acl-fixed-case>ADAPT</span> System Description for the <span class=acl-fixed-case>STAPLE</span> 2020 <span class=acl-fixed-case>E</span>nglish-to-<span class=acl-fixed-case>P</span>ortuguese Translation Task</a></strong><br><a href=/people/r/rejwanul-haque/>Rejwanul Haque</a>
|
<a href=/people/y/yasmin-moslem/>Yasmin Moslem</a>
|
<a href=/people/a/andy-way/>Andy Way</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--17><div class="card-body p-3 small">This paper describes the ADAPT Centre&#8217;s submission to STAPLE (Simultaneous Translation and Paraphrase for Language Education) 2020, a shared task of the 4th Workshop on Neural Generation and Translation (WNGT), for the English-to-Portuguese translation task. In this shared task, the participants were asked to produce high-coverage sets of plausible translations given English prompts (input source sentences). We present our English-to-Portuguese machine translation (MT) models that were built applying various strategies, e.g. data and sentence selection, monolingual MT for generating alternative translations, and combining multiple n-best translations. Our experiments show that adding the aforementioned techniques to the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> yields an excellent performance in the English-to-Portuguese translation task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929839 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.25/>Efficient and High-Quality <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> with OpenNMT<span class=acl-fixed-case>O</span>pen<span class=acl-fixed-case>NMT</span></a></strong><br><a href=/people/g/guillaume-klein/>Guillaume Klein</a>
|
<a href=/people/d/dakun-zhang/>Dakun Zhang</a>
|
<a href=/people/c/clement-chouteau/>Clment Chouteau</a>
|
<a href=/people/j/josep-m-crego/>Josep Crego</a>
|
<a href=/people/j/jean-senellart/>Jean Senellart</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--25><div class="card-body p-3 small">This paper describes the OpenNMT submissions to the WNGT 2020 efficiency shared task. We explore training and acceleration of Transformer models with various sizes that are trained in a teacher-student setup. We also present a custom and optimized C++ inference engine that enables fast CPU and GPU decoding with few dependencies. By combining additional <a href=https://en.wikipedia.org/wiki/Optimizing_compiler>optimizations</a> and <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallelization techniques</a>, we create small, efficient, and high-quality neural machine translation models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.ngt-1.26.Dataset.txt data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929840 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.26/>Edinburghs Submissions to the 2020 Machine Translation Efficiency Task<span class=acl-fixed-case>E</span>dinburghs Submissions to the 2020 Machine Translation Efficiency Task</a></strong><br><a href=/people/n/nikolay-bogoychev/>Nikolay Bogoychev</a>
|
<a href=/people/r/roman-grundkiewicz/>Roman Grundkiewicz</a>
|
<a href=/people/a/alham-fikri-aji/>Alham Fikri Aji</a>
|
<a href=/people/m/maximiliana-behnke/>Maximiliana Behnke</a>
|
<a href=/people/k/kenneth-heafield/>Kenneth Heafield</a>
|
<a href=/people/s/sidharth-kashyap/>Sidharth Kashyap</a>
|
<a href=/people/e/emmanouil-ioannis-farsarakis/>Emmanouil-Ioannis Farsarakis</a>
|
<a href=/people/m/mateusz-chudyk/>Mateusz Chudyk</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--26><div class="card-body p-3 small">We participated in all tracks of the Workshop on Neural Generation and Translation 2020 Efficiency Shared Task : <a href=https://en.wikipedia.org/wiki/Single-core>single-core CPU</a>, <a href=https://en.wikipedia.org/wiki/Multi-core_processor>multi-core CPU</a>, and <a href=https://en.wikipedia.org/wiki/Graphics_processing_unit>GPU</a>. At the model level, we use teacher-student training with a variety of student sizes, tie embeddings and sometimes layers, use the Simpler Simple Recurrent Unit, and introduce head pruning. On <a href=https://en.wikipedia.org/wiki/Graphics_processing_unit>GPUs</a>, we used 16-bit floating-point tensor cores. On <a href=https://en.wikipedia.org/wiki/Central_processing_unit>CPUs</a>, we customized 8-bit quantization and <a href=https://en.wikipedia.org/wiki/Multiprocessing>multiple processes</a> with affinity for the <a href=https://en.wikipedia.org/wiki/Multi-core_processor>multi-core setting</a>. To reduce model size, we experimented with 4-bit log quantization but use floats at runtime. In the shared task, most of our submissions were Pareto optimal with respect the trade-off between time and quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ngt-1.27/>Improving Document-Level Neural Machine Translation with Domain Adaptation</a></strong><br><a href=/people/s/sami-ul-haq/>Sami Ul Haq</a>
|
<a href=/people/s/sadaf-abdul-rauf/>Sadaf Abdul Rauf</a>
|
<a href=/people/a/arslan-shoukat/>Arslan Shoukat</a>
|
<a href=/people/n/noor-e-hira/>Noor-e- Hira</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--27><div class="card-body p-3 small">Recent studies have shown that translation quality of NMT systems can be improved by providing document-level contextual information. In general sentence-based NMT models are extended to capture <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a> from large-scale document-level corpora which are difficult to acquire. Domain adaptation on the other hand promises adapting components of already developed <a href=https://en.wikipedia.org/wiki/System>systems</a> by exploiting limited in-domain data. This paper presents FJWU&#8217;s system submission at WNGT, we specifically participated in Document level MT task for German-English translation. Our system is based on context-aware Transformer model developed on top of original NMT architecture by integrating contextual information using attention networks. Our experimental results show providing previous sentences as context significantly improves the BLEU score as compared to a strong NMT baseline. We also studied the impact of domain adaptation on document level translationand were able to improve results by adaptingthe <a href=https://en.wikipedia.org/wiki/System>systems</a> according to the testing domain.</div></div></div><hr><div id=2020nli-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nli-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.nli-1/>Proceedings of the First Workshop on Natural Language Interfaces</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nli-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nli-1.0/>Proceedings of the First Workshop on Natural Language Interfaces</a></strong><br><a href=/people/a/ahmed-hassan/>Ahmed Hassan Awadallah</a>
|
<a href=/people/y/yu-su/>Yu Su</a>
|
<a href=/people/h/huan-sun/>Huan Sun</a>
|
<a href=/people/w/wen-tau-yih/>Scott Wen-tau Yih</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nli-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nli-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nli-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929797 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nli-1.1/>Answering Complex Questions by Combining Information from Curated and Extracted Knowledge Bases</a></strong><br><a href=/people/n/nikita-bhutani/>Nikita Bhutani</a>
|
<a href=/people/x/xinyi-zheng/>Xinyi Zheng</a>
|
<a href=/people/k/kun-qian/>Kun Qian</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/h/h-jagadish/>H. Jagadish</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nli-1--1><div class="card-body p-3 small">Knowledge-based question answering (KB_QA) has long focused on simple questions that can be answered from a single knowledge source, a manually curated or an automatically extracted KB. In this work, we look at answering complex questions which often require combining information from multiple sources. We present a novel KB-QA system, Multique, which can map a complex question to a complex query pattern using a sequence of simple queries each targeted at a specific KB. It finds simple queries using a neural-network based model capable of collective inference over textual relations in extracted KB and <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontological relations</a> in curated KB. Experiments show that our proposed system outperforms previous KB-QA systems on benchmark datasets, ComplexWebQuestions and WebQuestionsSP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nli-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nli-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nli-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929795 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nli-1.2/>Towards Reversal-Based Textual Data Augmentation for NLI Problems with Opposable Classes<span class=acl-fixed-case>NLI</span> Problems with Opposable Classes</a></strong><br><a href=/people/a/alexey-tarasov/>Alexey Tarasov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nli-1--2><div class="card-body p-3 small">Data augmentation methods are commonly used in <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a> and <a href=https://en.wikipedia.org/wiki/Speech>speech</a>. However, in domains dealing with <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual data</a>, such techniques are not that common. Most of the existing methods rely on <a href=https://en.wikipedia.org/wiki/Rephrasing>rephrasing</a>, i.e. new sentences are generated by changing a source sentence, preserving its meaning. We argue that in tasks with opposable classes (such as Positive and Negative in sentiment analysis), it might be beneficial to also invert the source sentence, reversing its meaning, to generate examples of the opposing class. Methods that use somewhat similar intuition exist in the space of <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning</a>, but are not always applicable to text classification (in our experiments, some of them were even detrimental to the resulting classifier accuracy). We propose and evaluate two reversal-based methods on an NLI task of recognising a type of a simple logical expression from its description in plain-text form. After gathering a dataset on <a href=https://en.wikipedia.org/wiki/MTurk>MTurk</a>, we show that a simple <a href=https://en.wikipedia.org/wiki/Heuristic>heuristic</a> using a notion of negating the main verb has a potential not only on its own, but that it can also boost existing state-of-the-art rephrasing-based approaches.</div></div></div><hr><div id=2020nlp4convai-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.nlp4convai-1/>Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.0/>Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI</a></strong><br><a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/z/zhou-yu/>Zhou Yu</a>
|
<a href=/people/a/alexandros-papangelis/>Alexandros Papangelis</a>
|
<a href=/people/m/mihail-eric/>Mihail Eric</a>
|
<a href=/people/a/anuj-kumar/>Anuj Kumar</a>
|
<a href=/people/i/inigo-casanueva/>Iigo Casanueva</a>
|
<a href=/people/r/rushin-shah/>Rushin Shah</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929634 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.4/>How to Tame Your Data : <a href=https://en.wikipedia.org/wiki/Data_augmentation>Data Augmentation</a> for Dialog State Tracking</a></strong><br><a href=/people/a/adam-summerville/>Adam Summerville</a>
|
<a href=/people/j/jordan-hashemi/>Jordan Hashemi</a>
|
<a href=/people/j/james-ryan/>James Ryan</a>
|
<a href=/people/w/william-ferguson/>William Ferguson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--4><div class="card-body p-3 small">Dialog State Tracking (DST) is a problem space in which the effective vocabulary is practically limitless. For example, the domain of possible <a href=https://en.wikipedia.org/wiki/Film_title_design>movie titles</a> or restaurant names is bound only by the limits of language. As such, DST systems often encounter out-of-vocabulary words at inference time that were never encountered during training. To combat this issue, we present a targeted data augmentation process, by which a practitioner observes the types of errors made on held-out evaluation data, and then modifies the training data with additional corpora to increase the vocabulary size at training time. Using this with a RoBERTa-based Transformer architecture, we achieve state-of-the-art results in comparison to systems that only mask trouble slots with special tokens. Additionally, we present a data-representation scheme for seamlessly retargeting DST architectures to new domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.nlp4convai-1.5.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929632 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlp4convai-1.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.5/>Efficient Intent Detection with Dual Sentence Encoders</a></strong><br><a href=/people/i/inigo-casanueva/>Iigo Casanueva</a>
|
<a href=/people/t/tadas-temcinas/>Tadas Teminas</a>
|
<a href=/people/d/daniela-gerz/>Daniela Gerz</a>
|
<a href=/people/m/matthew-henderson/>Matthew Henderson</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vuli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--5><div class="card-body p-3 small">Building conversational systems in new domains and with added functionality requires resource-efficient models that work under low-data regimes (i.e., in few-shot setups). Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT. We demonstrate the usefulness and wide applicability of the proposed intent detectors, showing that : 1) they outperform intent detectors based on fine-tuning the full BERT-Large model or using BERT as a fixed black-box encoder on three diverse intent detection data sets ; 2) the gains are especially pronounced in few-shot setups (i.e., with only 10 or 30 annotated examples per intent) ; 3) our intent detectors can be trained in a matter of minutes on a single CPU ; and 4) they are stable across different hyperparameter settings. In hope of facilitating and democratizing research focused on intention detection, we release our code, as well as a new challenging single-domain intent detection dataset comprising 13,083 annotated examples over 77 intents.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlp4convai-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.6/>Accelerating <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Understanding</a> in Task-Oriented Dialog</a></strong><br><a href=/people/o/ojas-ahuja/>Ojas Ahuja</a>
|
<a href=/people/s/shrey-desai/>Shrey Desai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--6><div class="card-body p-3 small">Task-oriented dialog models typically leverage complex neural architectures and large-scale, pre-trained Transformers to achieve state-of-the-art performance on popular natural language understanding benchmarks. However, these models frequently have in excess of tens of millions of parameters, making them impossible to deploy on-device where <a href=https://en.wikipedia.org/wiki/Resource_efficiency>resource-efficiency</a> is a major concern. In this work, we show that a simple convolutional model compressed with structured pruning achieves largely comparable results to BERT on <a href=https://en.wikipedia.org/wiki/Automatic_terminal_information_service>ATIS</a> and Snips, with under 100 K parameters. Moreover, we perform acceleration experiments on <a href=https://en.wikipedia.org/wiki/Central_processing_unit>CPUs</a>, where we observe our multi-task model predicts intents and slots nearly 63x faster than even DistilBERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.nlp4convai-1.9.Software.txt data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.nlp4convai-1.9.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929630 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.9/>Automating Template Creation for Ranking-Based Dialogue Models</a></strong><br><a href=/people/j/jingxiang-chen/>Jingxiang Chen</a>
|
<a href=/people/h/heba-elfardy/>Heba Elfardy</a>
|
<a href=/people/s/simi-wang/>Simi Wang</a>
|
<a href=/people/a/andrea-kahn/>Andrea Kahn</a>
|
<a href=/people/j/jared-kramer/>Jared Kramer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--9><div class="card-body p-3 small">Dialogue response generation models that use template ranking rather than direct sequence generation allow model developers to limit generated responses to pre-approved messages. However, manually creating templates is time-consuming and requires domain expertise. To alleviate this problem, we explore automating the process of creating dialogue templates by using <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a> to cluster historical utterances and selecting representative utterances from each <a href=https://en.wikipedia.org/wiki/Cluster_analysis>cluster</a>. Specifically, we propose an end-to-end model called Deep Sentence Encoder Clustering (DSEC) that uses an auto-encoder structure to jointly learn the utterance representation and construct template clusters. We compare this method to a random baseline that randomly assigns templates to clusters as well as a strong baseline that performs the sentence encoding and the utterance clustering sequentially. To evaluate the performance of the proposed method, we perform an automatic evaluation with two annotated customer service datasets to assess clustering effectiveness, and a human-in-the-loop experiment using a live customer service application to measure the acceptance rate of the generated templates. DSEC performs best in the automatic evaluation, beats both the sequential and random baselines on most metrics in the human-in-the-loop experiment, and shows promising results when compared to gold / manually created templates.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929641 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlp4convai-1.13" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.13/>MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines<span class=acl-fixed-case>M</span>ulti<span class=acl-fixed-case>WOZ</span> 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines</a></strong><br><a href=/people/x/xiaoxue-zang/>Xiaoxue Zang</a>
|
<a href=/people/a/abhinav-rastogi/>Abhinav Rastogi</a>
|
<a href=/people/s/srinivas-sunkara/>Srinivas Sunkara</a>
|
<a href=/people/r/raghav-gupta/>Raghav Gupta</a>
|
<a href=/people/j/jianguo-zhang/>Jianguo Zhang</a>
|
<a href=/people/j/jindong-chen/>Jindong Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--13><div class="card-body p-3 small">MultiWOZ is a well-known task-oriented dialogue dataset containing over 10,000 annotated dialogues spanning 8 domains. It is extensively used as a benchmark for dialogue state tracking. However, recent works have reported presence of substantial noise in the dialogue state annotations. MultiWOZ 2.1 identified and fixed many of these erroneous <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> and user utterances, resulting in an improved version of this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. This work introduces MultiWOZ 2.2, which is a yet another improved version of this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. Firstly, we identify and fix dialogue state annotation errors across 17.3 % of the utterances on top of MultiWOZ 2.1. Secondly, we redefine the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> by disallowing vocabularies of slots with a large number of possible values (e.g., restaurant name, time of booking). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them. We also benchmark a few state of the art dialogue state tracking models on the corrected dataset to facilitate comparison for future work. In the end, we discuss best practices for dialogue data collection that can help avoid annotation errors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929635 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlp4convai-1.15" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.15/>Probing Neural Dialog Models for Conversational Understanding</a></strong><br><a href=/people/a/abdelrhman-saleh/>Abdelrhman Saleh</a>
|
<a href=/people/t/tovly-deutsch/>Tovly Deutsch</a>
|
<a href=/people/s/stephen-casper/>Stephen Casper</a>
|
<a href=/people/y/yonatan-belinkov/>Yonatan Belinkov</a>
|
<a href=/people/s/stuart-m-shieber/>Stuart Shieber</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--15><div class="card-body p-3 small">The predominant approach to open-domain dialog generation relies on end-to-end training of neural models on chat datasets. However, this approach provides little insight as to what these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> learn (or do not learn) about engaging in <a href=https://en.wikipedia.org/wiki/Dialogue>dialog</a>. In this study, we analyze the internal representations learned by neural open-domain dialog systems and evaluate the quality of these <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> for learning basic conversational skills. Our results suggest that standard open-domain dialog systems struggle with answering questions, inferring <a href=https://en.wikipedia.org/wiki/Contradiction>contradiction</a>, and determining the topic of conversation, among other tasks. We also find that the dyadic, turn-taking nature of <a href=https://en.wikipedia.org/wiki/Dialogue>dialog</a> is not fully leveraged by these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. By exploring these limitations, we highlight the need for additional research into <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> and <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training methods</a> that can better capture high-level information about dialog.</div></div></div><hr><div id=2020nlpcovid19-acl><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.nlpcovid19-acl/>Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-acl.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-acl.0/>Proceedings of the 1st Workshop on <span class=acl-fixed-case>NLP</span> for <span class=acl-fixed-case>COVID-19</span> at <span class=acl-fixed-case>ACL</span> 2020</a></strong><br><a href=/people/k/karin-verspoor/>Karin Verspoor</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/e/emilio-ferrara/>Emilio Ferrara</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/r/robert-munro/>Robert Munro</a>
|
<a href=/people/c/cecile-paris/>Cecile Paris</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-acl.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpcovid19-acl--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpcovid19-acl.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-acl.3/>Document Classification for COVID-19 Literature<span class=acl-fixed-case>COVID-19</span> Literature</a></strong><br><a href=/people/b/bernal-jimenez-gutierrez/>Bernal Jimnez Gutirrez</a>
|
<a href=/people/j/juncheng-zeng/>Juncheng Zeng</a>
|
<a href=/people/d/dongdong-zhang/>Dongdong Zhang</a>
|
<a href=/people/p/ping-zhang/>Ping Zhang</a>
|
<a href=/people/y/yu-su/>Yu Su</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpcovid19-acl--3><div class="card-body p-3 small">The global pandemic has made it more important than ever to quickly and accurately retrieve relevant scientific literature for effective consumption by researchers in a wide range of fields. We provide an analysis of several multi-label document classification models on the LitCovid dataset. We find that pre-trained language models outperform other <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> in both low and high data regimes, achieving a maximum F1 score of around 86 %. We note that even the highest performing models still struggle with label correlation, distraction from introductory text and CORD-19 generalization. Both data and code are available on GitHub.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-acl.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpcovid19-acl--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpcovid19-acl.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlpcovid19-acl.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-acl.5/>Self-supervised context-aware COVID-19 document exploration through atlas grounding<span class=acl-fixed-case>COVID-19</span> document exploration through atlas grounding</a></strong><br><a href=/people/d/dusan-grujicic/>Dusan Grujicic</a>
|
<a href=/people/g/gorjan-radevski/>Gorjan Radevski</a>
|
<a href=/people/t/tinne-tuytelaars/>Tinne Tuytelaars</a>
|
<a href=/people/m/matthew-blaschko/>Matthew Blaschko</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpcovid19-acl--5><div class="card-body p-3 small">In this paper, we aim to develop a self-supervised grounding of Covid-related medical text based on the actual spatial relationships between the referred anatomical concepts. More specifically, we learn to project sentences into a physical space defined by a three-dimensional anatomical atlas, allowing for a visual approach to navigating Covid-related literature. We design a straightforward and empirically effective training objective to reduce the curated data dependency issue. We use BERT as the main building block of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and perform a quantitative analysis that demonstrates that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> learns a context-aware mapping. We illustrate two potential use-cases for our approach, one in interactive, 3D data exploration, and the other in <a href=https://en.wikipedia.org/wiki/Document_retrieval>document retrieval</a>. To accelerate research in this direction, we make public all trained models, codebase and the developed tools, which can be accessed at https://github.com/gorjanradevski/macchina/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-acl.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpcovid19-acl--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpcovid19-acl.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-acl.12/>Estimating the effect of COVID-19 on mental health : Linguistic indicators of depression during a global pandemic<span class=acl-fixed-case>COVID-19</span> on mental health: Linguistic indicators of depression during a global pandemic</a></strong><br><a href=/people/j/jt-wolohan/>JT Wolohan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpcovid19-acl--12><div class="card-body p-3 small">This preliminary analysis uses a deep LSTM neural network with fastText embeddings to predict population rates of depression on <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a> in order to estimate the effect of COVID-19 on mental health. We find that year over year, depression rates on <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a> are up 50 %, suggesting a 15-million person increase in the number of depressed Americans and a $ 7.5 billion increase in depression related spending. This finding suggests that utility in NLP approaches to longitudinal public-health surveillance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-acl.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpcovid19-acl--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpcovid19-acl.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlpcovid19-acl.13" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-acl.13/>Exploration of Gender Differences in COVID-19 Discourse on Reddit<span class=acl-fixed-case>COVID-19</span> Discourse on <span class=acl-fixed-case>R</span>eddit</a></strong><br><a href=/people/j/jai-aggarwal/>Jai Aggarwal</a>
|
<a href=/people/e/ella-rabinovich/>Ella Rabinovich</a>
|
<a href=/people/s/suzanne-stevenson/>Suzanne Stevenson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpcovid19-acl--13><div class="card-body p-3 small">Decades of research on differences in the language of men and women have established postulates about the nature of lexical, topical, and emotional preferences between the two genders, along with their sociological underpinnings. Using a novel dataset of male and female linguistic productions collected from the Reddit discussion platform, we further confirm existing assumptions about gender-linked affective distinctions, and demonstrate that these distinctions are amplified in social media postings involving emotionally-charged discourse related to COVID-19. Our analysis also confirms considerable differences in topical preferences between male and female authors in pandemic-related discussions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-acl.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpcovid19-acl--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpcovid19-acl.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-acl.15/>Cross-lingual Transfer Learning for COVID-19 Outbreak Alignment<span class=acl-fixed-case>COVID-19</span> Outbreak Alignment</a></strong><br><a href=/people/s/sharon-levy/>Sharon Levy</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpcovid19-acl--15><div class="card-body p-3 small">The spread of COVID-19 has become a significant and troubling aspect of society in 2020. With millions of cases reported across countries, new outbreaks have occurred and followed patterns of previously affected areas. Many disease detection models do not incorporate the wealth of social media data that can be utilized for modeling and predicting its spread. It is useful to ask, can we utilize this knowledge in one country to model the outbreak in another? To answer this, we propose the task of cross-lingual transfer learning for epidemiological alignment. Utilizing both macro and micro text features, we train on Italy&#8217;s early COVID-19 outbreak through <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and transfer to several other countries. Our experiments show strong results with up to 0.85 <a href=https://en.wikipedia.org/wiki/Spearman_correlation>Spearman correlation</a> in cross-country predictions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-acl.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpcovid19-acl--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpcovid19-acl.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlpcovid19-acl.17" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-acl.17/>NLP-based Feature Extraction for the Detection of COVID-19 Misinformation Videos on YouTube<span class=acl-fixed-case>NLP</span>-based Feature Extraction for the Detection of <span class=acl-fixed-case>COVID</span>-19 Misinformation Videos on <span class=acl-fixed-case>Y</span>ou<span class=acl-fixed-case>T</span>ube</a></strong><br><a href=/people/j/juan-carlos-medina-serrano/>Juan Carlos Medina Serrano</a>
|
<a href=/people/o/orestis-papakyriakopoulos/>Orestis Papakyriakopoulos</a>
|
<a href=/people/s/simon-hegelich/>Simon Hegelich</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpcovid19-acl--17><div class="card-body p-3 small">We present a simple NLP methodology for detecting COVID-19 misinformation videos on <a href=https://en.wikipedia.org/wiki/YouTube>YouTube</a> by leveraging user comments. We use transfer learning pre-trained models to generate a multi-label classifier that can categorize conspiratorial content. We use the percentage of misinformation comments on each video as a new <a href=https://en.wikipedia.org/wiki/Software_feature>feature</a> for video classification.</div></div></div><hr><div id=2020nlpmc-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpmc-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.nlpmc-1/>Proceedings of the First Workshop on Natural Language Processing for Medical Conversations</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpmc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpmc-1.0/>Proceedings of the First Workshop on Natural Language Processing for Medical Conversations</a></strong><br><a href=/people/p/parminder-bhatia/>Parminder Bhatia</a>
|
<a href=/people/s/steven-lin/>Steven Lin</a>
|
<a href=/people/r/rashmi-gangadharaiah/>Rashmi Gangadharaiah</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a>
|
<a href=/people/i/izhak-shafran/>Izhak Shafran</a>
|
<a href=/people/c/chaitanya-shivade/>Chaitanya Shivade</a>
|
<a href=/people/n/nan-du/>Nan Du</a>
|
<a href=/people/m/mona-diab/>Mona Diab</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpmc-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpmc-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpmc-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929890 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlpmc-1.1/>Methods for Extracting Information from Messages from Primary Care Providers to Specialists</a></strong><br><a href=/people/x/xiyu-ding/>Xiyu Ding</a>
|
<a href=/people/m/michael-barnett/>Michael Barnett</a>
|
<a href=/people/a/ateev-mehrotra/>Ateev Mehrotra</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpmc-1--1><div class="card-body p-3 small">Electronic consult (eConsult) systems allow specialists more flexibility to respond to referrals more efficiently, thereby increasing access in under-resourced healthcare settings like safety net systems. Understanding the usage patterns of eConsult system is an important part of improving specialist efficiency. In this work, we develop and apply classifiers to a dataset of eConsult questions from primary care providers to specialists, classifying the messages for how they were triaged by the specialist office, and the underlying type of clinical question posed by the primary care provider. We show that pre-trained transformer models are strong baselines, with improving performance from domain-specific training and shared representations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpmc-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpmc-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpmc-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929893 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlpmc-1.2/>Towards Understanding ASR Error Correction for Medical Conversations<span class=acl-fixed-case>ASR</span> Error Correction for Medical Conversations</a></strong><br><a href=/people/a/anirudh-mani/>Anirudh Mani</a>
|
<a href=/people/s/shruti-palaskar/>Shruti Palaskar</a>
|
<a href=/people/s/sandeep-konam/>Sandeep Konam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpmc-1--2><div class="card-body p-3 small">Domain Adaptation for Automatic Speech Recognition (ASR) error correction via <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> is a useful technique for improving out-of-domain outputs of pre-trained ASR systems to obtain optimal results for specific in-domain tasks. We use this technique on our dataset of Doctor-Patient conversations using two off-the-shelf ASR systems : Google ASR (commercial) and the ASPIRE model (open-source). We train a Sequence-to-Sequence Machine Translation model and evaluate it on seven specific UMLS Semantic types, including Pharmacological Substance, Sign or Symptom, and Diagnostic Procedure to name a few. Lastly, we breakdown, analyze and discuss the 7 % overall improvement in <a href=https://en.wikipedia.org/wiki/Word_error_rate>word error rate</a> in view of each Semantic type.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpmc-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpmc-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpmc-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929892 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlpmc-1.7/>On the Utility of Audiovisual Dialog Technologies and Signal Analytics for Real-time Remote Monitoring of Depression Biomarkers</a></strong><br><a href=/people/m/michael-neumann/>Michael Neumann</a>
|
<a href=/people/o/oliver-roessler/>Oliver Roessler</a>
|
<a href=/people/d/david-suendermann-oeft/>David Suendermann-Oeft</a>
|
<a href=/people/v/vikram-ramanarayanan/>Vikram Ramanarayanan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpmc-1--7><div class="card-body p-3 small">We investigate the utility of audiovisual dialog systems combined with speech and video analytics for real-time remote monitoring of depression at scale in uncontrolled environment settings. We collected audiovisual conversational data from participants who interacted with a cloud-based multimodal dialog system, and automatically extracted a large set of speech and vision metrics based on the rich existing literature of laboratory studies. We report on the efficacy of various audio and video metrics in differentiating people with mild, moderate and severe depression, and discuss the implications of these results for the deployment of such technologies in real-world neurological diagnosis and monitoring applications.</div></div></div><hr><div id=2020nuse-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.nuse-1/>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nuse-1.0/>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a></strong><br><a href=/people/c/claire-bonial/>Claire Bonial</a>
|
<a href=/people/t/tommaso-caselli/>Tommaso Caselli</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/alejandro-jaimes/>Alejandro Jaimes</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/l/lara-j-martin/>Lara J. Martin</a>
|
<a href=/people/b/ben-miller/>Ben Miller</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/j/joel-tetreault/>Joel Tetreault</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nuse-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nuse-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929742 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nuse-1.3/>Improving the Identification of the Discourse Function of News Article Paragraphs</a></strong><br><a href=/people/d/deya-banisakher/>Deya Banisakher</a>
|
<a href=/people/w/w-victor-yarlott/>W. Victor Yarlott</a>
|
<a href=/people/m/mohammed-aldawsari/>Mohammed Aldawsari</a>
|
<a href=/people/n/naphtali-rishe/>Naphtali Rishe</a>
|
<a href=/people/m/mark-finlayson/>Mark Finlayson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nuse-1--3><div class="card-body p-3 small">Identifying the discourse structure of documents is an important task in understanding <a href=https://en.wikipedia.org/wiki/Writing>written text</a>. Building on prior work, we demonstrate an improved approach to automatically identifying the discourse function of paragraphs in <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. We start with the hierarchical theory of news discourse developed by van Dijk (1988) which proposes how paragraphs function within <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. This discourse information is a level intermediate between phrase- or sentence-sized discourse segments and document genre, characterizing how individual paragraphs convey information about the events in the storyline of the article. Specifically, the theory categorizes the relationships between narrated events and (1) the overall storyline (such as Main Events, Background, or Consequences) as well as (2) commentary (such as Verbal Reactions and Evaluations). We trained and tested a linear chain conditional random field (CRF) with new features to model van Dijk&#8217;s labels and compared it against several machine learning models presented in previous work. Our model significantly outperformed all <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> and prior approaches, achieving an average of 0.71 <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> which represents a 31.5 % improvement over the previously best-performing <a href=https://en.wikipedia.org/wiki/Support_vector_machine>support vector machine model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nuse-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nuse-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929744 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nuse-1.5/>Extensively Matching for Few-shot Learning Event Detection</a></strong><br><a href=/people/v/viet-dac-lai/>Viet Dac Lai</a>
|
<a href=/people/t/thien-huu-nguyen/>Thien Huu Nguyen</a>
|
<a href=/people/f/franck-dernoncourt/>Franck Dernoncourt</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nuse-1--5><div class="card-body p-3 small">Current event detection models under supervised learning settings fail to transfer to new event types. Few-shot learning has not been explored in event detection even though it allows a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to perform well with high <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> on new event types. In this work, we formulate event detection as a few-shot learning problem to enable to extend event detection to new event types. We propose two novel <a href=https://en.wikipedia.org/wiki/Loss_factor>loss factors</a> that matching examples in the support set to provide more <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training signals</a> to the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. Moreover, these <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training signals</a> can be applied in many metric-based few-shot learning models. Our extensive experiments on the ACE-2005 dataset (under a few-shot learning setting) show that the proposed method can improve the performance of few-shot learning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nuse-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nuse-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929748 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nuse-1.9/>Annotating and quantifying narrative time disruptions in modernist and hypertext fiction</a></strong><br><a href=/people/e/edward-kearns/>Edward Kearns</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nuse-1--9><div class="card-body p-3 small">This paper outlines work in progress on a new method of annotating and quantitatively discussing <a href=https://en.wikipedia.org/wiki/Narrative>narrative techniques</a> related to time in fiction. Specifically those techniques are <a href=https://en.wikipedia.org/wiki/Analepsis>analepsis</a>, <a href=https://en.wikipedia.org/wiki/Prolepsis>prolepsis</a>, narrative level changes, and <a href=https://en.wikipedia.org/wiki/Stream_of_consciousness>stream-of-consciousness</a> and free-indirect-discourse narration. By counting the frequency and extent of the usage of these <a href=https://en.wikipedia.org/wiki/List_of_narrative_techniques>techniques</a>, the <a href=https://en.wikipedia.org/wiki/Narrative>narrative characteristics</a> of different works from different time periods and genres can be compared. This project uses <a href=https://en.wikipedia.org/wiki/Literary_modernism>modernist fiction</a> and <a href=https://en.wikipedia.org/wiki/Hypertext_fiction>hypertext fiction</a> as its case studies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nuse-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nuse-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939705 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nuse-1.10" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nuse-1.10/>Exploring aspects of similarity between spoken personal narratives by disentangling them into narrative clause types</a></strong><br><a href=/people/b/belen-saldias/>Belen Saldias</a>
|
<a href=/people/d/deb-roy/>Deb Roy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nuse-1--10><div class="card-body p-3 small">Sharing personal narratives is a fundamental aspect of <a href=https://en.wikipedia.org/wiki/Social_behavior>human social behavior</a> as it helps share our life experiences. We can tell stories and rely on our background to understand their context, similarities, and differences. A substantial effort has been made towards developing storytelling machines or inferring characters&#8217; features. However, we do n&#8217;t usually find <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that compare narratives. This task is remarkably challenging for machines since they, as sometimes we do, lack an understanding of what similarity means. To address this challenge, we first introduce a corpus of real-world spoken personal narratives comprising 10,296 narrative clauses from 594 <a href=https://en.wikipedia.org/wiki/Videotape>video transcripts</a>. Second, we ask non-narrative experts to annotate those clauses under Labov&#8217;s sociolinguistic model of personal narratives (i.e., action, orientation, and evaluation clause types) and train a classifier that reaches 84.7 % F-score for the highest-agreed clauses. Finally, we match stories and explore whether people implicitly rely on Labov&#8217;s framework to compare narratives. We show that actions followed by the narrator&#8217;s evaluation of these are the aspects non-experts consider the most. Our approach is intended to help inform <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning methods</a> aimed at studying or representing <a href=https://en.wikipedia.org/wiki/Personal_narrative>personal narratives</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nuse-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nuse-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929754 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nuse-1.14/>On-The-Fly Information Retrieval Augmentation for <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a></a></strong><br><a href=/people/h/hai-wang/>Hai Wang</a>
|
<a href=/people/d/david-mcallester/>David McAllester</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nuse-1--14><div class="card-body p-3 small">Here we experiment with the use of <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> as an augmentation for pre-trained language models. The <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a> used in <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> can be viewed as form of <a href=https://en.wikipedia.org/wiki/Episodic_memory>episodic memory</a> which grows over time. By augmenting GPT 2.0 with <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> we achieve a zero shot 15 % relative reduction in perplexity on Gigaword corpus without any re-training. We also validate our IR augmentation on an event co-reference task.</div></div></div><hr><div id=2020repl4nlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.repl4nlp-1/>Proceedings of the 5th Workshop on Representation Learning for NLP</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.0/>Proceedings of the 5th Workshop on Representation Learning for NLP</a></strong><br><a href=/people/s/spandana-gella/>Spandana Gella</a>
|
<a href=/people/j/johannes-welbl/>Johannes Welbl</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/f/fabio-petroni/>Fabio Petroni</a>
|
<a href=/people/p/patrick-lewis/>Patrick Lewis</a>
|
<a href=/people/e/emma-strubell/>Emma Strubell</a>
|
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929767 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.1/>Zero-Resource Cross-Domain Named Entity Recognition</a></strong><br><a href=/people/z/zihan-liu/>Zihan Liu</a>
|
<a href=/people/g/genta-indra-winata/>Genta Indra Winata</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--1><div class="card-body p-3 small">Existing models for cross-domain named entity recognition (NER) rely on numerous unlabeled corpus or labeled NER training data in target domains. However, collecting data for low-resource target domains is not only expensive but also time-consuming. Hence, we propose a cross-domain NER model that does not use any <a href=https://en.wikipedia.org/wiki/Resource_(computing)>external resources</a>. We first introduce a Multi-Task Learning (MTL) by adding a new <a href=https://en.wikipedia.org/wiki/Loss_function>objective function</a> to detect whether tokens are named entities or not. We then introduce a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> called Mixture of Entity Experts (MoEE) to improve the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> for zero-resource domain adaptation. Finally, experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms strong unsupervised cross-domain sequence labeling models, and the performance of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is close to that of the state-of-the-art model which leverages extensive resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929768 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.2/>Encodings of Source Syntax : Similarities in NMT Representations Across Target Languages<span class=acl-fixed-case>NMT</span> Representations Across Target Languages</a></strong><br><a href=/people/t/tyler-a-chang/>Tyler A. Chang</a>
|
<a href=/people/a/anna-n-rafferty/>Anna Rafferty</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--2><div class="card-body p-3 small">We train neural machine translation (NMT) models from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to six target languages, using NMT encoder representations to predict ancestor constituent labels of source language words. We find that NMT encoders learn similar source syntax regardless of NMT target language, relying on explicit morphosyntactic cues to extract syntactic features from source sentences. Furthermore, the NMT encoders outperform RNNs trained directly on several of the constituent label prediction tasks, suggesting that NMT encoder representations can be used effectively for natural language tasks involving <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a>. However, both the NMT encoders and the directly-trained RNNs learn substantially different syntactic information from a probabilistic context-free grammar (PCFG) parser. Despite lower overall accuracy scores, the PCFG often performs well on sentences for which the RNN-based models perform poorly, suggesting that RNN architectures are constrained in the types of syntax they can learn.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929769 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.3/>Learning Probabilistic Sentence Representations from Paraphrases</a></strong><br><a href=/people/m/mingda-chen/>Mingda Chen</a>
|
<a href=/people/k/kevin-gimpel/>Kevin Gimpel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--3><div class="card-body p-3 small">Probabilistic word embeddings have shown effectiveness in capturing notions of generality and <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment</a>, but there is very little work on doing the analogous type of investigation for sentences. In this paper we define <a href=https://en.wikipedia.org/wiki/Statistical_model>probabilistic models</a> that produce <a href=https://en.wikipedia.org/wiki/Probability_distribution>distributions</a> for sentences. Our best-performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> treats each word as a <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformation operator</a> applied to a <a href=https://en.wikipedia.org/wiki/Normal_distribution>multivariate Gaussian distribution</a>. We train our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a> and demonstrate that they naturally capture sentence specificity. While our proposed model achieves the best performance overall, we also show that <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>specificity</a> is represented by simpler <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> via the norm of the sentence vectors. Qualitative analysis shows that our probabilistic model captures sentential entailment and provides ways to analyze the specificity and preciseness of individual words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929770 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.4/>Word Embeddings as Tuples of Feature Probabilities</a></strong><br><a href=/people/s/siddharth-bhat/>Siddharth Bhat</a>
|
<a href=/people/a/alok-debnath/>Alok Debnath</a>
|
<a href=/people/s/souvik-banerjee/>Souvik Banerjee</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--4><div class="card-body p-3 small">In this paper, we provide an alternate perspective on <a href=https://en.wikipedia.org/wiki/Word_(group_theory)>word representations</a>, by reinterpreting the dimensions of the vector space of a <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> as a collection of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. In this reinterpretation, every component of the word vector is normalized against all the word vectors in the vocabulary. This idea now allows us to view each vector as an n-tuple (akin to a fuzzy set), where n is the dimensionality of the word representation and each element represents the probability of the word possessing a <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature</a>. Indeed, this representation enables the use fuzzy set theoretic operations, such as <a href=https://en.wikipedia.org/wiki/Union_(set_theory)>union</a>, <a href=https://en.wikipedia.org/wiki/Intersection_(set_theory)>intersection</a> and <a href=https://en.wikipedia.org/wiki/Subtraction>difference</a>. Unlike previous attempts, we show that this representation of words provides a notion of similarity which is inherently asymmetric and hence closer to human similarity judgements. We compare the performance of this representation with various <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a>, and explore some of the unique properties including function word detection, detection of polysemous words, and some insight into the interpretability provided by set theoretic operations.<tex-math>n</tex-math>-tuple (akin to a fuzzy set), where <tex-math>n</tex-math> is the dimensionality of the word representation and each element represents the probability of the word possessing a feature. Indeed, this representation enables the use fuzzy set theoretic operations, such as union, intersection and difference. Unlike previous attempts, we show that this representation of words provides a notion of similarity which is inherently asymmetric and hence closer to human similarity judgements. We compare the performance of this representation with various benchmarks, and explore some of the unique properties including function word detection, detection of polysemous words, and some insight into the interpretability provided by set theoretic operations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929771 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.5/>Compositionality and Capacity in Emergent Languages</a></strong><br><a href=/people/a/abhinav-gupta/>Abhinav Gupta</a>
|
<a href=/people/c/cinjon-resnick/>Cinjon Resnick</a>
|
<a href=/people/j/jakob-foerster/>Jakob Foerster</a>
|
<a href=/people/a/andrew-dai/>Andrew Dai</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--5><div class="card-body p-3 small">Recent works have discussed the extent to which <a href=https://en.wikipedia.org/wiki/Emergence>emergent languages</a> can exhibit properties of <a href=https://en.wikipedia.org/wiki/Natural_language>natural languages</a> particularly learning compositionality. In this paper, we investigate the <a href=https://en.wikipedia.org/wiki/Learning_bias>learning biases</a> that affect the efficacy and <a href=https://en.wikipedia.org/wiki/Compositionality>compositionality</a> in multi-agent communication in addition to the communicative bandwidth. Our foremost contribution is to explore how the capacity of a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> impacts its ability to learn a compositional language. We additionally introduce a set of evaluation metrics with which we analyze the learned languages. Our hypothesis is that there should be a specific range of model capacity and <a href=https://en.wikipedia.org/wiki/Bandwidth_(signal_processing)>channel bandwidth</a> that induces compositional structure in the resulting language and consequently encourages systematic generalization. While we empirically see evidence for the bottom of this range, we curiously do not find evidence for the top part of the range and believe that this is an open question for the community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.repl4nlp-1.6.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929772 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.6/>Learning Geometric Word Meta-Embeddings</a></strong><br><a href=/people/p/pratik-jawanpuria/>Pratik Jawanpuria</a>
|
<a href=/people/s/satya-dev-n-t-v/>Satya Dev N T V</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/b/bamdev-mishra/>Bamdev Mishra</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--6><div class="card-body p-3 small">We propose a geometric framework for learning meta-embeddings of words from different embedding sources. Our framework transforms the <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> into a common latent space, where, for example, simple averaging or concatenation of different embeddings (of a given word) is more amenable. The proposed latent space arises from two particular geometric transformations-source embedding specific orthogonal rotations and a common Mahalanobis metric scaling. Empirical results on several word similarity and word analogy benchmarks illustrate the efficacy of the proposed framework.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929776 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.10/>Exploring the Limits of Simple Learners in Knowledge Distillation for <a href=https://en.wikipedia.org/wiki/Document_classification>Document Classification</a> with DocBERT<span class=acl-fixed-case>D</span>oc<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/a/ashutosh-adhikari/>Ashutosh Adhikari</a>
|
<a href=/people/a/achyudh-ram/>Achyudh Ram</a>
|
<a href=/people/r/raphael-tang/>Raphael Tang</a>
|
<a href=/people/w/william-l-hamilton/>William L. Hamilton</a>
|
<a href=/people/j/jimmy-lin/>Jimmy Lin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--10><div class="card-body p-3 small">Fine-tuned variants of BERT are able to achieve state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on many natural language processing tasks, although at significant computational costs. In this paper, we verify BERT&#8217;s effectiveness for document classification and investigate the extent to which BERT-level effectiveness can be obtained by different baselines, combined with knowledge distillationa popular model compression method. The results show that BERT-level effectiveness can be achieved by a single-layer LSTM with at least 40 fewer FLOPS and only 3 % parameters. More importantly, this study analyzes the limits of knowledge distillation as we distill BERT&#8217;s knowledge all the way down to linear modelsa relevant baseline for the task. We report substantial improvement in <a href=https://en.wikipedia.org/wiki/Effectiveness>effectiveness</a> for even the simplest <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, as they capture the knowledge learnt by BERT.<tex-math>40\\times</tex-math> fewer FLOPS and only <tex-math>{\\sim}3\\%</tex-math> parameters. More importantly, this study analyzes the limits of knowledge distillation as we distill BERT&#8217;s knowledge all the way down to linear models&#8212;a relevant baseline for the task. We report substantial improvement in effectiveness for even the simplest models, as they capture the knowledge learnt by BERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929782 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.repl4nlp-1.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.16/>Are All Languages Created Equal in Multilingual BERT?<span class=acl-fixed-case>BERT</span>?</a></strong><br><a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--16><div class="card-body p-3 small">Multilingual BERT (mBERT) trained on 104 languages has shown surprisingly good cross-lingual performance on several NLP tasks, even without explicit cross-lingual signals. However, these evaluations have focused on cross-lingual transfer with high-resource languages, covering only a third of the languages covered by mBERT. We explore how mBERT performs on a much wider set of languages, focusing on the quality of representation for low-resource languages, measured by within-language performance. We consider three tasks : <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> (99 languages), <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>Part-of-speech Tagging</a> and Dependency Parsing (54 languages each). mBERT does better than or comparable to baselines on high resource languages but does much worse for low resource languages. Furthermore, monolingual BERT models for these <a href=https://en.wikipedia.org/wiki/Language>languages</a> do even worse. Paired with similar languages, the performance gap between monolingual BERT and mBERT can be narrowed. We find that better <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for low resource languages require more efficient pretraining techniques or more data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.repl4nlp-1.22.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929788 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.22/>Evaluating Compositionality of Sentence Representation Models</a></strong><br><a href=/people/h/hanoz-bhathena/>Hanoz Bhathena</a>
|
<a href=/people/a/angelica-willis/>Angelica Willis</a>
|
<a href=/people/n/nathan-dass/>Nathan Dass</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--22><div class="card-body p-3 small">We evaluate the compositionality of general-purpose sentence encoders by proposing two different <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to quantify compositional understanding capability of sentence encoders. We introduce a novel <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, Polarity Sensitivity Scoring (PSS), which utilizes sentiment perturbations as a proxy for measuring <a href=https://en.wikipedia.org/wiki/Compositionality>compositionality</a>. We then compare results from PSS with those obtained via our proposed extension of a <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> called Tree Reconstruction Error (TRE) (CITATION) where compositionality is evaluated by measuring how well a true representation producing model can be approximated by a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that explicitly combines representations of its primitives.</div></div></div><hr><div id=2020sigmorphon-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.sigmorphon-1/>Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.0/>Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></strong><br><a href=/people/g/garrett-nicolai/>Garrett Nicolai</a>
|
<a href=/people/k/kyle-gorman/>Kyle Gorman</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.6/>The CMU-LTI submission to the SIGMORPHON 2020 Shared Task 0 : Language-Specific Cross-Lingual Transfer<span class=acl-fixed-case>CMU</span>-<span class=acl-fixed-case>LTI</span> submission to the <span class=acl-fixed-case>SIGMORPHON</span> 2020 Shared Task 0: Language-Specific Cross-Lingual Transfer</a></strong><br><a href=/people/n/nikitha-murikinati/>Nikitha Murikinati</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--6><div class="card-body p-3 small">This paper describes the CMU-LTI submission to the SIGMORPHON 2020 Shared Task 0 on typologically diverse morphological inflection. The (unrestricted) submission uses the cross-lingual approach of our last year&#8217;s winning submission (Anastasopoulos and Neubig, 2019), but adapted to use specific transfer languages for each test language. Our <a href=https://en.wikipedia.org/wiki/System>system</a>, with fixed non-tuned hyperparameters, achieved a macro-averaged accuracy of 80.65 ranking 20th among 31 systems, but it was still tied for best <a href=https://en.wikipedia.org/wiki/System>system</a> in 25 of the 90 total languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.7/>Grapheme-to-Phoneme Conversion with a Multilingual Transformer Model</a></strong><br><a href=/people/o/omnia-elsaadany/>Omnia ElSaadany</a>
|
<a href=/people/b/benjamin-suter/>Benjamin Suter</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--7><div class="card-body p-3 small">In this paper, we describe our three submissions to the SIGMORPHON 2020 shared task 1 on grapheme-to-phoneme conversion for 15 languages. We experimented with a single multilingual transformer model. We observed that the multilingual model achieves results on par with our separately trained <a href=https://en.wikipedia.org/wiki/Monolingualism>monolingual models</a> and is even able to avoid a few of the errors made by the <a href=https://en.wikipedia.org/wiki/Monolingualism>monolingual models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.9/>The IMSCUBoulder System for the SIGMORPHON 2020 Shared Task on Unsupervised Morphological Paradigm Completion<span class=acl-fixed-case>IMS</span><span class=acl-fixed-case>CUB</span>oulder System for the <span class=acl-fixed-case>SIGMORPHON</span> 2020 Shared Task on Unsupervised Morphological Paradigm Completion</a></strong><br><a href=/people/m/manuel-mager/>Manuel Mager</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--9><div class="card-body p-3 small">In this paper, we present the systems of the University of Stuttgart IMS and the University of Colorado Boulder (IMSCUBoulder) for SIGMORPHON 2020 Task 2 on unsupervised morphological paradigm completion (Kann et al., 2020). The task consists of generating the <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological paradigms</a> of a set of lemmas, given only the lemmas themselves and unlabeled text. Our proposed <a href=https://en.wikipedia.org/wiki/System>system</a> is a modified version of the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> introduced together with the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. In particular, we experiment with substituting the inflection generation component with an LSTM sequence-to-sequence model and an LSTM pointer-generator network. Our pointer-generator system obtains the best score of all seven submitted systems on average over all languages, and outperforms the official baseline, which was best overall, on <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a> and <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.14/>Exploring Neural Architectures And Techniques For Typologically Diverse Morphological Inflection</a></strong><br><a href=/people/p/pratik-jayarao/>Pratik Jayarao</a>
|
<a href=/people/s/siddhanth-pillay/>Siddhanth Pillay</a>
|
<a href=/people/p/pranav-thombre/>Pranav Thombre</a>
|
<a href=/people/a/aditi-chaudhary/>Aditi Chaudhary</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--14><div class="card-body p-3 small">Morphological inflection in low resource languages is critical to augment existing corpora in Low Resource Languages, which can help develop several applications in these languages with very good social impact. We describe our attention-based encoder-decoder approach that we implement using <a href=https://en.wikipedia.org/wiki/Light-emitting_diode>LSTMs</a> and <a href=https://en.wikipedia.org/wiki/Transformers_(video_game)>Transformers</a> as the base units. We also describe the ancillary techniques that we experimented with, such as <a href=https://en.wikipedia.org/wiki/Hallucination>hallucination</a>, language vector injection, sparsemax loss and adversarial language network alongside our approach to select the related language(s) for training. We present the results we generated on the constrained as well as unconstrained SIGMORPHON 2020 dataset (CITATION). One of the primary goals of our paper was to study the contribution varied components described above towards the performance of our <a href=https://en.wikipedia.org/wiki/System>system</a> and perform an analysis on the same.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.17/>Leveraging Principal Parts for Morphological Inflection</a></strong><br><a href=/people/l/ling-liu/>Ling Liu</a>
|
<a href=/people/m/mans-hulden/>Mans Hulden</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--17><div class="card-body p-3 small">This paper presents the submission by the CU Ling team from the University of Colorado to SIGMORPHON 2020 shared task 0 on morphological inflection. The task is to generate the target <a href=https://en.wikipedia.org/wiki/Inflection>inflected word form</a> given a <a href=https://en.wikipedia.org/wiki/Lemma_(morphology)>lemma form</a> and a target <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphosyntactic description</a>. Our <a href=https://en.wikipedia.org/wiki/System>system</a> uses the Transformer architecture. Our overall approach is to treat the morphological inflection task as a paradigm cell filling problem and to design the system to leverage principal parts information for better morphological inflection when the training data is limited. We train one <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for each language separately without <a href=https://en.wikipedia.org/wiki/Data>external data</a>. The overall average performance of our submission ranks the first in both <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>average accuracy</a> and <a href=https://en.wikipedia.org/wiki/Levenshtein_distance>Levenshtein distance</a> from the gold inflection among all submissions including those using external resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.29.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--29 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.29 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929874 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.29/>Multi-Tiered Strictly Local Functions</a></strong><br><a href=/people/p/phillip-burness/>Phillip Burness</a>
|
<a href=/people/k/kevin-mcmullin/>Kevin McMullin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--29><div class="card-body p-3 small">Tier-based Strictly Local functions, as they have so far been defined, are equipped with just a single tier. In light of this fact, they are currently incapable of modelling simultaneous phonological processes that would require different tiers. In this paper we consider whether and how we can allow a single function to operate over more than one tier. We conclude that multiple tiers can and should be permitted, but that the relationships between them must be restricted in some way to avoid overgeneration. The particular restriction that we propose comes in two parts. First, each input element is associated with a set of tiers that on their own can fully determine what the element is mapped to. Second, the set of tiers associated to a given input element must form a strict superset-subset hierarchy. In this way, we can track multiple, related sources of information when deciding how to process a particular input element. We demonstrate that doing so enables simple and intuitive analyses to otherwise challenging <a href=https://en.wikipedia.org/wiki/Phonology>phonological phenomena</a>.</div></div></div><hr><div id=2020socialnlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.socialnlp-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.socialnlp-1/>Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.socialnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.socialnlp-1.0/>Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media</a></strong><br><a href=/people/l/lun-wei-ku/>Lun-Wei Ku</a>
|
<a href=/people/c/cheng-te-li/>Cheng-Te Li</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.socialnlp-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--socialnlp-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.socialnlp-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929901 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.socialnlp-1.1/>Enhancing Bias Detection in <a href=https://en.wikipedia.org/wiki/Political_journalism>Political News</a> Using Pragmatic Presupposition</a></strong><br><a href=/people/l/lalitha-kameswari/>Lalitha Kameswari</a>
|
<a href=/people/d/dama-sravani/>Dama Sravani</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--socialnlp-1--1><div class="card-body p-3 small">Usage of presuppositions in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and news discourse can be a powerful way to influence the readers as they usually tend to not examine the truth value of the hidden or indirectly expressed information. Fairclough and Wodak (1997) discuss <a href=https://en.wikipedia.org/wiki/Presupposition>presupposition</a> at a discourse level where some implicit claims are taken for granted in the explicit meaning of a text or utterance. From the Gricean perspective, the presuppositions of a sentence determine the class of contexts in which the sentence could be felicitously uttered. This paper aims to correlate the type of knowledge presupposed in a news article to the bias present in it. We propose a set of guidelines to identify various kinds of presuppositions in news articles and present a dataset consisting of 1050 articles which are annotated for <a href=https://en.wikipedia.org/wiki/Bias>bias</a> (positive, negative or neutral) and the magnitude of <a href=https://en.wikipedia.org/wiki/Presupposition>presupposition</a>. We introduce a supervised classification approach for detecting bias in <a href=https://en.wikipedia.org/wiki/Political_journalism>political news</a> which significantly outperforms the existing systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.socialnlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--socialnlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.socialnlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929903 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.socialnlp-1.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.socialnlp-1.3/>NARMADA : Need and Available Resource Managing Assistant for Disasters and Adversities<span class=acl-fixed-case>NARMADA</span>: Need and Available Resource Managing Assistant for Disasters and Adversities</a></strong><br><a href=/people/k/kaustubh-hiware/>Kaustubh Hiware</a>
|
<a href=/people/r/ritam-dutt/>Ritam Dutt</a>
|
<a href=/people/s/sayan-sinha/>Sayan Sinha</a>
|
<a href=/people/s/sohan-patro/>Sohan Patro</a>
|
<a href=/people/k/kripa-ghosh/>Kripa Ghosh</a>
|
<a href=/people/s/saptarshi-ghosh/>Saptarshi Ghosh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--socialnlp-1--3><div class="card-body p-3 small">Although a lot of research has been done on utilising <a href=https://en.wikipedia.org/wiki/Social_media>Online Social Media</a> during disasters, there exists no system for a specific task that is critical in a post-disaster scenario identifying resource-needs and resource-availabilities in the disaster-affected region, coupled with their subsequent matching. To this end, we present NARMADA, a semi-automated platform which leverages the crowd-sourced information from social media posts for assisting post-disaster relief coordination efforts. The system employs <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> and Information Retrieval techniques for identifying resource-needs and resource-availabilities from <a href=https://en.wikipedia.org/wiki/Microblogging>microblogs</a>, extracting resources from the posts, and also matching the needs to suitable availabilities. The <a href=https://en.wikipedia.org/wiki/System>system</a> is thus capable of facilitating the judicious management of resources during <a href=https://en.wikipedia.org/wiki/Emergency_management>post-disaster relief operations</a>.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright &nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>