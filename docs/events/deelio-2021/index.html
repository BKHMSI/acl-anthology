<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Deep Learning Inside Out (DeeLIO): The Workshop on Knowledge Extraction and Integration for Deep Learning Architectures (2021) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Deep Learning Inside Out (DeeLIO): The Workshop on Knowledge Extraction and Integration for Deep Learning Architectures (2021)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2021deelio-1>Proceedings of Deep Learning Inside Out (DeeLIO): The 2nd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</a>
<span class="badge badge-info align-middle ml-1">5&nbsp;papers</span></li></ul></div></div><div id=2021deelio-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.deelio-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2021.deelio-1/>Proceedings of Deep Learning Inside Out (DeeLIO): The 2nd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.deelio-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.deelio-1.0/>Proceedings of Deep Learning Inside Out (DeeLIO): The 2nd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</a></strong><br><a href=/people/e/eneko-agirre/>Eneko Agirre</a>
|
<a href=/people/m/marianna-apidianaki/>Marianna Apidianaki</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.deelio-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--deelio-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.deelio-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.deelio-1.4/>Augmenting Topic Aware Knowledge-Grounded Conversations with Dynamic Built Knowledge Graphs</a></strong><br><a href=/people/j/junjie-wu/>Junjie Wu</a>
|
<a href=/people/h/hao-zhou/>Hao Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--deelio-1--4><div class="card-body p-3 small">Dialog topic management and background knowledge selection are essential factors for the success of knowledge-grounded open-domain conversations. However, existing models are primarily performed with symmetric knowledge bases or stylized with pre-defined roles between conversational partners, while people usually have their own knowledge before a real chit-chat. To address this problem, we propose a dynamic knowledge graph-based topical conversation model (DKGT). Given a dialog history context, our model first builds knowledge graphs from the context as an imitation of human&#8217;s ability to form logical relationships between known and unknown topics during a conversation. This logical information will be fed into a topic predictor to promote topic management, then facilitate background knowledge selection and response generation. To the best of our knowledge, this is the first attempt to dynamically form <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a> between chatting topics to assist dialog topic management during a conversation. Experimental results manifest that our model can properly schedule conversational topics and pick suitable knowledge to generate informative responses comparing to several strong baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.deelio-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--deelio-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.deelio-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.deelio-1.5/>What Makes My Model Perplexed? A Linguistic Investigation on Neural Language Models Perplexity</a></strong><br><a href=/people/a/alessio-miaschi/>Alessio Miaschi</a>
|
<a href=/people/d/dominique-brunato/>Dominique Brunato</a>
|
<a href=/people/f/felice-dellorletta/>Felice Dell’Orletta</a>
|
<a href=/people/g/giulia-venturi/>Giulia Venturi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--deelio-1--5><div class="card-body p-3 small">This paper presents an investigation aimed at studying how the linguistic structure of a sentence affects the perplexity of two of the most popular Neural Language Models (NLMs), BERT and GPT-2. We first compare the sentence-level likelihood computed with BERT and the GPT-2&#8217;s perplexity showing that the two <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> are correlated. In addition, we exploit linguistic features capturing a wide set of morpho-syntactic and syntactic phenomena showing how they contribute to predict the perplexity of the two NLMs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.deelio-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--deelio-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.deelio-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.deelio-1.12.OptionalSupplementaryData.pdf data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.deelio-1.12/>What BERTs and GPTs know about your brand? Probing contextual language models for affect associations<span class=acl-fixed-case>BERT</span>s and <span class=acl-fixed-case>GPT</span>s know about your brand? Probing contextual language models for affect associations</a></strong><br><a href=/people/v/vivek-srivastava/>Vivek Srivastava</a>
|
<a href=/people/s/stephen-pilli/>Stephen Pilli</a>
|
<a href=/people/s/savita-bhat/>Savita Bhat</a>
|
<a href=/people/n/niranjan-pedanekar/>Niranjan Pedanekar</a>
|
<a href=/people/s/shirish-karande/>Shirish Karande</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--deelio-1--12><div class="card-body p-3 small">Investigating brand perception is fundamental to <a href=https://en.wikipedia.org/wiki/Marketing_strategy>marketing strategies</a>. In this regard, <a href=https://en.wikipedia.org/wiki/Brand_image>brand image</a>, defined by a set of attributes (Aaker, 1997), is recognized as a key element in indicating how a brand is perceived by various stakeholders such as consumers and competitors. Traditional <a href=https://en.wikipedia.org/wiki/Brand_management>approaches</a> (e.g., surveys) to monitor brand perceptions are time-consuming and inefficient. In the era of <a href=https://en.wikipedia.org/wiki/Digital_marketing>digital marketing</a>, both brand managers and consumers engage with a vast amount of <a href=https://en.wikipedia.org/wiki/Digital_marketing>digital marketing content</a>. The exponential growth of <a href=https://en.wikipedia.org/wiki/Digital_content>digital content</a> has propelled the emergence of pre-trained language models such as BERT and GPT as essential tools in solving myriads of challenges with textual data. This paper seeks to investigate the extent of brand perceptions (i.e., brand and image attribute associations) these <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> encode. We believe that any kind of bias for a brand and attribute pair may influence customer-centric downstream tasks such as <a href=https://en.wikipedia.org/wiki/Recommender_system>recommender systems</a>, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, and <a href=https://en.wikipedia.org/wiki/Question_answering>question-answering</a>, e.g., suggesting a specific brand consistently when queried for innovative products. We use <a href=https://en.wikipedia.org/wiki/Data>synthetic data</a> and real-life data and report comparison results for five contextual LMs, viz. BERT, RoBERTa, DistilBERT, ALBERT and BART.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.deelio-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--deelio-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.deelio-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.deelio-1.13/>Attention vs non-attention for a Shapley-based explanation method</a></strong><br><a href=/people/t/tom-kersten/>Tom Kersten</a>
|
<a href=/people/h/hugh-mee-wong/>Hugh Mee Wong</a>
|
<a href=/people/j/jaap-jumelet/>Jaap Jumelet</a>
|
<a href=/people/d/dieuwke-hupkes/>Dieuwke Hupkes</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--deelio-1--13><div class="card-body p-3 small">The field of explainable AI has recently seen an explosion in the number of explanation methods for highly non-linear deep neural networks. The extent to which such methods that are often proposed and tested in the domain of <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a> are appropriate to address the explainability challenges in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> is yet relatively unexplored. In this work, we consider Contextual Decomposition (CD) a Shapley-based input feature attribution method that has been shown to work well for recurrent NLP models and we test the extent to which it is useful for models that contain attention operations. To this end, we extend CD to cover the <a href=https://en.wikipedia.org/wiki/Operation_(mathematics)>operations</a> necessary for attention-based models. We then compare how long distance subject-verb relationships are processed by models with and without <a href=https://en.wikipedia.org/wiki/Attention>attention</a>, considering a number of different syntactic structures in two different languages : <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>. Our experiments confirm that CD can successfully be applied for attention-based models as well, providing an alternative Shapley-based attribution method for modern <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. In particular, using <a href=https://en.wikipedia.org/wiki/Compact_disc>CD</a>, we show that the English and Dutch models demonstrate similar processing behaviour, but that under the hood there are consistent differences between our attention and non-attention models.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>