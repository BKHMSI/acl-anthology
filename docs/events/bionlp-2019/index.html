<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Biomedical Natural Language Processing Workshop (2019) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Biomedical Natural Language Processing Workshop (2019)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#w19-50>Proceedings of the 18th BioNLP Workshop and Shared Task</a>
<span class="badge badge-info align-middle ml-1">24&nbsp;papers</span></li><li><a class=align-middle href=#d19-57>Proceedings of The 5th Workshop on BioNLP Open Shared Tasks</a>
<span class="badge badge-info align-middle ml-1">16&nbsp;papers</span></li></ul></div></div><div id=w19-50><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-50.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/W19-50/>Proceedings of the 18th BioNLP Workshop and Shared Task</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5000/>Proceedings of the 18th BioNLP Workshop and Shared Task</a></strong><br><a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a>
|
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5002 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5002/>Learning from the Experience of Doctors : Automated Diagnosis of Appendicitis Based on Clinical Notes</a></strong><br><a href=/people/s/steven-kester-yuwono/>Steven Kester Yuwono</a>
|
<a href=/people/h/hwee-tou-ng/>Hwee Tou Ng</a>
|
<a href=/people/k/kee-yuan-ngiam/>Kee Yuan Ngiam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5002><div class="card-body p-3 small">The objective of this work is to develop an automated diagnosis system that is able to predict the probability of appendicitis given a free-text emergency department (ED) note and additional structured information (e.g., lab test results). Our clinical corpus consists of about 180,000 ED notes based on ten years of patient visits to the Accident and Emergency (A&E) Department of the National University Hospital (NUH), Singapore. We propose a novel neural network approach that learns to diagnose <a href=https://en.wikipedia.org/wiki/Appendicitis>acute appendicitis</a> based on doctors&#8217; free-text ED notes without any <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a>. On a test set of 2,000 ED notes with equal number of appendicitis (positive) and non-appendicitis (negative) diagnosis and in which all the negative ED notes only consist of abdominal-related diagnosis, our model is able to achieve a promising F_0.5-score of 0.895 while <a href=https://en.wikipedia.org/wiki/Emergency_department>ED doctors</a> achieve F_0.5-score of 0.900. Visualization shows that our model is able to learn important features, signs, and symptoms of patients from unstructured free-text ED notes, which will help doctors to make better diagnosis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5003 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5003/>A Paraphrase Generation System for EHR Question Answering<span class=acl-fixed-case>EHR</span> Question Answering</a></strong><br><a href=/people/s/sarvesh-soni/>Sarvesh Soni</a>
|
<a href=/people/k/kirk-roberts/>Kirk Roberts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5003><div class="card-body p-3 small">This paper proposes a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and method for automatically generating paraphrases for clinical questions relating to patient-specific information in electronic health records (EHRs). Crowdsourcing is used to collect 10,578 unique questions across 946 semantically distinct paraphrase clusters. This <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is then used with a deep learning-based question paraphrasing method utilizing variational autoencoder and LSTM encoder / decoder. The ultimate use of such a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is to improve the performance of automatic question answering methods for <a href=https://en.wikipedia.org/wiki/Electronic_health_record>EHRs</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5006 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5006" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5006/>Transfer Learning in Biomedical Natural Language Processing : An Evaluation of BERT and ELMo on Ten Benchmarking Datasets<span class=acl-fixed-case>BERT</span> and <span class=acl-fixed-case>ELM</span>o on Ten Benchmarking Datasets</a></strong><br><a href=/people/y/yifan-peng/>Yifan Peng</a>
|
<a href=/people/s/shankai-yan/>Shankai Yan</a>
|
<a href=/people/z/zhiyong-lu/>Zhiyong Lu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5006><div class="card-body p-3 small">Inspired by the success of the General Language Understanding Evaluation benchmark, we introduce the Biomedical Language Understanding Evaluation (BLUE) benchmark to facilitate research in the development of pre-training language representations in the biomedicine domain. The <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> consists of five tasks with ten <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> that cover both biomedical and clinical texts with different dataset sizes and difficulties. We also evaluate several baselines based on <a href=https://en.wikipedia.org/wiki/Brain-derived_neurotrophic_factor>BERT</a> and ELMo and find that the <a href=https://en.wikipedia.org/wiki/Brain-derived_neurotrophic_factor>BERT model</a> pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results. We make the datasets, pre-trained models, and codes publicly available at https://github.com/ ncbi-nlp / BLUE_Benchmark.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5007 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5007" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5007/>Combining Structured and Free-text Electronic Medical Record Data for Real-time Clinical Decision Support</a></strong><br><a href=/people/e/emilia-apostolova/>Emilia Apostolova</a>
|
<a href=/people/t/tony-wang/>Tony Wang</a>
|
<a href=/people/t/tim-tschampel/>Tim Tschampel</a>
|
<a href=/people/i/ioannis-koutroulis/>Ioannis Koutroulis</a>
|
<a href=/people/t/tom-velez/>Tom Velez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5007><div class="card-body p-3 small">The goal of this work is to utilize Electronic Medical Record (EMR) data for real-time Clinical Decision Support (CDS). We present a deep learning approach to combining in real time available diagnosis codes (ICD codes) and free-text notes : Patient Context Vectors. Patient Context Vectors are created by averaging ICD code embeddings, and by predicting the same from free-text notes via a <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>Convolutional Neural Network</a>. The Patient Context Vectors were then simply appended to available structured data (vital signs and lab results) to build prediction models for a specific condition. Experiments on predicting ARDS, a rare and complex condition, demonstrate the utility of Patient Context Vectors as a means of summarizing the patient history and overall condition, and improve significantly the prediction model results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5010 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5010/>Deep Contextualized Biomedical Abbreviation Expansion</a></strong><br><a href=/people/q/qiao-jin/>Qiao Jin</a>
|
<a href=/people/j/jinling-liu/>Jinling Liu</a>
|
<a href=/people/x/xinghua-lu/>Xinghua Lu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5010><div class="card-body p-3 small">Automatic identification and expansion of ambiguous abbreviations are essential for biomedical natural language processing applications, such as <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> and question answering systems. In this paper, we present DEep Contextualized Biomedical Abbreviation Expansion (DECBAE) model. DECBAE automatically collects substantial and relatively clean annotated contexts for 950 ambiguous abbreviations from PubMed abstracts using a simple <a href=https://en.wikipedia.org/wiki/Heuristic>heuristic</a>. Then it utilizes BioELMo to extract the contextualized features of words, and feed those <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> to abbreviation-specific bidirectional LSTMs, where the hidden states of the ambiguous abbreviations are used to assign the exact definitions. Our DECBAE model outperforms other baselines by large margins, achieving average accuracy of 0.961 and macro-F1 of 0.917 on the dataset. It also surpasses human performance for expanding a sample abbreviation, and remains robust in imbalanced, low-resources and clinical settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5011 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5011" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5011/>RNN Embeddings for Identifying Difficult to Understand Medical Words<span class=acl-fixed-case>RNN</span> Embeddings for Identifying Difficult to Understand Medical Words</a></strong><br><a href=/people/h/hanna-pylieva/>Hanna Pylieva</a>
|
<a href=/people/a/artem-chernodub/>Artem Chernodub</a>
|
<a href=/people/n/natalia-grabar/>Natalia Grabar</a>
|
<a href=/people/t/thierry-hamon/>Thierry Hamon</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5011><div class="card-body p-3 small">Patients and their families often require a better understanding of medical information provided by doctors. We currently address this issue by improving the identification of difficult to understand medical words. We introduce novel embeddings received from RNN-FrnnMUTE (French RNN Medical Understandability Text Embeddings) which allow to reach up to 87.0 F1 score in identification of difficult words. We also note that adding pre-trained FastText word embeddings to the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature set</a> substantially improves the performance of the model which classifies words according to their difficulty. We study the generalizability of different <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> through three cross-validation scenarios which allow testing <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> in real-world conditions : understanding of medical words by new users, and classification of new unseen words by the automatic models. The RNN-FrnnMUTE embeddings and the categorization code are being made available for the research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5012 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5012/>A distantly supervised dataset for <a href=https://en.wikipedia.org/wiki/Data_extraction>automated data extraction</a> from diagnostic studies</a></strong><br><a href=/people/c/christopher-norman/>Christopher Norman</a>
|
<a href=/people/m/mariska-leeflang/>Mariska Leeflang</a>
|
<a href=/people/r/rene-spijker/>René Spijker</a>
|
<a href=/people/e/evangelos-kanoulas/>Evangelos Kanoulas</a>
|
<a href=/people/a/aurelie-neveol/>Aurélie Névéol</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5012><div class="card-body p-3 small">Systematic reviews are important in <a href=https://en.wikipedia.org/wiki/Evidence-based_medicine>evidence based medicine</a>, but are expensive to produce. Automating or semi-automating the data extraction of index test, target condition, and reference standard from articles has the potential to decrease the cost of conducting <a href=https://en.wikipedia.org/wiki/Systematic_review>systematic reviews</a> of diagnostic test accuracy, but relevant training data is not available. We create a distantly supervised dataset of approximately 90,000 sentences, and let two experts manually annotate a small subset of around 1,000 sentences for evaluation. We evaluate the performance of BioBERT and logistic regression for <a href=https://en.wikipedia.org/wiki/Ranking>ranking</a> the sentences, and compare the performance for distant and direct supervision. Our results suggest that distant supervision can work as well as, or better than direct supervision on this problem, and that distantly trained models can perform as well as, or better than human annotators.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5015 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5015/>A Comparison of Word-based and Context-based Representations for Classification Problems in Health Informatics</a></strong><br><a href=/people/a/aditya-joshi/>Aditya Joshi</a>
|
<a href=/people/s/sarvnaz-karimi/>Sarvnaz Karimi</a>
|
<a href=/people/r/ross-sparks/>Ross Sparks</a>
|
<a href=/people/c/cecile-paris/>Cecile Paris</a>
|
<a href=/people/c/c-raina-macintyre/>C Raina MacIntyre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5015><div class="card-body p-3 small">Distributed representations of text can be used as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> when training a <a href=https://en.wikipedia.org/wiki/Statistical_classification>statistical classifier</a>. These <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> may be created as a composition of word vectors or as context-based sentence vectors. We compare the two kinds of representations (word versus context) for three classification problems : influenza infection classification, drug usage classification and personal health mention classification. For statistical classifiers trained for each of these problems, context-based representations based on ELMo, Universal Sentence Encoder, Neural-Net Language Model and <a href=https://en.wikipedia.org/wiki/FLAIR>FLAIR</a> are better than Word2Vec, <a href=https://en.wikipedia.org/wiki/GloVe_(machine_learning)>GloVe</a> and the two adapted using the MESH ontology. There is an improvement of 2-4 % in the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> when these context-based representations are used instead of word-based representations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5021 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5021" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5021/>Annotating Temporal Information in Clinical Notes for Timeline Reconstruction : Towards the Definition of Calendar Expressions</a></strong><br><a href=/people/n/natalia-viani/>Natalia Viani</a>
|
<a href=/people/h/hegler-tissot/>Hegler Tissot</a>
|
<a href=/people/a/ariane-bernardino/>Ariane Bernardino</a>
|
<a href=/people/s/sumithra-velupillai/>Sumithra Velupillai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5021><div class="card-body p-3 small">To automatically analyse complex trajectory information enclosed in clinical text (e.g. timing of symptoms, duration of treatment), it is important to understand the related temporal aspects, anchoring each event on an absolute point in time. In the clinical domain, few temporally annotated corpora are currently available. Moreover, underlying annotation schemas-which mainly rely on the TimeML standard-are not necessarily easily applicable for applications such as patient timeline reconstruction. In this work, we investigated how temporal information is documented in clinical text by annotating a corpus of medical reports with time expressions (TIMEXes), based on <a href=https://en.wikipedia.org/wiki/TimeML>TimeML</a>. The developed <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is available to the NLP community. Starting from our annotations, we analysed the suitability of the TimeML TIMEX schema for capturing timeline information, identifying challenges and possible solutions. As a result, we propose a novel annotation schema that could be useful for timeline reconstruction : CALendar EXpression (CALEX).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5023 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5023/>Enhancing PIO Element Detection in Medical Text Using Contextualized Embedding<span class=acl-fixed-case>PIO</span> Element Detection in Medical Text Using Contextualized Embedding</a></strong><br><a href=/people/h/hichem-mezaoui/>Hichem Mezaoui</a>
|
<a href=/people/i/isuru-gunasekara/>Isuru Gunasekara</a>
|
<a href=/people/a/aleksandr-gontcharov/>Aleksandr Gontcharov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5023><div class="card-body p-3 small">In this paper, we presented an improved <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to extract PIO elements, from abstracts of medical papers, that reduces <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a>. The proposed technique was used to build a dataset of PIO elements that we call <a href=https://en.wikipedia.org/wiki/Piconet>PICONET</a>. We further proposed a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> of PIO elements classification using state of the art BERT embedding. In addition, we investigated a contextualized embedding, BioBERT, trained on medical corpora. It has been found that using the BioBERT embedding improved the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification accuracy</a>, outperforming the BERT-based model. This result reinforces the idea of the importance of embedding contextualization in subsequent classification tasks in this specific context. Furthermore, to enhance the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of the model, we have investigated an <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble method</a> based on the LGBM algorithm. We trained the LGBM model, with the above models as base learners, to learn a linear combination of the predicted probabilities for the 3 classes with the TF-IDF score and the QIEF that optimizes the classification. The results indicate that these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>text features</a> were good features to consider in order to boost the deeply contextualized classification model. We compared the performance of the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> when using the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> with one of the base learners and the case where we combine the base learners along with the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. We obtained the highest score in terms of <a href=https://en.wikipedia.org/wiki/Analysis_of_covariance>AUC</a> when we combine the base learners. The present work resulted in the creation of a PIO element dataset, PICONET, and a classification tool. These constitute and important component of our system of automatic mining of medical abstracts. We intend to extend the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> to <a href=https://en.wikipedia.org/wiki/Medical_literature>full medical articles</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5025 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5025/>Can Character Embeddings Improve Cause-of-Death Classification for Verbal Autopsy Narratives?</a></strong><br><a href=/people/z/zhaodong-yan/>Zhaodong Yan</a>
|
<a href=/people/s/serena-jeblee/>Serena Jeblee</a>
|
<a href=/people/g/graeme-hirst/>Graeme Hirst</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5025><div class="card-body p-3 small">We present two models for combining word and character embeddings for cause-of-death classification of verbal autopsy reports using the text of the narratives. We find that for smaller datasets (500 to 1000 records), adding character information to the model improves <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>, making character-based CNNs a promising method for automated verbal autopsy coding.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5026 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5026/>Is artificial data useful for biomedical Natural Language Processing algorithms?</a></strong><br><a href=/people/z/zixu-wang/>Zixu Wang</a>
|
<a href=/people/j/julia-ive/>Julia Ive</a>
|
<a href=/people/s/sumithra-velupillai/>Sumithra Velupillai</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5026><div class="card-body p-3 small">A major obstacle to the development of Natural Language Processing (NLP) methods in the biomedical domain is data accessibility. This problem can be addressed by generating medical data artificially. Most previous studies have focused on the generation of short clinical text, and evaluation of the data utility has been limited. We propose a generic <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to guide the generation of clinical text with key phrases. We use the artificial data as additional training data in two key biomedical NLP tasks : <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> and temporal relation extraction. We show that artificially generated training data used in conjunction with real training data can lead to performance boosts for data-greedy neural network algorithms. We also demonstrate the usefulness of the generated data for NLP setups where it fully replaces real training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5027 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5027" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5027/>ChiMed : A Chinese Medical Corpus for <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a><span class=acl-fixed-case>C</span>hi<span class=acl-fixed-case>M</span>ed: A <span class=acl-fixed-case>C</span>hinese Medical Corpus for Question Answering</a></strong><br><a href=/people/y/yuanhe-tian/>Yuanhe Tian</a>
|
<a href=/people/w/weicheng-ma/>Weicheng Ma</a>
|
<a href=/people/f/fei-xia/>Fei Xia</a>
|
<a href=/people/y/yan-song/>Yan Song</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5027><div class="card-body p-3 small">Question answering (QA) is a challenging task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>, especially when it is applied to specific domains. While <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> trained in the <a href=https://en.wikipedia.org/wiki/Domain_(biology)>general domain</a> can be adapted to a new target domain, their performance often degrades significantly due to domain mismatch. Alternatively, one can require a large amount of domain-specific QA data, but such <a href=https://en.wikipedia.org/wiki/Data>data</a> are rare, especially for the medical domain. In this study, we first collect a large-scale Chinese medical QA corpus called ChiMed ; second we annotate a small fraction of the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to check the quality of the answers ; third, we extract two datasets from the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and use them for the relevancy prediction task and the adoption prediction task. Several <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark models</a> are applied to the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, producing good results for both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5038.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5038 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5038 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5038/>Extracting relations between outcomes and <a href=https://en.wikipedia.org/wiki/Statistical_significance>significance levels</a> in Randomized Controlled Trials (RCTs) publications<span class=acl-fixed-case>RCT</span>s) publications</a></strong><br><a href=/people/a/anna-koroleva/>Anna Koroleva</a>
|
<a href=/people/p/patrick-paroubek/>Patrick Paroubek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5038><div class="card-body p-3 small">Randomized controlled trials assess the effects of an experimental intervention by comparing it to a control intervention with regard to some variables-trial outcomes. Statistical hypothesis testing is used to test if the <a href=https://en.wikipedia.org/wiki/Design_of_experiments>experimental intervention</a> is superior to the <a href=https://en.wikipedia.org/wiki/Scientific_control>control</a>. Statistical significance is typically reported for the measured outcomes and is an important characteristic of the results. We propose a machine learning approach to automatically extract reported outcomes, <a href=https://en.wikipedia.org/wiki/Statistical_significance>significance levels</a> and the relation between them. We annotated a corpus of 663 sentences with 2,552 outcome-significance level relations (1,372 positive and 1,180 negative relations). We compared several <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a>, using a manually crafted feature set, and a number of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a>. The best performance (F-measure of 94 %) was shown by the BioBERT fine-tuned model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5039 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5039" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5039/>Overview of the MEDIQA 2019 Shared Task on Textual Inference, <a href=https://en.wikipedia.org/wiki/Question_answering>Question Entailment</a> and <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a><span class=acl-fixed-case>MEDIQA</span> 2019 Shared Task on Textual Inference, Question Entailment and Question Answering</a></strong><br><a href=/people/a/asma-ben-abacha/>Asma Ben Abacha</a>
|
<a href=/people/c/chaitanya-shivade/>Chaitanya Shivade</a>
|
<a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5039><div class="card-body p-3 small">This paper presents the MEDIQA 2019 shared task organized at the ACL-BioNLP workshop. The shared task is motivated by a need to develop relevant methods, techniques and gold standards for <a href=https://en.wikipedia.org/wiki/Inference>inference</a> and entailment in the medical domain, and their application to improve domain specific information retrieval and question answering systems. MEDIQA 2019 includes three tasks : Natural Language Inference (NLI), Recognizing Question Entailment (RQE), and Question Answering (QA) in the medical domain. 72 teams participated in the challenge, achieving an accuracy of 98 % in the NLI task, 74.9 % in the RQE task, and 78.3 % in the QA task. In this paper, we describe the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, and the participants&#8217; approaches and results. We hope that this shared task will attract further research efforts in textual inference, question entailment, and <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> in the medical domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5043 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5043/>Surf at MEDIQA 2019 : Improving Performance of Natural Language Inference in the Clinical Domain by Adopting Pre-trained Language Model<span class=acl-fixed-case>MEDIQA</span> 2019: Improving Performance of Natural Language Inference in the Clinical Domain by Adopting Pre-trained Language Model</a></strong><br><a href=/people/j/jiin-nam/>Jiin Nam</a>
|
<a href=/people/s/seunghyun-yoon/>Seunghyun Yoon</a>
|
<a href=/people/k/kyomin-jung/>Kyomin Jung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5043><div class="card-body p-3 small">While deep learning techniques have shown promising results in many natural language processing (NLP) tasks, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> has not been widely applied to the clinical domain. The lack of <a href=https://en.wikipedia.org/wiki/Data_set>large datasets</a> and the pervasive use of <a href=https://en.wikipedia.org/wiki/Domain-specific_language>domain-specific language</a> (i.e. abbreviations and acronyms) in the clinical domain causes slower progress in NLP tasks than that of the general NLP tasks. To fill this gap, we employ word / subword-level based models that adopt large-scale data-driven methods such as pre-trained language models and <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> in analyzing text for the clinical domain. Empirical results demonstrate the superiority of the proposed <a href=https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations>methods</a> by achieving 90.6 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> in <a href=https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations>medical domain natural language inference task</a>. Furthermore, we inspect the independent strengths of the proposed approaches in quantitative and qualitative manners. This analysis will help researchers to select necessary components in building <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for the <a href=https://en.wikipedia.org/wiki/Medicine>medical domain</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5044.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5044 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5044 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5044" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5044/>WTMED at MEDIQA 2019 : A Hybrid Approach to Biomedical Natural Language Inference<span class=acl-fixed-case>WTMED</span> at <span class=acl-fixed-case>MEDIQA</span> 2019: A Hybrid Approach to Biomedical Natural Language Inference</a></strong><br><a href=/people/z/zhaofeng-wu/>Zhaofeng Wu</a>
|
<a href=/people/y/yan-song/>Yan Song</a>
|
<a href=/people/s/sicong-huang/>Sicong Huang</a>
|
<a href=/people/y/yuanhe-tian/>Yuanhe Tian</a>
|
<a href=/people/f/fei-xia/>Fei Xia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5044><div class="card-body p-3 small">Natural language inference (NLI) is challenging, especially when <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is applied to technical domains such as <a href=https://en.wikipedia.org/wiki/Biomedical_sciences>biomedical settings</a>. In this paper, we propose a hybrid approach to biomedical NLI where different types of information are exploited for this task. Our base model includes a pre-trained text encoder as the core component, and a syntax encoder and a feature encoder to capture syntactic and domain-specific information. Then we combine the output of different base models to form more powerful ensemble models. Finally, we design two conflict resolution strategies when the test data contain multiple (premise, hypothesis) pairs with the same premise. We train our <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> on the MedNLI dataset, yielding the best performance on the test set of the MEDIQA 2019 Task 1.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5045.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5045 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5045 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5045/>KU_ai at MEDIQA 2019 : Domain-specific Pre-training and Transfer Learning for Medical NLI<span class=acl-fixed-case>KU</span>_ai at <span class=acl-fixed-case>MEDIQA</span> 2019: Domain-specific Pre-training and Transfer Learning for Medical <span class=acl-fixed-case>NLI</span></a></strong><br><a href=/people/c/cemil-cengiz/>Cemil Cengiz</a>
|
<a href=/people/u/ulas-sert/>Ulaş Sert</a>
|
<a href=/people/d/deniz-yuret/>Deniz Yuret</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5045><div class="card-body p-3 small">In this paper, we describe our <a href=https://en.wikipedia.org/wiki/System>system</a> and results submitted for the Natural Language Inference (NLI) track of the MEDIQA 2019 Shared Task. As KU_ai team, we used BERT as our baseline model and pre-processed the MedNLI dataset to mitigate the negative impact of de-identification artifacts. Moreover, we investigated different pre-training and transfer learning approaches to improve the performance. We show that pre-training the <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> on rich biomedical corpora has a significant effect in teaching the model domain-specific language. In addition, training the model on large NLI datasets such as MultiNLI and SNLI helps in learning task-specific reasoning. Finally, we ensembled our highest-performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, and achieved 84.7 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on the unseen test dataset and ranked 10th out of 17 teams in the official results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5048 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5048/>Dr. Quad at MEDIQA 2019 : Towards Textual Inference and Question Entailment using contextualized representations<span class=acl-fixed-case>D</span>r.<span class=acl-fixed-case>Q</span>uad at <span class=acl-fixed-case>MEDIQA</span> 2019: Towards Textual Inference and Question Entailment using contextualized representations</a></strong><br><a href=/people/v/vinayshekhar-bannihatti-kumar/>Vinayshekhar Bannihatti Kumar</a>
|
<a href=/people/a/ashwin-srinivasan/>Ashwin Srinivasan</a>
|
<a href=/people/a/aditi-chaudhary/>Aditi Chaudhary</a>
|
<a href=/people/j/james-route/>James Route</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5048><div class="card-body p-3 small">This paper presents the submissions by TeamDr. Quad to the ACL-BioNLP 2019 shared task on Textual Inference and Question Entailment in the Medical Domain. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is based on the prior work Liu et al. (2019) which uses a multi-task objective function for <a href=https://en.wikipedia.org/wiki/Textual_entailment>textual entailment</a>. In this work, we explore different strategies for generalizing state-of-the-art language understanding models to the specialized medical domain. Our results on the shared task demonstrate that incorporating <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> through <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> is a powerful strategy for addressing challenges posed specialized domains such as <a href=https://en.wikipedia.org/wiki/Medicine>medicine</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5049.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5049 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5049 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5049/>Sieg at MEDIQA 2019 : Multi-task Neural Ensemble for Biomedical Inference and Entailment<span class=acl-fixed-case>MEDIQA</span> 2019: Multi-task Neural Ensemble for Biomedical Inference and Entailment</a></strong><br><a href=/people/s/sai-abishek-bhaskar/>Sai Abishek Bhaskar</a>
|
<a href=/people/r/rashi-rungta/>Rashi Rungta</a>
|
<a href=/people/j/james-route/>James Route</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5049><div class="card-body p-3 small">This paper presents a multi-task learning approach to natural language inference (NLI) and question entailment (RQE) in the biomedical domain. Recognizing textual inference relations and question similarity can address the issue of answering new consumer health questions by mapping them to Frequently Asked Questions on reputed websites like the NIH. We show that leveraging information from parallel tasks across domains along with medical knowledge integration allows our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to learn better biomedical feature representations. Our final models for the NLI and RQE tasks achieve the 4th and 2nd rank on the shared-task leaderboard respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5052 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5052/>MSIT_SRIB at MEDIQA 2019 : Knowledge Directed Multi-task Framework for Natural Language Inference in Clinical Domain.<span class=acl-fixed-case>MSIT</span>_<span class=acl-fixed-case>SRIB</span> at <span class=acl-fixed-case>MEDIQA</span> 2019: Knowledge Directed Multi-task Framework for Natural Language Inference in Clinical Domain.</a></strong><br><a href=/people/s/sahil-chopra/>Sahil Chopra</a>
|
<a href=/people/a/ankita-gupta/>Ankita Gupta</a>
|
<a href=/people/a/anupama-kaushik/>Anupama Kaushik</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5052><div class="card-body p-3 small">In this paper, we present Biomedical Multi-Task Deep Neural Network (Bio-MTDNN) on the NLI task of MediQA 2019 challenge. Bio-MTDNN utilizes transfer learning based paradigm where not only the source and target domains are different but also the source and target tasks are varied, although related. Further, Bio-MTDNN integrates knowledge from external sources such as clinical databases (UMLS) enhancing its performance on the clinical domain. Our proposed method outperformed the official baseline and other prior models (such as ESIM and Infersent on dev set) by a considerable margin as evident from our experimental results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5056.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5056 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5056 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5056/>IITP at MEDIQA 2019 : Systems Report for Natural Language Inference, Question Entailment and Question Answering<span class=acl-fixed-case>IITP</span> at <span class=acl-fixed-case>MEDIQA</span> 2019: Systems Report for Natural Language Inference, Question Entailment and Question Answering</a></strong><br><a href=/people/d/dibyanayan-bandyopadhyay/>Dibyanayan Bandyopadhyay</a>
|
<a href=/people/b/baban-gain/>Baban Gain</a>
|
<a href=/people/t/tanik-saikh/>Tanik Saikh</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5056><div class="card-body p-3 small">This paper presents the experiments accomplished as a part of our participation in the MEDIQA challenge, an (Abacha et al., 2019) shared task. We participated in all the three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> defined in this particular <a href=https://en.wikipedia.org/wiki/Task_(project_management)>shared task</a>. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> are viz. i. Natural Language Inference (NLI) ii. Recognizing Question Entailment(RQE) and their application in medical Question Answering (QA). We submitted runs using multiple deep learning based systems (runs) for each of these three tasks. We submitted five <a href=https://en.wikipedia.org/wiki/System>system</a> results in each of the NLI and RQE tasks, and four system results for the QA task. The <a href=https://en.wikipedia.org/wiki/System>systems</a> yield encouraging results in all the three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. The highest performance obtained in NLI, RQE and QA tasks are 81.8 %, 53.2 %, and 71.7 %, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5057.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5057 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5057 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5057/>LasigeBioTM at MEDIQA 2019 : Biomedical Question Answering using Bidirectional Transformers and Named Entity Recognition<span class=acl-fixed-case>L</span>asige<span class=acl-fixed-case>B</span>io<span class=acl-fixed-case>TM</span> at <span class=acl-fixed-case>MEDIQA</span> 2019: Biomedical Question Answering using Bidirectional Transformers and Named Entity Recognition</a></strong><br><a href=/people/a/andre-lamurias/>Andre Lamurias</a>
|
<a href=/people/f/francisco-m-couto/>Francisco M Couto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5057><div class="card-body p-3 small">Biomedical Question Answering (QA) aims at providing automated answers to user questions, regarding a variety of biomedical topics. For example, these questions may ask for related to <a href=https://en.wikipedia.org/wiki/Disease>diseases</a>, <a href=https://en.wikipedia.org/wiki/Drug>drugs</a>, <a href=https://en.wikipedia.org/wiki/Symptom>symptoms</a>, or <a href=https://en.wikipedia.org/wiki/Medical_procedure>medical procedures</a>. Automated biomedical QA systems could improve the retrieval of information necessary to answer these questions. The MEDIQA challenge consisted of three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> concerning various aspects of biomedical QA. This challenge aimed at advancing approaches to Natural Language Inference (NLI) and Recognizing Question Entailment (RQE), which would then result in enhanced approaches to biomedical QA. Our approach explored a common Transformer-based architecture that could be applied to each <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. This approach shared the same pre-trained weights, but which were then fine-tuned for each task using the provided training data. Furthermore, we augmented the training data with external datasets and enriched the question and answer texts using MER, a named entity recognition tool. Our approach obtained high levels of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, in particular on the NLI task, which classified pairs of text according to their relation. For the QA task, we obtained higher Spearman&#8217;s rank correlation values using the entities recognized by MER.</div></div></div><hr><div id=d19-57><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-57.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/D19-57/>Proceedings of The 5th Workshop on BioNLP Open Shared Tasks</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5700/>Proceedings of The 5th Workshop on BioNLP Open Shared Tasks</a></strong><br><a href=/people/k/kim-jin-dong/>Kim Jin-Dong</a>
|
<a href=/people/n/nedellec-claire/>Nédellec Claire</a>
|
<a href=/people/b/bossy-robert/>Bossy Robert</a>
|
<a href=/people/d/deleger-louise/>Deléger Louise</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5701.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5701 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5701 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5701/>PharmaCoNER : Pharmacological Substances, Compounds and proteins Named Entity Recognition track<span class=acl-fixed-case>P</span>harma<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NER</span>: Pharmacological Substances, Compounds and proteins Named Entity Recognition track</a></strong><br><a href=/people/a/aitor-gonzalez-agirre/>Aitor Gonzalez-Agirre</a>
|
<a href=/people/m/montserrat-marimon/>Montserrat Marimon</a>
|
<a href=/people/a/ander-intxaurrondo/>Ander Intxaurrondo</a>
|
<a href=/people/o/obdulia-rabal/>Obdulia Rabal</a>
|
<a href=/people/m/marta-villegas/>Marta Villegas</a>
|
<a href=/people/m/martin-krallinger/>Martin Krallinger</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5701><div class="card-body p-3 small">One of the biomedical entity types of relevance for <a href=https://en.wikipedia.org/wiki/Medicine>medicine</a> or biosciences are <a href=https://en.wikipedia.org/wiki/Chemical_compound>chemical compounds</a> and <a href=https://en.wikipedia.org/wiki/Drug>drugs</a>. The correct detection these entities is critical for other text mining applications building on them, such as adverse drug-reaction detection, medication-related fake news or drug-target extraction. Although a significant effort was made to detect mentions of drugs / chemicals in English texts, so far only very limited attempts were made to recognize them in medical documents in other languages. Taking into account the growing amount of <a href=https://en.wikipedia.org/wiki/Medical_literature>medical publications</a> and <a href=https://en.wikipedia.org/wiki/Medical_record>clinical records</a> written in <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, we have organized the first shared task on detecting drug and chemical entities in <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish medical documents</a>. Additionally, we included a clinical concept-indexing sub-track asking teams to return SNOMED-CT identifiers related to drugs / chemicals for a collection of documents. For this task, named PharmaCoNER, we generated annotation guidelines together with a corpus of 1,000 manually annotated clinical case studies. A total of 22 teams participated in the sub-track 1, (77 system runs), and 7 teams in the sub-track 2 (19 system runs). Top scoring teams used sophisticated <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning approaches</a> yielding very competitive results with F-measures above 0.91. These results indicate that there is a real interest in promoting biomedical text mining efforts beyond <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We foresee that the PharmaCoNER annotation guidelines, corpus and participant systems will foster the development of new resources for clinical and biomedical text mining systems of Spanish medical data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5704.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5704 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5704 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5704/>IxaMed at PharmacoNER Challenge 2019<span class=acl-fixed-case>I</span>xa<span class=acl-fixed-case>M</span>ed at <span class=acl-fixed-case>P</span>harmaco<span class=acl-fixed-case>NER</span> Challenge 2019</a></strong><br><a href=/people/x/xabier-lahuerta/>Xabier Lahuerta</a>
|
<a href=/people/i/iakes-goenaga/>Iakes Goenaga</a>
|
<a href=/people/k/koldo-gojenola/>Koldo Gojenola</a>
|
<a href=/people/a/aitziber-atutxa-salazar/>Aitziber Atutxa Salazar</a>
|
<a href=/people/m/maite-oronoz/>Maite Oronoz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5704><div class="card-body p-3 small">The aim of this paper is to present our approach (IxaMed) in the PharmacoNER 2019 task. The task consists of identifying chemical, drug, and gene / protein mentions from clinical case studies written in <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. The evaluation of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is divided in two scenarios : one corresponding to the detection of named entities and one corresponding to the indexation of named entities that have been previously identified. In order to identify <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a> we have made use of a Bi-LSTM with a CRF on top in combination with different types of <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. We have achieved our best result (86.81 F-Score) combining pretrained word embeddings of <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> and <a href=https://en.wikipedia.org/wiki/Electronic_health_record>Electronic Health Records</a> (50 M words) with contextual string embeddings of <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> and <a href=https://en.wikipedia.org/wiki/Electronic_health_record>Electronic Health Records</a>. On the other hand, for the indexation of the named entities we have used the <a href=https://en.wikipedia.org/wiki/Levenshtein_distance>Levenshtein distance</a> obtaining a 85.34 <a href=https://en.wikipedia.org/wiki/F-score>F-Score</a> as our best result.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5706.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5706 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5706 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5706/>A Deep Learning-Based System for PharmaCoNER<span class=acl-fixed-case>P</span>harma<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/y/ying-xiong/>Ying Xiong</a>
|
<a href=/people/y/yedan-shen/>Yedan Shen</a>
|
<a href=/people/y/yuanhang-huang/>Yuanhang Huang</a>
|
<a href=/people/s/shuai-chen/>Shuai Chen</a>
|
<a href=/people/b/buzhou-tang/>Buzhou Tang</a>
|
<a href=/people/x/xiaolong-wang/>Xiaolong Wang</a>
|
<a href=/people/q/qingcai-chen/>Qingcai Chen</a>
|
<a href=/people/j/jun-yan/>Jun Yan</a>
|
<a href=/people/y/yi-zhou/>Yi Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5706><div class="card-body p-3 small">The Biological Text Mining Unit at BSC and CNIO organized the first shared task on chemical & drug mention recognition from Spanish medical texts called PharmaCoNER (Pharmacological Substances, Compounds and proteins and Named Entity Recognition track) in 2019, which includes two tracks : one for NER offset and entity classification (track 1) and the other one for concept indexing (track 2). We developed a pipeline system based on deep learning methods for this shared task, specifically, a subsystem based on BERT (Bidirectional Encoder Representations from Transformers) for NER offset and entity classification and a subsystem based on Bpool (Bi-LSTM with max / mean pooling) for concept indexing. Evaluation conducted on the shared task data showed that our system achieves a micro-average F1-score of 0.9105 on track 1 and a micro-average F1-score of 0.8391 on track 2.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5708.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5708 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5708 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5708/>A Neural Pipeline Approach for the PharmaCoNER Shared Task using Contextual Exhaustive Models<span class=acl-fixed-case>P</span>harma<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NER</span> Shared Task using Contextual Exhaustive Models</a></strong><br><a href=/people/m/mohammad-golam-sohrab/>Mohammad Golam Sohrab</a>
|
<a href=/people/m/minh-thang-pham/>Minh Thang Pham</a>
|
<a href=/people/m/makoto-miwa/>Makoto Miwa</a>
|
<a href=/people/h/hiroya-takamura/>Hiroya Takamura</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5708><div class="card-body p-3 small">We present a neural pipeline approach that performs named entity recognition (NER) and concept indexing (CI), which links them to concept unique identifiers (CUIs) in a knowledge base, for the PharmaCoNER shared task on pharmaceutical drugs and chemical entities. We proposed a neural NER model that captures the surrounding semantic information of a given sequence by capturing the forward- and backward-context of bidirectional LSTM (Bi-LSTM) output of a target span using contextual span representation-based exhaustive approach. The <a href=https://en.wikipedia.org/wiki/NER_model>NER model</a> enumerates all possible spans as potential entity mentions and classify them into entity types or no entity with <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a>. For representing span, we compare several different neural network architectures and their <a href=https://en.wikipedia.org/wiki/Network_topology>ensembling</a> for the <a href=https://en.wikipedia.org/wiki/NER_model>NER model</a>. We then perform dictionary matching for CI and, if there is no matching, we further compute similarity scores between a mention and CUIs using entity embeddings to assign the CUI with the highest score to the mention. We evaluate our <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> on the two sub-tasks in the shared task. Among the five submitted runs, the best run for each <a href=https://en.wikipedia.org/wiki/Task_(project_management)>sub-task</a> achieved the F-score of 86.76 % on Sub-task 1 (NER) and the F-score of 79.97 % (strict) on Sub-task 2 (CI).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5709.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5709 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5709 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-5709" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-5709/>Biomedical Named Entity Recognition with Multilingual BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/k/kai-hakala/>Kai Hakala</a>
|
<a href=/people/s/sampo-pyysalo/>Sampo Pyysalo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5709><div class="card-body p-3 small">We present the approach of the Turku NLP group to the PharmaCoNER task on Spanish biomedical named entity recognition. We apply a CRF-based baseline approach and multilingual BERT to the task, achieving an F-score of 88 % on the development data and 87 % on the test set with BERT. Our approach reflects a straightforward application of a state-of-the-art multilingual model that is not specifically tailored to either the language nor the application domain. The source code is available at : https://github.com/chaanim/pharmaconer</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5710.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5710 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5710 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-5710" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-5710/>An Overview of the Active Gene Annotation Corpus and the BioNLP OST 2019 AGAC Track Tasks<span class=acl-fixed-case>B</span>io<span class=acl-fixed-case>NLP</span> <span class=acl-fixed-case>OST</span> 2019 <span class=acl-fixed-case>AGAC</span> Track Tasks</a></strong><br><a href=/people/y/yuxing-wang/>Yuxing Wang</a>
|
<a href=/people/k/kaiyin-zhou/>Kaiyin Zhou</a>
|
<a href=/people/m/mina-gachloo/>Mina Gachloo</a>
|
<a href=/people/j/jingbo-xia/>Jingbo Xia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5710><div class="card-body p-3 small">The active gene annotation corpus (AGAC) was developed to support <a href=https://en.wikipedia.org/wiki/Knowledge_discovery>knowledge discovery</a> for <a href=https://en.wikipedia.org/wiki/Drug_repurposing>drug repurposing</a>. Based on the corpus, the AGAC track of the BioNLP Open Shared Tasks 2019 was organized, to facilitate cross-disciplinary collaboration across BioNLP and Pharmacoinformatics communities, for <a href=https://en.wikipedia.org/wiki/Drug_repurposing>drug repurposing</a>. The AGAC track consists of three subtasks : 1) <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, 2) thematic relation extraction, and 3) loss of function (LOF) / gain of function (GOF) topic classification. The AGAC track was participated by five teams, of which the performance are compared and analyzed. The the results revealed a substantial room for improvement in the design of the task, which we analyzed in terms of imbalanced data, selective annotation and latent topic annotation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5716.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5716 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5716 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5716/>A Multi-Task Learning Framework for Extracting Bacteria Biotope Information</a></strong><br><a href=/people/q/qi-zhang/>Qi Zhang</a>
|
<a href=/people/c/chao-liu/>Chao Liu</a>
|
<a href=/people/y/ying-chi/>Ying Chi</a>
|
<a href=/people/x/xuansong-xie/>Xuansong Xie</a>
|
<a href=/people/x/xiansheng-hua/>Xiansheng Hua</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5716><div class="card-body p-3 small">This paper presents a novel transfer multi-task learning method for Bacteria Biotope rel+ner task at BioNLP-OST 2019. To alleviate the data deficiency problem in domain-specific information extraction, we use BERT(Bidirectional Encoder Representations from Transformers) and pre-train it using mask language models and next sentence prediction on both general corpus and medical corpus like <a href=https://en.wikipedia.org/wiki/PubMed>PubMed</a>. In fine-tuning stage, we fine-tune the relation extraction layer and mention recognition layer designed by us on the top of BERT to extract mentions and relations simultaneously. The evaluation results show that our method achieves the best performance on all metrics (including slot error rate, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> and recall) in the Bacteria Biotope rel+ner subtask.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5718.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5718 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5718 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5718/>Using Snomed to recognize and index chemical and drug mentions.</a></strong><br><a href=/people/p/pilar-lopez-ubeda/>Pilar López Úbeda</a>
|
<a href=/people/m/manuel-carlos-diaz-galiano/>Manuel Carlos Díaz Galiano</a>
|
<a href=/people/l/l-alfonso-urena-lopez/>L. Alfonso Urena Lopez</a>
|
<a href=/people/m/m-teresa-martin-valdivia/>Maite Martin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5718><div class="card-body p-3 small">In this paper we describe a new named entity extraction system. Our work proposes a system for the identification and annotation of drug names in Spanish biomedical texts based on machine learning and deep learning models. Subsequently, a standardized code using <a href=https://en.wikipedia.org/wiki/Snomed>Snomed</a> is assigned to these <a href=https://en.wikipedia.org/wiki/Medication>drugs</a>, for this purpose, Natural Language Processing tools and techniques have been used, and a dictionary of different sources of information has been built. The results are promising, we obtain 78 % in F1 score on the first sub-track and in the second task we map with <a href=https://en.wikipedia.org/wiki/Snomed>Snomed</a> correctly 72 % of the found entities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5720.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5720 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5720 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-5720" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-5720/>Linguistically Informed Relation Extraction and Neural Architectures for Nested Named Entity Recognition in BioNLP-OST 2019<span class=acl-fixed-case>B</span>io<span class=acl-fixed-case>NLP</span>-<span class=acl-fixed-case>OST</span> 2019</a></strong><br><a href=/people/p/pankaj-gupta/>Pankaj Gupta</a>
|
<a href=/people/u/usama-yaseen/>Usama Yaseen</a>
|
<a href=/people/h/hinrich-schutze/>Hinrich Schütze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5720><div class="card-body p-3 small">Named Entity Recognition (NER) and Relation Extraction (RE) are essential tools in distilling knowledge from biomedical literature. This paper presents our findings from participating in BioNLP Shared Tasks 2019. We addressed <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> including <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>nested entities extraction</a>, Entity Normalization and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Relation Extraction</a>. Our proposed approach of <a href=https://en.wikipedia.org/wiki/Named_entity>Named Entities</a> can be generalized to different languages and we have shown it&#8217;s effectiveness for English and Spanish text. We investigated linguistic features, hybrid loss including ranking and Conditional Random Fields (CRF), multi-task objective and token level ensembling strategy to improve NER. We employed dictionary based fuzzy and semantic search to perform Entity Normalization. Finally, our RE system employed Support Vector Machine (SVM) with <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a>. Our NER submission (team : MIC-CIS) ranked first in BB-2019 norm+NER task with standard error rate (SER) of 0.7159 and showed competitive performance on PharmaCo NER task with F1-score of 0.8662. Our RE system ranked first in the SeeDev-binary Relation Extraction Task with F1-score of 0.3738.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5721.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5721 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5721 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5721/>An ensemble CNN method for biomedical entity normalization<span class=acl-fixed-case>CNN</span> method for biomedical entity normalization</a></strong><br><a href=/people/p/pan-deng/>Pan Deng</a>
|
<a href=/people/h/haipeng-chen/>Haipeng Chen</a>
|
<a href=/people/m/mengyao-huang/>Mengyao Huang</a>
|
<a href=/people/x/xiaowen-ruan/>Xiaowen Ruan</a>
|
<a href=/people/l/liang-xu/>Liang Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5721><div class="card-body p-3 small">Different representations of the same concept could often be seen in <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific reports</a> and publications. Entity normalization (or entity linking) is the task to match the different <a href=https://en.wikipedia.org/wiki/Representation_(systemics)>representations</a> to their standard concepts. In this paper, we present a two-step ensemble CNN method that normalizes microbiology-related entities in free text to concepts in standard <a href=https://en.wikipedia.org/wiki/Dictionary>dictionaries</a>. The method is capable of linking entities when only a small microbiology-related biomedical corpus is available for training, and achieved reasonable performance in the online test of the BioNLP-OST19 shared task Bacteria Biotope.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5722.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5722 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5722 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5722/>BOUN-ISIK Participation : An Unsupervised Approach for the Named Entity Normalization and Relation Extraction of Bacteria Biotopes<span class=acl-fixed-case>BOUN</span>-<span class=acl-fixed-case>ISIK</span> Participation: An Unsupervised Approach for the Named Entity Normalization and Relation Extraction of Bacteria Biotopes</a></strong><br><a href=/people/i/ilknur-karadeniz/>İlknur Karadeniz</a>
|
<a href=/people/o/omer-faruk-tuna/>Ömer Faruk Tuna</a>
|
<a href=/people/a/arzucan-ozgur/>Arzucan Özgür</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5722><div class="card-body p-3 small">This paper presents our participation to the Bacteria Biotope Task of the BioNLP Shared Task 2019. Our participation includes two systems for the two subtasks of the Bacteria Biotope Task : the normalization of entities (BB-norm) and the identification of the relations between the entities given a biomedical text (BB-rel). For the normalization of entities, we utilized <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and syntactic re-ranking. For the relation extraction task, pre-defined rules are used. Although both approaches are unsupervised, in the sense that they do not need any labeled data, they achieved promising results. Especially, for the BB-norm task, the results have shown that the proposed method performs as good as <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning based methods</a>, which require labeled data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5724.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5724 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5724 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5724/>Integration of <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a> and Traditional <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Learning</a> for <a href=https://en.wikipedia.org/wiki/Knowledge_extraction>Knowledge Extraction</a> from Biomedical Literature</a></strong><br><a href=/people/j/jihang-mao/>Jihang Mao</a>
|
<a href=/people/w/wanli-liu/>Wanli Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5724><div class="card-body p-3 small">In this paper, we present our participation in the Bacteria Biotope (BB) task at BioNLP-OST 2019. Our system utilizes fine-tuned language representation models and machine learning approaches based on <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> and lexical features for entities recognition, normalization and relation extraction. It achieves the state-of-the-art performance and is among the top two systems in five of all six subtasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5725.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5725 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5725 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5725/>CRAFT Shared Tasks 2019 Overview Integrated Structure, <a href=https://en.wikipedia.org/wiki/Semantics>Semantics</a>, and <a href=https://en.wikipedia.org/wiki/Coreference>Coreference</a><span class=acl-fixed-case>CRAFT</span> Shared Tasks 2019 Overview — Integrated Structure, Semantics, and Coreference</a></strong><br><a href=/people/w/william-a-baumgartner-jr/>William Baumgartner</a>
|
<a href=/people/m/michael-bada/>Michael Bada</a>
|
<a href=/people/s/sampo-pyysalo/>Sampo Pyysalo</a>
|
<a href=/people/m/manuel-r-ciosici/>Manuel R. Ciosici</a>
|
<a href=/people/n/negacy-hailu/>Negacy Hailu</a>
|
<a href=/people/h/harrison-pielke-lombardo/>Harrison Pielke-Lombardo</a>
|
<a href=/people/m/michael-regan/>Michael Regan</a>
|
<a href=/people/l/lawrence-hunter/>Lawrence Hunter</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5725><div class="card-body p-3 small">As part of the BioNLP Open Shared Tasks 2019, the CRAFT Shared Tasks 2019 provides a platform to gauge the state of the art for three fundamental language processing tasks dependency parse construction, coreference resolution, and ontology concept identification over full-text biomedical articles. The structural annotation task requires the automatic generation of dependency parses for each sentence of an article given only the article text. The coreference resolution task focuses on linking coreferring base noun phrase mentions into chains using the symmetrical and transitive identity relation. The ontology concept annotation task involves the identification of concept mentions within text using the classes of ten distinct ontologies in the biomedical domain, both unmodified and augmented with extension classes. This paper provides an overview of each <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, including descriptions of the data provided to participants and the evaluation metrics used, and discusses participant results relative to baseline performances for each of the three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5726.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5726 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5726 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5726/>UZH@CRAFT-ST : a Sequence-labeling Approach to Concept Recognition<span class=acl-fixed-case>UZH</span>@<span class=acl-fixed-case>CRAFT</span>-<span class=acl-fixed-case>ST</span>: a Sequence-labeling Approach to Concept Recognition</a></strong><br><a href=/people/l/lenz-furrer/>Lenz Furrer</a>
|
<a href=/people/j/joseph-cornelius/>Joseph Cornelius</a>
|
<a href=/people/f/fabio-rinaldi/>Fabio Rinaldi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5726><div class="card-body p-3 small">As our submission to the CRAFT shared task 2019, we present two neural approaches to concept recognition. We propose two different systems for joint named entity recognition (NER) and normalization (NEN), both of which model the task as a sequence labeling problem. Our first system is a BiLSTM network with two separate outputs for NER and NEN trained from scratch, whereas the second system is an instance of BioBERT fine-tuned on the concept-recognition task. We exploit two strategies for extending concept coverage, ontology pretraining and <a href=https://en.wikipedia.org/wiki/Backoff>backoff</a> with a dictionary lookup. Our results show that the backoff strategy effectively tackles the problem of unseen concepts, addressing a major limitation of the chosen <a href=https://en.wikipedia.org/wiki/Design>design</a>. In the cross-system comparison, BioBERT proves to be a strong basis for creating a concept-recognition system, although some entity types are predicted more accurately by the BiLSTM-based system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5728.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5728 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5728 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5728/>Neural Dependency Parsing of Biomedical Text : TurkuNLP entry in the CRAFT Structural Annotation Task<span class=acl-fixed-case>T</span>urku<span class=acl-fixed-case>NLP</span> entry in the <span class=acl-fixed-case>CRAFT</span> Structural Annotation Task</a></strong><br><a href=/people/t/thang-minh-ngo/>Thang Minh Ngo</a>
|
<a href=/people/j/jenna-kanerva/>Jenna Kanerva</a>
|
<a href=/people/f/filip-ginter/>Filip Ginter</a>
|
<a href=/people/s/sampo-pyysalo/>Sampo Pyysalo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5728><div class="card-body p-3 small">We present the approach taken by the TurkuNLP group in the CRAFT Structural Annotation task, a shared task on dependency parsing. Our approach builds primarily on the Turku neural parser, a native dependency parser that ranked among the best in the recent CoNLL tasks on parsing Universal Dependencies. To adapt the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> to the biomedical domain, we considered and evaluated a number of approaches, including the generation of custom word embeddings, combination with other in-domain resources, and the incorporation of information from <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>. We achieved a labeled attachment score of 89.7 %, the best result among task participants.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>