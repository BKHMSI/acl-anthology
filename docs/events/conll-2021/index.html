<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Conference on Computational Natural Language Learning (2021) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Conference on Computational Natural Language Learning (2021)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2021conll-1>Proceedings of the 25th Conference on Computational Natural Language Learning</a>
<span class="badge badge-info align-middle ml-1">21&nbsp;papers</span></li></ul></div></div><div id=2021conll-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2021.conll-1/>Proceedings of the 25th Conference on Computational Natural Language Learning</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.0/>Proceedings of the 25th Conference on Computational Natural Language Learning</a></strong><br><a href=/people/a/arianna-bisazza/>Arianna Bisazza</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.1/>It’s our fault ! : Insights Into Users’ Understanding and Interaction With an Explanatory Collaborative Dialog System</a></strong><br><a href=/people/k/katharina-weitz/>Katharina Weitz</a>
|
<a href=/people/l/lindsey-vanderlyn/>Lindsey Vanderlyn</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a>
|
<a href=/people/e/elisabeth-andre/>Elisabeth André</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--1><div class="card-body p-3 small">Human-AI collaboration, a long standing goal in <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI</a>, refers to a partnership where a human and artificial intelligence work together towards a shared goal. Collaborative dialog allows human-AI teams to communicate and leverage strengths from both partners. To design collaborative dialog systems, it is important to understand what mental models users form about their AI-dialog partners, however, how users perceive these <a href=https://en.wikipedia.org/wiki/System>systems</a> is not fully understood. In this study, we designed a novel, collaborative, communication-based puzzle game and explanatory dialog system. We created a public corpus from 117 conversations and post-surveys and used this to analyze what <a href=https://en.wikipedia.org/wiki/Mental_model>mental models</a> users formed. Key takeaways include : Even when users were not engaged in the <a href=https://en.wikipedia.org/wiki/Game>game</a>, they perceived the AI-dialog partner as intelligent and likeable, implying they saw it as a partner separate from the game. This was further supported by users often overestimating the <a href=https://en.wikipedia.org/wiki/System>system</a>&#8217;s abilities and projecting human-like attributes which led to miscommunications. We conclude that creating shared mental models between users and <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI systems</a> is important to achieving successful dialogs. We propose that our insights on mental models and miscommunication, the <a href=https://en.wikipedia.org/wiki/Game>game</a>, and our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> provide useful tools for designing collaborative dialog systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.conll-1.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.5/>On <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a> for Creoles</a></strong><br><a href=/people/h/heather-lent/>Heather Lent</a>
|
<a href=/people/e/emanuele-bugliarello/>Emanuele Bugliarello</a>
|
<a href=/people/m/miryam-de-lhoneux/>Miryam de Lhoneux</a>
|
<a href=/people/c/chen-qiu/>Chen Qiu</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--5><div class="card-body p-3 small">Creole languages such as <a href=https://en.wikipedia.org/wiki/Nigerian_Pidgin_English>Nigerian Pidgin English</a> and <a href=https://en.wikipedia.org/wiki/Haitian_Creole>Haitian Creole</a> are under-resourced and largely ignored in the NLP literature. Creoles typically result from the fusion of a foreign language with multiple local languages, and what grammatical and lexical features are transferred to the <a href=https://en.wikipedia.org/wiki/Creole_language>creole</a> is a complex process. While <a href=https://en.wikipedia.org/wiki/Creole_language>creoles</a> are generally stable, the prominence of some features may be much stronger with certain demographics or in some linguistic situations. This paper makes several contributions : We collect existing corpora and release models for <a href=https://en.wikipedia.org/wiki/Haitian_Creole>Haitian Creole</a>, <a href=https://en.wikipedia.org/wiki/Nigerian_Pidgin_English>Nigerian Pidgin English</a>, and <a href=https://en.wikipedia.org/wiki/Singaporean_English>Singaporean Colloquial English</a>. We evaluate these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on intrinsic and extrinsic tasks. Motivated by the above literature, we compare standard language models with distributionally robust ones and find that, somewhat surprisingly, the standard language models are superior to the distributionally robust ones. We investigate whether this is an effect of <a href=https://en.wikipedia.org/wiki/Parameterized_complexity>over-parameterization</a> or relative distributional stability, and find that the difference persists in the absence of <a href=https://en.wikipedia.org/wiki/Parameterized_complexity>over-parameterization</a>, and that drift is limited, confirming the relative stability of <a href=https://en.wikipedia.org/wiki/Creole_language>creole languages</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.11/>Enriching Language Models with Visually-grounded Word Vectors and the Lancaster Sensorimotor Norms<span class=acl-fixed-case>L</span>ancaster Sensorimotor Norms</a></strong><br><a href=/people/c/casey-kennington/>Casey Kennington</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--11><div class="card-body p-3 small">Language models are trained only on text despite the fact that humans learn their first language in a highly interactive and multimodal environment where the first set of learned words are largely concrete, denoting physical entities and embodied states. To enrich language models with some of this missing experience, we leverage two sources of information : (1) the Lancaster Sensorimotor norms, which provide ratings (means and standard deviations) for over 40,000 English words along several dimensions of embodiment, and which capture the extent to which something is experienced across 11 different sensory modalities, and (2) vectors from coefficients of binary classifiers trained on images for the BERT vocabulary. We pre-trained the ELECTRA model and fine-tuned the RoBERTa model with these two sources of information then evaluate using the established GLUE benchmark and the Visual Dialog benchmark. We find that enriching <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> with the Lancaster norms and image vectors improves results in both tasks, with some implications for robust <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> that capture holistic linguistic meaning in a language learning context.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.15/>Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction</a></strong><br><a href=/people/s/shauli-ravfogel/>Shauli Ravfogel</a>
|
<a href=/people/g/grusha-prasad/>Grusha Prasad</a>
|
<a href=/people/t/tal-linzen/>Tal Linzen</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--15><div class="card-body p-3 small">When language models process syntactically complex sentences, do they use their representations of syntax in a manner that is consistent with the grammar of the language? We propose AlterRep, an intervention-based method to address this question. For any linguistic feature of a given sentence, AlterRep generates counterfactual representations by altering how the <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>feature</a> is encoded, while leaving in- tact all other aspects of the original <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representation</a>. By measuring the change in a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>&#8217;s word prediction behavior when these counterfactual representations are substituted for the original ones, we can draw conclusions about the causal effect of the linguistic feature in question on the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>&#8217;s behavior. We apply this method to study how BERT models of different sizes process relative clauses (RCs). We find that BERT variants use RC boundary information during <a href=https://en.wikipedia.org/wiki/Word_prediction>word prediction</a> in a manner that is consistent with the rules of English grammar ; this RC boundary information generalizes to a considerable extent across different RC types, suggesting that BERT represents RCs as an abstract linguistic category.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.16/>Who’s on First? : Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains</a></strong><br><a href=/people/d/david-demeter/>David Demeter</a>
|
<a href=/people/d/doug-downey/>Doug Downey</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--16><div class="card-body p-3 small">The capabilities of today&#8217;s <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing systems</a> are typically evaluated using large datasets of curated questions and answers. While these are critical benchmarks of progress, they also suffer from weakness due to <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>artificial distributions</a> and <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>incomplete knowledge</a>. Artifacts arising from artificial distributions can overstate <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> performance, while incomplete knowledge limits fine-grained analysis. In this work, we introduce a complementary benchmarking approach based on SimPlified Language Activity Traces (SPLAT). SPLATs are corpora of language encodings of activity in some closed domain (we study traces from chess and baseball games in this work). SPLAT datasets use naturally-arising distributions, allow the generation of question-answer pairs at scale, and afford complete knowledge in their closed domains. We show that <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> of three different architectures can answer questions about <a href=https://en.wikipedia.org/wiki/State_(polity)>world states</a> using only verb-like encodings of activity. Our approach is extensible to new <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> and additional question-answering tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.17/>Data Augmentation of Incorporating Real Error Patterns and Linguistic Knowledge for Grammatical Error Correction</a></strong><br><a href=/people/x/xia-li/>Xia Li</a>
|
<a href=/people/j/junyi-he/>Junyi He</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--17><div class="card-body p-3 small">Data augmentation aims at expanding training data with clean text using noising schemes to improve the performance of <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>grammatical error correction (GEC)</a>. In practice, there are a great number of real error patterns in the manually annotated training data. We argue that these real error patterns can be introduced into clean text to effectively generate more real and high quality synthetic data, which is not fully explored by previous studies. Moreover, we also find that linguistic knowledge can be incorporated into <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> for generating more representative and more diverse <a href=https://en.wikipedia.org/wiki/Synthetic_data>synthetic data</a>. In this paper, we propose a novel data augmentation method that fully considers the real error patterns and the linguistic knowledge for the GEC task. We conduct extensive experiments on public data sets and the experimental results show that our method outperforms several strong baselines with far less external unlabeled clean text data, highlighting its extraordinary effectiveness in the GEC task that lacks large-scale labeled training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.conll-1.19" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.19/>A Multilingual Benchmark for Probing Negation-Awareness with Minimal Pairs</a></strong><br><a href=/people/m/mareike-hartmann/>Mareike Hartmann</a>
|
<a href=/people/m/miryam-de-lhoneux/>Miryam de Lhoneux</a>
|
<a href=/people/d/daniel-hershcovich/>Daniel Hershcovich</a>
|
<a href=/people/y/yova-kementchedjhieva/>Yova Kementchedjhieva</a>
|
<a href=/people/l/lukas-nielsen/>Lukas Nielsen</a>
|
<a href=/people/c/chen-qiu/>Chen Qiu</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--19><div class="card-body p-3 small">Negation is one of the most fundamental concepts in human cognition and language, and several natural language inference (NLI) probes have been designed to investigate pretrained language models&#8217; ability to detect and reason with <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a>. However, the existing probing datasets are limited to English only, and do not enable controlled probing of performance in the absence or presence of <a href=https://en.wikipedia.org/wiki/Negation>negation</a>. In response, we present a multilingual (English, Bulgarian, German, French and Chinese) benchmark collection of NLI examples that are grammatical and correctly labeled, as a result of manual inspection and reformulation. We use the benchmark to probe the negation-awareness of multilingual language models and find that models that correctly predict examples with negation cues, often fail to correctly predict their counter-examples without negation cues, even when the cues are irrelevant for semantic inference.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.conll-1.23" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.23/>A Coarse-to-Fine Labeling Framework for Joint Word Segmentation, POS Tagging, and Constituent Parsing<span class=acl-fixed-case>POS</span> Tagging, and Constituent Parsing</a></strong><br><a href=/people/y/yang-hou/>Yang Hou</a>
|
<a href=/people/h/houquan-zhou/>Houquan Zhou</a>
|
<a href=/people/z/zhenghua-li/>Zhenghua Li</a>
|
<a href=/people/y/yu-zhang/>Yu Zhang</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/z/zhefeng-wang/>Zhefeng Wang</a>
|
<a href=/people/b/baoxing-huai/>Baoxing Huai</a>
|
<a href=/people/n/nicholas-jing-yuan/>Nicholas Jing Yuan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--23><div class="card-body p-3 small">The most straightforward approach to joint word segmentation (WS), part-of-speech (POS) tagging, and constituent parsing is converting a word-level tree into a char-level tree, which, however, leads to two severe challenges. First, a larger label set (e.g., 600) and longer inputs both increase computational costs. Second, it is difficult to rule out illegal trees containing conflicting production rules, which is important for reliable model evaluation. If a POS tag (like VV) is above a phrase tag (like VP) in the output tree, it becomes quite complex to decide word boundaries. To deal with both challenges, this work proposes a two-stage coarse-to-fine labeling framework for joint WS-POS-PAR. In the coarse labeling stage, the joint model outputs a bracketed tree, in which each node corresponds to one of four labels (i.e., phrase, subphrase, word, subword). The <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>tree</a> is guaranteed to be legal via constrained CKY decoding. In the fine labeling stage, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> expands each coarse label into a final label (such as VP, VP *, VV, VV *). Experiments on Chinese Penn Treebank 5.1 and 7.0 show that our joint model consistently outperforms the <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline approach</a> on both settings of <a href=https://en.wikipedia.org/wiki/W/o>w/o</a> and <a href=https://en.wikipedia.org/wiki/BERT>w/ BERT</a>, and achieves new state-of-the-art performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.24/>Understanding the Extent to which Content Quality Metrics Measure the Information Quality of Summaries</a></strong><br><a href=/people/d/daniel-deutsch/>Daniel Deutsch</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--24><div class="card-body p-3 small">Reference-based metrics such as <a href=https://en.wikipedia.org/wiki/ROUGE_(metric)>ROUGE</a> or BERTScore evaluate the content quality of a summary by comparing the summary to a reference. Ideally, this comparison should measure the summary&#8217;s information quality by calculating how much information the summaries have in common. In this work, we analyze the token alignments used by ROUGE and BERTScore to compare summaries and argue that their scores largely can not be interpreted as measuring information overlap. Rather, they are better estimates of the extent to which the summaries discuss the same topics. Further, we provide evidence that this result holds true for many other summarization evaluation metrics. The consequence of this result is that the most frequently used summarization evaluation metrics do not align with the community&#8217;s research goal, to generate summaries with high-quality information. However, we conclude by demonstrating that a recently proposed <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, QAEval, which scores summaries using <a href=https://en.wikipedia.org/wiki/Question_answering>question-answering</a>, appears to better capture <a href=https://en.wikipedia.org/wiki/Information_quality>information quality</a> than current evaluations, highlighting a direction for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.conll-1.25" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.25/>Summary-Source Proposition-level Alignment : Task, Datasets and Supervised Baseline</a></strong><br><a href=/people/o/ori-ernst/>Ori Ernst</a>
|
<a href=/people/o/ori-shapira/>Ori Shapira</a>
|
<a href=/people/r/ramakanth-pasunuru/>Ramakanth Pasunuru</a>
|
<a href=/people/m/michael-lepioshkin/>Michael Lepioshkin</a>
|
<a href=/people/j/jacob-goldberger/>Jacob Goldberger</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--25><div class="card-body p-3 small">Aligning sentences in a reference summary with their counterparts in source documents was shown as a useful auxiliary summarization task, notably for generating training data for <a href=https://en.wikipedia.org/wiki/Salience_(neuroscience)>salience detection</a>. Despite its assessed utility, the alignment step was mostly approached with heuristic unsupervised methods, typically ROUGE-based, and was never independently optimized or evaluated. In this paper, we propose establishing summary-source alignment as an explicit task, while introducing two major novelties : (1) applying it at the more accurate proposition span level, and (2) approaching it as a supervised classification task. To that end, we created a novel <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training dataset</a> for proposition-level alignment, derived automatically from available summarization evaluation data. In addition, we crowdsourced dev and test datasets, enabling model development and proper evaluation. Utilizing these data, we present a supervised proposition alignment baseline model, showing improved alignment-quality over the unsupervised approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.27/>Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning</a></strong><br><a href=/people/c/christos-theodoropoulos/>Christos Theodoropoulos</a>
|
<a href=/people/j/james-henderson/>James Henderson</a>
|
<a href=/people/a/andrei-catalin-coman/>Andrei Catalin Coman</a>
|
<a href=/people/m/marie-francine-moens/>Marie-Francine Moens</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--27><div class="card-body p-3 small">Though language model text embeddings have revolutionized NLP research, their ability to capture high-level semantic information, such as relations between entities in text, is limited. In this paper, we propose a novel contrastive learning framework that trains <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a> to encode the relations in a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a>. Given a sentence (unstructured text) and its <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>, we use contrastive learning to impose relation-related structure on the token level representations of the sentence obtained with a CharacterBERT (El Boukkouri et al., 2020) model. The resulting relation-aware sentence embeddings achieve state-of-the-art results on the relation extraction task using only a simple KNN classifier, thereby demonstrating the success of the proposed method. Additional visualization by a tSNE analysis shows the effectiveness of the learned <a href=https://en.wikipedia.org/wiki/Representation_space>representation space</a> compared to baselines. Furthermore, we show that we can learn a different space for <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, again using a contrastive learning objective, and demonstrate how to successfully combine both representation spaces in an entity-relation task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.29.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--29 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.29 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.29/>Pragmatic competence of pre-trained language models through the lens of discourse connectives</a></strong><br><a href=/people/l/lalchand-pandia/>Lalchand Pandia</a>
|
<a href=/people/y/yan-cong/>Yan Cong</a>
|
<a href=/people/a/allyson-ettinger/>Allyson Ettinger</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--29><div class="card-body p-3 small">As pre-trained language models (LMs) continue to dominate <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, it is increasingly important that we understand the depth of language capabilities in these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. In this paper, we target pre-trained LMs&#8217; competence in <a href=https://en.wikipedia.org/wiki/Pragmatics>pragmatics</a>, with a focus on <a href=https://en.wikipedia.org/wiki/Pragmatics>pragmatics</a> relating to discourse connectives. We formulate cloze-style tests using a combination of naturally-occurring data and controlled inputs drawn from <a href=https://en.wikipedia.org/wiki/Psycholinguistics>psycholinguistics</a>. We focus on testing <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>&#8217; ability to use pragmatic cues to predict discourse connectives, <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>&#8217; ability to understand implicatures relating to connectives, and the extent to which <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> show humanlike preferences regarding temporal dynamics of connectives. We find that although models predict connectives reasonably well in the context of naturally-occurring data, when we control contexts to isolate high-level pragmatic cues, model sensitivity is much lower. Models also do not show substantial humanlike temporal preferences. Overall, the findings suggest that at present, dominant pre-training paradigms do not result in substantial pragmatic competence in our models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.32/>Scaffolded input promotes atomic organization in the recurrent neural network language model</a></strong><br><a href=/people/p/philip-a-huebner/>Philip A. Huebner</a>
|
<a href=/people/j/jon-a-willits/>Jon A. Willits</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--32><div class="card-body p-3 small">The recurrent neural network (RNN) language model is a powerful tool for learning arbitrary sequential dependencies in language data. Despite its enormous success in representing <a href=https://en.wikipedia.org/wiki/Lexical_item>lexical sequences</a>, little is known about the quality of the <a href=https://en.wikipedia.org/wiki/Lexical_item>lexical representations</a> that it acquires. In this work, we conjecture that it is straightforward to extract <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical representations</a> (i.e. static word embeddings) from an RNN, but that the amount of semantic information that is encoded is limited when lexical items in the training data provide redundant semantic information. We conceptualize this limitation of the RNN as a failure to learn atomic internal states-states which capture information relevant to single word types without being influenced by redundant information provided by words with which they co-occur. Using a corpus of artificial language, we verify that redundancy in the training data yields non-atomic internal states, and propose a novel method for inducing atomic internal states. We show that 1) our method successfully induces atomic internal organization in controlled experiments, and 2) under more realistic conditions in which the training consists of child-directed language, application of our method improves the performance of lexical representations on a downstream semantic categorization task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.35.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--35 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.35 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.35/>Relation-aware Bidirectional Path Reasoning for Commonsense Question Answering</a></strong><br><a href=/people/j/junxing-wang/>Junxing Wang</a>
|
<a href=/people/x/xinyi-li/>Xinyi Li</a>
|
<a href=/people/z/zhen-tan/>Zhen Tan</a>
|
<a href=/people/x/xiang-zhao/>Xiang Zhao</a>
|
<a href=/people/w/weidong-xiao/>Weidong Xiao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--35><div class="card-body p-3 small">Commonsense Question Answering is an important natural language processing (NLP) task that aims to predict the correct answer to a question through <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a>. Previous studies utilize pre-trained models on large-scale corpora such as BERT, or perform <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a> on <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a>. However, these methods do not explicitly model the <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> that connect entities, which are informational and can be used to enhance <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a>. To address this issue, we propose a relation-aware reasoning method. Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources. The enhanced representations of relations are then fed to a bidirectional reasoning module. A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability. Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.<i>relations</i> that connect entities, which are informational and can be used to enhance reasoning. To address this issue, we propose a relation-aware reasoning method. Our method uses a relation-aware graph neural network to capture the rich contextual information from both entities and relations. Compared with methods that use fixed relation embeddings from pre-trained models, our model dynamically updates relations with contextual information from a multi-source subgraph, built from multiple external knowledge sources. The enhanced representations of relations are then fed to a bidirectional reasoning module. A bidirectional attention mechanism is applied between the question sequence and the paths that connect entities, which provides us with transparent interpretability. Experimental results on the CommonsenseQA dataset illustrate that our method results in significant improvements over the baselines while also providing clear reasoning paths.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.38.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--38 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.38 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.38/>Commonsense Knowledge in <a href=https://en.wikipedia.org/wiki/Word_association>Word Associations</a> and ConceptNet<span class=acl-fixed-case>C</span>oncept<span class=acl-fixed-case>N</span>et</a></strong><br><a href=/people/c/chunhua-liu/>Chunhua Liu</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a>
|
<a href=/people/l/lea-frermann/>Lea Frermann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--38><div class="card-body p-3 small">Humans use countless basic, shared facts about the world to efficiently navigate in their environment. This <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> is rarely communicated explicitly, however, understanding how <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> is represented in different paradigms is important for (a) a deeper understanding of human cognition and (b) augmenting automatic reasoning systems. This paper presents an in-depth comparison of two large-scale resources of general knowledge : <a href=https://en.wikipedia.org/wiki/ConceptNet>ConceptNet</a>, an engineered relational database, and SWOW, a <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a> derived from crowd-sourced word associations. We examine the structure, overlap and differences between the two <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a>, as well as the extent of situational commonsense knowledge present in the two <a href=https://en.wikipedia.org/wiki/Factors_of_production>resources</a>. We finally show empirically that both resources improve downstream task performance on commonsense reasoning benchmarks over text-only baselines, suggesting that large-scale word association data, which have been obtained for several languages through crowd-sourcing, can be a valuable complement to curated knowledge graphs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.39.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--39 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.39 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.conll-1.39" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.39/>Cross-document Event Identity via Dense Annotation</a></strong><br><a href=/people/a/adithya-pratapa/>Adithya Pratapa</a>
|
<a href=/people/z/zhengzhong-liu/>Zhengzhong Liu</a>
|
<a href=/people/k/kimihiro-hasegawa/>Kimihiro Hasegawa</a>
|
<a href=/people/l/linwei-li/>Linwei Li</a>
|
<a href=/people/y/yukari-yamakawa/>Yukari Yamakawa</a>
|
<a href=/people/s/shikun-zhang/>Shikun Zhang</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--39><div class="card-body p-3 small">In this paper, we study the identity of textual events from different documents. While the complex nature of event identity is previously studied (Hovy et al., 2013), the case of events across documents is unclear. Prior work on cross-document event coreference has two main drawbacks. First, they restrict the <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> to a limited set of event types. Second, they insufficiently tackle the concept of event identity. Such annotation setup reduces the pool of event mentions and prevents one from considering the possibility of quasi-identity relations. We propose a dense annotation approach for cross-document event coreference, comprising a rich source of event mentions and a dense annotation effort between related document pairs. To this end, we design a new annotation workflow with careful quality control and an easy-to-use annotation interface. In addition to the links, we further collect overlapping event contexts, including time, location, and participants, to shed some light on the relation between <a href=https://en.wikipedia.org/wiki/Identity_(social_science)>identity decisions</a> and context. We present an open-access dataset for cross-document event coreference, CDEC-WN, collected from English Wikinews and open-source our annotation toolkit to encourage further research on cross-document tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.41.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--41 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.41 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.conll-1.41" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.41/>Negation-Instance Based Evaluation of End-to-End Negation Resolution</a></strong><br><a href=/people/e/elizaveta-sineva/>Elizaveta Sineva</a>
|
<a href=/people/s/stefan-grunewald/>Stefan Grünewald</a>
|
<a href=/people/a/annemarie-friedrich/>Annemarie Friedrich</a>
|
<a href=/people/j/jonas-kuhn/>Jonas Kuhn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--41><div class="card-body p-3 small">In this paper, we revisit the task of negation resolution, which includes the subtasks of cue detection (e.g. not, never) and scope resolution. In the context of previous shared tasks, a variety of evaluation metrics have been proposed. Subsequent works usually use different subsets of these, including variations and custom implementations, rendering meaningful comparisons between systems difficult. Examining the problem both from a linguistic perspective and from a downstream viewpoint, we here argue for a negation-instance based approach to evaluating negation resolution. Our proposed <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> correspond to expectations over per-instance scores and hence are intuitively interpretable. To render research comparable and to foster future work, we provide results for a set of current state-of-the-art systems for negation resolution on three English corpora, and make our implementation of the evaluation scripts publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.42.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--42 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.42 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.42/>Controlling Prosody in End-to-End TTS : A Case Study on Contrastive Focus Generation<span class=acl-fixed-case>TTS</span>: A Case Study on Contrastive Focus Generation</a></strong><br><a href=/people/s/siddique-latif/>Siddique Latif</a>
|
<a href=/people/i/inyoung-kim/>Inyoung Kim</a>
|
<a href=/people/i/ioan-calapodescu/>Ioan Calapodescu</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--42><div class="card-body p-3 small">While End-2-End Text-to-Speech (TTS) has made significant progresses over the past few years, these systems still lack intuitive user controls over <a href=https://en.wikipedia.org/wiki/Prosody_(linguistics)>prosody</a>. For instance, generating <a href=https://en.wikipedia.org/wiki/Speech>speech</a> with fine-grained prosody control (prosodic prominence, contextually appropriate emotions) is still an open challenge. In this paper, we investigate whether we can control <a href=https://en.wikipedia.org/wiki/Prosody_(linguistics)>prosody</a> directly from the input text, in order to code information related to contrastive focus which emphasizes a specific word that is contrary to the presuppositions of the interlocutor. We build and share a specific <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for this purpose and show that it allows to train a TTS system were this fine-grained prosodic feature can be correctly conveyed using control tokens. Our evaluation compares synthetic and natural utterances and shows that prosodic patterns of contrastive focus (variations of Fo, Intensity and Duration) can be learnt accurately. Such a milestone is important to allow, for example, <a href=https://en.wikipedia.org/wiki/Smart_speaker>smart speakers</a> to be programmatically controlled in terms of output prosody.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.43.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--43 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.43 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.conll-1.43" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.43/>A Large-scale Comprehensive Abusiveness Detection Dataset with Multifaceted Labels from Reddit<span class=acl-fixed-case>R</span>eddit</a></strong><br><a href=/people/h/hoyun-song/>Hoyun Song</a>
|
<a href=/people/s/soo-hyun-ryu/>Soo Hyun Ryu</a>
|
<a href=/people/h/huije-lee/>Huije Lee</a>
|
<a href=/people/j/jong-c-park/>Jong Park</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--43><div class="card-body p-3 small">As users in <a href=https://en.wikipedia.org/wiki/Online_community>online communities</a> suffer from severe side effects of <a href=https://en.wikipedia.org/wiki/Abuse>abusive language</a>, many researchers attempted to detect abusive texts from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, presenting several <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> for such detection. However, none of them contain both comprehensive labels and contextual information, which are essential for thoroughly detecting all kinds of abusiveness from texts, since datasets with such fine-grained features demand a significant amount of <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a>, leading to much increased <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a>. In this paper, we propose a Comprehensive Abusiveness Detection Dataset (CADD), collected from the English Reddit posts, with multifaceted labels and contexts. Our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is annotated hierarchically for an efficient <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> through <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> on a large-scale. We also empirically explore the characteristics of our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and provide a detailed analysis for novel insights. The results of our experiments with strong pre-trained natural language understanding models on our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> show that our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> gives rise to meaningful performance, assuring its practicality for abusive language detection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.conll-1.51.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--conll-1--51 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.conll-1.51 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.conll-1.51/>Predicting non-native speech perception using the Perceptual Assimilation Model and state-of-the-art acoustic models</a></strong><br><a href=/people/j/juliette-millet/>Juliette Millet</a>
|
<a href=/people/i/ioana-chitoran/>Ioana Chitoran</a>
|
<a href=/people/e/ewan-dunbar/>Ewan Dunbar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--conll-1--51><div class="card-body p-3 small">Our <a href=https://en.wikipedia.org/wiki/First_language>native language</a> influences the way we perceive <a href=https://en.wikipedia.org/wiki/Phone_(phonetics)>speech sounds</a>, affecting our ability to discriminate non-native sounds. We compare two ideas about the influence of the <a href=https://en.wikipedia.org/wiki/First_language>native language</a> on <a href=https://en.wikipedia.org/wiki/Speech_perception>speech perception</a> : the Perceptual Assimilation Model, which appeals to a mental classification of sounds into native phoneme categories, versus the idea that rich, fine-grained phonetic representations tuned to the statistics of the native language, are sufficient. We operationalise this idea using representations from two state-of-the-art speech models, a Dirichlet process Gaussian mixture model and the more recent wav2vec 2.0 model. We present a new, open dataset of French- and English-speaking participants&#8217; speech perception behaviour for 61 vowel sounds from six languages. We show that phoneme assimilation is a better predictor than fine-grained phonetic modelling, both for the discrimination behaviour as a whole, and for predicting differences in discriminability associated with differences in native language background. We also show that wav2vec 2.0, while not good at capturing the effects of <a href=https://en.wikipedia.org/wiki/First_language>native language</a> on <a href=https://en.wikipedia.org/wiki/Speech_perception>speech perception</a>, is complementary to information about native phoneme assimilation, and provides a good model of low-level phonetic representations, supporting the idea that both categorical and fine-grained perception are used during <a href=https://en.wikipedia.org/wiki/Speech_perception>speech perception</a>.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>