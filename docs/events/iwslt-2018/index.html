<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>International Conference on Spoken Language Translation (2018) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>International Conference on Spoken Language Translation (2018)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2018iwslt-1>Proceedings of the 15th International Conference on Spoken Language Translation</a>
<span class="badge badge-info align-middle ml-1">12&nbsp;papers</span></li></ul></div></div><div id=2018iwslt-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2018.iwslt-1/>Proceedings of the 15th International Conference on Spoken Language Translation</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.0/>Proceedings of the 15th International Conference on Spoken Language Translation</a></strong><br><a href=/people/m/marco-turchi/>Marco Turchi</a>
|
<a href=/people/j/jan-niehues/>Jan Niehues</a>
|
<a href=/people/m/marcello-frederico/>Marcello Frederico</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.2/>Unsupervised Parallel Sentence Extraction from Comparable Corpora</a></strong><br><a href=/people/v/viktor-hangya/>Viktor Hangya</a>
|
<a href=/people/f/fabienne-braune/>Fabienne Braune</a>
|
<a href=/people/y/yuliya-kalasouskaya/>Yuliya Kalasouskaya</a>
|
<a href=/people/a/alexander-fraser/>Alexander Fraser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--2><div class="card-body p-3 small">Mining parallel sentences from comparable corpora is of great interest for many downstream tasks. In the BUCC 2017 shared task, <a href=https://en.wikipedia.org/wiki/System>systems</a> performed well by training on gold standard parallel sentences. However, we often want to mine <a href=https://en.wikipedia.org/wiki/Parallelism_(grammar)>parallel sentences</a> without bilingual supervision. We present a simple approach relying on bilingual word embeddings trained in an unsupervised fashion. We incorporate orthographic similarity in order to handle words with similar surface forms. In addition, we propose a dynamic threshold method to decide if a candidate sentence-pair is parallel which eliminates the need to fine tune a static value for different datasets. Since we do not employ any language specific engineering our approach is highly generic. We show that our approach is effective, on three language-pairs, without the use of any bilingual signal which is important because parallel sentence mining is most useful in low resource scenarios.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.4/>Analyzing Knowledge Distillation in Neural Machine Translation</a></strong><br><a href=/people/d/dakun-zhang/>Dakun Zhang</a>
|
<a href=/people/j/josep-m-crego/>Josep Crego</a>
|
<a href=/people/j/jean-senellart/>Jean Senellart</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--4><div class="card-body p-3 small">Knowledge distillation has recently been successfully applied to <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. It allows for building shrunk networks while the resulting <a href=https://en.wikipedia.org/wiki/System>systems</a> retain most of the quality of the original <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. Despite the fact that many authors report on the benefits of knowledge distillation, few have discussed the actual reasons why it works, especially in the context of neural MT. In this paper, we conduct several experiments aimed at understanding why and how <a href=https://en.wikipedia.org/wiki/Distillation>distillation</a> impacts <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on an English-German translation task. We show that translation complexity is actually reduced when building a distilled / synthesised bi-text when compared to the reference bi-text. We further remove noisy data from synthesised translations and merge filtered synthesised data together with original reference, thus achieving additional gains in terms of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Best Student Paper"><i class="fas fa-award"></i></span></span>
<span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.7/>Multi-Source Neural Machine Translation with Data Augmentation</a></strong><br><a href=/people/y/yuta-nishimura/>Yuta Nishimura</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--7><div class="card-body p-3 small">Multi-source translation systems translate from multiple languages to a single target language. By using information from these multiple sources, these <a href=https://en.wikipedia.org/wiki/System>systems</a> achieve large gains in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. To train these systems, it is necessary to have corpora with parallel text in multiple sources and the target language. However, these <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> are rarely complete in practice due to the difficulty of providing human translations in all of the relevant languages. In this paper, we propose a data augmentation approach to fill such incomplete parts using multi-source neural machine translation (NMT). In our experiments, results varied over different language combinations but significant gains were observed when using a source language similar to the target language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.10/>The USTC-NEL Speech Translation system at IWSLT 2018<span class=acl-fixed-case>USTC</span>-<span class=acl-fixed-case>NEL</span> Speech Translation system at <span class=acl-fixed-case>IWSLT</span> 2018</a></strong><br><a href=/people/d/dan-liu/>Dan Liu</a>
|
<a href=/people/j/junhua-liu/>Junhua Liu</a>
|
<a href=/people/w/wu-guo/>Wu Guo</a>
|
<a href=/people/s/shifu-xiong/>Shifu Xiong</a>
|
<a href=/people/z/zhiqiang-ma/>Zhiqiang Ma</a>
|
<a href=/people/r/rui-song/>Rui Song</a>
|
<a href=/people/c/chongliang-wu/>Chongliang Wu</a>
|
<a href=/people/q/quan-liu/>Quan Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--10><div class="card-body p-3 small">This paper describes the USTC-NEL (short for National Engineering Laboratory for Speech and Language Information Processing University of science and technology of china) system to the speech translation task of the IWSLT Evaluation 2018. The system is a conventional <a href=https://en.wikipedia.org/wiki/Pipeline_(computing)>pipeline system</a> which contains 3 modules : <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a>, <a href=https://en.wikipedia.org/wiki/Video_post-processing>post-processing</a> and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. We train a group of hybrid-HMM models for our <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a>, and for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> we train transformer based neural machine translation models with speech recognition output style text as input. Experiments conducted on the IWSLT 2018 task indicate that, compared to baseline system from KIT, our <a href=https://en.wikipedia.org/wiki/System>system</a> achieved 14.9 BLEU improvement.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.11/>The ADAPT System Description for the IWSLT 2018 Basque to English Translation Task<span class=acl-fixed-case>ADAPT</span> System Description for the <span class=acl-fixed-case>IWSLT</span> 2018 <span class=acl-fixed-case>B</span>asque to <span class=acl-fixed-case>E</span>nglish Translation Task</a></strong><br><a href=/people/a/alberto-poncelas/>Alberto Poncelas</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/k/kepa-sarasola/>Kepa Sarasola</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--11><div class="card-body p-3 small">In this paper we present the ADAPT system built for the Basque to English Low Resource MT Evaluation Campaign. Basque is a low-resourced, morphologically-rich language. This poses a challenge for Neural Machine Translation models which usually achieve better performance when trained with large sets of data. Accordingly, we used <a href=https://en.wikipedia.org/wiki/Synthetic_data>synthetic data</a> to improve the translation quality produced by a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> built using only authentic data. Our proposal uses back-translated data to : (a) create new sentences, so the system can be trained with more data ; and (b) translate sentences that are close to the test set, so the model can be fine-tuned to the document to be translated.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.13/>The MeMAD Submission to the IWSLT 2018 Speech Translation Task<span class=acl-fixed-case>M</span>e<span class=acl-fixed-case>MAD</span> Submission to the <span class=acl-fixed-case>IWSLT</span> 2018 Speech Translation Task</a></strong><br><a href=/people/u/umut-sulubacak/>Umut Sulubacak</a>
|
<a href=/people/j/jorg-tiedemann/>Jörg Tiedemann</a>
|
<a href=/people/a/aku-rouhe/>Aku Rouhe</a>
|
<a href=/people/s/stig-arnegronroos/>Stig-ArneGrönroos</a>
|
<a href=/people/m/mikko-kurimo/>Mikko Kurimo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--13><div class="card-body p-3 small">This paper describes the MeMAD project entry to the IWSLT Speech Translation Shared Task, addressing the translation of English audio into German text. Between the <a href=https://en.wikipedia.org/wiki/Pipeline_(computing)>pipeline</a> and end-to-end model tracks, we participated only in the former, with three contrastive systems. We tried also the latter, but were not able to finish our end-to-end model in time. All of our systems start by transcribing the audio into text through an automatic speech recognition (ASR) model trained on the TED-LIUM English Speech Recognition Corpus (TED-LIUM). Afterwards, we feed the transcripts into English-German text-based neural machine translation (NMT) models. Our systems employ three different translation models trained on separate training sets compiled from the English-German part of the TED Speech Translation Corpus (TED-TRANS) and the OPENSUBTITLES2018 section of the OPUS collection. In this paper, we also describe the experiments leading up to our final <a href=https://en.wikipedia.org/wiki/Thermodynamic_system>systems</a>. Our experiments indicate that using OPENSUBTITLES2018 in training significantly improves <a href=https://en.wikipedia.org/wiki/Translation_(biology)>translation</a> performance. We also experimented with various preand postprocessing routines for the NMT module, but we did not have much success with these. Our best-scoring system attains a BLEU score of 16.45 on the test set for this year&#8217;s task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.17/>Samsung and University of Edinburgh’s System for the IWSLT 2018 Low Resource MT Task<span class=acl-fixed-case>S</span>amsung and <span class=acl-fixed-case>U</span>niversity of <span class=acl-fixed-case>E</span>dinburgh’s System for the <span class=acl-fixed-case>IWSLT</span> 2018 Low Resource <span class=acl-fixed-case>MT</span> Task</a></strong><br><a href=/people/p/philip-williams/>Philip Williams</a>
|
<a href=/people/m/marcin-chochowski/>Marcin Chochowski</a>
|
<a href=/people/p/pawel-przybysz/>Pawel Przybysz</a>
|
<a href=/people/r/rico-sennrich/>Rico Sennrich</a>
|
<a href=/people/b/barry-haddow/>Barry Haddow</a>
|
<a href=/people/a/alexandra-birch/>Alexandra Birch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--17><div class="card-body p-3 small">This paper describes the joint submission to the IWSLT 2018 Low Resource MT task by Samsung R&D Institute, Poland, and the University of Edinburgh. We focused on supplementing the very limited in-domain Basque-English training data with out-of-domain data, with <a href=https://en.wikipedia.org/wiki/Synthetic_data>synthetic data</a>, and with data for other language pairs. We also experimented with a variety of model architectures and features, which included the development of extensions to the Nematus toolkit. Our submission was ultimately produced by a system combination in which we reranked translations from our strongest individual system using multiple weaker systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.18/>The AFRL IWSLT 2018 Systems : What Worked, What Did n’t<span class=acl-fixed-case>AFRL</span> <span class=acl-fixed-case>IWSLT</span> 2018 Systems: What Worked, What Didn’t</a></strong><br><a href=/people/b/brian-ore/>Brian Ore</a>
|
<a href=/people/e/eric-hansen/>Eric Hansen</a>
|
<a href=/people/k/katherine-young/>Katherine Young</a>
|
<a href=/people/g/grant-erdmann/>Grant Erdmann</a>
|
<a href=/people/j/jeremy-gwinnup/>Jeremy Gwinnup</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--18><div class="card-body p-3 small">This report summarizes the Air Force Research Laboratory (AFRL) machine translation (MT) and automatic speech recognition (ASR) systems submitted to the spoken language translation (SLT) and low-resource MT tasks as part of the IWSLT18 evaluation campaign.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.21/>CUNI Basque-to-English Submission in IWSLT18<span class=acl-fixed-case>CUNI</span> <span class=acl-fixed-case>B</span>asque-to-<span class=acl-fixed-case>E</span>nglish Submission in <span class=acl-fixed-case>IWSLT</span>18</a></strong><br><a href=/people/t/tom-kocmi/>Tom Kocmi</a>
|
<a href=/people/d/dusan-varis/>Dušan Variš</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--21><div class="card-body p-3 small">We present our submission to the IWSLT18 Low Resource task focused on the translation from Basque-to-English. Our submission is based on the current state-of-the-art self-attentive neural network architecture, Transformer. We further improve this strong <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> by exploiting available <a href=https://en.wikipedia.org/wiki/Monolingualism>monolingual data</a> using the back-translation technique. We also present further improvements gained by a <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, a technique that trains a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> using a high-resource language pair (Czech-English) and then fine-tunes the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> using the target low-resource language pair (Basque-English).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.26/>Data Selection with Feature Decay Algorithms Using an Approximated Target Side</a></strong><br><a href=/people/a/alberto-poncelas/>Alberto Poncelas</a>
|
<a href=/people/g/gideon-maillette-de-buy-wenniger/>Gideon Maillette de Buy Wenniger</a>
|
<a href=/people/a/andy-way/>Andy Way</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--26><div class="card-body p-3 small">Data selection techniques applied to neural machine translation (NMT) aim to increase the performance of a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> by retrieving a subset of sentences for use as training data. One of the possible data selection techniques are <a href=https://en.wikipedia.org/wiki/Transduction_(machine_learning)>transductive learning methods</a>, which select the data based on the test set, i.e. the document to be translated. A limitation of these methods to date is that using the source-side test set does not by itself guarantee that sentences are selected with correct translations, or translations that are suitable given the test-set domain. Some <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a>, such as subtitle corpora, may contain parallel sentences with inaccurate translations caused by <a href=https://en.wikipedia.org/wiki/Internationalization_and_localization>localization</a> or length restrictions. In order to try to fix this problem, in this paper we propose to use an approximated target-side in addition to the source-side when selecting suitable sentence-pairs for training a model. This approximated target-side is built by pre-translating the source-side. In this work, we explore the performance of this general idea for one specific data selection approach called Feature Decay Algorithms (FDA). We train German-English NMT models on data selected by using the test set (source), the approximated target side, and a mixture of both. Our findings reveal that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> built using a combination of outputs of <a href=https://en.wikipedia.org/wiki/Food_and_Drug_Administration>FDA</a> (using the <a href=https://en.wikipedia.org/wiki/Test_set>test set</a> and an approximated target side) perform better than those solely using the <a href=https://en.wikipedia.org/wiki/Test_set>test set</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2018.iwslt-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2018--iwslt-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2018.iwslt-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2018.iwslt-1.27/>Multi-paraphrase Augmentation to Leverage Neural Caption Translation</a></strong><br><a href=/people/j/johanes-effendi/>Johanes Effendi</a>
|
<a href=/people/s/sakriani-sakti/>Sakriani Sakti</a>
|
<a href=/people/k/katsuhito-sudoh/>Katsuhito Sudoh</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2018--iwslt-1--27><div class="card-body p-3 small">Paraphrasing has been proven to improve translation quality in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT)</a> and has been widely studied alongside with the development of <a href=https://en.wikipedia.org/wiki/Statistical_machine_translation>statistical MT (SMT)</a>. In this paper, we investigate and utilize neural paraphrasing to improve <a href=https://en.wikipedia.org/wiki/Translation_(biology)>translation quality</a> in neural MT (NMT), which has not yet been much explored. Our first contribution is to propose a new way of creating a multi-paraphrase corpus through visual description. After that, we also proposed to construct neural paraphrase models which initiate expert models and utilize them to leverage NMT. Here, we diffuse the image information by using image-based paraphrasing without using the image itself. Our proposed image-based multi-paraphrase augmentation strategies showed improvement against a vanilla NMT baseline.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>