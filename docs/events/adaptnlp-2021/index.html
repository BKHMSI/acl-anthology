<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Workshop on Domain Adaptation for NLP (2021) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Workshop on Domain Adaptation for NLP (2021)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2021adaptnlp-1>Proceedings of the Second Workshop on Domain Adaptation for NLP</a>
<span class="badge badge-info align-middle ml-1">11&nbsp;papers</span></li></ul></div></div><div id=2021adaptnlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2021.adaptnlp-1/>Proceedings of the Second Workshop on Domain Adaptation for NLP</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.0/>Proceedings of the Second Workshop on Domain Adaptation for NLP</a></strong><br><a href=/people/e/eyal-ben-david/>Eyal Ben-David</a>
|
<a href=/people/s/shay-b-cohen/>Shay Cohen</a>
|
<a href=/people/r/ryan-mcdonald/>Ryan McDonald</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a>
|
<a href=/people/r/roi-reichart/>Roi Reichart</a>
|
<a href=/people/g/guy-rotman/>Guy Rotman</a>
|
<a href=/people/y/yftah-ziser/>Yftah Ziser</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.adaptnlp-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.6/>Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data<span class=acl-fixed-case>F</span>risian-<span class=acl-fixed-case>D</span>utch Data</a></strong><br><a href=/people/a/anouck-braggaar/>Anouck Braggaar</a>
|
<a href=/people/r/rob-van-der-goot/>Rob van der Goot</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--6><div class="card-body p-3 small">While high performance have been obtained for high-resource languages, performance on low-resource languages lags behind. In this paper we focus on the <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> of the low-resource language Frisian. We use a sample of code-switched, spontaneously spoken data, which proves to be a challenging setup. We propose to train a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> specifically tailored towards the target domain, by selecting instances from multiple <a href=https://en.wikipedia.org/wiki/Treebank>treebanks</a>. Specifically, we use Latent Dirichlet Allocation (LDA), with word and character N-grams. We use a deep biaffine parser initialized with mBERT. The best single source treebank (nl_alpino) resulted in an <a href=https://en.wikipedia.org/wiki/Greatest_common_divisor>LAS</a> of 54.7 whereas our data selection outperformed the single best transfer treebank and led to 55.6 <a href=https://en.wikipedia.org/wiki/Greatest_common_divisor>LAS</a> on the test data. Additional experiments consisted of removing <a href=https://en.wikipedia.org/wiki/Diacritic>diacritics</a> from our Frisian data, creating more similar training data by cropping sentences and running our best <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> using XLM-R. These experiments did not lead to a better performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.9/>Addressing Zero-Resource Domains Using Document-Level Context in Neural Machine Translation</a></strong><br><a href=/people/d/dario-stojanovski/>Dario Stojanovski</a>
|
<a href=/people/a/alexander-fraser/>Alexander Fraser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--9><div class="card-body p-3 small">Achieving satisfying performance in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> on domains for which there is no training data is challenging. Traditional supervised domain adaptation is not suitable for addressing such zero-resource domains because it relies on in-domain parallel data. We show that when in-domain parallel data is not available, access to document-level context enables better capturing of domain generalities compared to only having access to a single sentence. Having access to more information provides a more reliable domain estimation. We present two document-level Transformer models which are capable of using large context sizes and we compare these <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a> against strong Transformer baselines. We obtain improvements for the two zero-resource domains we study. We additionally provide an analysis where we vary the amount of context and look at the case where in-domain data is available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.12/>BERTologiCoMix : How does Code-Mixing interact with Multilingual BERT?<span class=acl-fixed-case>BERT</span>ologi<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>M</span>ix: How does Code-Mixing interact with Multilingual <span class=acl-fixed-case>BERT</span>?</a></strong><br><a href=/people/s/sebastin-santy/>Sebastin Santy</a>
|
<a href=/people/a/anirudh-srinivasan/>Anirudh Srinivasan</a>
|
<a href=/people/m/monojit-choudhury/>Monojit Choudhury</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--12><div class="card-body p-3 small">Models such as mBERT and XLMR have shown success in solving Code-Mixed NLP tasks even though they were not exposed to such text during pretraining. Code-Mixed NLP models have relied on using <a href=https://en.wikipedia.org/wiki/Synthetic_genomics>synthetically generated data</a> along with <a href=https://en.wikipedia.org/wiki/Natural_language_processing>naturally occurring data</a> to improve their performance. Finetuning mBERT on such <a href=https://en.wikipedia.org/wiki/Data_(computing)>data</a> improves it&#8217;s code-mixed performance, but the benefits of using the different types of Code-Mixed data are n&#8217;t clear. In this paper, we study the impact of <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a> with different types of code-mixed data and outline the changes that occur to the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> during such <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a>. Our findings suggest that using naturally occurring code-mixed data brings in the best performance improvement after <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a> and that <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a> with any type of code-mixed text improves the responsivity of it&#8217;s attention heads to code-mixed text inputs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.13/>Locality Preserving Loss : Neighbors that Live together, Align together</a></strong><br><a href=/people/a/ashwinkumar-ganesan/>Ashwinkumar Ganesan</a>
|
<a href=/people/f/francis-ferraro/>Francis Ferraro</a>
|
<a href=/people/t/tim-oates/>Tim Oates</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--13><div class="card-body p-3 small">We present a locality preserving loss (LPL) that improves the alignment between vector space embeddings while separating uncorrelated representations. Given two pretrained embedding manifolds, LPL optimizes a model to project an <a href=https://en.wikipedia.org/wiki/Embedding>embedding</a> and maintain its local neighborhood while aligning one <a href=https://en.wikipedia.org/wiki/Manifold>manifold</a> to another. This reduces the overall size of the dataset required to align the two in <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> such as crosslingual word alignment. We show that the LPL-based alignment between input vector spaces acts as a <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularizer</a>, leading to better and consistent accuracy than the baseline, especially when the size of the training set is small. We demonstrate the effectiveness of LPL-optimized alignment on semantic text similarity (STS), natural language inference (SNLI), multi-genre language inference (MNLI) and cross-lingual word alignment (CLA) showing consistent improvements, finding up to 16 % improvement over our baseline in lower resource settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.15/>Trajectory-Based Meta-Learning for Out-Of-Vocabulary Word Embedding Learning</a></strong><br><a href=/people/g/gordon-buck/>Gordon Buck</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--15><div class="card-body p-3 small">Word embedding learning methods require a large number of occurrences of a word to accurately learn its embedding. However, out-of-vocabulary (OOV) words which do not appear in the training corpus emerge frequently in the smaller downstream data. Recent work formulated OOV embedding learning as a few-shot regression problem and demonstrated that <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a> can improve results obtained. However, the <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> used, model-agnostic meta-learning (MAML) is known to be unstable and perform worse when a large number of gradient steps are used for parameter updates. In this work, we propose the use of Leap, a meta-learning algorithm which leverages the entire trajectory of the learning process instead of just the beginning and the end points, and thus ameliorates these two issues. In our experiments on a benchmark OOV embedding learning dataset and in an extrinsic evaluation, Leap performs comparably or better than MAML. We go on to examine which contexts are most beneficial to learn an OOV embedding from, and propose that the choice of contexts may matter more than the meta-learning employed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.adaptnlp-1.17" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.17/>An Empirical Study of Compound PCFGs<span class=acl-fixed-case>PCFG</span>s</a></strong><br><a href=/people/y/yanpeng-zhao/>Yanpeng Zhao</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--17><div class="card-body p-3 small">Compound probabilistic context-free grammars (C-PCFGs) have recently established a new state of the art for phrase-structure grammar induction. However, due to the high <a href=https://en.wikipedia.org/wiki/Time_complexity>time-complexity</a> of chart-based representation and inference, it is difficult to investigate them comprehensively. In this work, we rely on a fast implementation of C-PCFGs to conduct evaluation complementary to that of (CITATION). We highlight three key findings : (1) C-PCFGs are data-efficient, (2) C-PCFGs make the best use of global sentence-level information in preterminal rule probabilities, and (3) the best configurations of C-PCFGs on <a href=https://en.wikipedia.org/wiki/English_language>English</a> do not always generalize to morphology-rich languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.adaptnlp-1.20" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.20/>Effective Distant Supervision for Temporal Relation Extraction</a></strong><br><a href=/people/x/xinyu-zhao/>Xinyu Zhao</a>
|
<a href=/people/s/shih-ting-lin/>Shih-Ting Lin</a>
|
<a href=/people/g/greg-durrett/>Greg Durrett</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--20><div class="card-body p-3 small">A principal barrier to training temporal relation extraction models in new domains is the lack of varied, high quality examples and the challenge of collecting more. We present a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> of automatically collecting distantly-supervised examples of temporal relations. We scrape and automatically label event pairs where the temporal relations are made explicit in text, then mask out those explicit cues, forcing a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained on this <a href=https://en.wikipedia.org/wiki/Data>data</a> to learn other signals. We demonstrate that a pre-trained Transformer model is able to transfer from the weakly labeled examples to human-annotated benchmarks in both zero-shot and few-shot settings, and that the masking scheme is important in improving generalization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.adaptnlp-1.21" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.21/>Zero-Shot Cross-Lingual Dependency Parsing through Contextual Embedding Transformation</a></strong><br><a href=/people/h/haoran-xu/>Haoran Xu</a>
|
<a href=/people/p/philipp-koehn/>Philipp Koehn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--21><div class="card-body p-3 small">Linear embedding transformation has been shown to be effective for zero-shot cross-lingual transfer tasks and achieve surprisingly promising results. However, cross-lingual embedding space mapping is usually studied in static word-level embeddings, where a space transformation is derived by aligning representations of translation pairs that are referred from dictionaries. We move further from this line and investigate a contextual embedding alignment approach which is sense-level and dictionary-free. To enhance the quality of the <a href=https://en.wikipedia.org/wiki/Map_(mathematics)>mapping</a>, we also provide a deep view of properties of contextual embeddings, i.e., the <a href=https://en.wikipedia.org/wiki/Anisotropy>anisotropy problem</a> and its solution. Experiments on zero-shot dependency parsing through the concept-shared space built by our embedding transformation substantially outperform state-of-the-art methods using multilingual embeddings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.adaptnlp-1.22" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.22/>Gradual Fine-Tuning for Low-Resource Domain Adaptation</a></strong><br><a href=/people/h/haoran-xu/>Haoran Xu</a>
|
<a href=/people/s/seth-ebner/>Seth Ebner</a>
|
<a href=/people/m/mahsa-yarmohammadi/>Mahsa Yarmohammadi</a>
|
<a href=/people/a/aaron-steven-white/>Aaron Steven White</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a>
|
<a href=/people/k/kenton-murray/>Kenton Murray</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--22><div class="card-body p-3 small">Fine-tuning is known to improve NLP models by adapting an initial <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained on more plentiful but less domain-salient examples to data in a target domain. Such <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> is typically done using one stage of <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>. We demonstrate that gradually fine-tuning in a multi-step process can yield substantial further gains and can be applied without modifying the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> or learning objective.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.adaptnlp-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--adaptnlp-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.adaptnlp-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.adaptnlp-1.25/>Semantic Parsing of Brief and Multi-Intent Natural Language Utterances</a></strong><br><a href=/people/l/logan-lebanoff/>Logan Lebanoff</a>
|
<a href=/people/c/charles-newton/>Charles Newton</a>
|
<a href=/people/v/victor-hung/>Victor Hung</a>
|
<a href=/people/b/beth-atkinson/>Beth Atkinson</a>
|
<a href=/people/j/john-killilea/>John Killilea</a>
|
<a href=/people/f/fei-liu-utdallas/>Fei Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--adaptnlp-1--25><div class="card-body p-3 small">Many military communication domains involve rapidly conveying situation awareness with few words. Converting natural language utterances to logical forms in these domains is challenging, as these utterances are brief and contain multiple intents. In this paper, we present a first effort toward building a weakly-supervised semantic parser to transform brief, multi-intent natural utterances into logical forms. Our findings suggest a new projection and reduction method that iteratively performs projection from natural to canonical utterances followed by reduction of natural utterances is the most effective. We conduct extensive experiments on two military and a general-domain dataset and provide a new baseline for future research toward accurate parsing of multi-intent utterances.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>