<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Australasian Language Technology Association Workshop (2019) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Australasian Language Technology Association Workshop (2019)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#u19-1>Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association</a>
<span class="badge badge-info align-middle ml-1">8&nbsp;papers</span></li></ul></div></div><div id=u19-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/U19-1/>Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/U19-1000/>Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association</a></strong><br><a href=/people/m/meladel-mistica/>Meladel Mistica</a>
|
<a href=/people/m/massimo-piccardi/>Massimo Piccardi</a>
|
<a href=/people/a/andrew-mackinlay/>Andrew MacKinlay</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-U19-1001 data-toggle=collapse aria-expanded=false aria-controls=abstract-U19-1001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/U19-1001/>Towards A Robust Morphological Analyzer for Kunwinjku</a></strong><br><a href=/people/w/william-lane/>William Lane</a>
|
<a href=/people/s/steven-bird/>Steven Bird</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-U19-1001><div class="card-body p-3 small">Kunwinjku is an <a href=https://en.wikipedia.org/wiki/Australian_Aboriginal_languages>indigenous Australian language</a> spoken in northern Australia which exhibits agglutinative and polysynthetic properties. Members of the community have expressed interest in co-developing language applications that promote their values and priorities. Modeling the <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphology</a> of the <a href=https://en.wikipedia.org/wiki/Kunwinjku_language>Kunwinjku language</a> is an important step towards accomplishing the community&#8217;s goals. Finite State Transducers have long been the go-to method for modeling morphologically rich languages, and in this paper we discuss some of the distinct modeling challenges present in the <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphosyntax</a> of verbs in <a href=https://en.wikipedia.org/wiki/Kunwinjku>Kunwinjku</a>. We show that a fairly straightforward implementation using standard features of the foma toolkit can account for much of the verb structure. Continuing challenges include <a href=https://en.wikipedia.org/wiki/Robustness_(evolution)>robustness</a> in the face of <a href=https://en.wikipedia.org/wiki/Variation_(linguistics)>variation</a> and unseen vocabulary, as well as how to handle complex reduplicative processes. Our future work will build off the baseline and challenges presented here.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-U19-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-U19-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/U19-1003/>Readability of Twitter Tweets for Second Language Learners<span class=acl-fixed-case>T</span>witter Tweets for Second Language Learners</a></strong><br><a href=/people/p/patrick-jacob/>Patrick Jacob</a>
|
<a href=/people/a/alexandra-l-uitdenbogerd/>Alexandra Uitdenbogerd</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-U19-1003><div class="card-body p-3 small">Optimal <a href=https://en.wikipedia.org/wiki/Language_acquisition>language acquisition</a> via <a href=https://en.wikipedia.org/wiki/Reading>reading</a> requires the learners to read slightly above their current <a href=https://en.wikipedia.org/wiki/Language_proficiency>language skill level</a>. Identifying material at the right level is the essential role of automatic readability measurement. Short message platforms such as <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> offer the opportunity for <a href=https://en.wikipedia.org/wiki/Language_acquisition>language practice</a> while reading about current topics and engaging in conversation in small doses, and can be filtered according to linguistic criteria to suit the learner. In this research, we explore how readable tweets are for <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>English language learners</a> and which factors contribute to their <a href=https://en.wikipedia.org/wiki/Readability>readability</a>. With participants from six language groups, we collected 14,659 data points, each representing a tweet from a pool of 4100 tweets, and a judgement of perceived readability. Traditional readability measures and <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> failed on the data-set, but <a href=https://en.wikipedia.org/wiki/Demography>demographic data</a> showed that judgements were largely genuine and reflected reported language skill, which is consistent with other recent studies. We report on the properties of the data set and implications for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-U19-1010 data-toggle=collapse aria-expanded=false aria-controls=abstract-U19-1010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=U19-1010" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/U19-1010/>Improved <a href=https://en.wikipedia.org/wiki/Document_modelling>Document Modelling</a> with a Neural Discourse Parser</a></strong><br><a href=/people/f/fajri-koto/>Fajri Koto</a>
|
<a href=/people/j/jey-han-lau/>Jey Han Lau</a>
|
<a href=/people/t/timothy-baldwin/>Timothy Baldwin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-U19-1010><div class="card-body p-3 small">Despite the success of attention-based neural models for natural language generation and classification tasks, they are unable to capture the discourse structure of larger documents. We hypothesize that explicit discourse representations have utility for NLP tasks over longer documents or document sequences, which sequence-to-sequence models are unable to capture. For abstractive summarization, for instance, conventional neural models simply match source documents and the summary in a latent space without explicit representation of text structure or relations. In this paper, we propose to use neural discourse representations obtained from a rhetorical structure theory (RST) parser to enhance document representations. Specifically, document representations are generated for discourse spans, known as the elementary discourse units (EDUs). We empirically investigate the benefit of the proposed approach on two different tasks : abstractive summarization and popularity prediction of online petitions. We find that the proposed approach leads to substantial improvements in all cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-U19-1011 data-toggle=collapse aria-expanded=false aria-controls=abstract-U19-1011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/U19-1011/>Does an LSTM forget more than a CNN? An empirical study of catastrophic forgetting in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a><span class=acl-fixed-case>LSTM</span> forget more than a <span class=acl-fixed-case>CNN</span>? An empirical study of catastrophic forgetting in <span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/g/gaurav-arora/>Gaurav Arora</a>
|
<a href=/people/a/afshin-rahimi/>Afshin Rahimi</a>
|
<a href=/people/t/timothy-baldwin/>Timothy Baldwin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-U19-1011><div class="card-body p-3 small">Catastrophic forgetting whereby a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> trained on one <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is fine-tuned on a second, and in doing so, suffers a catastrophic drop in performance over the first <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is a hurdle in the development of better transfer learning techniques. Despite impressive progress in reducing catastrophic forgetting, we have limited understanding of how different <a href=https://en.wikipedia.org/wiki/Network_architecture>architectures</a> and hyper-parameters affect <a href=https://en.wikipedia.org/wiki/Forgetting>forgetting</a> in a <a href=https://en.wikipedia.org/wiki/Computer_network>network</a>. With this study, we aim to understand factors which cause <a href=https://en.wikipedia.org/wiki/Forgetting>forgetting</a> during sequential training. Our primary finding is that CNNs forget less than LSTMs. We show that max-pooling is the underlying operation which helps CNNs alleviate forgetting compared to LSTMs. We also found that curriculum learning, placing a hard task towards the end of task sequence, reduces <a href=https://en.wikipedia.org/wiki/Forgetting>forgetting</a>. We analysed the effect of <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning contextual embeddings</a> on catastrophic forgetting and found that using embeddings as feature extractor is preferable to <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> in continual learning setup.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-U19-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-U19-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/U19-1014/>Detecting Chemical Reactions in Patents</a></strong><br><a href=/people/h/hiyori-yoshikawa/>Hiyori Yoshikawa</a>
|
<a href=/people/d/dat-quoc-nguyen/>Dat Quoc Nguyen</a>
|
<a href=/people/z/zenan-zhai/>Zenan Zhai</a>
|
<a href=/people/c/christian-druckenbrodt/>Christian Druckenbrodt</a>
|
<a href=/people/c/camilo-thorne/>Camilo Thorne</a>
|
<a href=/people/s/saber-a-akhondi/>Saber A. Akhondi</a>
|
<a href=/people/t/timothy-baldwin/>Timothy Baldwin</a>
|
<a href=/people/k/karin-verspoor/>Karin Verspoor</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-U19-1014><div class="card-body p-3 small">Extracting <a href=https://en.wikipedia.org/wiki/Chemical_reaction>chemical reactions</a> from <a href=https://en.wikipedia.org/wiki/Patent>patents</a> is a crucial task for chemists working on <a href=https://en.wikipedia.org/wiki/Chemical_engineering>chemical exploration</a>. In this paper we introduce the novel task of detecting the textual spans that describe or refer to <a href=https://en.wikipedia.org/wiki/Chemical_reaction>chemical reactions</a> within patents. We formulate this task as a paragraph-level sequence tagging problem, where the system is required to return a sequence of paragraphs which contain a description of a reaction. To address this new task, we construct an annotated dataset from an existing proprietary database of chemical reactions manually extracted from <a href=https://en.wikipedia.org/wiki/Patent>patents</a>. We introduce several baseline methods for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> and evaluate them over our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. Through error analysis, we discuss what makes the task complex and challenging, and suggest possible directions for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-U19-1015 data-toggle=collapse aria-expanded=false aria-controls=abstract-U19-1015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/U19-1015/>Identifying Patients with Pain in Emergency Departments using Conventional <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Learning</a> and Deep Learning</a></strong><br><a href=/people/t/thanh-vu/>Thanh Vu</a>
|
<a href=/people/a/anthony-nguyen/>Anthony Nguyen</a>
|
<a href=/people/n/nathan-brown/>Nathan Brown</a>
|
<a href=/people/j/james-hughes/>James Hughes</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-U19-1015><div class="card-body p-3 small">Pain is the main symptom that patients present with to the emergency department (ED). Pain management, however, is often poorly done aspect of <a href=https://en.wikipedia.org/wiki/Emergency_medicine>emergency care</a> and patients with painful conditions can endure long waits before their pain is assessed or treated. To improve pain management quality, identifying whether or not an ED patient presents with pain is an important task and allows for further investigation of the quality of care provided. In this paper, <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> was utilised to handle the task of automatically detecting patients who present at EDs with pain from retrospective data. Experimental results on a manually annotated dataset show that our proposed <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> achieve high performances, in which the highest <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and macro-averaged F1 are 91.00 % and 90.96 %, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/U19-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-U19-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-U19-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/U19-1024/>An Improved Coarse-to-Fine Method for Solving Generation Tasks</a></strong><br><a href=/people/w/wenyv-guan/>Wenyv Guan</a>
|
<a href=/people/q/qianying-liu/>Qianying Liu</a>
|
<a href=/people/g/guangzhi-han/>Guangzhi Han</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-U19-1024><div class="card-body p-3 small">The coarse-to-fine (coarse2fine) methods have recently been widely used in the generation tasks. The methods first generate a rough sketch in the coarse stage and then use the sketch to get the final result in the fine stage. However, <a href=https://en.wikipedia.org/wiki/They_(2017_film)>they</a> usually lack the correction ability when getting a wrong sketch. To solve this problem, in this paper, we propose an improved coarse2fine model with a control mechanism, with which our method can control the influence of the sketch on the final results in the fine stage. Even if the sketch is wrong, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> still has the opportunity to get a correct result. We have experimented our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on the tasks of <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> and math word problem solving. The results have shown the effectiveness of our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>