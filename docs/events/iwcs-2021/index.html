<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>International Conference on Computational Semantics (2021) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>International Conference on Computational Semantics (2021)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2021iwcs-1>Proceedings of the 14th International Conference on Computational Semantics (IWCS)</a>
<span class="badge badge-info align-middle ml-1">9&nbsp;papers</span></li><li><a class=align-middle href=#2021isa-1>Proceedings of the 17th Joint ACL - ISO Workshop on Interoperable Semantic Annotation</a>
<span class="badge badge-info align-middle ml-1">5&nbsp;papers</span></li><li><a class=align-middle href=#2021mmsr-1>Proceedings of the 1st Workshop on Multimodal Semantic Representations (MMSR)</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2021naloma-1>Proceedings of the 1st and 2nd Workshops on Natural Logic Meets Machine Learning (NALOMA)</a>
<span class="badge badge-info align-middle ml-1">5&nbsp;papers</span></li><li><a class=align-middle href=#2021semspace-1>Proceedings of the 2021 Workshop on Semantic Spaces at the Intersection of NLP, Physics, and Cognitive Science (SemSpace)</a>
<span class="badge badge-info align-middle ml-1">6&nbsp;papers</span></li></ul></div></div><div id=2021iwcs-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2021.iwcs-1/>Proceedings of the 14th International Conference on Computational Semantics (IWCS)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.iwcs-1.0/>Proceedings of the 14th International Conference on Computational Semantics (IWCS)</a></strong><br><a href=/people/s/sina-zarriess/>Sina Zarrieß</a>
|
<a href=/people/j/johan-bos/>Johan Bos</a>
|
<a href=/people/r/rik-van-noord/>Rik van Noord</a>
|
<a href=/people/l/lasha-abzianidze/>Lasha Abzianidze</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwcs-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwcs-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.iwcs-1.1" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.iwcs-1.1/>Switching Contexts : Transportability Measures for NLP<span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/g/guy-marshall/>Guy Marshall</a>
|
<a href=/people/m/mokanarangan-thayaparan/>Mokanarangan Thayaparan</a>
|
<a href=/people/p/philip-osborne/>Philip Osborne</a>
|
<a href=/people/a/andre-freitas/>André Freitas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwcs-1--1><div class="card-body p-3 small">This paper explores the topic of transportability, as a sub-area of generalisability. By proposing the utilisation of <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> based on well-established statistics, we are able to estimate the change in performance of <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP models</a> in new contexts. Defining a new measure for transportability may allow for better estimation of NLP system performance in new domains, and is crucial when assessing the performance of NLP systems in new tasks and domains. Through several instances of increasing <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>complexity</a>, we demonstrate how lightweight domain similarity measures can be used as estimators for the transportability in NLP applications. The proposed transportability measures are evaluated in the context of <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> and Natural Language Inference tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwcs-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwcs-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.iwcs-1.2/>Applied Temporal Analysis : A Complete Run of the FraCaS Test Suite<span class=acl-fixed-case>F</span>ra<span class=acl-fixed-case>C</span>a<span class=acl-fixed-case>S</span> Test Suite</a></strong><br><a href=/people/j/jean-philippe-bernardy/>Jean-Philippe Bernardy</a>
|
<a href=/people/s/stergios-chatzikyriakidis/>Stergios Chatzikyriakidis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwcs-1--2><div class="card-body p-3 small">In this paper, we propose an implementation of temporal semantics that translates <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>syntax trees</a> to <a href=https://en.wikipedia.org/wiki/Well-formed_formula>logical formulas</a>, suitable for consumption by the <a href=https://en.wikipedia.org/wiki/Coq>Coq proof assistant</a>. The analysis supports a wide range of phenomena including : temporal references, temporal adverbs, aspectual classes and progressives. The new semantics are built on top of a previous system handling all sections of the FraCaS test suite except the temporal reference section, and we obtain an accuracy of 81 percent overall and 73 percent for the problems explicitly marked as related to temporal reference. To the best of our knowledge, this is the best performance of a <a href=https://en.wikipedia.org/wiki/Formal_system>logical system</a> on the whole of the FraCaS.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwcs-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwcs-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.iwcs-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.iwcs-1.7/>Critical Thinking for <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a></a></strong><br><a href=/people/g/gregor-betz/>Gregor Betz</a>
|
<a href=/people/c/christian-voigt/>Christian Voigt</a>
|
<a href=/people/k/kyle-richardson/>Kyle Richardson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwcs-1--7><div class="card-body p-3 small">This paper takes a first step towards a critical thinking curriculum for neural auto-regressive language models. We introduce a synthetic corpus of deductively valid arguments, and generate artificial argumentative texts to train CRiPT : a <a href=https://en.wikipedia.org/wiki/Critical_thinking>critical thinking</a> intermediarily pre-trained transformer based on GPT-2. Significant transfer learning effects can be observed : Trained on three simple core schemes, CRiPT accurately completes conclusions of different, and more complex types of arguments, too. CRiPT generalizes the core argument schemes in a correct way. Moreover, we obtain consistent and promising results for NLU benchmarks. In particular, CRiPT&#8217;s zero-shot accuracy on the GLUE diagnostics exceeds GPT-2&#8217;s performance by 15 percentage points. The findings suggest that intermediary pre-training on texts that exemplify basic reasoning abilities (such as typically covered in critical thinking textbooks) might help <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> to acquire a broad range of reasoning skills. The synthetic argumentative texts presented in this paper are a promising starting point for building such a critical thinking curriculum for <a href=https://en.wikipedia.org/wiki/Language_model>language models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwcs-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwcs-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Outstanding Paper"><i class="fas fa-award"></i></span><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.iwcs-1.12.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment>
<i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.iwcs-1.12" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.iwcs-1.12/>Monotonicity Marking from Universal Dependency Trees<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependency Trees</a></strong><br><a href=/people/z/zeming-chen/>Zeming Chen</a>
|
<a href=/people/q/qiyue-gao/>Qiyue Gao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwcs-1--12><div class="card-body p-3 small">Dependency parsing is a tool widely used in the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural language processing</a> and <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a>. However, there is hardly any work that connects dependency parsing to <a href=https://en.wikipedia.org/wiki/Monotonic_function>monotonicity</a>, which is an essential part of logic and linguistic semantics. In this paper, we present a system that automatically annotates <a href=https://en.wikipedia.org/wiki/Monotonic_function>monotonicity information</a> based on Universal Dependency parse trees. Our system utilizes surface-level monotonicity facts about <a href=https://en.wikipedia.org/wiki/Quantifier_(logic)>quantifiers</a>, <a href=https://en.wikipedia.org/wiki/Lexical_item>lexical items</a>, and token-level polarity information. We compared our <a href=https://en.wikipedia.org/wiki/System>system</a>&#8217;s performance with existing systems in the literature, including NatLog and ccg2mono, on a small evaluation dataset. Results show that our <a href=https://en.wikipedia.org/wiki/System>system</a> outperforms NatLog and ccg2mono.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwcs-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwcs-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Outstanding Paper"><i class="fas fa-award"></i></span><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.iwcs-1.13" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.iwcs-1.13/>Is that really a question? Going beyond factoid questions in NLP<span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/a/aikaterini-lida-kalouli/>Aikaterini-Lida Kalouli</a>
|
<a href=/people/r/rebecca-kehlbeck/>Rebecca Kehlbeck</a>
|
<a href=/people/r/rita-sevastjanova/>Rita Sevastjanova</a>
|
<a href=/people/o/oliver-deussen/>Oliver Deussen</a>
|
<a href=/people/d/daniel-keim/>Daniel Keim</a>
|
<a href=/people/m/miriam-butt/>Miriam Butt</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwcs-1--13><div class="card-body p-3 small">Research in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> has mainly focused on factoid questions, with the goal of finding quick and reliable ways of matching a query to an answer. However, human discourse involves more than that : <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> contains non-canonical questions deployed to achieve specific communicative goals. In this paper, we investigate this under-studied aspect of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> by introducing a targeted <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, creating an appropriate <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> and providing baseline models of diverse nature. With this, we are also able to generate useful insights on the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> and open the way for future research in this direction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwcs-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwcs-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.iwcs-1.15/>Breeding Fillmore’s Chickens and Hatching the Eggs : Recombining Frames and Roles in Frame-Semantic Parsing<span class=acl-fixed-case>F</span>illmore’s Chickens and Hatching the Eggs: Recombining Frames and Roles in Frame-Semantic Parsing</a></strong><br><a href=/people/g/gosse-minnema/>Gosse Minnema</a>
|
<a href=/people/m/malvina-nissim/>Malvina Nissim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwcs-1--15><div class="card-body p-3 small">Frame-semantic parsers traditionally predict <a href=https://en.wikipedia.org/wiki/Predicate_(grammar)>predicates</a>, <a href=https://en.wikipedia.org/wiki/Frame_(artificial_intelligence)>frames</a>, and semantic roles in a fixed order. This paper explores the &#8216;chicken-or-egg&#8217; problem of interdependencies between these components theoretically and practically. We introduce a flexible BERT-based sequence labeling architecture that allows for predicting frames and roles independently from each other or combining them in several ways. Our results show that our setups can approximate more complex traditional <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>&#8217; performance, while allowing for a clearer view of the interdependencies between the pipeline&#8217;s components, and of how frame and role prediction models make different use of BERT&#8217;s layers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwcs-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwcs-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.iwcs-1.16/>Large-scale text pre-training helps with dialogue act recognition, but not without <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a></a></strong><br><a href=/people/b/bill-noble/>Bill Noble</a>
|
<a href=/people/v/vladislav-maraev/>Vladislav Maraev</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwcs-1--16><div class="card-body p-3 small">We use dialogue act recognition (DAR) to investigate how well BERT represents utterances in dialogue, and how fine-tuning and large-scale pre-training contribute to its performance. We find that while both the standard BERT pre-training and pretraining on dialogue-like data are useful, task-specific fine-tuning is essential for good performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.iwcs-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--iwcs-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.iwcs-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.iwcs-1.22" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.iwcs-1.22/>Variation in framing as a function of temporal reporting distance</a></strong><br><a href=/people/l/levi-remijnse/>Levi Remijnse</a>
|
<a href=/people/m/marten-postma/>Marten Postma</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--iwcs-1--22><div class="card-body p-3 small">In this paper, we measure variation in <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>framing</a> as a function of <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>foregrounding</a> and <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>backgrounding</a> in a co-referential corpus with a range of temporal distance. In one type of experiment, frame-annotated corpora grouped under event types were contrasted, resulting in a ranking of frames with typicality rates. In contrasting between publication dates, a different ranking of frames emerged for documents that are close to or far from the event instance. In the second type of analysis, we trained a diagnostic classifier with frame occurrences in order to let it differentiate documents based on their temporal distance class (close to or far from the event instance). The <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifier</a> performs above chance and outperforms <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> with words.</div></div></div><hr><div id=2021isa-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.isa-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2021.isa-1/>Proceedings of the 17th Joint ACL - ISO Workshop on Interoperable Semantic Annotation</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.isa-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.isa-1.0/>Proceedings of the 17th Joint ACL - ISO Workshop on Interoperable Semantic Annotation</a></strong><br><a href=/people/h/harry-bunt/>Harry Bunt</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.isa-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--isa-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.isa-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.isa-1.2/>Towards the ISO 24617-2-compliant Typology of Metacognitive Events<span class=acl-fixed-case>ISO</span> 24617-2-compliant Typology of Metacognitive Events</a></strong><br><a href=/people/v/volha-petukhova/>Volha Petukhova</a>
|
<a href=/people/h/hafiza-erum-manzoor/>Hafiza Erum Manzoor</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--isa-1--2><div class="card-body p-3 small">The paper presents ongoing efforts in design of a <a href=https://en.wikipedia.org/wiki/Typology_(psychology)>typology</a> of <a href=https://en.wikipedia.org/wiki/Metacognition>metacognitive events</a> observed in a multimodal dialogue. The typology will serve as a tool to identify relations between participants&#8217; dispositions, <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue actions</a> and <a href=https://en.wikipedia.org/wiki/Metacognition>metacognitive indicators</a>. It will be used to support an assessment of metacognitive knowledge, experiences and strategies of dialogue participants. Based on the mutidimensional dialogue model defined within the framework of Dynamic Interpretation Theory and ISO 24617-2 annotation standard, the proposed approach provides a systematic analysis of <a href=https://en.wikipedia.org/wiki/Metacognition>metacognitive events</a> in terms of <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue acts</a>, i.e. concepts that dialogue research community is used to operate on in dialogue modelling and system design tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.isa-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--isa-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.isa-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.isa-1.3/>Annotating Quantified Phenomena in Complex Sentence Structures Using the Example of Generalising Statements in Literary Texts</a></strong><br><a href=/people/t/tillmann-donicke/>Tillmann Dönicke</a>
|
<a href=/people/l/luisa-godeke/>Luisa Gödeke</a>
|
<a href=/people/h/hanna-varachkina/>Hanna Varachkina</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--isa-1--3><div class="card-body p-3 small">We present a tagset for the annotation of quantification which we currently use to annotate certain quantified statements in fictional works of literature. Literary texts feature a rich variety in expressing <a href=https://en.wikipedia.org/wiki/Quantification_(linguistics)>quantification</a>, including a broad range of lexemes to express quantifiers and complex sentence structures to express the restrictor and the nuclear scope of a quantification. Our tagset consists of seven tags and covers all types of <a href=https://en.wikipedia.org/wiki/Quantifier_(linguistics)>quantification</a> that occur in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>, including vague quantification and generic quantification. In the second part of the paper, we introduce our German corpus with annotations of generalising statements, which form a proper subset of quantified statements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.isa-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--isa-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.isa-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.isa-1.5/>Discourse-based Argument Segmentation and Annotation</a></strong><br><a href=/people/e/ekaterina-saveleva/>Ekaterina Saveleva</a>
|
<a href=/people/v/volha-petukhova/>Volha Petukhova</a>
|
<a href=/people/m/marius-mosbach/>Marius Mosbach</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--isa-1--5><div class="card-body p-3 small">The paper presents a discourse-based approach to the analysis of argumentative texts departing from the assumption that the coherence of a text should capture argumentation structure as well and, therefore, existing discourse analysis tools can be successfully applied for argument segmentation and annotation tasks. We tested the widely used Penn Discourse Tree Bank full parser (Lin et al., 2010) and the state-of-the-art neural network NeuralEDUSeg (Wang et al., 2018) and XLNet (Yang et al., 2019) models on the two-stage discourse segmentation and discourse relation recognition. The two-stage approach outperformed the PDTB parser by broad margin, i.e. the best achieved F1 scores of 21.2 % for PDTB parser vs 66.37 % for NeuralEDUSeg and XLNet models. Neural network models were fine-tuned and evaluated on the argumentative corpus showing a promising <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 60.22 %. The complete <a href=https://en.wikipedia.org/wiki/Argument_(linguistics)>argument structures</a> were reconstructed for further argumentation mining tasks. The reference Dagstuhl argumentative corpus containing 2,222 elementary discourse unit pairs annotated with the top-level and fine-grained PDTB relations will be released to the research community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.isa-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--isa-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.isa-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.isa-1.6.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.isa-1.6/>Converting Multilayer Glosses into Semantic and Pragmatic forms with GENLIS<span class=acl-fixed-case>GENLIS</span></a></strong><br><a href=/people/r/rodolfo-delmonte/>Rodolfo Delmonte</a>
|
<a href=/people/s/serena-trolvi/>Serena Trolvi</a>
|
<a href=/people/f/francesco-stiffoni/>Francesco Stiffoni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--isa-1--6><div class="card-body p-3 small">This paper presents work carried out to transform glosses of a fable in <a href=https://en.wikipedia.org/wiki/Italian_Sign_Language>Italian Sign Language (LIS)</a> into a text which is then read by a TTS synthesizer from an SSML modified version of the same text. Whereas many systems exist that generate <a href=https://en.wikipedia.org/wiki/Sign_language>sign language</a> from a text, we decided to do the reverse operation and generate text from <a href=https://en.wikipedia.org/wiki/Lisp_(programming_language)>LIS</a>. For that purpose we used a version of the fable The Tortoise and the Hare, signed and made available on Youtube by ALBA cooperativa sociale, which was annotated manually by second author for her master&#8217;s thesis. In order to achieve our goal, we converted the <a href=https://en.wikipedia.org/wiki/Gloss_(annotation)>multilayer glosses</a> into linear Prolog terms to be fed to the <a href=https://en.wikipedia.org/wiki/Generator_(mathematics)>generator</a>. In the paper we focus on the main problems encountered in the transformation of the glosses into a semantically and pragmatically consistent representation. The main problems have been caused by the complexities of a text like a fable which requires <a href=https://en.wikipedia.org/wiki/Coreference>coreference mechanisms</a> and <a href=https://en.wikipedia.org/wiki/Speech_act>speech acts</a> to be implemented in the representation which are often unexpressed and constitute implicit information.</div></div></div><hr><div id=2021mmsr-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2021.mmsr-1/>Proceedings of the 1st Workshop on Multimodal Semantic Representations (MMSR)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mmsr-1.0/>Proceedings of the 1st Workshop on Multimodal Semantic Representations (MMSR)</a></strong><br><a href=/people/l/lucia-donatelli/>Lucia Donatelli</a>
|
<a href=/people/n/nikhil-krishnaswamy/>Nikhil Krishnaswamy</a>
|
<a href=/people/k/kenneth-lai/>Kenneth Lai</a>
|
<a href=/people/j/james-pustejovsky/>James Pustejovsky</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mmsr-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mmsr-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mmsr-1.1/>What is Multimodality?</a></strong><br><a href=/people/l/letitia-parcalabescu/>Letitia Parcalabescu</a>
|
<a href=/people/n/nils-trost/>Nils Trost</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mmsr-1--1><div class="card-body p-3 small">The last years have shown rapid developments in the field of multimodal machine learning, combining e.g., <a href=https://en.wikipedia.org/wiki/Computer_vision>vision</a>, <a href=https://en.wikipedia.org/wiki/Written_language>text</a> or <a href=https://en.wikipedia.org/wiki/Speech>speech</a>. In this position paper we explain how the <a href=https://en.wikipedia.org/wiki/Field_(mathematics)>field</a> uses outdated definitions of <a href=https://en.wikipedia.org/wiki/Multimodality>multimodality</a> that prove unfit for the <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning era</a>. We propose a new task-relative definition of (multi)modality in the context of multimodal machine learning that focuses on representations and information that are relevant for a given machine learning task. With our new definition of <a href=https://en.wikipedia.org/wiki/Multimodality>multimodality</a> we aim to provide a missing foundation for multimodal research, an important component of language grounding and a crucial milestone towards <a href=https://en.wikipedia.org/wiki/Natural_language_understanding>NLU</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mmsr-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mmsr-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mmsr-1.4/>Seeing past words : Testing the cross-modal capabilities of pretrained V&L models on counting tasks<span class=acl-fixed-case>V</span>&<span class=acl-fixed-case>L</span> models on counting tasks</a></strong><br><a href=/people/l/letitia-parcalabescu/>Letitia Parcalabescu</a>
|
<a href=/people/a/albert-gatt/>Albert Gatt</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a>
|
<a href=/people/i/iacer-calixto/>Iacer Calixto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mmsr-1--4><div class="card-body p-3 small">We investigate the reasoning ability of pretrained vision and language (V&L) models in two tasks that require multimodal integration : (1) discriminating a correct image-sentence pair from an incorrect one, and (2) counting entities in an image. We evaluate three pretrained V&L models on these tasks : ViLBERT, ViLBERT 12-in-1 and LXMERT, in zero-shot and finetuned settings. Our results show that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> solve task (1) very well, as expected, since all <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are pretrained on task (1). However, none of the pretrained V&L models is able to adequately solve task (2), our counting probe, and they can not generalise to out-of-distribution quantities. We propose a number of explanations for these findings : LXMERT (and to some extent ViLBERT 12-in-1) show some evidence of catastrophic forgetting on task (1). Concerning our results on the counting probe, we find evidence that all models are impacted by dataset bias, and also fail to individuate entities in the visual input. While a selling point of pretrained V&L models is their ability to solve complex tasks, our findings suggest that understanding their reasoning and grounding capabilities requires more targeted investigations on specific phenomena.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mmsr-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mmsr-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mmsr-1.5/>How Vision Affects Language : Comparing Masked Self-Attention in Uni-Modal and Multi-Modal Transformer</a></strong><br><a href=/people/n/nikolai-ilinykh/>Nikolai Ilinykh</a>
|
<a href=/people/s/simon-dobnik/>Simon Dobnik</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mmsr-1--5><div class="card-body p-3 small">The problem of interpretation of knowledge learned by multi-head self-attention in transformers has been one of the central questions in <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a>. However, a lot of work mainly focused on <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> trained for uni-modal tasks, e.g. machine translation. In this paper, we examine masked self-attention in a multi-modal transformer trained for the task of image captioning. In particular, we test whether the multi-modality of the task objective affects the learned attention patterns. Our visualisations of masked self-attention demonstrate that (i) it can learn general linguistic knowledge of the textual input, and (ii) its <a href=https://en.wikipedia.org/wiki/Attention>attention patterns</a> incorporate artefacts from <a href=https://en.wikipedia.org/wiki/Visual_system>visual modality</a> even though it has never accessed it directly. We compare our transformer&#8217;s attention patterns with masked attention in distilgpt-2 tested for uni-modal text generation of image captions. Based on the maps of extracted attention weights, we argue that masked self-attention in image captioning transformer seems to be enhanced with semantic knowledge from images, exemplifying joint language-and-vision information in its attention patterns.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mmsr-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mmsr-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.mmsr-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.mmsr-1.6/>EMISSOR : A platform for capturing multimodal interactions as Episodic Memories and Interpretations with Situated Scenario-based Ontological References<span class=acl-fixed-case>EMISSOR</span>: A platform for capturing multimodal interactions as Episodic Memories and Interpretations with Situated Scenario-based Ontological References</a></strong><br><a href=/people/s/selene-baez-santamaria/>Selene Baez Santamaria</a>
|
<a href=/people/t/thomas-baier/>Thomas Baier</a>
|
<a href=/people/t/taewoon-kim/>Taewoon Kim</a>
|
<a href=/people/l/lea-krause/>Lea Krause</a>
|
<a href=/people/j/jaap-kruijt/>Jaap Kruijt</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mmsr-1--6><div class="card-body p-3 small">We present EMISSOR : a platform to capture multimodal interactions as recordings of episodic experiences with explicit referential interpretations that also yield an episodic Knowledge Graph (eKG). The <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> stores streams of multiple modalities as <a href=https://en.wikipedia.org/wiki/Parallel_communication>parallel signals</a>. Each signal is segmented and annotated independently with interpretation. Annotations are eventually mapped to explicit identities and relations in the <a href=https://en.wikipedia.org/wiki/Electrocardiography>eKG</a>. As we ground signal segments from different modalities to the same instance representations, we also ground different modalities across each other. Unique to our <a href=https://en.wikipedia.org/wiki/Electrocardiography>eKG</a> is that it accepts different interpretations across modalities, sources and experiences and supports reasoning over conflicting information and uncertainties that may result from multimodal experiences. EMISSOR can record and annotate experiments in virtual and real-world, combine data, evaluate system behavior and their performance for preset goals but also model the accumulation of knowledge and interpretations in the Knowledge Graph as a result of these episodic experiences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mmsr-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mmsr-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mmsr-1.8/>Incremental Unit Networks for Multimodal, Fine-grained Information State Representation</a></strong><br><a href=/people/c/casey-kennington/>Casey Kennington</a>
|
<a href=/people/d/david-schlangen/>David Schlangen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mmsr-1--8><div class="card-body p-3 small">We offer a fine-grained information state annotation scheme that follows directly from the Incremental Unit abstract model of dialogue processing when used within a multimodal, co-located, interactive setting. We explain the Incremental Unit model and give an example application using the Localized Narratives dataset, then offer avenues for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mmsr-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mmsr-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mmsr-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mmsr-1.9/>Teaching Arm and Head Gestures to a Humanoid Robot through Interactive Demonstration and Spoken Instruction</a></strong><br><a href=/people/m/michael-brady/>Michael Brady</a>
|
<a href=/people/h/han-du/>Han Du</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mmsr-1--9><div class="card-body p-3 small">We describe work in progress for training a <a href=https://en.wikipedia.org/wiki/Humanoid_robot>humanoid robot</a> to produce iconic arm and head gestures as part of task-oriented dialogue interaction. This involves the development and use of a multimodal dialog manager for non-experts to quickly &#8216;program&#8217; the robot through <a href=https://en.wikipedia.org/wiki/Speech>speech</a> and <a href=https://en.wikipedia.org/wiki/Visual_system>vision</a>. Using this <a href=https://en.wikipedia.org/wiki/Dialog_manager>dialog manager</a>, videos of <a href=https://en.wikipedia.org/wiki/Gesture_recognition>gesture demonstrations</a> are collected. Motor positions are extracted from these videos to specify motor trajectories where collections of motor trajectories are used to produce robot gestures following a Gaussian mixtures approach. Concluding discussion considers how learned representations may be used for <a href=https://en.wikipedia.org/wiki/Gesture_recognition>gesture recognition</a> by the robot, and how the framework may mature into a system to address language grounding and semantic representation.</div></div></div><hr><div id=2021naloma-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naloma-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2021.naloma-1/>Proceedings of the 1st and 2nd Workshops on Natural Logic Meets Machine Learning (NALOMA)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naloma-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naloma-1.0/>Proceedings of the 1st and 2nd Workshops on Natural Logic Meets Machine Learning (NALOMA)</a></strong><br><a href=/people/a/aikaterini-lida-kalouli/>Aikaterini-Lida Kalouli</a>
|
<a href=/people/l/lawrence-s-moss/>Lawrence S. Moss</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naloma-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naloma-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naloma-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naloma-1.3/>Attentive Tree-structured Network for Monotonicity Reasoning</a></strong><br><a href=/people/z/zeming-chen/>Zeming Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naloma-1--3><div class="card-body p-3 small">Many state-of-art neural models designed for monotonicity reasoning perform poorly on downward inference. To address this shortcoming, we developed an attentive tree-structured neural network. It consists of a tree-based long-short-term-memory network (Tree-LSTM) with soft attention. It is designed to model the syntactic parse tree information from the sentence pair of a reasoning task. A self-attentive aggregator is used for aligning the representations of the premise and the hypothesis. We present our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and evaluate it using the Monotonicity Entailment Dataset (MED). We show and attempt to explain that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on MED.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naloma-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naloma-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naloma-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naloma-1.4/>Transferring Representations of Logical Connectives</a></strong><br><a href=/people/a/aaron-traylor/>Aaron Traylor</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a>
|
<a href=/people/r/roman-feiman/>Roman Feiman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naloma-1--4><div class="card-body p-3 small">In modern natural language processing pipelines, it is common practice to pretrain a generative language model on a large corpus of text, and then to finetune the created representations by continuing to train them on a discriminative textual inference task. However, it is not immediately clear whether the <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>logical meaning</a> necessary to model <a href=https://en.wikipedia.org/wiki/Logical_consequence>logical entailment</a> is captured by <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> in this <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a>. We examine this pretrain-finetune recipe with language models trained on a synthetic propositional language entailment task, and present results on test sets probing models&#8217; knowledge of axioms of first order logic.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naloma-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naloma-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naloma-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naloma-1.5/>Monotonic Inference for Underspecified Episodic Logic</a></strong><br><a href=/people/g/gene-kim/>Gene Kim</a>
|
<a href=/people/m/mandar-juvekar/>Mandar Juvekar</a>
|
<a href=/people/l/lenhart-schubert/>Lenhart Schubert</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naloma-1--5><div class="card-body p-3 small">We present a method of making natural logic inferences from Unscoped Logical Form of Episodic Logic. We establish a correspondence between inference rules of scope resolved Episodic Logic and the natural logic treatment by Snchez Valencia (1991a), and hence demonstrate the ability to handle foundational natural logic inferences from prior literature as well as more general nested monotonicity inferences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naloma-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naloma-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naloma-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naloma-1.7/>Bayesian Classification and Inference in a Probabilistic Type Theory with Records<span class=acl-fixed-case>B</span>ayesian Classification and Inference in a Probabilistic Type Theory with Records</a></strong><br><a href=/people/s/staffan-larsson/>Staffan Larsson</a>
|
<a href=/people/r/robin-cooper/>Robin Cooper</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naloma-1--7><div class="card-body p-3 small">We propose a probabilistic account of semantic inference and classification formulated in terms of probabilistic type theory with records, building on Cooper et. al. (2014) and Cooper et. al. We suggest probabilistic type theoretic formulations of <a href=https://en.wikipedia.org/wiki/Naive_Bayes_classifier>Naive Bayes Classifiers</a> and <a href=https://en.wikipedia.org/wiki/Bayesian_network>Bayesian Networks</a>. A central element of these constructions is a type-theoretic version of a <a href=https://en.wikipedia.org/wiki/Random_variable>random variable</a>. We illustrate this account with a simple <a href=https://en.wikipedia.org/wiki/Language_game>language game</a> combining probabilistic classification of perceptual input with probabilistic (semantic) inference.</div></div></div><hr><div id=2021semspace-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semspace-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2021.semspace-1/>Proceedings of the 2021 Workshop on Semantic Spaces at the Intersection of NLP, Physics, and Cognitive Science (SemSpace)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semspace-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semspace-1.0/>Proceedings of the 2021 Workshop on Semantic Spaces at the Intersection of NLP, Physics, and Cognitive Science (SemSpace)</a></strong><br><a href=/people/m/martha-lewis/>Martha Lewis</a>
|
<a href=/people/m/mehrnoosh-sadrzadeh/>Mehrnoosh Sadrzadeh</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semspace-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semspace-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semspace-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semspace-1.2/>LinPP : a Python-friendly algorithm for Linear Pregroup Parsing<span class=acl-fixed-case>L</span>in<span class=acl-fixed-case>PP</span>: a Python-friendly algorithm for Linear Pregroup Parsing</a></strong><br><a href=/people/i/irene-rizzo/>Irene Rizzo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semspace-1--2><div class="card-body p-3 small">We define a linear pregroup parser, by applying some key modifications to the minimal parser defined in (Preller, 2007). These include handling words as separate blocks, and thus respecting their syntactic role in the sentence. We prove correctness of our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> with respect to parsing sentences in a subclass of <a href=https://en.wikipedia.org/wiki/Pregroup_grammar>pregroup grammars</a>. The <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> was specifically designed for a seamless implementation in <a href=https://en.wikipedia.org/wiki/Python_(programming_language)>Python</a>. This facilitates its integration within the DisCopy module for QNLP and vastly increases the applicability of pregroup grammars to parsing real-world text data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semspace-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semspace-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semspace-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semspace-1.3/>A CCG-Based Version of the DisCoCat Framework<span class=acl-fixed-case>CCG</span>-Based Version of the <span class=acl-fixed-case>D</span>is<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>C</span>at Framework</a></strong><br><a href=/people/r/richie-yeung/>Richie Yeung</a>
|
<a href=/people/d/dimitri-kartsaklis/>Dimitri Kartsaklis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semspace-1--3><div class="card-body p-3 small">While the DisCoCat model (Coecke et al., 2010) has been proved a valuable tool for studying compositional aspects of language at the level of semantics, its strong dependency on pregroup grammars poses important restrictions : first, it prevents large-scale experimentation due to the absence of a pregroup parser ; and second, it limits the expressibility of the model to context-free grammars. In this paper we solve these problems by reformulating DisCoCat as a passage from Combinatory Categorial Grammar (CCG) to a category of semantics. We start by showing that standard categorial grammars can be expressed as a biclosed category, where all rules emerge as currying / uncurrying the identity ; we then proceed to model permutation-inducing rules by exploiting the symmetry of the <a href=https://en.wikipedia.org/wiki/Compact_category>compact closed category</a> encoding the word meaning. We provide a proof of concept for our method, converting Alice in Wonderland into DisCoCat form, a corpus that we make available to the community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semspace-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semspace-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semspace-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semspace-1.4/>Grammar equations</a></strong><br><a href=/people/b/bob-coecke/>Bob Coecke</a>
|
<a href=/people/v/vincent-wang/>Vincent Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semspace-1--4><div class="card-body p-3 small">Diagrammatically speaking, grammatical calculi such as pregroups provide wires between words in order to elucidate their interactions, and this enables one to verify grammatical correctness of phrases and sentences. In this paper we also provide wirings within words. This will enable us to identify <a href=https://en.wikipedia.org/wiki/Grammatical_construction>grammatical constructs</a> that we expect to be either equal or closely related. Hence, our work paves the way for a new theory of grammar, that provides novel &#8216;grammatical truths&#8217;. We give a nogo-theorem for the fact that our wirings for words make no sense for preordered monoids, the form which grammatical calculi usually take. Instead, they require <a href=https://en.wikipedia.org/wiki/Diagram_(category_theory)>diagrams</a> or equivalently, (free) monoidal categories.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semspace-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semspace-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semspace-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.semspace-1.6.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.semspace-1.6/>Conversational Negation using Worldly Context in Compositional Distributional Semantics</a></strong><br><a href=/people/b/benjamin-rodatz/>Benjamin Rodatz</a>
|
<a href=/people/r/razin-shaikh/>Razin Shaikh</a>
|
<a href=/people/l/lia-yeh/>Lia Yeh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semspace-1--6><div class="card-body p-3 small">We propose a framework to model an operational conversational negation by applying worldly context (prior knowledge) to <a href=https://en.wikipedia.org/wiki/Logical_negation>logical negation</a> in compositional distributional semantics. Given a word, our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> can create its <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a> that is similar to how humans perceive <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a>. The framework corrects <a href=https://en.wikipedia.org/wiki/Negation>logical negation</a> to weight meanings closer in the <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment hierarchy</a> more than meanings further apart. The proposed <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> is flexible to accommodate different choices of <a href=https://en.wikipedia.org/wiki/Negation>logical negations</a>, <a href=https://en.wikipedia.org/wiki/Musical_composition>compositions</a>, and worldly context generation. In particular, we propose and motivate a new <a href=https://en.wikipedia.org/wiki/Negation>logical negation</a> using <a href=https://en.wikipedia.org/wiki/Matrix_inverse>matrix inverse</a>. We validate the sensibility of our conversational negation framework by performing experiments, leveraging <a href=https://en.wikipedia.org/wiki/Density_matrix>density matrices</a> to encode graded entailment information. We conclude that the combination of subtraction negation and phaser in the basis of the <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negated word</a> yields the highest <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson correlation</a> of 0.635 with human ratings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semspace-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semspace-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semspace-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.semspace-1.7.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.semspace-1.7/>Parsing conjunctions in DisCoCirc<span class=acl-fixed-case>D</span>is<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>C</span>irc</a></strong><br><a href=/people/t/tiffany-duneau/>Tiffany Duneau</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semspace-1--7><div class="card-body p-3 small">In distributional compositional models of meaning logical words require special interpretations, that specify the way in which other words in the sentence interact with each other. So far within the DisCoCat framework, <a href=https://en.wikipedia.org/wiki/Conjunction_(grammar)>conjunctions</a> have been implemented as merging both conjuncts into a single output, however in the new framework of DisCoCirc merging between nouns is no longer possible. We provide an account of <a href=https://en.wikipedia.org/wiki/Logical_conjunction>conjunction</a> and an interpretation for the word &#8216;and&#8217; that solves this, and moreover ensures certain intuitively similar sentences can be given the same interpretations.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>