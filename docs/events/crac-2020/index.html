<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Workshop on Computational Models of Reference, Anaphora and Coreference (2020) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Workshop on Computational Models of Reference, Anaphora and Coreference (2020)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2020crac-1>Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference</a>
<span class="badge badge-info align-middle ml-1">11&nbsp;papers</span></li></ul></div></div><div id=2020crac-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.crac-1/>Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.0/>Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference</a></strong><br><a href=/people/m/maciej-ogrodniczuk/>Maciej Ogrodniczuk</a>
|
<a href=/people/v/vincent-ng/>Vincent Ng</a>
|
<a href=/people/y/yulia-grishina/>Yulia Grishina</a>
|
<a href=/people/s/sameer-pradhan/>Sameer Pradhan</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.2/>It’s absolutely divine ! Can fine-grained sentiment analysis benefit from <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>?</a></strong><br><a href=/people/o/orphee-de-clercq/>Orphee De Clercq</a>
|
<a href=/people/v/veronique-hoste/>Veronique Hoste</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--2><div class="card-body p-3 small">While it has been claimed that anaphora or <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> plays an important role in <a href=https://en.wikipedia.org/wiki/Opinion_mining>opinion mining</a>, it is not clear to what extent <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> actually boosts performance, if at all. In this paper, we investigate the potential added value of <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> for the aspect-based sentiment analysis of restaurant reviews in two languages, <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>. We focus on the task of aspect category classification and investigate whether including coreference information prior to <a href=https://en.wikipedia.org/wiki/Categorization>classification</a> to resolve implicit aspect mentions is beneficial. Because <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> is not a solved task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, we rely on both automatically-derived and gold-standard coreference relations, allowing us to investigate the true upper bound. By training a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> on a combination of lexical and semantic features, we show that resolving the coreferential relations prior to <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> is beneficial in a joint optimization setup. However, this is only the case when relying on <a href=https://en.wikipedia.org/wiki/Gold_standard>gold-standard relations</a> and the result is more outspoken for <a href=https://en.wikipedia.org/wiki/English_language>English</a> than for <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>. When validating the optimal models, however, we found that only the Dutch pipeline is able to achieve a satisfying performance on a held-out test set and does so regardless of whether coreference information was included.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.3/>Anaphoric Zero Pronoun Identification : A Multilingual Approach</a></strong><br><a href=/people/a/abdulrahman-aloraini/>Abdulrahman Aloraini</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--3><div class="card-body p-3 small">Pro-drop languages such as <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a> or <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> allow morphologically null but referential arguments in certain syntactic positions, called anaphoric zero-pronouns. Much NLP work on anaphoric zero-pronouns (AZP) is based on gold mentions, but models for their identification are a fundamental prerequisite for their resolution in real-life applications. Such <a href=https://en.wikipedia.org/wiki/Identity_(social_science)>identification</a> requires <a href=https://en.wikipedia.org/wiki/Complex_system>complex language understanding</a> and knowledge of real-world entities. Transfer learning models, such as BERT, have recently shown to learn surface, syntactic, and semantic information, which can be very useful in recognizing AZPs. We propose a BERT-based multilingual model for AZP identification from predicted zero pronoun positions, and evaluate it on the Arabic and Chinese portions of OntoNotes 5.0. As far as we know, this is the first neural network model of AZP identification for <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> ; and our approach outperforms the stateof-the-art for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. Experiment results suggest that BERT implicitly encode information about AZPs through their surrounding context.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.4/>Predicting Coreference in Abstract Meaning Representations<span class=acl-fixed-case>A</span>bstract <span class=acl-fixed-case>M</span>eaning <span class=acl-fixed-case>R</span>epresentations</a></strong><br><a href=/people/t/tatiana-anikina/>Tatiana Anikina</a>
|
<a href=/people/a/alexander-koller/>Alexander Koller</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--4><div class="card-body p-3 small">This work addresses <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> in Abstract Meaning Representation (AMR) graphs, a popular formalism for <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>. We evaluate several current coreference resolution techniques on a recently published AMR coreference corpus, establishing baselines for future work. We also demonstrate that <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> can improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of a state-of-the-art <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a> on this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.crac-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.6/>TwiConv : A Coreference-annotated Corpus of Twitter Conversations<span class=acl-fixed-case>T</span>wi<span class=acl-fixed-case>C</span>onv: A Coreference-annotated Corpus of <span class=acl-fixed-case>T</span>witter Conversations</a></strong><br><a href=/people/b/berfin-aktas/>Berfin Aktaş</a>
|
<a href=/people/a/annalena-kohnert/>Annalena Kohnert</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--6><div class="card-body p-3 small">This article introduces TwiConv, an English coreference-annotated corpus of microblog conversations from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. We describe the corpus compilation process and the annotation scheme, and release the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> publicly, along with this paper. We manually annotated nominal coreference in 1756 tweets arranged in 185 conversation threads. The <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> achieves satisfactory <a href=https://en.wikipedia.org/wiki/Annotation>annotation agreement</a> results. We also present a new method for mapping the tweet contents with distributed stand-off annotations, which can easily be adapted to different annotation tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.8/>Reference to Discourse Topics : Introducing Global Shell Nouns</a></strong><br><a href=/people/f/fabian-simonjetz/>Fabian Simonjetz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--8><div class="card-body p-3 small">Shell nouns (SNs) are abstract nouns like fact, issue, and decision, which are capable of refer- ring to non-nominal antecedents, much like <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphoric pronouns</a>. As an extension of classical anaphora resolution, the automatic detection of SNs alongside their respective antecedents has received a growing research interest in recent years but proved to be a challenging task. This paper critically examines the assumption prevalent in previous research that SNs are typically accompanied by a specific antecedent, arguing that SNs like issue and decision are frequently used to refer, not to specific antecedents, but to global discourse topics, in which case they are out of reach of previously proposed resolution strategies that are tailored to SNs with explicit antecedents. The contribution of this work is three-fold. First, the notion of global SNs is defined ; second, their qualitative and quantitative impact on previous SN research is investigated ; and third, implications for previous and future approaches to SN resolution are discussed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.10/>Partially-supervised Mention Detection</a></strong><br><a href=/people/l/lesly-miculicich-werlen/>Lesly Miculicich</a>
|
<a href=/people/j/james-henderson/>James Henderson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--10><div class="card-body p-3 small">Learning to detect entity mentions without using syntactic information can be useful for integration and joint optimization with other tasks. However, it is common to have partially annotated data for this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>. Here, we investigate two approaches to deal with partial annotation of mentions : weighted loss and soft-target classification. We also propose two neural mention detection approaches : a sequence tagging, and an <a href=https://en.wikipedia.org/wiki/Brute-force_search>exhaustive search</a>. We evaluate our methods with <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> as a downstream task, using <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a>. The results show that the <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> and <a href=https://en.wikipedia.org/wiki/F1_score>F1 score</a> improve for all <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.12/>Enhanced Labelling in Active Learning for <a href=https://en.wikipedia.org/wiki/Coreference_resolution>Coreference Resolution</a></a></strong><br><a href=/people/v/vebjorn-espeland/>Vebjørn Espeland</a>
|
<a href=/people/b/beatrice-alex/>Beatrice Alex</a>
|
<a href=/people/b/benjamin-bach/>Benjamin Bach</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--12><div class="card-body p-3 small">In this paper we describe our attempt to increase the amount of information that can be retrieved through active learning sessions compared to previous approaches. We optimise the annotator&#8217;s labelling process using active learning in the context of <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>. Using simulated active learning experiments, we suggest three adjustments to ensure the labelling time is spent as efficiently as possible. All three adjustments provide more information to the machine learner than the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>, though a large impact on the F1 score over time is not observed. Compared to previous <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a>, we report a marginal F1 improvement on the final coreference models trained using for two out of the three approaches tested when applied to the English OntoNotes 2012 Coreference Resolution data. Our best-performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 58.01 <a href=https://en.wikipedia.org/wiki/F-number>F1</a>, an increase of 0.93 F1 over the baseline model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.13/>Reference in Team Communication for Robot-Assisted Disaster Response : An Initial Analysis</a></strong><br><a href=/people/n/natalia-skachkova/>Natalia Skachkova</a>
|
<a href=/people/i/ivana-kruijff-korbayova/>Ivana Kruijff-Korbayova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--13><div class="card-body p-3 small">We analyze reference phenomena in a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of robot-assisted disaster response team communication. The annotation scheme we designed for this purpose distinguishes different types of <a href=https://en.wikipedia.org/wiki/Legal_person>entities</a>, <a href=https://en.wikipedia.org/wiki/Role>roles</a>, reference units and <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a>. We focus particularly on mission-relevant objects, locations and actors and also annotate a rich set of reference links, including <a href=https://en.wikipedia.org/wiki/Co-reference>co-reference</a> and various other kinds of relations. We explain the categories used in our <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, present their distribution in the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and discuss challenging cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.14/>Resolving Pronouns in Twitter Streams : Context can Help !<span class=acl-fixed-case>T</span>witter Streams: Context can Help!</a></strong><br><a href=/people/a/anietie-andy/>Anietie Andy</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a>
|
<a href=/people/d/derry-tanti-wijaya/>Derry Tanti Wijaya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--14><div class="card-body p-3 small">Many people live-tweet televised events like <a href=https://en.wikipedia.org/wiki/United_States_presidential_debates>Presidential debates</a> and popular TV-shows and discuss people or characters in the event. Naturally, many tweets make pronominal reference to these people / characters. We propose an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for resolving <a href=https://en.wikipedia.org/wiki/Personal_pronoun>personal pronouns</a> that make reference to people involved in an event, in tweet streams collected during the event.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.15/>Coreference Strategies in English-German Translation<span class=acl-fixed-case>E</span>nglish-<span class=acl-fixed-case>G</span>erman Translation</a></strong><br><a href=/people/e/ekaterina-lapshinova-koltunski/>Ekaterina Lapshinova-Koltunski</a>
|
<a href=/people/m/marie-pauline-krielke/>Marie-Pauline Krielke</a>
|
<a href=/people/c/christian-hardmeier/>Christian Hardmeier</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--15><div class="card-body p-3 small">We present a study focusing on variation of <a href=https://en.wikipedia.org/wiki/Coreference>coreferential devices</a> in English original <a href=https://en.wikipedia.org/wiki/TED_(conference)>TED talks</a> and <a href=https://en.wikipedia.org/wiki/News>news texts</a> and their <a href=https://en.wikipedia.org/wiki/German_language>German translations</a>. Using exploratory techniques we contemplate a diverse set of coreference devices as <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> which we assume indicate language-specific and register-based variation as well as potential translation strategies. Our findings reflect differences on both dimensions with stronger variation along the lines of <a href=https://en.wikipedia.org/wiki/Register_(sociolinguistics)>register</a> than between languages. By exposing interactions between text type and cross-linguistic variation, they can also inform multilingual NLP applications, especially <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>