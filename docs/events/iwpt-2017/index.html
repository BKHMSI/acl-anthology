<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>International Conference on Parsing Technologies (2017) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>International Conference on Parsing Technologies (2017)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#w17-63>Proceedings of the 15th International Conference on Parsing Technologies</a>
<span class="badge badge-info align-middle ml-1">16&nbsp;papers</span></li></ul></div></div><div id=w17-63><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-63.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/W17-63/>Proceedings of the 15th International Conference on Parsing Technologies</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6300/>Proceedings of the 15th International Conference on Parsing Technologies</a></strong><br><a href=/people/y/yusuke-miyao/>Yusuke Miyao</a>
|
<a href=/people/k/kenji-sagae/>Kenji Sagae</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6301.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6301 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6301 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6301/>Automatically Acquired Lexical Knowledge Improves Japanese Joint Morphological and Dependency Analysis<span class=acl-fixed-case>J</span>apanese Joint Morphological and Dependency Analysis</a></strong><br><a href=/people/d/daisuke-kawahara/>Daisuke Kawahara</a>
|
<a href=/people/y/yuta-hayashibe/>Yuta Hayashibe</a>
|
<a href=/people/h/hajime-morita/>Hajime Morita</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6301><div class="card-body p-3 small">This paper presents a joint model for morphological and dependency analysis based on automatically acquired lexical knowledge. This model takes advantage of rich lexical knowledge to simultaneously resolve <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a>, POS, and dependency ambiguities. In our experiments on <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, we show the effectiveness of our joint model over conventional pipeline models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6302.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6302 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6302 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6302/>Dependency Language Models for Transition-based Dependency Parsing</a></strong><br><a href=/people/j/juntao-yu/>Juntao Yu</a>
|
<a href=/people/b/bernd-bohnet/>Bernd Bohnet</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6302><div class="card-body p-3 small">In this paper, we present an approach to improve the accuracy of a strong transition-based dependency parser by exploiting dependency language models that are extracted from a large parsed corpus. We integrated a small number of <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> based on the dependency language models into the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>. To demonstrate the effectiveness of the proposed approach, we evaluate our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> on standard English and Chinese data where the base parser could achieve competitive accuracy scores. Our enhanced <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> achieved state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese data</a> and competitive results on <a href=https://en.wikipedia.org/wiki/English_language>English data</a>. We gained a large absolute improvement of one point (UAS) on <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> and 0.5 points for <a href=https://en.wikipedia.org/wiki/English_language>English</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6303.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6303 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6303 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6303/>Lexicalized vs. Delexicalized Parsing in Low-Resource Scenarios</a></strong><br><a href=/people/a/agnieszka-falenska/>Agnieszka Falenska</a>
|
<a href=/people/o/ozlem-cetinoglu/>Özlem Çetinoğlu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6303><div class="card-body p-3 small">We present a systematic analysis of <a href=https://en.wikipedia.org/wiki/Lexicalization>lexicalized vs. delexicalized parsing</a> in low-resource scenarios, and propose a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to choose one method over another under certain conditions. We create a set of simulation experiments on 41 languages and apply our findings to 9 low-resource languages. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> chooses the best approach in 8 out of 9 cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6305.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6305 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6305 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6305/>Prepositional Phrase Attachment over Word Embedding Products</a></strong><br><a href=/people/p/pranava-swaroop-madhyastha/>Pranava Swaroop Madhyastha</a>
|
<a href=/people/x/xavier-carreras/>Xavier Carreras</a>
|
<a href=/people/a/ariadna-quattoni/>Ariadna Quattoni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6305><div class="card-body p-3 small">We present a low-rank multi-linear model for the task of solving prepositional phrase attachment ambiguity (PP task). Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> exploits tensor products of word embeddings, capturing all possible conjunctions of latent embeddings. Our results on a wide range of datasets and task settings show that <a href=https://en.wikipedia.org/wiki/Tensor_product>tensor products</a> are the best compositional operation and that a relatively simple multi-linear model that uses only word embeddings of lexical features can outperform more complex non-linear architectures that exploit the same information. Our proposed model gives the current best reported performance on an out-of-domain evaluation and performs competively on out-of-domain dependency parsing datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6306.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6306 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6306 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6306/>L1-L2 Parallel Dependency Treebank as Learner Corpus<span class=acl-fixed-case>L</span>1-<span class=acl-fixed-case>L</span>2 Parallel Dependency Treebank as Learner Corpus</a></strong><br><a href=/people/j/john-s-y-lee/>John Lee</a>
|
<a href=/people/k/keying-li/>Keying Li</a>
|
<a href=/people/h/herman-leung/>Herman Leung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6306><div class="card-body p-3 small">This opinion paper proposes the use of parallel treebank as learner corpus. We show how an L1-L2 parallel treebank i.e., <a href=https://en.wikipedia.org/wiki/Parse_tree>parse trees</a> of non-native sentences, aligned to the <a href=https://en.wikipedia.org/wiki/Parse_tree>parse trees</a> of their target hypotheses can facilitate retrieval of sentences with specific learner errors. We argue for its benefits, in terms of corpus re-use and interoperability, over a conventional learner corpus annotated with error tags. As a proof of concept, we conduct a case study on word-order errors made by learners of <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> as a foreign language. We report <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>precision</a> and <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> in retrieving a range of word-order error categories from L1-L2 tree pairs annotated in the Universal Dependency framework.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6307.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6307 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6307 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6307/>Splitting Complex English Sentences<span class=acl-fixed-case>E</span>nglish Sentences</a></strong><br><a href=/people/j/john-s-y-lee/>John Lee</a>
|
<a href=/people/j/j-buddhika-k-pathirage-don/>J. Buddhika K. Pathirage Don</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6307><div class="card-body p-3 small">This paper applies parsing technology to the task of syntactic simplification of English sentences, focusing on the identification of text spans that can be removed from a complex sentence. We report the most comprehensive evaluation to-date on this task, using a dataset of sentences that exhibit simplification based on coordination, subordination, punctuation / parataxis, adjectival clauses, participial phrases, and appositive phrases. We train a <a href=https://en.wikipedia.org/wiki/Decision_tree>decision tree</a> with features derived from text span length, POS tags and dependency relations, and show that it significantly outperforms a parser-only baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6308.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6308 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6308 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6308/>Hierarchical Word Structure-based Parsing : A Feasibility Study on UD-style Dependency Parsing in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a><span class=acl-fixed-case>UD</span>-style Dependency Parsing in <span class=acl-fixed-case>J</span>apanese</a></strong><br><a href=/people/t/takaaki-tanaka/>Takaaki Tanaka</a>
|
<a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6308><div class="card-body p-3 small">In applying word-based dependency parsing such as Universal Dependencies (UD) to <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, the uncertainty of <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> emerges for defining a word unit of the dependencies. We introduce the following hierarchical word structures to dependency parsing in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> : morphological units (a short unit word, SUW) and syntactic units (a long unit word, LUW). An SUW can be used to segment a sentence consistently, while it is too short to represent syntactic construction. An LUW is a unit including functional multiwords and LUW-based analysis facilitates the capturing of syntactic structure and makes <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> results more precise than SUW-based analysis. This paper describes the results of a feasibility study on the ability and the effectiveness of parsing methods based on hierarchical word structure (LUW chunking+parsing) in comparison to single layer word structure (SUW parsing). We also show joint analysis of LUW-chunking and dependency parsing improves the performance of identifying predicate-argument structures, while there is not much difference between overall results of them. not much difference between overall results of them.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6309.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6309 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6309 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6309/>Leveraging Newswire Treebanks for Parsing Conversational Data with Argument Scrambling</a></strong><br><a href=/people/r/riyaz-ahmad-bhat/>Riyaz A. Bhat</a>
|
<a href=/people/i/irshad-bhat/>Irshad Bhat</a>
|
<a href=/people/d/dipti-misra-sharma/>Dipti Sharma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6309><div class="card-body p-3 small">We investigate the problem of parsing conversational data of morphologically-rich languages such as <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> where argument scrambling occurs frequently. We evaluate a state-of-the-art non-linear transition-based parsing system on a new dataset containing 506 dependency trees for sentences from Bollywood (Hindi) movie scripts and Twitter posts of Hindi monolingual speakers. We show that a <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parser</a> trained on a newswire treebank is strongly biased towards the <a href=https://en.wikipedia.org/wiki/Canonical_form>canonical structures</a> and degrades when applied to conversational data. Inspired by <a href=https://en.wikipedia.org/wiki/Transformational_grammar>Transformational Generative Grammar</a> (Chomsky, 1965), we mitigate the <a href=https://en.wikipedia.org/wiki/Sampling_bias>sampling bias</a> by generating all theoretically possible alternative word orders of a clause from the existing (kernel) structures in the <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a>. Training our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> on canonical and transformed structures improves performance on conversational data by around 9 % LAS over the baseline newswire parser.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6310.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6310 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6310 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-6310" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-6310/>Using <a href=https://en.wikipedia.org/wiki/Hyperlink>hyperlinks</a> to improve multilingual partial parsers</a></strong><br><a href=/people/a/anders-sogaard/>Anders Søgaard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6310><div class="card-body p-3 small">Syntactic annotation is costly and not available for the vast majority of the world&#8217;s languages. We show that sometimes we can do away with less labeled data by exploiting more readily available forms of <a href=https://en.wikipedia.org/wiki/Markup_language>mark-up</a>. Specifically, we revisit an idea from Valentin Spitkovsky&#8217;s work (2010), namely that <a href=https://en.wikipedia.org/wiki/Hyperlink>hyperlinks</a> typically bracket syntactic constituents or chunks. We strengthen his results by showing that not only can <a href=https://en.wikipedia.org/wiki/Hyperlink>hyperlinks</a> help in low resource scenarios, exemplified here by Quechua, but learning from <a href=https://en.wikipedia.org/wiki/Hyperlink>hyperlinks</a> can also improve state-of-the-art NLP models for English newswire. We also present out-of-domain evaluation on English Ontonotes 4.0.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6311.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6311 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6311 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6311/>Correcting prepositional phrase attachments using multimodal corpora</a></strong><br><a href=/people/s/sebastien-delecraz/>Sebastien Delecraz</a>
|
<a href=/people/a/alexis-nasr/>Alexis Nasr</a>
|
<a href=/people/f/frederic-bechet/>Frederic Bechet</a>
|
<a href=/people/b/benoit-favre/>Benoit Favre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6311><div class="card-body p-3 small">PP-attachments are an important source of errors in parsing <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. We propose in this article to use data coming from a multimodal corpus, combining textual, visual and conceptual information, as well as a correction strategy, to propose alternative attachments in the output of a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6312.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6312 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6312 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6312/>Exploiting Structure in <a href=https://en.wikipedia.org/wiki/Parsing>Parsing</a> to 1-Endpoint-Crossing Graphs</a></strong><br><a href=/people/r/robin-kurtz/>Robin Kurtz</a>
|
<a href=/people/m/marco-kuhlmann/>Marco Kuhlmann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6312><div class="card-body p-3 small">Deep dependency parsing can be cast as the search for maximum acyclic subgraphs in weighted digraphs. Because this search problem is intractable in the general case, we consider its restriction to the class of 1-endpoint-crossing (1ec) graphs, which has high coverage on standard data sets. Our main contribution is a characterization of 1ec graphs as a subclass of the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a> with pagenumber at most 3. Building on this we show how to extend an existing <a href=https://en.wikipedia.org/wiki/Parsing>parsing algorithm</a> for 1-endpoint-crossing trees to the full class. While the <a href=https://en.wikipedia.org/wiki/Time_complexity>runtime complexity</a> of the extended <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> is polynomial in the length of the input sentence, it features a large constant, which poses a challenge for practical implementations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6313.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6313 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6313 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6313/>Effective Online Reordering with Arc-Eager Transitions</a></strong><br><a href=/people/r/ryosuke-kohita/>Ryosuke Kohita</a>
|
<a href=/people/h/hiroshi-noji/>Hiroshi Noji</a>
|
<a href=/people/y/yuji-matsumoto/>Yuji Matsumoto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6313><div class="card-body p-3 small">We present a new <a href=https://en.wikipedia.org/wiki/Transition_system>transition system</a> with word reordering for unrestricted non-projective dependency parsing. Our system is based on decomposed arc-eager rather than arc-standard, which allows more flexible ambiguity resolution between a local projective and non-local crossing attachment. In our experiment on Universal Dependencies 2.0, we find our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> outperforms the ordinary swap-based parser particularly on languages with a large amount of non-projectivity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6314.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6314 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6314 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-6314.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-6314" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-6314/>Arc-Hybrid Non-Projective Dependency Parsing with a Static-Dynamic Oracle</a></strong><br><a href=/people/m/miryam-de-lhoneux/>Miryam de Lhoneux</a>
|
<a href=/people/s/sara-stymne/>Sara Stymne</a>
|
<a href=/people/j/joakim-nivre/>Joakim Nivre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6314><div class="card-body p-3 small">In this paper, we extend the arc-hybrid system for transition-based parsing with a swap transition that enables reordering of the words and construction of non-projective trees. Although this extension breaks the arc-decomposability of the transition system, we show how the existing dynamic oracle for this <a href=https://en.wikipedia.org/wiki/System>system</a> can be modified and combined with a static oracle only for the swap transition. Experiments on 5 languages show that the new <a href=https://en.wikipedia.org/wiki/System>system</a> gives competitive accuracy and is significantly better than a <a href=https://en.wikipedia.org/wiki/System>system</a> trained with a purely static oracle.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6315.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6315 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6315 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-6315" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-6315/>Encoder-Decoder Shift-Reduce Syntactic Parsing</a></strong><br><a href=/people/j/jiangming-liu/>Jiangming Liu</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6315><div class="card-body p-3 small">Encoder-decoder neural networks have been used for many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP tasks</a>, such as <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. They have also been applied to constituent parsing by using bracketed tree structures as a target language, translating input sentences into syntactic trees. A more commonly used method to linearize syntactic trees is the shift-reduce system, which uses a sequence of transition-actions to build <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>trees</a>. We empirically investigate the effectiveness of applying the encoder-decoder network to transition-based parsing. On standard benchmarks, our system gives comparable results to the stack LSTM parser for dependency parsing, and significantly better results compared to the aforementioned <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> for constituent parsing, which uses bracketed tree formats.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6318.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6318 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6318 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6318/>Evaluating LSTM models for grammatical function labelling<span class=acl-fixed-case>LSTM</span> models for grammatical function labelling</a></strong><br><a href=/people/b/bich-ngoc-do/>Bich-Ngoc Do</a>
|
<a href=/people/i/ines-rehbein/>Ines Rehbein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6318><div class="card-body p-3 small">To improve grammatical function labelling for <a href=https://en.wikipedia.org/wiki/German_language>German</a>, we augment the labelling component of a neural dependency parser with a decision history. We present different ways to encode the history, using different LSTM architectures, and show that our models yield significant improvements, resulting in a LAS for <a href=https://en.wikipedia.org/wiki/German_language>German</a> that is close to the best result from the SPMRL 2014 shared task (without the reranker).</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>