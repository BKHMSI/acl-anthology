<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Clinical Natural Language Processing Workshop (2020) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Clinical Natural Language Processing Workshop (2020)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2020clinicalnlp-1>Proceedings of the 3rd Clinical Natural Language Processing Workshop</a>
<span class="badge badge-info align-middle ml-1">15&nbsp;papers</span></li></ul></div></div><div id=2020clinicalnlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.clinicalnlp-1/>Proceedings of the 3rd Clinical Natural Language Processing Workshop</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.0/>Proceedings of the 3rd Clinical Natural Language Processing Workshop</a></strong><br><a href=/people/a/anna-rumshisky/>Anna Rumshisky</a>
|
<a href=/people/k/kirk-roberts/>Kirk Roberts</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a>
|
<a href=/people/t/tristan-naumann/>Tristan Naumann</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939817 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.1/>Various Approaches for Predicting Stroke Prognosis using Magnetic Resonance Imaging Text Records</a></strong><br><a href=/people/t/tak-sung-heo/>Tak-Sung Heo</a>
|
<a href=/people/c/chulho-kim/>Chulho Kim</a>
|
<a href=/people/j/jeong-myeong-choi/>Jeong-Myeong Choi</a>
|
<a href=/people/y/yeong-seok-jeong/>Yeong-Seok Jeong</a>
|
<a href=/people/y/yu-seop-kim/>Yu-Seop Kim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--1><div class="card-body p-3 small">Stroke is one of the leading causes of death and disability worldwide. Stroke is treatable, but <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is prone to disability after treatment and must be prevented. To grasp the degree of disability caused by <a href=https://en.wikipedia.org/wiki/Stroke>stroke</a>, we use magnetic resonance imaging text records to predict <a href=https://en.wikipedia.org/wiki/Stroke>stroke</a> and measure the performance according to the document-level and sentence-level representation. As a result of the experiment, the document-level representation shows better performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939836 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.3/>BERT-XML : Large Scale Automated ICD Coding Using BERT Pretraining<span class=acl-fixed-case>BERT</span>-<span class=acl-fixed-case>XML</span>: Large Scale Automated <span class=acl-fixed-case>ICD</span> Coding Using <span class=acl-fixed-case>BERT</span> Pretraining</a></strong><br><a href=/people/z/zachariah-zhang/>Zachariah Zhang</a>
|
<a href=/people/j/jingshu-liu/>Jingshu Liu</a>
|
<a href=/people/n/narges-razavian/>Narges Razavian</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--3><div class="card-body p-3 small">ICD coding is the task of classifying and cod-ing all diagnoses, symptoms and proceduresassociated with a patient&#8217;s visit. The process isoften manual, extremely time-consuming andexpensive for hospitals as clinical interactionsare usually recorded in free text medical notes. In this paper, we propose a machine learningmodel, BERT-XML, for large scale automatedICD coding of EHR notes, utilizing recentlydeveloped unsupervised pretraining that haveachieved state of the art performance on a va-riety of NLP tasks. We train a BERT modelfrom scratch on EHR notes, learning with vo-cabulary better suited for EHR tasks and thusoutperform off-the-shelf models. We furtheradapt the BERT architecture for ICD codingwith multi-label attention. We demonstratethe effectiveness of BERT-based models on thelarge scale ICD code classification task usingmillions of EHR notes to predict thousands ofunique codes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939823 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.4/>Incorporating Risk Factor Embeddings in Pre-trained Transformers Improves Sentiment Prediction in Psychiatric Discharge Summaries</a></strong><br><a href=/people/x/xiyu-ding/>Xiyu Ding</a>
|
<a href=/people/m/mei-hua-hall/>Mei-Hua Hall</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--4><div class="card-body p-3 small">Reducing rates of early hospital readmission has been recognized and identified as a key to improve quality of care and reduce costs. There are a number of <a href=https://en.wikipedia.org/wiki/Risk_factor>risk factors</a> that have been hypothesized to be important for understanding re-admission risk, including such factors as problems with substance abuse, ability to maintain work, relations with family. In this work, we develop Roberta-based models to predict the sentiment of sentences describing readmission risk factors in discharge summaries of patients with psychosis. We improve substantially on previous results by a scheme that shares information across <a href=https://en.wikipedia.org/wiki/Risk_factor>risk factors</a> while also allowing the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to learn risk factor-specific information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939829 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.7/>BioBERTpt-A Portuguese Neural Language Model for Clinical Named Entity Recognition<span class=acl-fixed-case>B</span>io<span class=acl-fixed-case>BERT</span>pt - A <span class=acl-fixed-case>P</span>ortuguese Neural Language Model for Clinical Named Entity Recognition</a></strong><br><a href=/people/e/elisa-terumi-rubel-schneider/>Elisa Terumi Rubel Schneider</a>
|
<a href=/people/j/joao-vitor-andrioli-de-souza/>João Vitor Andrioli de Souza</a>
|
<a href=/people/j/julien-knafou/>Julien Knafou</a>
|
<a href=/people/l/lucas-emanuel-silva-e-oliveira/>Lucas Emanuel Silva e Oliveira</a>
|
<a href=/people/j/jenny-copara/>Jenny Copara</a>
|
<a href=/people/y/yohan-bonescki-gumiel/>Yohan Bonescki Gumiel</a>
|
<a href=/people/l/lucas-ferro-antunes-de-oliveira/>Lucas Ferro Antunes de Oliveira</a>
|
<a href=/people/e/emerson-cabrera-paraiso/>Emerson Cabrera Paraiso</a>
|
<a href=/people/d/douglas-teodoro/>Douglas Teodoro</a>
|
<a href=/people/c/claudia-maria-cabral-moro-barra/>Cláudia Maria Cabral Moro Barra</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--7><div class="card-body p-3 small">With the growing number of <a href=https://en.wikipedia.org/wiki/Electronic_health_record>electronic health record data</a>, clinical NLP tasks have become increasingly relevant to unlock valuable information from unstructured clinical text. Although the performance of downstream NLP tasks, such as named-entity recognition (NER), in English corpus has recently improved by contextualised language models, less research is available for clinical texts in low resource languages. Our goal is to assess a deep contextual embedding model for <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese</a>, so called BioBERTpt, to support clinical and biomedical NER. We transfer learned information encoded in a multilingual-BERT model to a corpora of clinical narratives and biomedical-scientific papers in <a href=https://en.wikipedia.org/wiki/Brazilian_Portuguese>Brazilian Portuguese</a>. To evaluate the performance of BioBERTpt, we ran NER experiments on two annotated corpora containing clinical narratives and compared the results with existing BERT models. Our in-domain model outperformed the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline model</a> in <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> by 2.72 %, achieving higher performance in 11 out of 13 assessed entities. We demonstrate that enriching contextual embedding models with domain literature can play an important role in improving performance for specific NLP tasks. The transfer learning process enhanced the Portuguese biomedical NER model by reducing the necessity of labeled data and the demand for retraining a whole new <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939814 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.13/>How You Ask Matters : The Effect of Paraphrastic Questions to BERT Performance on a Clinical SQuAD Dataset<span class=acl-fixed-case>BERT</span> Performance on a Clinical <span class=acl-fixed-case>SQ</span>u<span class=acl-fixed-case>AD</span> Dataset</a></strong><br><a href=/people/s/sungrim-riea-moon/>Sungrim (Riea) Moon</a>
|
<a href=/people/j/jungwei-fan/>Jungwei Fan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--13><div class="card-body p-3 small">Reading comprehension style question-answering (QA) based on patient-specific documents represents a growing area in clinical NLP with plentiful applications. Bidirectional Encoder Representations from Transformers (BERT) and its derivatives lead the state-of-the-art accuracy on the task, but most evaluation has treated the data as a pre-mixture without systematically looking into the potential effect of imperfect train / test questions. The current study seeks to address this gap by experimenting with full versus partial train / test data consisting of paraphrastic questions. Our key findings include 1) training with all pooled question variants yielded best <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, 2) the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> varied widely, from 0.74 to 0.80, when trained with each single question variant, and 3) questions of similar lexical / syntactic structure tended to induce identical answers. The results suggest that how you ask questions matters in BERT-based QA, especially at the training stage.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.clinicalnlp-1.15.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939819 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.clinicalnlp-1.15" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.15/>MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining<span class=acl-fixed-case>M</span>e<span class=acl-fixed-case>DAL</span>: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a></strong><br><a href=/people/z/zhi-wen/>Zhi Wen</a>
|
<a href=/people/x/xing-han-lu/>Xing Han Lu</a>
|
<a href=/people/s/siva-reddy/>Siva Reddy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--15><div class="card-body p-3 small">One of the biggest challenges that prohibit the use of many current <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP methods</a> in clinical settings is the availability of <a href=https://en.wikipedia.org/wiki/Data_set>public datasets</a>. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a> pre-training in the medical domain. We pre-trained several models of common architectures on this dataset and empirically showed that such pre-training leads to improved performance and <a href=https://en.wikipedia.org/wiki/Convergence_of_random_variables>convergence speed</a> when <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> on downstream medical tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939827 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.21/>Extracting Relations between Radiotherapy Treatment Details</a></strong><br><a href=/people/d/danielle-bitterman/>Danielle Bitterman</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a>
|
<a href=/people/d/david-harris/>David Harris</a>
|
<a href=/people/c/chen-lin/>Chen Lin</a>
|
<a href=/people/s/sean-finan/>Sean Finan</a>
|
<a href=/people/j/jeremy-warner/>Jeremy Warner</a>
|
<a href=/people/r/raymond-mak/>Raymond Mak</a>
|
<a href=/people/g/guergana-savova/>Guergana Savova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--21><div class="card-body p-3 small">We present work on extraction of radiotherapy treatment information from the clinical narrative in the <a href=https://en.wikipedia.org/wiki/Electronic_health_record>electronic medical records</a>. Radiotherapy is a central component of the treatment of most solid cancers. Its details are described in non-standardized fashions using jargon not found in other medical specialties, complicating the already difficult task of manual data extraction. We examine the performance of several state-of-the-art neural methods for relation extraction of radiotherapy treatment details, with a goal of automating detailed information extraction. The <a href=https://en.wikipedia.org/wiki/Nervous_system>neural systems</a> perform at 0.82-0.88 macro-average F1, which approximates or in some cases exceeds the <a href=https://en.wikipedia.org/wiki/Inter-annotator_agreement>inter-annotator agreement</a>. To the best of our knowledge, this is the first effort to develop models for radiotherapy relation extraction and one of the few efforts for <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a> to describe <a href=https://en.wikipedia.org/wiki/Treatment_of_cancer>cancer treatment</a> in general.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939830 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.22/>Cancer Registry Information Extraction via <a href=https://en.wikipedia.org/wiki/Transfer_learning>Transfer Learning</a></a></strong><br><a href=/people/y/yan-jie-lin/>Yan-Jie Lin</a>
|
<a href=/people/h/hong-jie-dai/>Hong-Jie Dai</a>
|
<a href=/people/y/you-chen-zhang/>You-Chen Zhang</a>
|
<a href=/people/c/chung-yang-wu/>Chung-Yang Wu</a>
|
<a href=/people/y/yu-cheng-chang/>Yu-Cheng Chang</a>
|
<a href=/people/p/pin-jou-lu/>Pin-Jou Lu</a>
|
<a href=/people/c/chih-jen-huang/>Chih-Jen Huang</a>
|
<a href=/people/y/yu-tsang-wang/>Yu-Tsang Wang</a>
|
<a href=/people/h/hui-min-hsieh/>Hui-Min Hsieh</a>
|
<a href=/people/k/kun-san-chao/>Kun-San Chao</a>
|
<a href=/people/t/tsang-wu-liu/>Tsang-Wu Liu</a>
|
<a href=/people/i/i-shou-chang/>I-Shou Chang</a>
|
<a href=/people/y/yi-hsin-connie-yang/>Yi-Hsin Connie Yang</a>
|
<a href=/people/t/ti-hao-wang/>Ti-Hao Wang</a>
|
<a href=/people/k/ko-jiunn-liu/>Ko-Jiunn Liu</a>
|
<a href=/people/l/li-tzong-chen/>Li-Tzong Chen</a>
|
<a href=/people/s/sheau-fang-yang/>Sheau-Fang Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--22><div class="card-body p-3 small">A <a href=https://en.wikipedia.org/wiki/Cancer_registry>cancer registry</a> is a critical and massive database for which various types of <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> are needed and whose maintenance requires labor-intensive <a href=https://en.wikipedia.org/wiki/Data_curation>data curation</a>. In order to facilitate the curation process for building a high-quality and integrated cancer registry database, we compiled a cross-hospital corpus and applied neural network methods to develop a natural language processing system for extracting cancer registry variables buried in unstructured pathology reports. The performance of the developed networks was compared with various baselines using standard <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>micro-precision</a>, recall and <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a>. Furthermore, we conducted experiments to study the feasibility of applying <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> to rapidly develop a well-performing <a href=https://en.wikipedia.org/wiki/System>system</a> for processing reports from different sources that might be presented in different writing styles and formats. The results demonstrate that the transfer learning method enables us to develop a satisfactory <a href=https://en.wikipedia.org/wiki/System>system</a> for a new hospital with only a few annotations and suggest more opportunities to reduce the burden of <a href=https://en.wikipedia.org/wiki/Cancer_registry>cancer registry curation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939833 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.24/>Where’s the Question? A Multi-channel Deep Convolutional Neural Network for Question Identification in Textual Data</a></strong><br><a href=/people/g/george-michalopoulos/>George Michalopoulos</a>
|
<a href=/people/h/helen-chen/>Helen Chen</a>
|
<a href=/people/a/alexander-wong/>Alexander Wong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--24><div class="card-body p-3 small">In most clinical practice settings, there is no rigorous reviewing of the clinical documentation, resulting in inaccurate information captured in the patient medical records. The gold standard in clinical data capturing is achieved via expert-review, where clinicians can have a dialogue with a domain expert (reviewers) and ask them questions about data entry rules. Automatically identifying real questions in these dialogues could uncover ambiguities or common problems in data capturing in a given clinical setting. In this study, we proposed a novel multi-channel deep convolutional neural network architecture, namely Quest-CNN, for the purpose of separating real questions that expect an answer (information or help) about an issue from sentences that are not questions, as well as from questions referring to an issue mentioned in a nearby sentence (e.g., can you clarify this?), which we will refer as c-questions. We conducted a comprehensive performance comparison analysis of the proposed multi-channel deep convolutional neural network against other <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a>. Furthermore, we evaluated the performance of traditional rule-based and learning-based methods for detecting question sentences. The proposed Quest-CNN achieved the best F1 score both on a dataset of data entry-review dialogue in a dialysis care setting, and on a general domain dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939816 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.28/>An Ensemble Approach for Automatic Structuring of Radiology Reports</a></strong><br><a href=/people/m/morteza-pourreza-shahri/>Morteza Pourreza Shahri</a>
|
<a href=/people/a/amir-tahmasebi/>Amir Tahmasebi</a>
|
<a href=/people/b/bingyang-ye/>Bingyang Ye</a>
|
<a href=/people/h/henghui-zhu/>Henghui Zhu</a>
|
<a href=/people/j/javed-aslam/>Javed Aslam</a>
|
<a href=/people/t/timothy-ferris/>Timothy Ferris</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--28><div class="card-body p-3 small">Automatic structuring of electronic medical records is of high demand for clinical workflow solutions to facilitate extraction, storage, and querying of patient care information. However, developing a scalable solution is extremely challenging, specifically for radiology reports, as most healthcare institutes use either no template or department / institute specific templates. Moreover, radiologists&#8217; reporting style varies from one to another as sentences are written in a telegraphic format and do not follow general English grammar rules. In this work, we present an <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble method</a> that consolidates the predictions of three models, capturing various attributes of textual information for automatic labeling of sentences with section labels. These three models are : 1) Focus Sentence model, capturing context of the target sentence ; 2) Surrounding Context model, capturing the neighboring context of the target sentence ; and finally, 3) Formatting / Layout model, aimed at learning report formatting cues. We utilize Bi-directional LSTMs, followed by sentence encoders, to acquire the context. Furthermore, we define several <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> that incorporate the structure of reports. We compare our proposed approach against multiple baselines and state-of-the-art approaches on a proprietary dataset as well as 100 manually annotated radiology notes from the MIMIC-III dataset, which we are making publicly available. Our proposed <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a> significantly outperforms other <a href=https://en.wikipedia.org/wiki/Scientific_method>approaches</a> by achieving 97.1 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.30.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--30 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.30 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939834 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.30/>Advancing Seq2seq with Joint Paraphrase Learning</a></strong><br><a href=/people/s/so-yeon-min/>So Yeon Min</a>
|
<a href=/people/p/preethi-raghavan/>Preethi Raghavan</a>
|
<a href=/people/p/peter-szolovits/>Peter Szolovits</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--30><div class="card-body p-3 small">We address the problem of model generalization for sequence to sequence (seq2seq) architectures. We propose going beyond <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> via paraphrase-optimized multi-task learning and observe that it is useful in correctly handling unseen sentential paraphrases as inputs. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> greatly outperform SOTA seq2seq models for <a href=https://en.wikipedia.org/wiki/Semantic_analysis_(linguistics)>semantic parsing</a> on diverse domains (Overnight-up to 3.2 % and emrQA-7 %) and <a href=https://en.wikipedia.org/wiki/Nematus>Nematus</a>, the winning solution for WMT 2017, for <a href=https://en.wikipedia.org/wiki/Czech_language>Czech to English translation</a> (CzENG 1.6-1.5 BLEU).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.31.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--31 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.31 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939812 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.31/>On the diminishing return of labeling clinical reports</a></strong><br><a href=/people/j/jean-baptiste-lamare/>Jean-Baptiste Lamare</a>
|
<a href=/people/o/oloruntobiloba-olatunji/>Oloruntobiloba Olatunji</a>
|
<a href=/people/l/li-yao/>Li Yao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--31><div class="card-body p-3 small">Ample evidence suggests that better machine learning models may be steadily obtained by training on increasingly larger datasets on natural language processing (NLP) problems from non-medical domains. Whether the same holds true for medical NLP has by far not been thoroughly investigated. This work shows that this is indeed not always the case. We reveal the somehow counter-intuitive observation that performant medical NLP models may be obtained with small amount of labeled data, quite the opposite to the common belief, most likely due to the domain specificity of the problem. We show quantitatively the effect of training data size on a fixed test set composed of two of the largest public chest x-ray radiology report datasets on the task of abnormality classification. The trained <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> not only make use of the training data efficiently, but also outperform the current state-of-the-art <a href=https://en.wikipedia.org/wiki/Rule-based_system>rule-based systems</a> by a significant margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939828 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.32/>The Chilean Waiting List Corpus : a new resource for clinical Named Entity Recognition in Spanish<span class=acl-fixed-case>C</span>hilean Waiting List Corpus: a new resource for clinical Named Entity Recognition in <span class=acl-fixed-case>S</span>panish</a></strong><br><a href=/people/p/pablo-baez/>Pablo Báez</a>
|
<a href=/people/f/fabian-villena/>Fabián Villena</a>
|
<a href=/people/m/matias-rojas/>Matías Rojas</a>
|
<a href=/people/m/manuel-duran/>Manuel Durán</a>
|
<a href=/people/j/jocelyn-dunstan/>Jocelyn Dunstan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--32><div class="card-body p-3 small">In this work we describe the Waiting List Corpus consisting of de-identified referrals for several specialty consultations from the waiting list in Chilean public hospitals. A subset of 900 referrals was manually annotated with 9,029 entities, 385 attributes, and 284 pairs of relations with clinical relevance. A trained medical doctor annotated these referrals, and then together with other three researchers, consolidated each of the annotations. The annotated corpus has nested entities, with 32.2 % of entities embedded in other entities. We use this annotated corpus to obtain preliminary results for Named Entity Recognition (NER). The best results were achieved by using a biLSTM-CRF architecture using word embeddings trained over <a href=https://en.wikipedia.org/wiki/Spanish_Wikipedia>Spanish Wikipedia</a> together with clinical embeddings computed by the group. NER models applied to this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> can leverage statistics of diseases and pending procedures within this waiting list. This work constitutes the first <a href=https://en.wikipedia.org/wiki/Text_corpus>annotated corpus</a> using clinical narratives from <a href=https://en.wikipedia.org/wiki/Chile>Chile</a>, and one of the few for the <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish language</a>. The annotated corpus, the clinical word embeddings, and the annotation guidelines are freely released to the research community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clinicalnlp-1.33.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clinicalnlp-1--33 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clinicalnlp-1.33 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939838 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.clinicalnlp-1.33" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.clinicalnlp-1.33/>Exploring Text Specific and Blackbox Fairness Algorithms in Multimodal Clinical NLP<span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/j/john-chen/>John Chen</a>
|
<a href=/people/i/ian-berlot-attwell/>Ian Berlot-Attwell</a>
|
<a href=/people/x/xindi-wang/>Xindi Wang</a>
|
<a href=/people/s/safwan-hossain/>Safwan Hossain</a>
|
<a href=/people/f/frank-rudzicz/>Frank Rudzicz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clinicalnlp-1--33><div class="card-body p-3 small">Clinical machine learning is increasingly multimodal, collected in both structured tabular formats and <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured forms</a> such as free text. We propose a novel task of exploring fairness on a multimodal clinical dataset, adopting equalized odds for the downstream medical prediction tasks. To this end, we investigate a modality-agnostic fairness algorithm-equalized odds post processing-and compare it to a text-specific fairness algorithm : debiased clinical word embeddings. Despite the fact that debiased word embeddings do not explicitly address equalized odds of protected groups, we show that a text-specific approach to <a href=https://en.wikipedia.org/wiki/Social_justice>fairness</a> may simultaneously achieve a good balance of performance classical notions of <a href=https://en.wikipedia.org/wiki/Social_justice>fairness</a>. Our work opens the door for future work at the critical intersection of clinical NLP and <a href=https://en.wikipedia.org/wiki/Social_justice>fairness</a>.<i>fairness</i> on a multimodal clinical dataset, adopting <i>equalized odds</i> for the downstream medical prediction tasks. To this end, we investigate a modality-agnostic fairness algorithm - equalized odds post processing - and compare it to a text-specific fairness algorithm: debiased clinical word embeddings. Despite the fact that debiased word embeddings do not explicitly address equalized odds of protected groups, we show that a text-specific approach to fairness may simultaneously achieve a good balance of performance classical notions of fairness. Our work opens the door for future work at the critical intersection of clinical NLP and fairness.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>