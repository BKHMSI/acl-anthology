<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>International Conference Recent Advances in Natural Language Processing (2019) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>International Conference Recent Advances in Natural Language Processing (2019)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#r19-1>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a>
<span class="badge badge-info align-middle ml-1">72&nbsp;papers</span></li><li><a class=align-middle href=#r19-2>Proceedings of the Student Research Workshop Associated with RANLP 2019</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#w19-87>Proceedings of the Human-Informed Translation and Interpreting Technology Workshop (HiT-IT 2019)</a>
<span class="badge badge-info align-middle ml-1">8&nbsp;papers</span></li><li><a class=align-middle href=#w19-89>Proceedings of the Workshop MultiLing 2019: Summarization Across Languages, Genres and Sources</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#w19-90>Proceedings of the Workshop on Language Technology for Digital Historical Archives</a>
<span class="badge badge-info align-middle ml-1">1&nbsp;paper</span></li></ul></div></div><div id=r19-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/R19-1/>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1000/>Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)</a></strong><br><a href=/people/r/ruslan-mitkov/>Ruslan Mitkov</a>
|
<a href=/people/g/galia-angelova/>Galia Angelova</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1002/>Identification of Good and Bad News on Twitter<span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/p/piush-aggarwal/>Piush Aggarwal</a>
|
<a href=/people/a/ahmet-aker/>Ahmet Aker</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1002><div class="card-body p-3 small">Social media plays a great role in <a href=https://en.wikipedia.org/wiki/Dissemination>news dissemination</a> which includes <a href=https://en.wikipedia.org/wiki/News>good and bad news</a>. However, studies show that <a href=https://en.wikipedia.org/wiki/News>news</a>, in general, has a significant impact on our mental stature and that this influence is more in bad news. An ideal situation would be that we have a tool that can help to filter out the type of news we do not want to consume. In this paper, we provide the basis for such a <a href=https://en.wikipedia.org/wiki/Tool>tool</a>. In our work, we focus on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. We release a manually annotated dataset containing 6,853 tweets from 5 different topical categories. Each tweet is annotated with good and bad labels. We also investigate various <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning systems</a> and <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> and evaluate their performance on the newly generated <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. We also perform a comparative analysis with <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiments</a> showing that <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment</a> alone is not enough to distinguish between good and bad news.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1003/>Bilingual Low-Resource Neural Machine Translation with Round-Tripping : The Case of Persian-Spanish<span class=acl-fixed-case>P</span>ersian-<span class=acl-fixed-case>S</span>panish</a></strong><br><a href=/people/b/benyamin-ahmadnia/>Benyamin Ahmadnia</a>
|
<a href=/people/b/bonnie-dorr/>Bonnie Dorr</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1003><div class="card-body p-3 small">The quality of Neural Machine Translation (NMT), as a data-driven approach, massively depends on quantity, quality, and relevance of the training dataset. Such approaches have achieved promising results for bilingually high-resource scenarios but are inadequate for low-resource conditions. This paper describes a round-trip training approach to bilingual low-resource NMT that takes advantage of monolingual datasets to address training data scarcity, thus augmenting translation quality. We conduct detailed experiments on <a href=https://en.wikipedia.org/wiki/Persian_language>Persian-Spanish</a> as a bilingually low-resource scenario. Experimental results demonstrate that this competitive approach outperforms the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1011 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1011/>Diachronic Analysis of Entities by Exploiting Wikipedia Page revisions<span class=acl-fixed-case>W</span>ikipedia Page revisions</a></strong><br><a href=/people/p/pierpaolo-basile/>Pierpaolo Basile</a>
|
<a href=/people/a/annalina-caputo/>Annalina Caputo</a>
|
<a href=/people/s/seamus-lawless/>Seamus Lawless</a>
|
<a href=/people/g/giovanni-semeraro/>Giovanni Semeraro</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1011><div class="card-body p-3 small">In the last few years, the increasing availability of large corpora spanning several time periods has opened new opportunities for the diachronic analysis of language. This type of analysis can bring to the light not only linguistic phenomena related to the shift of word meanings over time, but it can also be used to study the impact that societal and cultural trends have on this language change. This paper introduces a new resource for performing the diachronic analysis of named entities built upon Wikipedia page revisions. This resource enables the analysis over time of changes in the relations between entities (concepts), surface forms (words), and the contexts surrounding entities and surface forms, by analysing the whole history of Wikipedia internal links. We provide some useful use cases that prove the impact of this <a href=https://en.wikipedia.org/wiki/Resource>resource</a> on diachronic studies and delineate some possible future usage.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1012 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1012/>Using a Lexical Semantic Network for the Ontology Building</a></strong><br><a href=/people/n/nadia-bebeshina-clairet/>Nadia Bebeshina-Clairet</a>
|
<a href=/people/s/sylvie-despres/>Sylvie Despres</a>
|
<a href=/people/m/mathieu-lafourcade/>Mathieu Lafourcade</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1012><div class="card-body p-3 small">Building multilingual ontologies is a hard task as <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontologies</a> are often data-rich resources. We introduce an approach which allows exploiting structured lexical semantic knowledge for the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology building</a>. Given a multilingual lexical semantic (non ontological) resource and an <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology model</a>, it allows mining relevant semantic knowledge and make the ontology building and enhancement process faster.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1016 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1016/>Evaluating the Consistency of Word Embeddings from <a href=https://en.wikipedia.org/wiki/Small_data>Small Data</a></a></strong><br><a href=/people/j/jelke-bloem/>Jelke Bloem</a>
|
<a href=/people/a/antske-fokkens/>Antske Fokkens</a>
|
<a href=/people/a/aurelie-herbelot/>Aurélie Herbelot</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1016><div class="card-body p-3 small">In this work, we address the evaluation of distributional semantic models trained on smaller, domain-specific texts, specifically, philosophical text. Specifically, we inspect the behaviour of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using a pre-trained background space in <a href=https://en.wikipedia.org/wiki/Machine_learning>learning</a>. We propose a <a href=https://en.wikipedia.org/wiki/Measurement>measure</a> of <a href=https://en.wikipedia.org/wiki/Consistency>consistency</a> which can be used as an evaluation metric when no in-domain gold-standard data is available. This <a href=https://en.wikipedia.org/wiki/Measure_(mathematics)>measure</a> simply computes the ability of a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to learn similar embeddings from different parts of some <a href=https://en.wikipedia.org/wiki/Homogeneity_(statistics)>homogeneous data</a>. We show that in spite of being a simple evaluation, consistency actually depends on various combinations of factors, including the nature of the data itself, the model used to train the <a href=https://en.wikipedia.org/wiki/Semantic_space>semantic space</a>, and the frequency of the learnt terms, both in the background space and in the in-domain data of interest.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1018.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1018 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1018 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1018/>Learning Sentence Embeddings for Coherence Modelling and Beyond</a></strong><br><a href=/people/t/tanner-bohn/>Tanner Bohn</a>
|
<a href=/people/y/yining-hu/>Yining Hu</a>
|
<a href=/people/j/jinhang-zhang/>Jinhang Zhang</a>
|
<a href=/people/c/charles-ling/>Charles Ling</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1018><div class="card-body p-3 small">We present a novel and effective technique for performing text coherence tasks while facilitating deeper insights into the data. Despite obtaining ever-increasing task performance, modern deep-learning approaches to NLP tasks often only provide users with the final network decision and no additional understanding of the data. In this work, we show that a new type of <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embedding</a> learned through self-supervision can be applied effectively to text coherence tasks while serving as a window through which deeper understanding of the data can be obtained. To produce these sentence embeddings, we train a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a> to take individual sentences and predict their location in a document in the form of a distribution over locations. We demonstrate that these embeddings, combined with simple visual heuristics, can be used to achieve performance competitive with <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on multiple text coherence tasks, outperforming more complex and specialized approaches. Additionally, we demonstrate that these embeddings can provide insights useful to writers for improving writing quality and informing document structuring, and assisting readers in summarizing and locating information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1021 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1021/>Classifying Author Intention for Writer Feedback in Related Work</a></strong><br><a href=/people/a/arlene-casey/>Arlene Casey</a>
|
<a href=/people/b/bonnie-webber/>Bonnie Webber</a>
|
<a href=/people/d/dorota-glowacka/>Dorota Glowacka</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1021><div class="card-body p-3 small">The ability to produce high-quality publishable material is critical to academic success but many Post-Graduate students struggle to learn to do so. While recent years have seen an increase in tools designed to provide feedback on aspects of writing, one aspect that has so far been neglected is the Related Work section of <a href=https://en.wikipedia.org/wiki/Academic_publishing>academic research papers</a>. To address this, we have trained a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised classifier</a> on a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of 94 Related Work sections and evaluated it against a manually annotated gold standard. The <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifier</a> uses novel features pertaining to citation types and <a href=https://en.wikipedia.org/wiki/Co-reference>co-reference</a>, along with patterns found from studying Related Works. We show that these novel features contribute to <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> performance with performance being favourable compared to other similar works that classify author intentions and consider <a href=https://en.wikipedia.org/wiki/Feedback>feedback</a> for <a href=https://en.wikipedia.org/wiki/Academic_writing>academic writing</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1022 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1022" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1022/>Sparse Victory A Large Scale Systematic Comparison of count-based and prediction-based vectorizers for text classification</a></strong><br><a href=/people/r/rupak-chakraborty/>Rupak Chakraborty</a>
|
<a href=/people/a/ashima-elhence/>Ashima Elhence</a>
|
<a href=/people/k/kapil-arora/>Kapil Arora</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1022><div class="card-body p-3 small">In this paper we study the performance of several text vectorization algorithms on a diverse collection of 73 publicly available datasets. Traditional sparse vectorizers like Tf-Idf and Feature Hashing have been systematically compared with the latest state of the art neural word embeddings like Word2Vec, GloVe, FastText and character embeddings like ELMo, Flair. We have carried out an extensive analysis of the performance of these vectorizers across different dimensions like classification metrics (.i.e. precision, recall, accuracy), dataset-size, and imbalanced data (in terms of the distribution of the number of class labels). Our experiments reveal that the sparse vectorizers beat the neural word and character embedding models on 61 of the 73 datasets by an average margin of 3-5 % (in terms of macro f1 score) and this performance is consistent across the different dimensions of comparison.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1024/>Personality-dependent Neural Text Summarization</a></strong><br><a href=/people/p/pablo-costa/>Pablo Costa</a>
|
<a href=/people/i/ivandre-paraboni/>Ivandré Paraboni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1024><div class="card-body p-3 small">In Natural Language Generation systems, personalization strategies-i.e, the use of information about a target author to generate text that (more) closely resembles human-produced language-have long been applied to improve results. The present work addresses one such strategy-namely, the use of <a href=https://en.wikipedia.org/wiki/Big_Five_personality_traits>Big Five personality information</a> about the target author-applied to the case of abstractive text summarization using neural sequence-to-sequence models. Initial results suggest that having access to <a href=https://en.wikipedia.org/wiki/Personality_type>personality information</a> does lead to more accurate (or human-like) text summaries, and paves the way for more robust systems of this kind.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1029 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1029" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1029/>Detecting Toxicity in <a href=https://en.wikipedia.org/wiki/Article_(publishing)>News Articles</a> : Application to Bulgarian<span class=acl-fixed-case>B</span>ulgarian</a></strong><br><a href=/people/y/yoan-dinkov/>Yoan Dinkov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1029><div class="card-body p-3 small">Online media aim for reaching ever bigger audience and for attracting ever longer attention span. This competition creates an environment that rewards sensational, fake, and toxic news. To help limit their spread and impact, we propose and develop a news toxicity detector that can recognize various types of toxic content. While previous research primarily focused on <a href=https://en.wikipedia.org/wiki/English_language>English</a>, here we target <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a>. We created a new dataset by crawling a website that for five years has been collecting Bulgarian news articles that were manually categorized into eight toxicity groups. Then we trained a multi-class classifier with nine categories : eight toxic and one non-toxic. We experimented with different representations based on ElMo, BERT, and XLM, as well as with a variety of domain-specific features. Due to the small size of our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we created a separate <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> for each feature type, and we ultimately combined these <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> into a meta-classifier. The evaluation results show an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 59.0 % and a macro-F1 score of 39.7 %, which represent sizable improvements over the majority-class baseline (Acc=30.3 %, macro-F1=5.2 %).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1030.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1030 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1030 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1030/>De-Identification of Emails : Pseudonymizing Privacy-Sensitive Data in a German Email Corpus<span class=acl-fixed-case>G</span>erman Email Corpus</a></strong><br><a href=/people/e/elisabeth-eder/>Elisabeth Eder</a>
|
<a href=/people/u/ulrike-krieg-holz/>Ulrike Krieg-Holz</a>
|
<a href=/people/u/udo-hahn/>Udo Hahn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1030><div class="card-body p-3 small">We deal with the <a href=https://en.wikipedia.org/wiki/Pseudonymization>pseudonymization</a> of those stretches of text in emails that might allow to identify real individual persons. This <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> is decomposed into two steps. First, <a href=https://en.wikipedia.org/wiki/Legal_person>named entities</a> carrying privacy-sensitive information (e.g., names of persons, locations, phone numbers or dates) are identified, and, second, these <a href=https://en.wikipedia.org/wiki/Legal_person>privacy-bearing entities</a> are replaced by <a href=https://en.wikipedia.org/wiki/Legal_person>synthetically generated surrogates</a> (e.g., a person originally named &#8216;John Doe&#8217; is renamed as &#8216;Bill Powers&#8217;). We describe a <a href=https://en.wikipedia.org/wiki/Systems_architecture>system architecture</a> for surrogate generation and evaluate our approach on CodeAlltag, a German email corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1031.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1031 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1031 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1031/>Lexical Quantile-Based Text Complexity Measure</a></strong><br><a href=/people/m/maksim-eremeev/>Maksim Eremeev</a>
|
<a href=/people/k/konstantin-vorontsov/>Konstantin Vorontsov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1031><div class="card-body p-3 small">This paper introduces a new <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> to estimating the text document complexity. Common readability indices are based on average length of sentences and words. In contrast to these methods, we propose to count the number of rare words occurring abnormally often in the document. We use the reference corpus of texts and the quantile approach in order to determine what words are rare, and what frequencies are abnormal. We construct a general text complexity model, which can be adjusted for the specific <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, and introduce two special <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>. The experimental design is based on a set of thematically similar pairs of Wikipedia articles, labeled using <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a>. The experiments demonstrate the competitiveness of the proposed <a href=https://en.wikipedia.org/wiki/Methodology>approach</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1032 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1032/>Demo Application for LETO : Learning Engine Through Ontologies<span class=acl-fixed-case>LETO</span>: Learning Engine Through Ontologies</a></strong><br><a href=/people/s/suilan-estevez-velarde/>Suilan Estevez-Velarde</a>
|
<a href=/people/a/andres-montoyo/>Andrés Montoyo</a>
|
<a href=/people/y/yudivian-almeida-cruz/>Yudivian Almeida-Cruz</a>
|
<a href=/people/y/yoan-gutierrez/>Yoan Gutiérrez</a>
|
<a href=/people/a/alejandro-piad-morffis/>Alejandro Piad-Morffis</a>
|
<a href=/people/r/rafael-munoz/>Rafael Muñoz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1032><div class="card-body p-3 small">The massive amount of multi-formatted information available on the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>Web</a> necessitates the design of <a href=https://en.wikipedia.org/wiki/Software_system>software systems</a> that leverage this information to obtain knowledge that is valid and useful. The main challenge is to discover relevant information and continuously update, enrich and integrate knowledge from various sources of structured and unstructured data. This paper presents the Learning Engine Through Ontologies(LETO) framework, an architecture for the continuous and incremental discovery of knowledge from multiple sources of unstructured and structured data. We justify the main design decision behind LETO&#8217;s architecture and evaluate the <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a>&#8217;s feasibility using the Internet Movie Data Base(IMDB) and <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> as a practical application.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1033.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1033 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1033 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1033/>Sentence Simplification for Semantic Role Labelling and Information Extraction</a></strong><br><a href=/people/r/richard-evans/>Richard Evans</a>
|
<a href=/people/c/constantin-orasan/>Constantin Orasan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1033><div class="card-body p-3 small">In this paper, we report on the extrinsic evaluation of an automatic sentence simplification method with respect to two NLP tasks : semantic role labelling (SRL) and information extraction (IE). The paper begins with our observation of challenges in the intrinsic evaluation of sentence simplification systems, which motivates the use of extrinsic evaluation of these systems with respect to other NLP tasks. We describe the two NLP systems and the test data used in the extrinsic evaluation, and present arguments and evidence motivating the integration of a sentence simplification step as a means of improving the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of these <a href=https://en.wikipedia.org/wiki/System>systems</a>. Our evaluation reveals that their performance is improved by the simplification step : the SRL system is better able to assign semantic roles to the majority of the arguments of verbs and the IE system is better able to identify fillers for all IE template slots.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1034 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1034/>OlloBot-Towards A Text-Based Arabic Health Conversational Agent : Evaluation and Results<span class=acl-fixed-case>O</span>llo<span class=acl-fixed-case>B</span>ot - Towards A Text-Based <span class=acl-fixed-case>A</span>rabic Health Conversational Agent: Evaluation and Results</a></strong><br><a href=/people/a/ahmed-fadhil/>Ahmed Fadhil</a>
|
<a href=/people/a/ahmed-aburaed/>Ahmed AbuRa’ed</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1034><div class="card-body p-3 small">We introduce OlloBot, an Arabic conversational agent that assists physicians and supports patients with the care process. It does n&#8217;t replace the physicians, instead provides health tracking and support and assists physicians with the <a href=https://en.wikipedia.org/wiki/Health_care>care delivery</a> through a conversation medium. The current model comprises <a href=https://en.wikipedia.org/wiki/Healthy_diet>healthy diet</a>, <a href=https://en.wikipedia.org/wiki/Physical_activity>physical activity</a>, <a href=https://en.wikipedia.org/wiki/Mental_health>mental health</a>, in addition to food logging. Not only OlloBot tracks user daily food, it also offers useful tips for healthier living. We will discuss the design, development and testing of OlloBot, and highlight the findings and limitations arose from the testing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1036.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1036 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1036 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1036/>Summarizing Legal Rulings : Comparative Experiments</a></strong><br><a href=/people/d/diego-feijo/>Diego Feijo</a>
|
<a href=/people/v/viviane-moreira/>Viviane Moreira</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1036><div class="card-body p-3 small">In the context of <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a>, texts in the legal domain have peculiarities related to their length and to their specialized vocabulary. Recent neural network-based approaches can achieve high-quality scores for <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a>. However, these approaches have been used mostly for generating very short abstracts for <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. Thus, their applicability to the legal domain remains an open issue. In this work, we experimented with ten extractive and four abstractive models in a real dataset of <a href=https://en.wikipedia.org/wiki/Judgment_(law)>legal rulings</a>. These models were compared with an extractive baseline based on <a href=https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making>heuristics</a> to select the most relevant parts of the text. Our results show that <a href=https://en.wikipedia.org/wiki/Abstraction>abstractive approaches</a> significantly outperform extractive methods in terms of ROUGE scores.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1039 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1039/>Comparing Automated Methods to Detect Explicit Content in Song Lyrics</a></strong><br><a href=/people/m/michael-fell/>Michael Fell</a>
|
<a href=/people/e/elena-cabrio/>Elena Cabrio</a>
|
<a href=/people/m/michele-corazza/>Michele Corazza</a>
|
<a href=/people/f/fabien-gandon/>Fabien Gandon</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1039><div class="card-body p-3 small">The Parental Advisory Label (PAL) is a warning label that is placed on <a href=https://en.wikipedia.org/wiki/Sound_recording_and_reproduction>audio recordings</a> in recognition of profanity or inappropriate references, with the intention of alerting parents of material potentially unsuitable for children. Since 2015, digital providers such as <a href=https://en.wikipedia.org/wiki/ITunes>iTunes</a>, <a href=https://en.wikipedia.org/wiki/Spotify>Spotify</a>, <a href=https://en.wikipedia.org/wiki/Amazon_Music>Amazon Music</a> and Deezer also follow PAL guidelines and tag such tracks as explicit. Nowadays, such <a href=https://en.wikipedia.org/wiki/Labelling>labelling</a> is carried out mainly manually on voluntary basis, with the drawbacks of being time consuming and therefore costly, error prone and partly a subjective task. In this paper, we compare automated methods ranging from dictionary-based lookup to state-of-the-art <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a> to automatically detect explicit contents in English lyrics. We show that more complex <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> perform only slightly better on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, and relying on a qualitative analysis of the data, we discuss the inherent hardness and subjectivity of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1040.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1040 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1040 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1040/>Linguistic classification : dealing jointly with irrelevance and inconsistency</a></strong><br><a href=/people/l/laura-franzoi/>Laura Franzoi</a>
|
<a href=/people/a/andrea-sgarro/>Andrea Sgarro</a>
|
<a href=/people/a/anca-dinu/>Anca Dinu</a>
|
<a href=/people/l/liviu-p-dinu/>Liviu P. Dinu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1040><div class="card-body p-3 small">In this paper, we present new methods for <a href=https://en.wikipedia.org/wiki/Language_classification>language classification</a> which put to good use both syntax and fuzzy tools, and are capable of dealing with irrelevant linguistic features (i.e. features which should not contribute to the classification) and even inconsistent features (which do not make sense for specific languages). We introduce a <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric distance</a>, based on the generalized Steinhaus transform, which allows one to deal jointly with irrelevance and inconsistency. To evaluate our methods, we test them on a syntactic data set, due to the linguist G. Longobardi and his school. We obtain <a href=https://en.wikipedia.org/wiki/Phylogenetic_tree>phylogenetic trees</a> which sometimes outperform the ones obtained by Atkinson and Gray.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1043 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1043/>Two Discourse Tree-Based Approaches to Indexing Answers</a></strong><br><a href=/people/b/boris-galitsky/>Boris Galitsky</a>
|
<a href=/people/d/dmitry-ilvovsky/>Dmitry Ilvovsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1043><div class="card-body p-3 small">We explore anatomy of answers with respect to which text fragments from an answer are worth matching with a question and which should not be matched. We apply the <a href=https://en.wikipedia.org/wiki/Rhetorical_structure_theory>Rhetorical Structure Theory</a> to build a discourse tree of an answer and select elementary discourse units that are suitable for indexing. Manual rules for selection of these discourse units as well as automated classification based on web search engine mining are evaluated con-cerning improving search accuracy. We form two sets of question-answer pairs for FAQ and community QA search domains and use them for evaluation of the proposed indexing methodology, which delivers up to 16 percent improvement in search recall.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1045.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1045 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1045 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1045/>On a <a href=https://en.wikipedia.org/wiki/Chatbot>Chatbot</a> Providing Virtual Dialogues</a></strong><br><a href=/people/b/boris-galitsky/>Boris Galitsky</a>
|
<a href=/people/d/dmitry-ilvovsky/>Dmitry Ilvovsky</a>
|
<a href=/people/e/elizaveta-goncharova/>Elizaveta Goncharova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1045><div class="card-body p-3 small">We present a <a href=https://en.wikipedia.org/wiki/Chatbot>chatbot</a> that delivers content in the form of virtual dialogues automatically produced from the plain texts that are extracted and selected from the documents. This virtual dialogue content is provided in the form of answers derived from the found and selected documents split into fragments, and questions that are automatically generated for these answers based on the initial text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1046.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1046 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1046 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1046/>Assessing socioeconomic status of Twitter users : A survey<span class=acl-fixed-case>T</span>witter users: A survey</a></strong><br><a href=/people/d/dhouha-ghazouani/>Dhouha Ghazouani</a>
|
<a href=/people/l/luigi-lancieri/>Luigi Lancieri</a>
|
<a href=/people/h/habib-ounelli/>Habib Ounelli</a>
|
<a href=/people/c/chaker-jebari/>Chaker Jebari</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1046><div class="card-body p-3 small">Every day, the emotion and opinion of different people across the world are reflected in the form of short messages using <a href=https://en.wikipedia.org/wiki/Microblogging>microblogging platforms</a>. Despite the existence of enormous potential introduced by this data source, the <a href=https://en.wikipedia.org/wiki/Twitter_community>Twitter community</a> is still ambiguous and is not fully explored yet. While there are a huge number of studies examining the possibilities of inferring gender and age, there exist hardly researches on socioeconomic status (SES) inference of Twitter users. As <a href=https://en.wikipedia.org/wiki/Socioeconomic_status>socioeconomic status</a> is essential to treating diverse questions linked to <a href=https://en.wikipedia.org/wiki/Human_behavior>human behavior</a> in several fields (sociology, <a href=https://en.wikipedia.org/wiki/Demography>demography</a>, <a href=https://en.wikipedia.org/wiki/Public_health>public health</a>, etc.), we conducted a comprehensive literature review of SES studies, <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference methods</a>, and <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>. With reference to the research on literature&#8217;s results, we came to outline the most critical challenges for researchers. To the best of our knowledge, this paper is the first review that introduces the different aspects of SES inference. Indeed, this article provides the benefits for practitioners who aim to process and explore Twitter SES inference.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1047.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1047 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1047 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1047/>Divide and Extract Disentangling Clause Splitting and Proposition Extraction</a></strong><br><a href=/people/d/darina-gold/>Darina Gold</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1047><div class="card-body p-3 small">Proposition extraction from sentences is an important task for information extraction systems Evaluation of such <a href=https://en.wikipedia.org/wiki/System>systems</a> usually conflates two aspects : splitting complex sentences into clauses and the extraction of propositions. It is thus difficult to independently determine the quality of the proposition extraction step. We create a manually annotated proposition dataset from sentences taken from restaurant reviews that distinguishes between clauses that need to be split and those that do not. The resulting proposition evaluation dataset allows us to independently compare the performance of proposition extraction systems on simple and complex clauses. Although performance drastically drops on more complex sentences, we show that the same <a href=https://en.wikipedia.org/wiki/System>systems</a> perform best on both simple and complex clauses. Furthermore, we show that specific kinds of <a href=https://en.wikipedia.org/wiki/Dependent_clause>subordinate clauses</a> pose difficulties to most systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1049.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1049 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1049 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1049/>Automatic Question Answering for Medical MCQs : Can It go Further than Information Retrieval?<span class=acl-fixed-case>MCQ</span>s: Can It go Further than Information Retrieval?</a></strong><br><a href=/people/l/le-an-ha/>Le An Ha</a>
|
<a href=/people/v/victoria-yaneva/>Victoria Yaneva</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1049><div class="card-body p-3 small">We present a novel approach to automatic question answering that does not depend on the performance of an information retrieval (IR) system and does not require that the training data come from the same source as the questions. We evaluate the <a href=https://en.wikipedia.org/wiki/System>system</a> performance on a challenging set of university-level medical science multiple-choice questions. Best performance is achieved when combining a <a href=https://en.wikipedia.org/wiki/Neural_circuit>neural approach</a> with an <a href=https://en.wikipedia.org/wiki/Information_theory>IR approach</a>, both of which work independently. Unlike previous approaches, the <a href=https://en.wikipedia.org/wiki/System>system</a> achieves statistically significant improvement over the random guess baseline even for questions that are labeled as challenging based on the performance of baseline solvers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1052 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1052/>Investigating Terminology Translation in Statistical and Neural Machine Translation : A Case Study on English-to-Hindi and Hindi-to-English<span class=acl-fixed-case>E</span>nglish-to-<span class=acl-fixed-case>H</span>indi and <span class=acl-fixed-case>H</span>indi-to-<span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/r/rejwanul-haque/>Rejwanul Haque</a>
|
<a href=/people/m/md-hasanuzzaman/>Md Hasanuzzaman</a>
|
<a href=/people/a/andy-way/>Andy Way</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1052><div class="card-body p-3 small">Terminology translation plays a critical role in domain-specific machine translation (MT). In this paper, we conduct a comparative qualitative evaluation on terminology translation in phrase-based statistical MT (PB-SMT) and neural MT (NMT) in two translation directions : English-to-Hindi and Hindi-to-English. For this, we select a test set from a legal domain corpus and create a gold standard for evaluating terminology translation in MT. We also propose an error typology taking the terminology translation errors into consideration. We evaluate the MT systems&#8217; performance on terminology translation, and demonstrate our findings, unraveling strengths, weaknesses, and similarities of PB-SMT and NMT in the area of term translation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1053" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1053/>Beyond English-Only Reading Comprehension : Experiments in Zero-shot Multilingual Transfer for Bulgarian<span class=acl-fixed-case>E</span>nglish-Only Reading Comprehension: Experiments in Zero-shot Multilingual Transfer for <span class=acl-fixed-case>B</span>ulgarian</a></strong><br><a href=/people/m/momchil-hardalov/>Momchil Hardalov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1053><div class="card-body p-3 small">Recently, reading comprehension models achieved near-human performance on large-scale datasets such as SQuAD, CoQA, MS Macro, RACE, etc. This is largely due to the release of pre-trained contextualized representations such as <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> and ELMo, which can be fine-tuned for the target task. Despite those advances and the creation of more challenging datasets, most of the work is still done for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Here, we study the effectiveness of multilingual BERT fine-tuned on large-scale English datasets for <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> (e.g., for RACE), and we apply it to Bulgarian multiple-choice reading comprehension. We propose a new dataset containing 2,221 questions from <a href=https://en.wikipedia.org/wiki/Matriculation_examination>matriculation exams</a> for twelfth grade in various subjects history, biology, geography and philosophy, and 412 additional questions from online quizzes in history. While the quiz authors gave no relevant context, we incorporate knowledge from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, retrieving documents matching the combination of question + each answer option. Moreover, we experiment with different indexing and pre-training strategies. The evaluation results show accuracy of 42.23 %, which is well above the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> of 24.89 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1056.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1056 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1056 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1056/>Emoji Powered Capsule Network to Detect Type and Target of Offensive Posts in <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a></a></strong><br><a href=/people/h/hansi-hettiarachchi/>Hansi Hettiarachchi</a>
|
<a href=/people/t/tharindu-ranasinghe/>Tharindu Ranasinghe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1056><div class="card-body p-3 small">This paper describes a novel research approach to detect type and target of offensive posts in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> using a capsule network. The input to the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> was <a href=https://en.wikipedia.org/wiki/Character_encoding>character embeddings</a> combined with <a href=https://en.wikipedia.org/wiki/Emoji>emoji embeddings</a>. The approach was evaluated on all three subtasks in Task 6-SemEval 2019 : OffensEval : Identifying and Categorizing Offensive Language in Social Media. The evaluation also showed that even though the capsule networks have not been used commonly in natural language processing tasks, they can outperform existing state of the art solutions for offensive language detection in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1063.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1063 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1063 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1063/>Using Syntax to Resolve NPE in English<span class=acl-fixed-case>NPE</span> in <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/p/payal-khullar/>Payal Khullar</a>
|
<a href=/people/a/allen-antony/>Allen Antony</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1063><div class="card-body p-3 small">This paper describes a novel, syntax-based system for automatic detection and resolution of Noun Phrase Ellipsis (NPE) in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. The <a href=https://en.wikipedia.org/wiki/System>system</a> takes in free input English text, detects the site of nominal elision, and if present, selects potential antecedent candidates. The rules are built using the syntactic information on <a href=https://en.wikipedia.org/wiki/Ellipsis_(linguistics)>ellipsis</a> and its antecedent discussed in previous theoretical linguistics literature on NPE. Additionally, we prepare a curated dataset of 337 sentences from well-known, reliable sources, containing positive and negative samples of <a href=https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values>NPE</a>. We split this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> into two parts, and use one part to refine our rules and the other to test the performance of our final <a href=https://en.wikipedia.org/wiki/System>system</a>. We get an <a href=https://en.wikipedia.org/wiki/Fluorescence_in_situ_hybridization>F1-score</a> of 76.47 % for <a href=https://en.wikipedia.org/wiki/Fluorescence_in_situ_hybridization>detection</a> and 70.27 % for <a href=https://en.wikipedia.org/wiki/Fluorescence_in_situ_hybridization>NPE resolution</a> on the testset. To the best of our knowledge, ours is the first <a href=https://en.wikipedia.org/wiki/System>system</a> that detects and resolves <a href=https://en.wikipedia.org/wiki/Non-player_character>NPE</a> in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. The curated dataset used for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, albeit small, covers a wide variety of NPE cases and will be made public for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1064.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1064 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1064 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1064/>Is Similarity Visually Grounded? Computational Model of Similarity for the Estonian language<span class=acl-fixed-case>E</span>stonian language</a></strong><br><a href=/people/c/claudia-kittask/>Claudia Kittask</a>
|
<a href=/people/e/eduard-barbu/>Eduard Barbu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1064><div class="card-body p-3 small">Researchers in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>Computational Linguistics</a> build <a href=https://en.wikipedia.org/wiki/Conceptual_model>models of similarity</a> and test them against <a href=https://en.wikipedia.org/wiki/Judgement>human judgments</a>. Although there are many empirical studies of the computational models of similarity for the <a href=https://en.wikipedia.org/wiki/English_language>English language</a>, the similarity for other languages is less explored. In this study we are chiefly interested in two aspects. In the first place we want to know how much of the human similarity is grounded in the <a href=https://en.wikipedia.org/wiki/Visual_perception>visual perception</a>. To answer this question two neural computer vision models are used and their correlation with the human derived similarity scores is computed. In the second place we investigate if <a href=https://en.wikipedia.org/wiki/Language>language</a> influences the similarity computation. To this purpose diverse <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> trained on Estonian resources are evaluated against <a href=https://en.wikipedia.org/wiki/Judgement>human judgments</a></div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1065.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1065 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1065 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1065/>Language-Agnostic Twitter-Bot Detection<span class=acl-fixed-case>T</span>witter-Bot Detection</a></strong><br><a href=/people/j/jurgen-knauth/>Jürgen Knauth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1065><div class="card-body p-3 small">In this paper we address the problem of detecting Twitter bots. We analyze a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 8385 <a href=https://en.wikipedia.org/wiki/Twitter>Twitter accounts</a> and their <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> consisting of both humans and different kinds of <a href=https://en.wikipedia.org/wiki/Internet_bot>bots</a>. We use this <a href=https://en.wikipedia.org/wiki/Data>data</a> to train <a href=https://en.wikipedia.org/wiki/Statistical_classification>machine learning classifiers</a> that distinguish between real and bot accounts. We identify <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> that are easy to extract while still providing good results. We analyze different feature groups based on account specific, tweet specific and behavioral specific features and measure their performance compared to other state of the art bot detection methods. For easy future portability of our work we focus on language-agnostic features. With <a href=https://en.wikipedia.org/wiki/AdaBoost>AdaBoost</a>, the best performing <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a>, we achieve an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 0.988 and an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>AUC</a> of 0.995. As the creation of good training data in <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> is often difficult-especially in the domain of Twitter bot detection-we additionally analyze to what extent smaller amounts of training data lead to useful results by reviewing cross-validated learning curves. Our results indicate that using few but expressive features already has a good practical benefit for bot detection, especially if only a small amount of <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> is available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1070.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1070 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1070 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1070" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1070/>Question Similarity in Community Question Answering : A Systematic Exploration of Preprocessing Methods and Models</a></strong><br><a href=/people/f/florian-kunneman/>Florian Kunneman</a>
|
<a href=/people/t/thiago-castro-ferreira/>Thiago Castro Ferreira</a>
|
<a href=/people/e/emiel-krahmer/>Emiel Krahmer</a>
|
<a href=/people/a/antal-van-den-bosch/>Antal van den Bosch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1070><div class="card-body p-3 small">Community Question Answering forums are popular among Internet users, and a basic problem they encounter is trying to find out if their question has already been posed before. To address this issue, NLP researchers have developed methods to automatically detect question-similarity, which was one of the shared tasks in <a href=https://en.wikipedia.org/wiki/SemEval>SemEval</a>. The best performing systems for this task made use of Syntactic Tree Kernels or the SoftCosine metric. However, it remains unclear why these methods seem to work, whether their performance can be improved by better preprocessing methods and what kinds of errors they (and other methods) make. In this paper, we therefore systematically combine and compare these two approaches with the more traditional BM25 and translation-based models. Moreover, we analyze the impact of preprocessing steps (lowercasing, suppression of punctuation and stop words removal) and word meaning similarity based on different distributions (word translation probability, Word2Vec, fastText and ELMo) on the performance of the task. We conduct an error analysis to gain insight into the differences in performance between the system set-ups. The implementation is made publicly available from https://github.com/fkunneman/DiscoSumo/tree/master/ranlp.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1072.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1072 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1072 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1072/>Resolving Pronouns for a Resource-Poor Language, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a> Using Resource-Rich Language, Tamil.<span class=acl-fixed-case>M</span>alayalam Using Resource-Rich Language, <span class=acl-fixed-case>T</span>amil.</a></strong><br><a href=/people/s/sobha-lalitha-devi/>Sobha Lalitha Devi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1072><div class="card-body p-3 small">In this paper we give in detail how a resource rich language can be used for resolving <a href=https://en.wikipedia.org/wiki/Pronoun>pronouns</a> for a less resource language. The source language, which is resource rich language in this study, is <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a> and the resource poor language is <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, both belonging to the same language family, <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian</a>. The Pronominal resolution developed for <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a> uses CRFs. Our approach is to leverage the Tamil language model to test Malayalam data and the processing required for Malayalam data is detailed. The similarity at the <a href=https://en.wikipedia.org/wiki/Syntax>syntactic level</a> between the languages is exploited in identifying the <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> for developing the Tamil language model. The <a href=https://en.wikipedia.org/wiki/Word_form>word form</a> or the <a href=https://en.wikipedia.org/wiki/Lexical_item>lexical item</a> is not considered as a <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>feature</a> for training the CRFs. Evaluation on Malayalam Wikipedia data shows that our approach is correct and the results, though not as good as <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, but comparable.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1073.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1073 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1073 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1073/>Semantic Role Labeling with Pretrained Language Models for Known and Unknown Predicates</a></strong><br><a href=/people/d/daniil-larionov/>Daniil Larionov</a>
|
<a href=/people/a/artem-shelmanov/>Artem Shelmanov</a>
|
<a href=/people/e/elena-chistova/>Elena Chistova</a>
|
<a href=/people/i/ivan-smirnov/>Ivan Smirnov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1073><div class="card-body p-3 small">We build the first full <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a> for semantic role labelling of Russian texts. The <a href=https://en.wikipedia.org/wiki/Pipeline_transport>pipeline</a> implements predicate identification, argument extraction, argument classification (labeling), and global scoring via <a href=https://en.wikipedia.org/wiki/Integer_linear_programming>integer linear programming</a>. We train supervised neural network models for argument classification using Russian semantically annotated corpus FrameBank. However, we note that this resource provides <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> only to a very limited set of predicates. We combat the problem of annotation scarcity by introducing two models that rely on different sets of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> : one for known predicates that are present in the training set and one for unknown predicates that are not. We show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for unknown predicates can alleviate the lack of <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> by using pretrained embeddings. We perform experiments with various types of embeddings including the ones generated by deep pretrained language models : word2vec, FastText, ELMo, BERT, and show that embeddings generated by deep pretrained language models are superior to classical shallow embeddings for argument classification of both known and unknown predicates.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1076.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1076 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1076 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1076/>The Impact of Semantic Linguistic Features in <a href=https://en.wikipedia.org/wiki/Relation_extraction>Relation Extraction</a> : A Logical Relational Learning Approach</a></strong><br><a href=/people/r/rinaldo-lima/>Rinaldo Lima</a>
|
<a href=/people/b/bernard-espinasse/>Bernard Espinasse</a>
|
<a href=/people/f/frederico-freitas/>Frederico Freitas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1076><div class="card-body p-3 small">Relation Extraction (RE) consists in detecting and classifying semantic relations between entities in a sentence. The vast majority of the state-of-the-art RE systems relies on morphosyntactic features and supervised machine learning algorithms. This paper tries to answer important questions concerning both the impact of semantic based features, and the integration of external linguistic knowledge resources on RE performance. For that, a RE system based on a logical and relational learning algorithm was used and evaluated on three reference datasets from two distinct domains. The yielded results confirm that the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> induced using the proposed richer feature set outperformed the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> built with morphosyntactic features in average 4 % (F1-measure).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1077.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1077 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1077 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1077/>Detecting Anorexia in Spanish Tweets<span class=acl-fixed-case>S</span>panish Tweets</a></strong><br><a href=/people/p/pilar-lopez-ubeda/>Pilar López Úbeda</a>
|
<a href=/people/f/flor-miriam-plaza-del-arco/>Flor Miriam Plaza del Arco</a>
|
<a href=/people/m/manuel-carlos-diaz-galiano/>Manuel Carlos Díaz Galiano</a>
|
<a href=/people/l/l-alfonso-urena-lopez/>L. Alfonso Urena Lopez</a>
|
<a href=/people/m/m-teresa-martin-valdivia/>Maite Martin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1077><div class="card-body p-3 small">Mental health is one of the main concerns of today&#8217;s society. Early detection of symptoms can greatly help people with <a href=https://en.wikipedia.org/wiki/Mental_disorder>mental disorders</a>. People are using <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>social networks</a> more and more to express emotions, <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiments</a> and <a href=https://en.wikipedia.org/wiki/Mental_state>mental states</a>. Thus, the treatment of this information using NLP technologies can be applied to the automatic detection of mental problems such as <a href=https://en.wikipedia.org/wiki/Eating_disorder>eating disorders</a>. However, the first step to solving the problem should be to provide a corpus in order to evaluate our <a href=https://en.wikipedia.org/wiki/System>systems</a>. In this paper, we specifically focus on detecting <a href=https://en.wikipedia.org/wiki/Anorexia_(symptom)>anorexia messages</a> on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. Firstly, we have generated a new corpus of tweets extracted from different accounts including anorexia and non-anorexia messages in <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is called SAD : Spanish Anorexia Detection corpus. In order to validate the effectiveness of the SAD corpus, we also propose several machine learning approaches for automatically detecting anorexia symptoms in the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>. The good results obtained show that the application of textual classification methods is a promising option for developing this kind of system demonstrating that these tools could be used by professionals to help in the early detection of mental problems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1079.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1079 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1079 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1079/>v-trel : Vocabulary Trainer for Tracing Word Relations-An Implicit Crowdsourcing Approach</a></strong><br><a href=/people/v/verena-lyding/>Verena Lyding</a>
|
<a href=/people/c/christos-rodosthenous/>Christos Rodosthenous</a>
|
<a href=/people/f/federico-sangati/>Federico Sangati</a>
|
<a href=/people/u/umair-ul-hassan/>Umair ul Hassan</a>
|
<a href=/people/l/lionel-nicolas/>Lionel Nicolas</a>
|
<a href=/people/a/alexander-konig/>Alexander König</a>
|
<a href=/people/j/jolita-horbacauskiene/>Jolita Horbacauskiene</a>
|
<a href=/people/a/anisia-katinskaia/>Anisia Katinskaia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1079><div class="card-body p-3 small">In this paper, we present our work on developing a vocabulary trainer that uses exercises generated from language resources such as <a href=https://en.wikipedia.org/wiki/ConceptNet>ConceptNet</a> and crowdsources the responses of the learners to enrich the language resource. We performed an empirical evaluation of our approach with 60 non-native speakers over two days, which shows that new entries to expand Concept-Net can efficiently be gathered through vocabulary exercises on word relations. We also report on the feedback gathered from the users and an expert from <a href=https://en.wikipedia.org/wiki/Language_acquisition>language teaching</a>, and discuss the potential of the vocabulary trainer application from the user and language learner perspective. The feedback suggests that v-trel has educational potential, while in its current state some shortcomings could be identified.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1080.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1080 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1080 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1080/>Jointly Learning Author and Annotated Character N-gram Embeddings : A Case Study in Literary Text</a></strong><br><a href=/people/s/suraj-maharjan/>Suraj Maharjan</a>
|
<a href=/people/d/deepthi-mave/>Deepthi Mave</a>
|
<a href=/people/p/prasha-shrestha/>Prasha Shrestha</a>
|
<a href=/people/m/manuel-montes/>Manuel Montes</a>
|
<a href=/people/f/fabio-a-gonzalez/>Fabio A. González</a>
|
<a href=/people/t/thamar-solorio/>Thamar Solorio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1080><div class="card-body p-3 small">An author&#8217;s way of presenting a story through his / her writing style has a great impact on whether the story will be liked by readers or not. In this paper, we learn <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> for authors of literary texts together with <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> for character n-grams annotated with their functional roles. We train a neural character n-gram based language model using an external corpus of literary texts and transfer learned representations for use in downstream tasks. We show that augmenting the knowledge from external works of authors produces results competitive with other style-based methods for book likability prediction, genre classification, and authorship attribution.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1081.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1081 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1081 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1081/>Generating Challenge Datasets for Task-Oriented Conversational Agents through Self-Play</a></strong><br><a href=/people/s/sourabh-majumdar/>Sourabh Majumdar</a>
|
<a href=/people/s/serra-sinem-tekiroglu/>Serra Sinem Tekiroglu</a>
|
<a href=/people/m/marco-guerini/>Marco Guerini</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1081><div class="card-body p-3 small">End-to-end neural approaches are becoming increasingly common in conversational scenarios due to their promising performances when provided with sufficient amount of data. In this paper, we present a novel <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to address the interpretability of neural approaches in such scenarios by creating challenge datasets using dialogue self-play over multiple tasks / intents. Dialogue self-play allows generating large amount of synthetic data ; by taking advantage of the complete control over the generation process, we show how neural approaches can be evaluated in terms of unseen dialogue patterns. We propose several out-of-pattern test cases each of which introduces a natural and unexpected user utterance phenomenon. As a proof of concept, we built a single and a multiple memory network, and show that these two architectures have diverse performances depending on the peculiar dialogue patterns.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1090.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1090 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1090 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1090/>Unsupervised Data Augmentation for Less-Resourced Languages with no Standardized Spelling</a></strong><br><a href=/people/a/alice-millour/>Alice Millour</a>
|
<a href=/people/k/karen-fort/>Karën Fort</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1090><div class="card-body p-3 small">Building representative linguistic resources and NLP tools for non-standardized languages is challenging : when <a href=https://en.wikipedia.org/wiki/Spelling>spelling</a> is not determined by a norm, multiple written forms can be encountered for a given word, inducing a large proportion of out-of-vocabulary words. To embrace this diversity, we propose a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> based on crowdsourced alternative spellings we use to extract rules applied to match OOV words with one of their spelling variants. This virtuous process enables the unsupervised augmentation of multi-variant lexicons without expert rule definition. We apply this multilingual methodology on <a href=https://en.wikipedia.org/wiki/Alsatian_dialect>Alsatian</a>, a <a href=https://en.wikipedia.org/wiki/Languages_of_France>French regional language</a> and provide an intrinsic evaluation of the correctness of the variants pairs, and an extrinsic evaluation on a downstream task. We show that in a low-resource scenario, 145 inital pairs can lead to the generation of 876 additional variant pairs, and a diminution of OOV words improving the <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a> performance by 1 to 4 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1091.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1091 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1091 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1091/>Neural Feature Extraction for Contextual Emotion Detection</a></strong><br><a href=/people/e/elham-mohammadi/>Elham Mohammadi</a>
|
<a href=/people/h/hessam-amini/>Hessam Amini</a>
|
<a href=/people/l/leila-kosseim/>Leila Kosseim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1091><div class="card-body p-3 small">This paper describes a new approach for the task of contextual emotion detection. The approach is based on a neural feature extractor, composed of a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a> with an <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a>, followed by a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a>, that can be neural or SVM-based. We evaluated the model with the dataset of the task 3 of SemEval 2019 (EmoContext), which includes short 3-turn conversations, tagged with 4 emotion classes. The best performing setup was achieved using ELMo word embeddings and POS tags as input, bidirectional GRU as hidden units, and an <a href=https://en.wikipedia.org/wiki/Symmetric_multiprocessing>SVM</a> as the final classifier. This configuration reached 69.93 % in terms of micro-average F1 score on the main 3 emotion classes, a score that outperformed the baseline system by 11.25 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1093.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1093 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1093 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1093/>A Fast and Accurate Partially Deterministic Morphological Analysis</a></strong><br><a href=/people/h/hajime-morita/>Hajime Morita</a>
|
<a href=/people/t/tomoya-iwakura/>Tomoya Iwakura</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1093><div class="card-body p-3 small">This paper proposes a partially deterministic morphological analysis method for improved processing speed. Maximum matching is a fast deterministic method for <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological analysis</a>. However, the <a href=https://en.wikipedia.org/wiki/Methodology>method</a> tends to decrease performance due to lack of consideration of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a>. In order to use <a href=https://en.wikipedia.org/wiki/Maximum_matching>maximum matching</a> safely, we propose the use of Context Independent Strings (CISs), which are strings that do not have <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a> in terms of <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological analysis</a>. Our method first identifies CISs in a sentence using <a href=https://en.wikipedia.org/wiki/Maximum_matching>maximum matching</a> without <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a>, then analyzes the unprocessed part of the sentence using a bi-gram-based morphological analysis model. We evaluate the <a href=https://en.wikipedia.org/wiki/Methodology>method</a> on a Japanese morphological analysis task. The experimental results show a 30 % reduction of <a href=https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)>running time</a> while maintaining improved <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1094.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1094 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1094 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1094/>incom.py-A Toolbox for Calculating Linguistic Distances and Asymmetries between Related Languages</a></strong><br><a href=/people/m/marius-mosbach/>Marius Mosbach</a>
|
<a href=/people/i/irina-stenger/>Irina Stenger</a>
|
<a href=/people/t/tania-avgustinova/>Tania Avgustinova</a>
|
<a href=/people/d/dietrich-klakow/>Dietrich Klakow</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1094><div class="card-body p-3 small">Languages may be differently distant from each other and their <a href=https://en.wikipedia.org/wiki/Mutual_intelligibility>mutual intelligibility</a> may be asymmetric. In this paper we introduce incom.py, a toolbox for calculating <a href=https://en.wikipedia.org/wiki/Linguistic_distance>linguistic distances</a> and asymmetries between related languages. incom.py allows linguist experts to quickly and easily perform <a href=https://en.wikipedia.org/wiki/Statistics>statistical analyses</a> and compare those with experimental results. We demonstrate the efficacy of incom.py in an incomprehension experiment on two <a href=https://en.wikipedia.org/wiki/Slavic_languages>Slavic languages</a> : <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a> and <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>. Using incom.py we were able to validate three methods to measure linguistic distances and asymmetries : <a href=https://en.wikipedia.org/wiki/Levenshtein_distance>Levenshtein distance</a>, word adaptation surprisal, and <a href=https://en.wikipedia.org/wiki/Conditional_entropy>conditional entropy</a> as predictors of success in a reading intercomprehension experiment.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1095.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1095 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1095 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1095/>A Holistic Natural Language Generation Framework for the <a href=https://en.wikipedia.org/wiki/Semantic_Web>Semantic Web</a></a></strong><br><a href=/people/a/axel-cyrille-ngonga-ngomo/>Axel-Cyrille Ngonga Ngomo</a>
|
<a href=/people/d/diego-moussallem/>Diego Moussallem</a>
|
<a href=/people/l/lorenz-buhmann/>Lorenz Bühmann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1095><div class="card-body p-3 small">With the ever-growing generation of data for the <a href=https://en.wikipedia.org/wiki/Semantic_Web>Semantic Web</a> comes an increasing demand for this <a href=https://en.wikipedia.org/wiki/Data>data</a> to be made available to non-semantic Web experts. One way of achieving this goal is to translate the languages of the <a href=https://en.wikipedia.org/wiki/Semantic_Web>Semantic Web</a> into <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. We present LD2NL, a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> that allows verbalizing the three key languages of the <a href=https://en.wikipedia.org/wiki/Semantic_Web>Semantic Web</a>, i.e., <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF</a>, <a href=https://en.wikipedia.org/wiki/Web_Ontology_Language>OWL</a>, and <a href=https://en.wikipedia.org/wiki/SPARQL>SPARQL</a>. Our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> is based on a <a href=https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design>bottom-up approach</a> to <a href=https://en.wikipedia.org/wiki/Verbalization>verbalization</a>. We evaluated LD2NL in an open survey with 86 persons. Our results suggest that our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> can generate verbalizations that are close to <a href=https://en.wikipedia.org/wiki/Natural_language>natural languages</a> and that can be easily understood by non-experts. Therewith, it enables non-domain experts to interpret Semantic Web data with more than 91 % of the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of domain experts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1098.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1098 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1098 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1098" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1098/>Large-Scale Hierarchical Alignment for Data-driven Text Rewriting</a></strong><br><a href=/people/n/nikola-i-nikolov/>Nikola I. Nikolov</a>
|
<a href=/people/r/richard-hahnloser/>Richard Hahnloser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1098><div class="card-body p-3 small">We propose a simple <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised method</a> for extracting pseudo-parallel monolingual sentence pairs from comparable corpora representative of two different text styles, such as <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> and <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific papers</a>. Our approach does not require a seed <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a>, but instead relies solely on hierarchical search over pre-trained embeddings of documents and sentences. We demonstrate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> through automatic and extrinsic evaluation on text simplification from the normal to the Simple Wikipedia. We show that pseudo-parallel sentences extracted with our method not only supplement existing parallel data, but can even lead to competitive performance on their own.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1099.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1099 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1099 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1099/>Dependency-Based Relative Positional Encoding for Transformer NMT<span class=acl-fixed-case>NMT</span></a></strong><br><a href=/people/y/yutaro-omote/>Yutaro Omote</a>
|
<a href=/people/a/akihiro-tamura/>Akihiro Tamura</a>
|
<a href=/people/t/takashi-ninomiya/>Takashi Ninomiya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1099><div class="card-body p-3 small">This paper proposes a new Transformer neural machine translation model that incorporates syntactic distances between two source words into the relative position representations of the self-attention mechanism. In particular, the proposed model encodes pair-wise relative depths on a source dependency tree, which are differences between the depths of the two source words, in the encoder&#8217;s self-attention. The experiments show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 0.5 point gain in BLEU on the Asian Scientific Paper Excerpt Corpus Japanese-to-English translation task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1101.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1101 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1101 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1101/>Building a <a href=https://en.wikipedia.org/wiki/Morphological_analysis>Morphological Analyser</a> for Laz<span class=acl-fixed-case>L</span>az</a></strong><br><a href=/people/e/esra-onal/>Esra Onal</a>
|
<a href=/people/f/francis-tyers/>Francis Tyers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1101><div class="card-body p-3 small">This study is an attempt to contribute to documentation and revitalization efforts of endangered Laz language, a member of South Caucasian language family mainly spoken on northeastern coastline of Turkey. It constitutes the first steps to create a general <a href=https://en.wikipedia.org/wiki/Computational_model>computational model</a> for word form recognition and production for Laz by building a rule-based morphological analyser using Helsinki Finite-State Toolkit (HFST). The evaluation results show that the <a href=https://en.wikipedia.org/wiki/Analyser>analyser</a> has a 64.9 % coverage over a corpus collected for this study with 111,365 tokens. We have also performed an error analysis on randomly selected 100 tokens from the corpus which are not covered by the analyser, and these results show that the errors mostly result from Turkish words in the corpus and missing stems in our lexicon.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1103.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1103 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1103 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1103/>Quotation Detection and Classification with a Corpus-Agnostic Model</a></strong><br><a href=/people/s/sean-papay/>Sean Papay</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1103><div class="card-body p-3 small">The detection of quotations (i.e., reported speech, <a href=https://en.wikipedia.org/wiki/Thought>thought</a>, and writing) has established itself as an <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP analysis task</a>. However, state-of-the-art models have been developed on the basis of specific corpora and incorpo- rate a high degree of corpus-specific assumptions and knowledge, which leads to fragmentation. In the spirit of task-agnostic modeling, we present a corpus-agnostic neural model for quotation detection and evaluate it on three <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> that vary in language, text genre, and structural assumptions. The model (a) approaches the state-of-the-art on the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> when using established feature sets and (b) shows reasonable performance even when us- ing solely word forms, which makes it applicable for non-standard (i.e., historical) corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1104 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1104/>Validation of Facts Against Textual Sources</a></strong><br><a href=/people/v/vamsi-krishna-pendyala/>Vamsi Krishna Pendyala</a>
|
<a href=/people/s/simran-sinha/>Simran Sinha</a>
|
<a href=/people/s/satya-prakash/>Satya Prakash</a>
|
<a href=/people/s/shriya-reddy/>Shriya Reddy</a>
|
<a href=/people/a/anupam-jamatia/>Anupam Jamatia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1104><div class="card-body p-3 small">In today&#8217;s digital world of information, a fact verification system to disprove assertions made in <a href=https://en.wikipedia.org/wiki/Public_speaking>speech</a>, <a href=https://en.wikipedia.org/wiki/Mass_media>print media</a> or <a href=https://en.wikipedia.org/wiki/Online_content>online content</a> is the need of the hour. We propose a <a href=https://en.wikipedia.org/wiki/System>system</a> which would verify a claim against a source and classify the claim to be true, false, out-of-context or an inappropriate claim with respect to the textual source provided to the <a href=https://en.wikipedia.org/wiki/System>system</a>. A true label is used if the claim is true, false if it is false, if the claim has no relation with the source then it is classified as out-of-context and if the claim can not be verified at all then it is classified as inappropriate. This would help us to verify a claim or a fact as well as know about the source or our knowledge base against which we are trying to verify our facts. We used a two-step approach to achieve our goal. At first, we retrieved evidence related to the claims from the textual source using the Term Frequency-Inverse Document Frequency(TF-IDF) vectors. Later we classified the claim-evidence pairs as true, false, inappropriate and out of context using a modified version of textual entailment module. Textual entailment module calculates the probability of each sentence supporting the claim, contradicting the claim or not providing any relevant information using Bi-LSTM network to assess the veracity of the claim. The <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of the best performing <a href=https://en.wikipedia.org/wiki/System>system</a> is 64.49 %</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1105.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1105 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1105 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1105/>A Neural Network Component for Knowledge-Based Semantic Representations of Text</a></strong><br><a href=/people/a/alejandro-piad-morffis/>Alejandro Piad-Morffis</a>
|
<a href=/people/r/rafael-munoz/>Rafael Muñoz</a>
|
<a href=/people/y/yoan-gutierrez/>Yoan Gutiérrez</a>
|
<a href=/people/y/yudivian-almeida-cruz/>Yudivian Almeida-Cruz</a>
|
<a href=/people/s/suilan-estevez-velarde/>Suilan Estevez-Velarde</a>
|
<a href=/people/a/andres-montoyo/>Andrés Montoyo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1105><div class="card-body p-3 small">This paper presents Semantic Neural Networks (SNNs), a knowledge-aware component based on <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a>. SNNs can be trained to encode explicit semantic knowledge from an arbitrary <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a>, and can subsequently be combined with other deep learning architectures. At prediction time, SNNs provide a semantic encoding extracted from the input data, which can be exploited by other neural network components to build extended representation models that can face alternative problems. The SNN architecture is defined in terms of the concepts and relations present in a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a>. Based on this <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a>, a training procedure is developed. Finally, an experimental setup is presented to illustrate the behaviour and performance of a SNN for a specific NLP problem, in this case, <a href=https://en.wikipedia.org/wiki/Opinion_mining>opinion mining</a> for the classification of movie reviews.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1108 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1108/>Unsupervised dialogue intent detection via hierarchical topic model</a></strong><br><a href=/people/a/artem-popov/>Artem Popov</a>
|
<a href=/people/v/victor-bulatov/>Victor Bulatov</a>
|
<a href=/people/d/darya-polyudova/>Darya Polyudova</a>
|
<a href=/people/e/eugenia-veselova/>Eugenia Veselova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1108><div class="card-body p-3 small">One of the challenges during a task-oriented chatbot development is the scarce availability of the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>labeled training data</a>. The best way of getting one is to ask the assessors to tag each dialogue according to its intent. Unfortunately, performing <a href=https://en.wikipedia.org/wiki/Label>labeling</a> without any provisional collection structure is difficult since the very notion of the intent is ill-defined. In this paper, we propose a hierarchical multimodal regularized topic model to obtain a first approximation of the intent set. Our rationale for hierarchical models usage is their ability to take into account several degrees of the dialogues relevancy. We attempt to build a <a href=https://en.wikipedia.org/wiki/Scientific_modelling>model</a> that can distinguish between subject-based (e.g. medicine and transport topics) and action-based (e.g. filing of an application and tracking application status) similarities. In order to achieve this, we divide set of all <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> into several groups according to part-of-speech analysis. Various feature groups are treated differently on different <a href=https://en.wikipedia.org/wiki/Hierarchy>hierarchy levels</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1111.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1111 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1111 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1111/>Are ambiguous conjunctions problematic for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>?</a></strong><br><a href=/people/m/maja-popovic/>Maja Popović</a>
|
<a href=/people/s/sheila-castilho/>Sheila Castilho</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1111><div class="card-body p-3 small">The translation of ambiguous words still poses challenges for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. In this work, we carry out a systematic quantitative analysis regarding the ability of different <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> to disambiguate the source language conjunctions but and and. We evaluate specialised test sets focused on the <a href=https://en.wikipedia.org/wiki/Translation_(geometry)>translation</a> of these two <a href=https://en.wikipedia.org/wiki/Logical_conjunction>conjunctions</a>. The test sets contain source languages that do not distinguish different variants of the given <a href=https://en.wikipedia.org/wiki/Logical_conjunction>conjunction</a>, whereas the target languages do. In total, we evaluate the <a href=https://en.wikipedia.org/wiki/Logical_conjunction>conjunction</a> but on 20 translation outputs, and the <a href=https://en.wikipedia.org/wiki/Logical_conjunction>conjunction</a> and on 10. All <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> almost perfectly recognise one variant of the target conjunction, especially for the source conjunction but. The other target variant, however, represents a challenge for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a>, with <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> varying from 50 % to 95 % for but and from 20 % to 57 % for and. The major error for all <a href=https://en.wikipedia.org/wiki/System>systems</a> is replacing the correct target variant with the opposite one.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1114.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1114 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1114 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1114" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1114/>NE-Table : A Neural key-value table for Named Entities<span class=acl-fixed-case>NE</span>-Table: A Neural key-value table for Named Entities</a></strong><br><a href=/people/j/janarthanan-rajendran/>Janarthanan Rajendran</a>
|
<a href=/people/j/jatin-ganhotra/>Jatin Ganhotra</a>
|
<a href=/people/x/xiaoxiao-guo/>Xiaoxiao Guo</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/s/satinder-singh/>Satinder Singh</a>
|
<a href=/people/l/lazaros-polymenakos/>Lazaros Polymenakos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1114><div class="card-body p-3 small">Many Natural Language Processing (NLP) tasks depend on using Named Entities (NEs) that are contained in texts and in external knowledge sources. While this is easy for humans, the present neural methods that rely on learned word embeddings may not perform well for these NLP tasks, especially in the presence of Out-Of-Vocabulary (OOV) or rare NEs. In this paper, we propose a solution for this problem, and present empirical evaluations on : a) a structured Question-Answering task, b) three related Goal-Oriented dialog tasks, and c) a Reading-Comprehension task, which show that the proposed method can be effective in dealing with both in-vocabulary and OOV NEs. We create extended versions of dialog bAbI tasks 1,2 and 4 and OOV versions of the CBT test set which are available at-https://github.com/IBM/ne-table-datasets/</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1116.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1116 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1116 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1116/>Semantic Textual Similarity with Siamese Neural Networks<span class=acl-fixed-case>S</span>iamese Neural Networks</a></strong><br><a href=/people/t/tharindu-ranasinghe/>Tharindu Ranasinghe</a>
|
<a href=/people/c/constantin-orasan/>Constantin Orasan</a>
|
<a href=/people/r/ruslan-mitkov/>Ruslan Mitkov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1116><div class="card-body p-3 small">Calculating the Semantic Textual Similarity (STS) is an important research area in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> which plays a significant role in many applications such as <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, document summarisation, <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> and <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>. This paper evaluates Siamese recurrent architectures, a special type of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, which are used here to measure STS. Several variants of the <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a> are compared with existing methods</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1119 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1119/>Self-Attentional Models Application in Task-Oriented Dialogue Generation Systems</a></strong><br><a href=/people/m/mansour-saffar-mehrjardi/>Mansour Saffar Mehrjardi</a>
|
<a href=/people/a/amine-trabelsi/>Amine Trabelsi</a>
|
<a href=/people/o/osmar-r-zaiane/>Osmar R. Zaiane</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1119><div class="card-body p-3 small">Self-attentional models are a new paradigm for sequence modelling tasks which differ from common sequence modelling methods, such as recurrence-based and convolution-based sequence learning, in the way that their architecture is only based on the attention mechanism. Self-attentional models have been used in the creation of the state-of-the-art models in many NLP task such as <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>, but their usage has not been explored for the task of training end-to-end task-oriented dialogue generation systems yet. In this study, we apply these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on the DSTC2 dataset for training task-oriented chatbots. Our finding shows that self-attentional models can be exploited to create end-to-end task-oriented chatbots which not only achieve higher evaluation scores compared to recurrence-based models, but also do so more efficiently.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1121.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1121 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1121 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1121/>Persistence pays off : Paying Attention to What the LSTM Gating Mechanism Persists<span class=acl-fixed-case>LSTM</span> Gating Mechanism Persists</a></strong><br><a href=/people/g/giancarlo-salton/>Giancarlo Salton</a>
|
<a href=/people/j/john-kelleher/>John Kelleher</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1121><div class="card-body p-3 small">Recurrent Neural Network Language Models composed of LSTM units, especially those augmented with an external memory, have achieved state-of-the-art results in <a href=https://en.wikipedia.org/wiki/Language_model>Language Modeling</a>. However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> still struggle to process long sequences which are more likely to contain long-distance dependencies because of information fading. In this paper we demonstrate an effective <a href=https://en.wikipedia.org/wiki/Mechanism_design>mechanism</a> for retrieving information in a memory augmented LSTM LM based on attending to information in memory in proportion to the number of timesteps the LSTM gating mechanism persisted the information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1122.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1122 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1122 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1122/>Development and Evaluation of Three Named Entity Recognition Systems for Serbian-The Case of Personal Names<span class=acl-fixed-case>S</span>erbian - The Case of Personal Names</a></strong><br><a href=/people/b/branislava-sandrih/>Branislava Šandrih</a>
|
<a href=/people/c/cvetana-krstev/>Cvetana Krstev</a>
|
<a href=/people/r/ranka-stankovic/>Ranka Stankovic</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1122><div class="card-body p-3 small">In this paper we present a rule- and lexicon-based system for the recognition of Named Entities (NE) in Serbian newspaper texts that was used to prepare a gold standard annotated with personal names. It was further used to prepare training sets for four different levels of annotation, which were further used to train two Named Entity Recognition (NER) systems : Stanford and <a href=https://en.wikipedia.org/wiki/SpaCy>spaCy</a>. All obtained models, together with a rule- and lexicon-based system were evaluated on two sample texts : a part of the gold standard and an independent newspaper text of approximately the same size. The results show that rule- and lexicon-based system outperforms trained <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> in all four scenarios (measured by F1), while Stanford models has the highest <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a>. All systems obtain best results in recognizing <a href=https://en.wikipedia.org/wiki/Personal_name>full names</a>, while the recognition of first names only is rather poor. The produced <a href=https://en.wikipedia.org/wiki/Physical_model>models</a> are incorporated into a Web platform NER&Beyond that provides various NE-related functions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1123.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1123 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1123 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1123/>Moral Stance Recognition and Polarity Classification from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and Elicited Text<span class=acl-fixed-case>T</span>witter and Elicited Text</a></strong><br><a href=/people/w/wesley-santos/>Wesley Santos</a>
|
<a href=/people/i/ivandre-paraboni/>Ivandré Paraboni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1123><div class="card-body p-3 small">We introduce a labelled corpus of stances about moral issues for the <a href=https://en.wikipedia.org/wiki/Brazilian_Portuguese>Brazilian Portuguese language</a>, and present reference results for both the stance recognition and polarity classification tasks. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is built from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and further expanded with data elicited through <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowd sourcing</a> and labelled by their own authors. Put together, the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and reference results are expected to be taken as a baseline for further studies in the field of stance recognition and polarity classification from text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1125.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1125 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1125 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1125/>Offence in Dialogues : A Corpus-Based Study</a></strong><br><a href=/people/j/johannes-schafer/>Johannes Schäfer</a>
|
<a href=/people/b/ben-burtenshaw/>Ben Burtenshaw</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1125><div class="card-body p-3 small">In recent years an increasing number of analyses of offensive language has been published, however, dealing mainly with the automatic detection and classification of isolated instances. In this paper we aim to understand the impact of offensive messages in online conversations diachronically, and in particular the change in offensiveness of dialogue turns. In turn, we aim to measure the progression of offence level as well as its direction-For example, whether a conversation is escalating or declining in offence. We present our method of extracting linear dialogues from tree-structured conversations in social media data and make our code publicly available. Furthermore, we discuss methods to analyse this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> through changes in discourse offensiveness. Our paper includes two main contributions ; first, using a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> to measure the level of offensiveness in conversations ; and second, the analysis of conversations around offensive comments using decoupling functions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1127.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1127 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1127 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1127/>A Morpho-Syntactically Informed LSTM-CRF Model for Named Entity Recognition<span class=acl-fixed-case>LSTM</span>-<span class=acl-fixed-case>CRF</span> Model for Named Entity Recognition</a></strong><br><a href=/people/l/lilia-simeonova/>Lilia Simeonova</a>
|
<a href=/people/k/kiril-simov/>Kiril Simov</a>
|
<a href=/people/p/petya-osenova/>Petya Osenova</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1127><div class="card-body p-3 small">We propose a morphologically informed model for <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, which is based on LSTM-CRF architecture and combines word embeddings, Bi-LSTM character embeddings, part-of-speech (POS) tags, and morphological information. While previous work has focused on learning from raw word input, using word and character embeddings only, we show that for morphologically rich languages, such as <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a>, access to POS information contributes more to the performance gains than the detailed morphological information. Thus, we show that <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> needs only coarse-grained POS tags, but at the same time it can benefit from simultaneously using some POS information of different granularity. Our evaluation results over a standard <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> show sizeable improvements over the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> for Bulgarian NER.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1131.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1131 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1131 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1131/>Automated Text Simplification as a Preprocessing Step for <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a> into an Under-resourced Language</a></strong><br><a href=/people/s/sanja-stajner/>Sanja Štajner</a>
|
<a href=/people/m/maja-popovic/>Maja Popović</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1131><div class="card-body p-3 small">In this work, we investigate the possibility of using fully automatic text simplification system on the English source in machine translation (MT) for improving its translation into an under-resourced language. We use the state-of-the-art automatic text simplification (ATS) system for lexically and syntactically simplifying source sentences, which are then translated with two state-of-the-art English-to-Serbian MT systems, the phrase-based MT (PBMT) and the neural MT (NMT). We explore three different scenarios for using the ATS in MT : (1) using the raw output of the ATS ; (2) automatically filtering out the sentences with low grammaticality and meaning preservation scores ; and (3) performing a minimal manual correction of the ATS output. Our results show improvement in fluency of the <a href=https://en.wikipedia.org/wiki/Translation>translation</a> regardless of the chosen scenario, and difference in success of the three scenarios depending on the MT approach used (PBMT or NMT) with regards to improving <a href=https://en.wikipedia.org/wiki/Translation>translation fluency</a> and post-editing effort.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1132.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1132 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1132 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1132/>Investigating Multilingual Abusive Language Detection : A Cautionary Tale</a></strong><br><a href=/people/k/kenneth-steimel/>Kenneth Steimel</a>
|
<a href=/people/d/daniel-dakota/>Daniel Dakota</a>
|
<a href=/people/y/yue-chen/>Yue Chen</a>
|
<a href=/people/s/sandra-kubler/>Sandra Kübler</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1132><div class="card-body p-3 small">Abusive language detection has received much attention in the last years, and recent approaches perform the task in a number of different languages. We investigate which factors have an effect on multilingual settings, focusing on the compatibility of data and annotations. In the current paper, we focus on <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a>. Our findings show large differences in performance between the two languages. We find that the best performance is achieved by different <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification algorithms</a>. Sampling to address class imbalance issues is detrimental for <a href=https://en.wikipedia.org/wiki/German_language>German</a> and beneficial for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. The only similarity that we find is that neither data set shows clear topics when we compare the results of <a href=https://en.wikipedia.org/wiki/Topic_modeling>topic modeling</a> to the gold standard. Based on our findings, we can conclude that a multilingual optimization of classifiers is not possible even in settings where comparable data sets are used.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1138.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1138 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1138 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1138/>SenZi : A Sentiment Analysis Lexicon for the Latinised Arabic (Arabizi)<span class=acl-fixed-case>S</span>en<span class=acl-fixed-case>Z</span>i: A Sentiment Analysis Lexicon for the Latinised <span class=acl-fixed-case>A</span>rabic (<span class=acl-fixed-case>A</span>rabizi)</a></strong><br><a href=/people/t/taha-tobaili/>Taha Tobaili</a>
|
<a href=/people/m/miriam-fernandez/>Miriam Fernandez</a>
|
<a href=/people/h/harith-alani/>Harith Alani</a>
|
<a href=/people/s/sanaa-sharafeddine/>Sanaa Sharafeddine</a>
|
<a href=/people/h/hazem-hajj/>Hazem Hajj</a>
|
<a href=/people/g/goran-glavas/>Goran Glavaš</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1138><div class="card-body p-3 small">Arabizi is an informal written form of <a href=https://en.wikipedia.org/wiki/Varieties_of_Arabic>dialectal Arabic</a> transcribed in <a href=https://en.wikipedia.org/wiki/Latin_script>Latin alphanumeric characters</a>. It has a proven popularity on chat platforms and <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, yet <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> suffers from a severe lack of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP) resources</a>. As such, texts written in <a href=https://en.wikipedia.org/wiki/Arabizi>Arabizi</a> are often disregarded in sentiment analysis tasks for <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>. In this paper we describe the creation of a sentiment lexicon for <a href=https://en.wikipedia.org/wiki/Arabizi>Arabizi</a> that was enriched with <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. The result is a new Arabizi lexicon consisting of 11.3 K positive and 13.3 K negative words. We evaluated this <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a> by classifying the sentiment of Arabizi tweets achieving an F1-score of 0.72. We provide a detailed error analysis to present the challenges that impact the <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> of <a href=https://en.wikipedia.org/wiki/Arabizi>Arabizi</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1140 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1140/>Cross-Lingual Word Embeddings for Morphologically Rich Languages</a></strong><br><a href=/people/a/ahmet-ustun/>Ahmet Üstün</a>
|
<a href=/people/g/gosse-bouma/>Gosse Bouma</a>
|
<a href=/people/g/gertjan-van-noord/>Gertjan van Noord</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1140><div class="card-body p-3 small">Cross-lingual word embedding models learn a shared vector space for two or more languages so that words with similar meaning are represented by similar vectors regardless of their language. Although the existing models achieve high performance on pairs of morphologically simple languages, they perform very poorly on morphologically rich languages such as <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish</a> and <a href=https://en.wikipedia.org/wiki/Finnish_language>Finnish</a>. In this paper, we propose a morpheme-based model in order to increase the performance of cross-lingual word embeddings on morphologically rich languages. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> includes a simple extension which enables us to exploit <a href=https://en.wikipedia.org/wiki/Morpheme>morphemes</a> for cross-lingual mapping. We applied our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for the <a href=https://en.wikipedia.org/wiki/Finnish_language>Turkish-Finnish language pair</a> on the bilingual word translation task. Results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the baseline models by 2 % in the <a href=https://en.wikipedia.org/wiki/Nearest_neighbour_search>nearest neighbour ranking</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1142.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1142 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1142 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1142/>Deep learning contextual models for prediction of sport event outcome from sportsman’s interviews</a></strong><br><a href=/people/b/boris-velichkov/>Boris Velichkov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/s/svetla-boytcheva/>Svetla Boytcheva</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1142><div class="card-body p-3 small">This paper presents an approach for prediction of results for <a href=https://en.wikipedia.org/wiki/Sport>sport events</a>. Usually the sport forecasting approaches are based on <a href=https://en.wikipedia.org/wiki/Structured_data>structured data</a>. We test the hypothesis that the sports results can be predicted by using <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and machine learning techniques applied over interviews with the players shortly before the sport events. The proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> uses deep learning contextual models, applied over <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured textual documents</a>. Several experiments were performed for interviews with players in individual sports like <a href=https://en.wikipedia.org/wiki/Boxing>boxing</a>, <a href=https://en.wikipedia.org/wiki/Martial_arts>martial arts</a>, and <a href=https://en.wikipedia.org/wiki/Tennis>tennis</a>. The results from the conducted experiment confirmed our initial assumption that an interview from a sportsman before a match contains information that can be used for prediction the outcome from it. Furthermore, the results provide strong evidence in support of our research hypothesis, that is, we can predict the outcome from a sport match analyzing an interview, given before it.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1144.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1144 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1144 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1144/>Exploiting <a href=https://en.wikipedia.org/wiki/Open_IE>Open IE</a> for Deriving Multiple Premises Entailment Corpus<span class=acl-fixed-case>IE</span> for Deriving Multiple Premises Entailment Corpus</a></strong><br><a href=/people/m/martin-vita/>Martin Víta</a>
|
<a href=/people/j/jakub-klimek/>Jakub Klímek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1144><div class="card-body p-3 small">Natural language inference (NLI) is a key part of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. The NLI task is defined as a <a href=https://en.wikipedia.org/wiki/Decision_problem>decision problem</a> whether a given sentence hypothesis can be inferred from a given text. Typically, we deal with a text consisting of just a single premise / single sentence, which is called a single premise entailment (SPE) task. Recently, a derived task of NLI from multiple premises (MPE) was introduced together with the first annotated corpus and corresponding several strong baselines. Nevertheless, the further development in MPE field requires accessibility of huge amounts of annotated data. In this paper we introduce a novel method for rapid deriving of MPE corpora from an existing NLI (SPE) annotated data that does not require any additional annotation work. This proposed approach is based on using an open <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction system</a>. We demonstrate the application of the <a href=https://en.wikipedia.org/wiki/Methodology>method</a> on a well known SNLI corpus. Over the obtained <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, we provide the first evaluations as well as we state a strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1147.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1147 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1147 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=R19-1147" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/R19-1147/>ETNLP : A Visual-Aided Systematic Approach to Select Pre-Trained Embeddings for a Downstream Task<span class=acl-fixed-case>ETNLP</span>: A Visual-Aided Systematic Approach to Select Pre-Trained Embeddings for a Downstream Task</a></strong><br><a href=/people/s/son-vu-xuan/>Son Vu Xuan</a>
|
<a href=/people/t/thanh-vu/>Thanh Vu</a>
|
<a href=/people/s/son-tran/>Son Tran</a>
|
<a href=/people/l/lili-jiang/>Lili Jiang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1147><div class="card-body p-3 small">Given many recent advanced embedding models, selecting pre-trained word representation (i.e., word embedding) models best fit for a specific downstream NLP task is non-trivial. In this paper, we propose a systematic approach to extracting, evaluating, and visualizing multiple sets of pre-trained word embed- dings to determine which embeddings should be used in a downstream task. First, for extraction, we provide a method to extract a subset of the <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> to be used in the downstream NLP tasks. Second, for evaluation, we analyse the quality of pre-trained embeddings using an input word analogy list. Finally, we visualize the <a href=https://en.wikipedia.org/wiki/Embedding>embedding space</a> to explore the embedded words interactively. We demonstrate the effectiveness of the proposed approach on our pre-trained word embedding models in <a href=https://en.wikipedia.org/wiki/Vietnamese_language>Vietnamese</a> to select which <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> are suitable for a named entity recogni- tion (NER) task. Specifically, we create a large Vietnamese word analogy list to evaluate and select the pre-trained embedding models for the task. We then utilize the selected embed- dings for the NER task and achieve the new state-of-the-art results on the task benchmark dataset. We also apply the approach to another downstream task of privacy-guaranteed embedding selection, and show that it helps users quickly select the most suitable embeddings. In addition, we create an <a href=https://en.wikipedia.org/wiki/Open-source_software>open-source system</a> using the proposed systematic approach to facilitate similar studies on other NLP tasks. The source code and data are available at https : //github.com / vietnlp / etnlp.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1150.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1150 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1150 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1150/>Bigger versus Similar : Selecting a Background Corpus for First Story Detection Based on Distributional Similarity</a></strong><br><a href=/people/f/fei-wang/>Fei Wang</a>
|
<a href=/people/r/robert-j-ross/>Robert J. Ross</a>
|
<a href=/people/j/john-kelleher/>John D. Kelleher</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1150><div class="card-body p-3 small">The current state of the art for First Story Detection (FSD) are nearest neighbour-based models with traditional term vector representations ; however, one challenge faced by FSD models is that the document representation is usually defined by the vocabulary and term frequency from a background corpus. Consequently, the ideal background corpus should arguably be both large-scale to ensure adequate term coverage, and similar to the target domain in terms of the <a href=https://en.wikipedia.org/wiki/Frequency_distribution>language distribution</a>. However, given these two factors can not always be mutually satisfied, in this paper we examine whether the distributional similarity of common terms is more important than the scale of common terms for FSD. As a basis for our analysis we propose a set of <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to quantitatively measure the scale of common terms and the distributional similarity between corpora. Using these <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> we rank different background corpora relative to a target corpus. We also apply <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> based on different background corpora to the FSD task. Our results show that term distributional similarity is more predictive of good FSD performance than the scale of common terms ; and, thus we demonstrate that a smaller recent domain-related corpus will be more suitable than a very large-scale general corpus for FSD.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1151.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1151 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1151 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1151/>Predicting Sentiment of Polish Language Short Texts<span class=acl-fixed-case>P</span>olish Language Short Texts</a></strong><br><a href=/people/a/aleksander-wawer/>Aleksander Wawer</a>
|
<a href=/people/j/julita-sobiczewska/>Julita Sobiczewska</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1151><div class="card-body p-3 small">The goal of this paper is to use all available Polish language data sets to seek the best possible performance in supervised sentiment analysis of short texts. We use text collections with labelled sentiment such as <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>, <a href=https://en.wikipedia.org/wiki/Film_criticism>movie reviews</a> and a sentiment treebank, in three comparison modes. In the first, we examine the performance of <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained and tested on the same <a href=https://en.wikipedia.org/wiki/Text_corpus>text collection</a> using standard cross-validation (in-domain). In the second we train <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> on all available <a href=https://en.wikipedia.org/wiki/Data>data</a> except the given test collection, which we use for testing (one vs rest cross-domain). In the third, we train a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> on one <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> and apply it to another one (one vs one cross-domain). We compare wide range of methods including <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> on bag-of-words representation, bidirectional recurrent neural networks as well as the most recent pre-trained architectures <a href=https://en.wikipedia.org/wiki/ELMO>ELMO</a> and BERT. We formulate conclusions as to cross-domain and in-domain performance of each <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a>. Unsurprisingly, BERT turned out to be a strong performer, especially in the cross-domain setting. What is surprising however, is solid performance of the relatively simple multinomial Naive Bayes classifier, which performed equally well as BERT on several data sets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1152.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1152 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1152 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1152/>Improving Named Entity Linking Corpora Quality</a></strong><br><a href=/people/a/albert-weichselbraun/>Albert Weichselbraun</a>
|
<a href=/people/a/adrian-m-p-brasoveanu/>Adrian M.P. Brasoveanu</a>
|
<a href=/people/p/philipp-kuntschik/>Philipp Kuntschik</a>
|
<a href=/people/l/lyndon-j-b-nixon/>Lyndon J.B. Nixon</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1152><div class="card-body p-3 small">Gold standard corpora and competitive evaluations play a key role in benchmarking named entity linking (NEL) performance and driving the development of more sophisticated NEL systems. The quality of the used corpora and the used evaluation metrics are crucial in this process. We, therefore, assess the quality of three popular evaluation corpora, identifying four major issues which affect these gold standards : (i) the use of different annotation styles, (ii) incorrect and missing annotations, (iii) Knowledge Base evolution, (iv) and differences in annotating co-occurrences. This paper addresses these issues by formalizing NEL annotations and corpus versioning which allows standardizing corpus creation, supports corpus evolution, and paves the way for the use of lenses to automatically transform between different corpus configurations. In addition, the use of clearly defined scoring rules and evaluation metrics ensures a better comparability of evaluation results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1156.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1156 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1156 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1156/>An Open, Extendible, and Fast Turkish Morphological Analyzer<span class=acl-fixed-case>T</span>urkish Morphological Analyzer</a></strong><br><a href=/people/o/olcay-taner-yildiz/>Olcay Taner Yıldız</a>
|
<a href=/people/b/begum-avar/>Begüm Avar</a>
|
<a href=/people/g/gokhan-ercan/>Gökhan Ercan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1156><div class="card-body p-3 small">In this paper, we present a two-level morphological analyzer for <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish</a>. The morphological analyzer consists of five main components : finite state transducer, rule engine for suffixation, <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a>, trie data structure, and <a href=https://en.wikipedia.org/wiki/LRU_cache>LRU cache</a>. We use <a href=https://en.wikipedia.org/wiki/Java_(programming_language)>Java language</a> to implement finite state machine logic and rule engine, Xml language to describe the finite state transducer rules of the <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish language</a>, which makes the morphological analyzer both easily extendible and easily applicable to other languages. Empowered with the comprehensiveness of a lexicon of 54,000 bare-forms including 19,000 proper nouns, our morphological analyzer presents one of the most reliable analyzers produced so far. The analyzer is compared with Turkish morphological analyzers in the literature. By using <a href=https://en.wikipedia.org/wiki/LRU_cache>LRU cache</a> and a <a href=https://en.wikipedia.org/wiki/Trie>trie data structure</a>, the <a href=https://en.wikipedia.org/wiki/System>system</a> can analyze 100,000 words per second, which enables users to analyze huge corpora in a few hours.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1159.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1159 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1159 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1159/>Multilingual Dynamic Topic Model</a></strong><br><a href=/people/e/elaine-zosa/>Elaine Zosa</a>
|
<a href=/people/m/mark-granroth-wilding/>Mark Granroth-Wilding</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1159><div class="card-body p-3 small">Dynamic topic models (DTMs) capture the evolution of topics and trends in <a href=https://en.wikipedia.org/wiki/Time_series>time series data</a>. Current DTMs are applicable only to monolingual datasets. In this paper we present the multilingual dynamic topic model (ML-DTM), a novel <a href=https://en.wikipedia.org/wiki/Topic_model>topic model</a> that combines DTM with an existing multilingual topic modeling method to capture cross-lingual topics that evolve across time. We present results of this model on a parallel German-English corpus of news articles and a comparable corpus of Finnish and Swedish news articles. We demonstrate the capability of ML-DTM to track significant events related to a topic and show that it finds distinct topics and performs as well as existing multilingual topic models in aligning cross-lingual topics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-1160.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-1160 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-1160 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-1160/>A Wide-Coverage Context-Free Grammar for Icelandic and an Accompanying Parsing System<span class=acl-fixed-case>I</span>celandic and an Accompanying Parsing System</a></strong><br><a href=/people/v/vilhjalmur-thorsteinsson/>Vilhjálmur Þorsteinsson</a>
|
<a href=/people/h/hulda-oladottir/>Hulda Óladóttir</a>
|
<a href=/people/h/hrafn-loftsson/>Hrafn Loftsson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-1160><div class="card-body p-3 small">We present an open-source, wide-coverage context-free grammar (CFG) for <a href=https://en.wikipedia.org/wiki/Icelandic_language>Icelandic</a>, and an accompanying parsing system. The grammar has over 5,600 <a href=https://en.wikipedia.org/wiki/Terminal_and_nonterminal_symbols>nonterminals</a>, 4,600 <a href=https://en.wikipedia.org/wiki/Terminal_and_nonterminal_symbols>terminals</a> and 19,000 productions in fully expanded form, with feature agreement constraints for <a href=https://en.wikipedia.org/wiki/Grammatical_case>case</a>, <a href=https://en.wikipedia.org/wiki/Grammatical_gender>gender</a>, number and person. The parsing system consists of an enhanced <a href=https://en.wikipedia.org/wiki/Earley_parser>Earley-based parser</a> and a mechanism to select best-scoring parse trees from shared packed parse forests. Our parsing system is able to parse about 90 % of all sentences in articles published on the main Icelandic news websites. Preliminary evaluation with evalb shows an <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a> of 70.72 % on parsed sentences. Our system demonstrates that parsing a morphologically rich language using a wide-coverage CFG can be practical.</div></div></div><hr><div id=r19-2><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-2.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/R19-2/>Proceedings of the Student Research Workshop Associated with RANLP 2019</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-2000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-2000/>Proceedings of the Student Research Workshop Associated with RANLP 2019</a></strong><br><a href=/people/v/venelin-kovatchev/>Venelin Kovatchev</a>
|
<a href=/people/i/irina-temnikova/>Irina Temnikova</a>
|
<a href=/people/b/branislava-sandrih/>Branislava Šandrih</a>
|
<a href=/people/i/ivelina-nikolova/>Ivelina Nikolova</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-2002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-2002 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-2002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-2002/>Classification Approaches to Identify Informative Tweets</a></strong><br><a href=/people/p/piush-aggarwal/>Piush Aggarwal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-2002><div class="card-body p-3 small">Social media platforms have become prime forums for reporting news, with users sharing what they saw, heard or read on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. News from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> is potentially useful for various stakeholders including aid organizations, news agencies, and individuals. However, <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> also contains a vast amount of non-news content. For users to be able to draw on benefits from news reported on social media it is necessary to reliably identify news content and differentiate <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> from non-news. In this paper, we tackle the challenge of classifying a social post as news or not. To this end, we provide a new manually annotated dataset containing 2,992 tweets from 5 different topical categories. Unlike earlier <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, it includes postings posted by personal users who do not promote a business or a product and are not affiliated with any organization. We also investigate various <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline systems</a> and evaluate their performance on the newly generated <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. Our results show that the best <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> are the SVM and BERT models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-2004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-2004 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-2004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-2004/>Multilingual Language Models for <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> in <a href=https://en.wikipedia.org/wiki/German_language>German</a> and English<span class=acl-fixed-case>G</span>erman and <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/a/antonia-baumann/>Antonia Baumann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-2004><div class="card-body p-3 small">We assess the language specificity of recent <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> by exploring the potential of a multilingual language model. In particular, we evaluate Google&#8217;s multilingual BERT (mBERT) model on Named Entity Recognition (NER) in <a href=https://en.wikipedia.org/wiki/German_language>German</a> and <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We expand the work on language model fine-tuning by Howard and Ruder (2018), applying it to the BERT architecture. We successfully reproduce the NER results published by Devlin et al. (2019).Our results show that the multilingual language model generalises well for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>NER</a> in the chosen languages, matching the native model in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and comparing well with recent approaches for <a href=https://en.wikipedia.org/wiki/German_language>German</a>. However, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> does not benefit from the added fine-tuning methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-2006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-2006 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-2006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-2006/>Cross-Lingual Coreference : The Case of <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a> and English<span class=acl-fixed-case>B</span>ulgarian and <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/z/zara-kancheva/>Zara Kancheva</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-2006><div class="card-body p-3 small">The paper presents several common approaches towards cross- and multi-lingual coreference resolution in a search of the most effective practices to be applied within the work on Bulgarian-English manual coreference annotation of a short story. The work aims at outlining the typology of the differences in the annotated parallel texts. The results of the research prove to be comparable with the tendencies observed in similar works on other <a href=https://en.wikipedia.org/wiki/Slavic_languages>Slavic languages</a> and show surprising differences between the types of markables and their frequency in <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a> and <a href=https://en.wikipedia.org/wiki/English_language>English</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-2008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-2008 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-2008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-2008/>Evaluation of Stacked Embeddings for <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a> on the Downstream Tasks POS and NERC<span class=acl-fixed-case>B</span>ulgarian on the Downstream Tasks <span class=acl-fixed-case>POS</span> and <span class=acl-fixed-case>NERC</span></a></strong><br><a href=/people/i/iva-marinova/>Iva Marinova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-2008><div class="card-body p-3 small">This paper reports on experiments with different stacks of word embeddings and evaluation of their usefulness for Bulgarian downstream tasks such as Named Entity Recognition and Classification (NERC) and Part-of-speech (POS) Tagging. Word embeddings stay in the core of the development of NLP, with several key language models being created over the last two years like FastText (CITATION), ElMo (CITATION), BERT (CITATION) and Flair (CITATION). Stacking or combining different word embeddings is another technique used in this paper and still not reported for Bulgarian NERC. Well-established architecture is used for the sequence tagging task such as BI-LSTM-CRF, and different pre-trained language models are combined in the embedding layer to decide which combination of them scores better.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-2009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-2009 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-2009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-2009/>Overview on NLP Techniques for Content-based Recommender Systems for Books<span class=acl-fixed-case>NLP</span> Techniques for Content-based Recommender Systems for Books</a></strong><br><a href=/people/m/melania-berbatova/>Melania Berbatova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-2009><div class="card-body p-3 small">Recommender systems are an essential part of today&#8217;s largest websites. Without <a href=https://en.wikipedia.org/wiki/Microsoft_Windows>them</a>, it would be hard for users to find the right products and content. One of the most popular <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for <a href=https://en.wikipedia.org/wiki/Recommender_system>recommendations</a> is <a href=https://en.wikipedia.org/wiki/Content-based_filtering>content-based filtering</a>. It relies on analysing product metadata, a great part of which is <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual data</a>. Despite their frequent use, there is still no standard procedure for developing and evaluating content-based recommenders. In this paper, we will first examine current approaches for designing, training and evaluating <a href=https://en.wikipedia.org/wiki/Recommender_system>recommender systems</a> based on <a href=https://en.wikipedia.org/wiki/Text-based_user_interface>textual data</a> for <a href=https://en.wikipedia.org/wiki/Recommender_system>books recommendations</a> for <a href=https://en.wikipedia.org/wiki/GoodReads>GoodReads&#8217; website</a>. We will give critiques on existing methods and suggest how <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language techniques</a> can be employed for the improvement of content-based recommenders.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/R19-2013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-R19-2013 data-toggle=collapse aria-expanded=false aria-controls=abstract-R19-2013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/R19-2013/>Multilingual Complex Word Identification : <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>Convolutional Neural Networks</a> with Morphological and Linguistic Features</a></strong><br><a href=/people/k/kim-cheng-sheang/>Kim Cheng Sheang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-R19-2013><div class="card-body p-3 small">The paper is about our experiments with Complex Word Identification system using deep learning approach with <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and engineered features.</div></div></div><hr><div id=w19-87><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-87.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/W19-87/>Proceedings of the Human-Informed Translation and Interpreting Technology Workshop (HiT-IT 2019)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8700/>Proceedings of the Human-Informed Translation and Interpreting Technology Workshop (HiT-IT 2019)</a></strong><br></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8701.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8701 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8701 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8701/>Comparison between Automatic and Human Subtitling : A Case Study with Game of Thrones</a></strong><br><a href=/people/s/sabrina-baldo-de-brebisson/>Sabrina Baldo de Brébisson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8701><div class="card-body p-3 small">In this submission, I would like to share my experiences with the software DeepL and the comparison analysis I have made with human subtitling offered by the DVD version of the corpus I have chosen as the topic of my study the eight Seasons of <a href=https://en.wikipedia.org/wiki/Game_of_Thrones>Game of Thrones</a>. The idea is to study if the version proposed by an automatic translation program could be used as a first draft for the professional subtitler. It is expected that the latter would work on the form of the subtitles, that is to say mainly on their length, in a second step.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8702.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8702 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8702 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8702/>Parallel Corpus of Croatian-Italian Administrative Texts<span class=acl-fixed-case>C</span>roatian-<span class=acl-fixed-case>I</span>talian Administrative Texts</a></strong><br><a href=/people/m/marija-brkic-bakaric/>Marija Brkic Bakaric</a>
|
<a href=/people/i/ivana-lalli-pacelat/>Ivana Lalli Pacelat</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8702><div class="card-body p-3 small">Parallel corpora constitute a unique re-source for providing assistance to human translators. The selection and preparation of the parallel corpora also conditions the quality of the resulting MT engine. Since <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian</a> is a national language and <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a> is officially recognized as a minority lan-guage in seven cities and twelve munici-palities of Istria County, a large amount of parallel texts is produced on a daily basis. However, there have been no attempts in using these texts for compiling a <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpus</a>. A domain-specific sentence-aligned parallel Croatian-Italian corpus of administrative texts would be of high value in creating different language tools and resources. The aim of this paper is, therefore, to explore the value of parallel documents which are publicly available mostly in pdf format and to investigate the use of automatically-built dictionaries in corpus compilation. The effects that a document format and, consequently sentence splitting, and the dictionary input have on the sentence alignment process are manually evaluated.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8703.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8703 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8703 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8703/>What Influences the Features of Post-editese? A Preliminary Study</a></strong><br><a href=/people/s/sheila-castilho/>Sheila Castilho</a>
|
<a href=/people/n/natalia-resende/>Natália Resende</a>
|
<a href=/people/r/ruslan-mitkov/>Ruslan Mitkov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8703><div class="card-body p-3 small">While a number of studies have shown evidence of translationese phenomena, that is, statistical differences between original texts and translated texts (Gellerstam, 1986), results of studies searching for translationese features in postedited texts (what has been called posteditese (Daems et al., 2017)) have presented mixed results. This paper reports a preliminary study aimed at identifying the presence of post-editese features in machine-translated post-edited texts and at understanding how they differ from translationese features. We test the influence of factors such as post-editing (PE) levels (full vs. light), <a href=https://en.wikipedia.org/wiki/Language_proficiency>translation proficiency</a> (professionals vs. students) and text domain (news vs. literary). Results show evidence of post-editese features, especially in light PE texts and in certain domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8705.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8705 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8705 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8705/>Human Evaluation of <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> : The Case of Deep Learning</a></strong><br><a href=/people/m/marie-escribe/>Marie Escribe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8705><div class="card-body p-3 small">Recent advances in <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>artificial neural networks</a> now have a great impact on <a href=https://en.wikipedia.org/wiki/Translation_technology>translation technology</a>. A considerable achievement was reached in this field with the publication of L&#8217;Apprentissage Profond. This book, originally written in English (Deep Learning), was entirely machine-translated into <a href=https://en.wikipedia.org/wiki/French_language>French</a> and post-edited by several experts. In this context, it appears essential to have a clear vision of the performance of MT tools. Providing an evaluation of <a href=https://en.wikipedia.org/wiki/Neurotransmitter_transporter>NMT</a> is precisely the aim of the present research paper. To accomplish this objective, a framework for error categorisation was built and a comparative analysis of the raw translation output and the post-edited version was performed with the purpose of identifying recurring patterns of errors. The findings showed that even though some <a href=https://en.wikipedia.org/wiki/Grammatical_error>grammatical errors</a> were spotted, the output was generally correct from a linguistic point of view. The most recurring errors are linked to the specialised terminology employed in this book. Further errors include parts of text that were not translated as well as edits based on <a href=https://en.wikipedia.org/wiki/Style_(visual_arts)>stylistic preferences</a>. The major part of the output was not acceptable as such and required several edits per segment, but some sentences were of publishable quality and were therefore left untouched in the final version.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8710.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8710 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8710 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8710/>The Chinese / English Political Interpreting Corpus (CEPIC): A New Electronic Resource for Translators and Interpreters<span class=acl-fixed-case>C</span>hinese/<span class=acl-fixed-case>E</span>nglish Political Interpreting Corpus (<span class=acl-fixed-case>CEPIC</span>): A New Electronic Resource for Translators and Interpreters</a></strong><br><a href=/people/j/jun-pan/>Jun Pan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8710><div class="card-body p-3 small">The Chinese / English Political Interpreting Corpus (CEPIC) is a new electronic and open access resource developed for translators and interpreters, especially those working with political text types. Over 6 million word tokens in size, the online corpus consists of transcripts of Chinese (Cantonese & Putonghua) / English political speeches and their translated and interpreted texts. It includes rich meta-data and is POS-tagged and annotated with prosodic and paralinguistic features that are of concern to spoken language and interpreting. The online platform of the CEPIC features main functions including <a href=https://en.wikipedia.org/wiki/Keyword_search>Keyword Search</a>, Word Collocation and Expanded Keyword in Context, which are illustrated in the paper. The <a href=https://en.wikipedia.org/wiki/CEPIC>CEPIC</a> can shed light on online translation and interpreting corpora development in the future.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8714.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8714 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8714 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8714/>Towards a Proactive MWE Terminological Platform for Cross-Lingual Mediation in the Age of <a href=https://en.wikipedia.org/wiki/Big_data>Big Data</a><span class=acl-fixed-case>MWE</span> Terminological Platform for Cross-Lingual Mediation in the Age of Big Data</a></strong><br><a href=/people/b/benjamin-k-tsou/>Benjamin K. Tsou</a>
|
<a href=/people/k/kapo-chow/>Kapo Chow</a>
|
<a href=/people/j/junru-nie/>Junru Nie</a>
|
<a href=/people/y/yuan-yuan/>Yuan Yuan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8714><div class="card-body p-3 small">The emergence of <a href=https://en.wikipedia.org/wiki/China>China</a> as a global economic power in the 21st Century has brought about surging needs for cross-lingual and cross-cultural mediation, typically performed by translators. Advances in <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>Artificial Intelligence</a> and <a href=https://en.wikipedia.org/wiki/Language_engineering>Language Engineering</a> have been bolstered by <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine learning</a> and suitable Big Data cultivation. They have helped to meet some of the translator&#8217;s needs, though the technical specialists have not kept pace with the practical and expanding requirements in language mediation. One major technical and linguistic hurdle involves words outside the vocabulary of the translator or the lexical database he / she consults, especially Multi-Word Expressions (Compound Words) in technical subjects. A further problem is in the multiplicity of renditions of a term in the target language. This paper discusses a proactive approach following the successful extraction and application of sizable bilingual Multi-Word Expressions (Compound Words) for language mediation in technical subjects, which do not fall within the expertise of typical translators, who have inadequate appreciation of the range of new technical tools available to help him / her. Our approach draws on the personal reflections of translators and teachers of translation and is based on the prior R&D efforts relating to 300,000 comparable Chinese-English patents. The subsequent <a href=https://en.wikipedia.org/wiki/Communication_protocol>protocol</a> we have developed aims to be proactive in meeting four identified practical challenges in technical translation (e.g. patents). It has broader economic implication in the Age of <a href=https://en.wikipedia.org/wiki/Big_data>Big Data</a> (Tsou et al, 2015) and <a href=https://en.wikipedia.org/wiki/Trade_war>Trade War</a>, as the workload, if not, the challenges, increasingly can not be met by currently available front-line translators. We shall demonstrate how new tools can be harnessed to spearhead the application of <a href=https://en.wikipedia.org/wiki/Language_technology>language technology</a> not only in language mediation but also in the teaching and learning of translation. It shows how a better appreciation of their needs may enhance the contributions of the technical specialists, and thus enhance the resultant synergetic benefits.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8717.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8717 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8717 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8717/>The Four Stages of Machine Translation Acceptance in a Freelancer’s Life</a></strong><br><a href=/people/m/maria-sgourou/>Maria Sgourou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8717><div class="card-body p-3 small">Technology is a big challenge and raises many questions and issues when it comes to its application in the <a href=https://en.wikipedia.org/wiki/Translation>translation process</a>, but <a href=https://en.wikipedia.org/wiki/Translation>translation</a>&#8217;s biggest problem is not technology ; it is rather how <a href=https://en.wikipedia.org/wiki/Technology>technology</a> is perceived by translators. MT developers and researchers should take into account this perception and move towards a more democratized approach to include the base of the translation industry and perhaps its more valuable asset, the translators.</div></div></div><hr><div id=w19-89><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-89.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/W19-89/>Proceedings of the Workshop MultiLing 2019: Summarization Across Languages, Genres and Sources</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8900.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8900/>Proceedings of the Workshop MultiLing 2019: Summarization Across Languages, Genres and Sources</a></strong><br><a href=/people/g/george-giannakopoulos/>George Giannakopoulos</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8901.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8901 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8901 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8901/>RANLP 2019 Multilingual Headline Generation Task Overview<span class=acl-fixed-case>RANLP</span> 2019 Multilingual Headline Generation Task Overview</a></strong><br><a href=/people/m/marina-litvak/>Marina Litvak</a>
|
<a href=/people/j/john-conroy/>John M. Conroy</a>
|
<a href=/people/p/peter-a-rankel/>Peter A. Rankel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8901><div class="card-body p-3 small">The objective of the 2019 RANLP Multilingual Headline Generation (HG) Task is to explore some of the challenges highlighted by current state of the art approaches on creating informative headlines to news articles : non-descriptive headlines, out-of-domain training data, generating headlines from long documents which are not well represented by the head heuristic, and dealing with multilingual domain. This tasks makes available a large set of <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> for headline generation and provides an <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation methods</a> for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Our <a href=https://en.wikipedia.org/wiki/Data_set>data sets</a> are drawn from <a href=https://en.wikipedia.org/wiki/Wikinews>Wikinews</a> as well as <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. Participants were required to generate <a href=https://en.wikipedia.org/wiki/Headline>headlines</a> for at least 3 languages, which were evaluated via <a href=https://en.wikipedia.org/wiki/Automatic_programming>automatic methods</a>. A key aspect of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is <a href=https://en.wikipedia.org/wiki/Multilinguality>multilinguality</a>. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> measures the performance of multilingual headline generation systems using the Wikipedia and Wikinews articles in multiple languages. The objective is to assess the performance of automatic headline generation techniques on <a href=https://en.wikipedia.org/wiki/Text_file>text documents</a> covering a diverse range of languages and topics outside the <a href=https://en.wikipedia.org/wiki/News_media>news domain</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8902.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8902 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8902 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8902/>MultiLing 2019 : Financial Narrative Summarisation<span class=acl-fixed-case>M</span>ulti<span class=acl-fixed-case>L</span>ing 2019: Financial Narrative Summarisation</a></strong><br><a href=/people/m/mahmoud-el-haj/>Mahmoud El-Haj</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8902><div class="card-body p-3 small">The Financial Narrative Summarisation task at MultiLing 2019 aims to demonstrate the value and challenges of applying automatic text summarisation to financial text written in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, usually referred to as financial narrative disclosures. The task dataset has been extracted from <a href=https://en.wikipedia.org/wiki/Office_of_Public_Sector_Information>UK annual reports</a> published in PDF file format. The participants were asked to provide structured summaries, based on real-world, publicly available financial annual reports of UK firms by extracting information from different key sections. Participants were asked to generate summaries that reflects the analysis and assessment of the financial trend of the business over the past year, as provided by <a href=https://en.wikipedia.org/wiki/Annual_report>annual reports</a>. The evaluation of the summaries was performed using AutoSummENG and Rouge automatic metrics. This paper focuses mainly on the data creation process.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8903.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8903 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8903 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8903/>The Summary Evaluation Task in the MultiLing-RANLP 2019 Workshop<span class=acl-fixed-case>M</span>ulti<span class=acl-fixed-case>L</span>ing - <span class=acl-fixed-case>RANLP</span> 2019 Workshop</a></strong><br><a href=/people/g/george-giannakopoulos/>George Giannakopoulos</a>
|
<a href=/people/n/nikiforos-pittaras/>Nikiforos Pittaras</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8903><div class="card-body p-3 small">This report covers the summarization evaluation task, proposed to the summarization community via the MultiLing 2019 Workshop of the RANLP 2019 conference. The task aims to encourage the development of automatic summarization evaluation methods closely aligned with manual, human-authored summary grades and judgements. A multilingual setting is adopted, building upon a corpus of Wikinews articles across 6 languages (English, <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, <a href=https://en.wikipedia.org/wiki/Romanian_language>Romanian</a>, <a href=https://en.wikipedia.org/wiki/Greek_language>Greek</a>, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> and Czech). The <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> utilizes human (golden) and machine-generated (peer) summaries, which have been assigned human evaluation scores from previous MultiLing tasks. Using these resources, the original <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is augmented with synthetic data, combining summary texts under three different strategies (reorder, merge and replace), each engineered to introduce noise in the summary in a controlled and quantifiable way. We estimate that the utilization of such data can extract and highlight useful attributes of summary quality estimation, aiding the creation of data-driven automatic methods with an increased correlation to human summary evaluations across domains and languages. This paper provides a brief description of the summary evaluation task, the data generation protocol and the resources made available by the MultiLing community, towards improving automatic summarization evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8904.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8904 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8904 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8904/>Multi-lingual Wikipedia Summarization and Title Generation On Low Resource Corpus<span class=acl-fixed-case>W</span>ikipedia Summarization and Title Generation On Low Resource Corpus</a></strong><br><a href=/people/w/wei-liu/>Wei Liu</a>
|
<a href=/people/l/lei-li/>Lei Li</a>
|
<a href=/people/z/zuying-huang/>Zuying Huang</a>
|
<a href=/people/y/yinan-liu/>Yinan Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8904><div class="card-body p-3 small">MultiLing 2019 Headline Generation Task on Wikipedia Corpus raised a critical and practical problem : multilingual task on low resource corpus. In this paper we proposed QDAS extractive summarization model enhanced by sentence2vec and try to apply <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> based on large multilingual pre-trained language model for Wikipedia Headline Generation task. We treat <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> as sequence labeling task and develop two schemes to handle with <a href=https://en.wikipedia.org/wiki/Information_technology>it</a>. Experimental results have shown that large pre-trained model can effectively utilize <a href=https://en.wikipedia.org/wiki/Learning>learned knowledge</a> to extract certain phrase using low resource supervised data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8907.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8907 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8907 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8907/>Social Web Observatory : An entity-driven, holistic information summarization platform across sources</a></strong><br><a href=/people/l/leonidas-tsekouras/>Leonidas Tsekouras</a>
|
<a href=/people/g/georgios-petasis/>Georgios Petasis</a>
|
<a href=/people/a/aris-kosmopoulos/>Aris Kosmopoulos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8907><div class="card-body p-3 small">The Social Web Observatory is an entity-driven, sentiment-aware, event summarization web platform, combining various methods and tools to overview trends across <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and <a href=https://en.wikipedia.org/wiki/News_media>news sources</a> in Greek. SWO crawls, clusters and summarizes information following an entity-centric view of text streams, allowing to monitor the public sentiment towards a specific person, organization or other entity. In this paper, we overview the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>, outline the analysis pipeline and describe a user study aimed to quantify the usefulness of the <a href=https://en.wikipedia.org/wiki/System>system</a> and especially the meaningfulness and coherence of discovered events.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8908.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-8908 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-8908 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8908/>EASY-M : Evaluation System for Multilingual Summarizers<span class=acl-fixed-case>EASY</span>-<span class=acl-fixed-case>M</span>: Evaluation System for Multilingual Summarizers</a></strong><br></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-8908><div class="card-body p-3 small">Automatic text summarization aims at producing a shorter version of a document (or a document set). Evaluation of summarization quality is a challenging task. Because human evaluations are expensive and evaluators often disagree between themselves, many researchers prefer to evaluate their <a href=https://en.wikipedia.org/wiki/System>systems</a> automatically, with help of <a href=https://en.wikipedia.org/wiki/Programming_tool>software tools</a>. Such a tool usually requires a point of reference in the form of one or more human-written summaries for each text in the corpus. Then, a system-generated summary is compared to one or more human-written summaries, according to selected <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>. However, a single <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> can not reflect all quality-related aspects of a summary. In this paper we present the EvAluation SYstem for Multilingual Summarization (EASY-M), which enables the evaluation of system-generated summaries in 17 different languages with several quality measures, based on comparison with their human-generated counterparts. The <a href=https://en.wikipedia.org/wiki/System>system</a> also provides comparative results with two built-in baselines. The source code and both online and offline versions of EASY-M is freely available for the NLP community.</div></div></div><hr><div id=w19-90><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-90.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/W19-90/>Proceedings of the Workshop on Language Technology for Digital Historical Archives</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-9000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-9000/>Proceedings of the Workshop on Language Technology for Digital Historical Archives</a></strong><br><a href=/people/u/university-of-hamburg-cristina-vertan/>University of Hamburg Cristina Vertan</a>
|
<a href=/people/b/bulgarian-cdemy-of-sciences-petya-osenova/>Bulgarian cdemy of Sciences Petya Osenova</a>
|
<a href=/people/s/st-kliment-ohridski-university-of-sofia/>St. Kliment Ohridski University of Sofia</a>
|
<a href=/people/s/st-kliment-ohridski-university-of-sofia-dimitar-iliev/>St. Kliment Ohridski University of Sofia Dimitar Iliev</a></span></p></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>