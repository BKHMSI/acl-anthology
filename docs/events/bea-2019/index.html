<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Workshop on Innovative Use of NLP for Building Educational Applications (2019) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Workshop on Innovative Use of NLP for Building Educational Applications (2019)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#w19-44>Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</a>
<span class="badge badge-info align-middle ml-1">28&nbsp;papers</span></li></ul></div></div><div id=w19-44><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-44.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/W19-44/>Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4400/>Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></strong><br><a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/e/ekaterina-kochmar/>Ekaterina Kochmar</a>
|
<a href=/people/c/claudia-leacock/>Claudia Leacock</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a>
|
<a href=/people/i/ildiko-pilan/>Ildikó Pilán</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4401.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4401 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4401 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4401/>The many dimensions of <a href=https://en.wikipedia.org/wiki/Algorithmic_fairness>algorithmic fairness</a> in educational applications</a></strong><br><a href=/people/a/anastassia-loukina/>Anastassia Loukina</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a>
|
<a href=/people/k/klaus-zechner/>Klaus Zechner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4401><div class="card-body p-3 small">The issues of <a href=https://en.wikipedia.org/wiki/Algorithmic_fairness>algorithmic fairness</a> and <a href=https://en.wikipedia.org/wiki/Bias>bias</a> have recently featured prominently in many publications highlighting the fact that training the <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> for maximum performance may often result in predictions that are biased against various groups. Educational applications based on <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> and <a href=https://en.wikipedia.org/wiki/Speech_processing>speech processing technologies</a> often combine multiple complex machine learning algorithms and are thus vulnerable to the same sources of <a href=https://en.wikipedia.org/wiki/Bias>bias</a> as other machine learning systems. Yet such <a href=https://en.wikipedia.org/wiki/System>systems</a> can have high impact on people&#8217;s lives especially when deployed as part of <a href=https://en.wikipedia.org/wiki/Test_(assessment)>high-stakes tests</a>. In this paper we discuss different definitions of <a href=https://en.wikipedia.org/wiki/Fair_division>fairness</a> and possible ways to apply them to <a href=https://en.wikipedia.org/wiki/Educational_technology>educational applications</a>. We then use simulated and real data to consider how test-takers&#8217; native language backgrounds can affect their automated scores on an English language proficiency assessment. We illustrate that total fairness may not be achievable and that different definitions of <a href=https://en.wikipedia.org/wiki/Equity_(economics)>fairness</a> may require different solutions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4404.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4404 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4404 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4404/>Computationally Modeling the Impact of Task-Appropriate Language Complexity and Accuracy on Human Grading of German Essays<span class=acl-fixed-case>G</span>erman Essays</a></strong><br><a href=/people/z/zarah-weiss/>Zarah Weiss</a>
|
<a href=/people/a/anja-riemenschneider/>Anja Riemenschneider</a>
|
<a href=/people/p/pauline-schroter/>Pauline Schröter</a>
|
<a href=/people/d/detmar-meurers/>Detmar Meurers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4404><div class="card-body p-3 small">Computational linguistic research on the <a href=https://en.wikipedia.org/wiki/Language_complexity>language complexity</a> of student writing typically involves human ratings as a gold standard. However, educational science shows that teachers find it difficult to identify and cleanly separate <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, different aspects of <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a>, <a href=https://en.wikipedia.org/wiki/Content_(media)>contents</a>, and <a href=https://en.wikipedia.org/wiki/Structure>structure</a>. In this paper, we therefore explore the use of computational linguistic methods to investigate how task-appropriate complexity and accuracy relate to the grading of overall performance, content performance, and language performance as assigned by teachers. Based on texts written by students for the official school-leaving state examination (Abitur), we show that teachers successfully assign higher language performance grades to essays with higher task-appropriate language complexity and properly separate this from content scores. Yet, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> impacts teacher assessment for all grading rubrics, also the content score, overemphasizing the role of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. Our analysis is based on broad computational linguistic modeling of German language complexity and an innovative theory- and data-driven feature aggregation method inferring task-appropriate language complexity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4405.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4405 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4405 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4405/>Analysing Rhetorical Structure as a Key Feature of Summary Coherence</a></strong><br><a href=/people/j/jan-snajder/>Jan Šnajder</a>
|
<a href=/people/t/tamara-sladoljev-agejev/>Tamara Sladoljev-Agejev</a>
|
<a href=/people/s/svjetlana-kolic-vehovec/>Svjetlana Kolić Vehovec</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4405><div class="card-body p-3 small">We present a model for automatic scoring of coherence based on comparing the rhetorical structure (RS) of college student summaries in L2 (English) against expert summaries. Coherence is conceptualised as a construct consisting of the rhetorical relation and its arguments. Comparison with expert-assigned scores shows that RS scores correlate with both <a href=https://en.wikipedia.org/wiki/Group_cohesiveness>cohesion</a> and <a href=https://en.wikipedia.org/wiki/Group_cohesiveness>coherence</a>. Furthermore, RS scores improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression model</a> for cohesion score prediction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4406.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4406 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4406 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4406/>The BEA-2019 Shared Task on Grammatical Error Correction<span class=acl-fixed-case>BEA</span>-2019 Shared Task on Grammatical Error Correction</a></strong><br><a href=/people/c/christopher-bryant/>Christopher Bryant</a>
|
<a href=/people/m/mariano-felice/>Mariano Felice</a>
|
<a href=/people/o/oistein-e-andersen/>Øistein E. Andersen</a>
|
<a href=/people/t/ted-briscoe/>Ted Briscoe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4406><div class="card-body p-3 small">This paper reports on the BEA-2019 Shared Task on Grammatical Error Correction (GEC). As with the CoNLL-2014 shared task, participants are required to correct all types of errors in test data. One of the main contributions of the BEA-2019 shared task is the introduction of a new dataset, the Write&Improve+LOCNESS corpus, which represents a wider range of native and learner English levels and abilities. Another contribution is the introduction of <a href=https://en.wikipedia.org/wiki/Track_(navigation)>tracks</a>, which control the amount of annotated data available to participants. Systems are evaluated in terms of ERRANT F_0.5, which allows us to report a much wider range of performance statistics. The competition was hosted on Codalab and remains open for further submissions on the blind test set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4407.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4407 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4407 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4407" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4407/>A Benchmark Corpus of English Misspellings and a Minimally-supervised Model for Spelling Correction<span class=acl-fixed-case>E</span>nglish Misspellings and a Minimally-supervised Model for Spelling Correction</a></strong><br><a href=/people/m/michael-flor/>Michael Flor</a>
|
<a href=/people/m/michael-fried/>Michael Fried</a>
|
<a href=/people/a/alla-rozovskaya/>Alla Rozovskaya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4407><div class="card-body p-3 small">Spelling correction has attracted a lot of attention in the NLP community. However, <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> have been usually evaluated on artificiallycreated or proprietary corpora. A publiclyavailable corpus of authentic misspellings, annotated in context, is still lacking. To address this, we present and release an annotated data set of 6,121 spelling errors in context, based on a corpus of essays written by <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>English language learners</a>. We also develop a minimallysupervised context-aware approach to spelling correction. It achieves strong results on our <a href=https://en.wikipedia.org/wiki/Data>data</a> : 88.12 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. This approach can also train with a minimal amount of annotated data (performance reduced by less than 1 %). Furthermore, this approach allows easy portability to <a href=https://en.wikipedia.org/wiki/Domain_name>new domains</a>. We evaluate our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> on data from a medical domain and demonstrate that it rivals the performance of a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained and tuned on in-domain data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4409.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4409 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4409 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4409/>Regression or classification? Automated Essay Scoring for Norwegian<span class=acl-fixed-case>N</span>orwegian</a></strong><br><a href=/people/s/stig-johan-berggren/>Stig Johan Berggren</a>
|
<a href=/people/t/taraka-rama/>Taraka Rama</a>
|
<a href=/people/l/lilja-ovrelid/>Lilja Øvrelid</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4409><div class="card-body p-3 small">In this paper we present first results for the task of <a href=https://en.wikipedia.org/wiki/Automated_essay_scoring>Automated Essay Scoring</a> for <a href=https://en.wikipedia.org/wiki/Norwegian_language>Norwegian learner language</a>. We analyze a number of properties of this task experimentally and assess (i) the formulation of the task as either <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression</a> or <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>, (ii) the use of various non-neural and neural machine learning architectures with various types of input representations, and (iii) applying <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> for joint prediction of essay scoring and native language identification. We find that a GRU-based attention model trained in a single-task setting performs best at the AES task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4411.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4411 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4411 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4411/>How to account for mispellings : Quantifying the benefit of character representations in neural content scoring models</a></strong><br><a href=/people/b/brian-riordan/>Brian Riordan</a>
|
<a href=/people/m/michael-flor/>Michael Flor</a>
|
<a href=/people/r/robert-pugh/>Robert Pugh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4411><div class="card-body p-3 small">Character-based representations in neural models have been claimed to be a tool to overcome spelling variation in in word token-based input. We examine this claim in neural models for content scoring. We formulate precise hypotheses about the possible effects of adding <a href=https://en.wikipedia.org/wiki/Character_(computing)>character representations</a> to word-based models and test these hypotheses on large-scale real world content scoring datasets. We find that, while character representations may provide small performance gains in general, their effectiveness in accounting for spelling variation may be limited. We show that spelling correction can provide larger gains than character representations, and that spelling correction improves the performance of models with character representations. With these insights, we report a new state of the art on the ASAP-SAS content scoring dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4412.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4412 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4412 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4412" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4412/>The Unreasonable Effectiveness of Transformer Language Models in Grammatical Error Correction</a></strong><br><a href=/people/d/dimitris-alikaniotis/>Dimitris Alikaniotis</a>
|
<a href=/people/v/vipul-raheja/>Vipul Raheja</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4412><div class="card-body p-3 small">Recent work on Grammatical Error Correction (GEC) has highlighted the importance of <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> in that it is certainly possible to achieve good performance by comparing the probabilities of the proposed edits. At the same time, advancements in <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> have managed to generate linguistic output, which is almost indistinguishable from that of human-generated text. In this paper, we up the ante by exploring the potential of more sophisticated language models in GEC and offer some key insights on their strengths and weaknesses. We show that, in line with recent results in other NLP tasks, Transformer architectures achieve consistently high performance and provide a competitive baseline for future machine learning models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4415.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4415 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4415 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4415/>Erroneous data generation for Grammatical Error Correction</a></strong><br><a href=/people/s/shuyao-xu/>Shuyao Xu</a>
|
<a href=/people/j/jiehao-zhang/>Jiehao Zhang</a>
|
<a href=/people/j/jin-chen/>Jin Chen</a>
|
<a href=/people/l/long-qin/>Long Qin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4415><div class="card-body p-3 small">It has been demonstrated that the utilization of a monolingual corpus in neural Grammatical Error Correction (GEC) systems can significantly improve the system performance. The previous state-of-the-art neural GEC system is an ensemble of four Transformer models pretrained on a large amount of Wikipedia Edits. The Singsound GEC system follows a similar approach but is equipped with a sophisticated erroneous data generating component. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieved an <a href=https://en.wikipedia.org/wiki/Formal_grammar>F0:5</a> of 66.61 in the BEA 2019 Shared Task : Grammatical Error Correction. With our novel erroneous data generating component, the Singsound neural GEC system yielded an M2 of 63.2 on the CoNLL-2014 benchmark (8.4 % relative improvement over the previous state-of-the-art system).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4416.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4416 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4416 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4416/>The LAIX Systems in the BEA-2019 GEC Shared Task<span class=acl-fixed-case>LAIX</span> Systems in the <span class=acl-fixed-case>BEA</span>-2019 <span class=acl-fixed-case>GEC</span> Shared Task</a></strong><br><a href=/people/r/ruobing-li/>Ruobing Li</a>
|
<a href=/people/c/chuan-wang/>Chuan Wang</a>
|
<a href=/people/y/yefei-zha/>Yefei Zha</a>
|
<a href=/people/y/yonghong-yu/>Yonghong Yu</a>
|
<a href=/people/s/shiman-guo/>Shiman Guo</a>
|
<a href=/people/q/qiang-wang/>Qiang Wang</a>
|
<a href=/people/y/yang-liu-icsi/>Yang Liu</a>
|
<a href=/people/h/hui-lin/>Hui Lin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4416><div class="card-body p-3 small">In this paper, we describe two <a href=https://en.wikipedia.org/wiki/System>systems</a> we developed for the three tracks we have participated in the BEA-2019 GEC Shared Task. We investigate competitive classification models with bi-directional recurrent neural networks (Bi-RNN) and neural machine translation (NMT) models. For different tracks, we use <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble systems</a> to selectively combine the NMT models, the classification models, and some rules, and demonstrate that an ensemble solution can effectively improve GEC performance over single systems. Our GEC systems ranked the first in the Unrestricted Track, and the third in both the Restricted Track and the Low Resource Track.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4421.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4421 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4421 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4421/>The BLCU System in the BEA 2019 Shared Task<span class=acl-fixed-case>BLCU</span> System in the <span class=acl-fixed-case>BEA</span> 2019 Shared Task</a></strong><br><a href=/people/l/liner-yang/>Liner Yang</a>
|
<a href=/people/c/chencheng-wang/>Chencheng Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4421><div class="card-body p-3 small">This paper describes the BLCU Group submissions to the Building Educational Applications (BEA) 2019 Shared Task on Grammatical Error Correction (GEC). The task is to detect and correct <a href=https://en.wikipedia.org/wiki/Error_(linguistics)>grammatical errors</a> that occurred in essays. We participate in 2 tracks including the Restricted Track and the Unrestricted Track. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is based on a Transformer model architecture. We integrate many effective <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> proposed in recent years. Such as, Byte Pair Encoding, model ensemble, checkpoints average and <a href=https://en.wikipedia.org/wiki/Spell_checker>spell checker</a>. We also corrupt the public monolingual data to further improve the performance of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. On the test data of the BEA 2019 Shared Task, our <a href=https://en.wikipedia.org/wiki/System>system</a> yields F0.5 = 58.62 and 59.50, ranking twelfth and fourth respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4424.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4424 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4424 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4424/>Neural and FST-based approaches to grammatical error correction<span class=acl-fixed-case>FST</span>-based approaches to grammatical error correction</a></strong><br><a href=/people/z/zheng-yuan/>Zheng Yuan</a>
|
<a href=/people/f/felix-stahlberg/>Felix Stahlberg</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/b/bill-byrne/>Bill Byrne</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4424><div class="card-body p-3 small">In this paper, we describe our submission to the BEA 2019 shared task on grammatical error correction. We present a <a href=https://en.wikipedia.org/wiki/Pipeline_(computing)>system pipeline</a> that utilises both <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection and correction models</a>. The input text is first corrected by two complementary neural machine translation systems : one using convolutional networks and <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>, and another using a neural Transformer-based system. Training is performed on publicly available data, along with artificial examples generated through <a href=https://en.wikipedia.org/wiki/Back-translation>back-translation</a>. The n-best lists of these two <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> are then combined and scored using a <a href=https://en.wikipedia.org/wiki/Finite-state_transducer>finite state transducer (FST)</a>. Finally, an unsupervised re-ranking system is applied to the n-best output of the <a href=https://en.wikipedia.org/wiki/Finite-state_machine>FST</a>. The re-ranker uses a number of <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection features</a> to re-rank the FST n-best list and identify the final 1-best correction hypothesis. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves 66.75 % F 0.5 on error correction (ranking 4th), and 82.52 % F 0.5 on token-level error detection (ranking 2nd) in the restricted track of the shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4425.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4425 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4425 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4425/>Improving Precision of Grammatical Error Correction with a Cheat Sheet</a></strong><br><a href=/people/m/mengyang-qiu/>Mengyang Qiu</a>
|
<a href=/people/x/xuejiao-chen/>Xuejiao Chen</a>
|
<a href=/people/m/maggie-liu/>Maggie Liu</a>
|
<a href=/people/k/krishna-parvathala/>Krishna Parvathala</a>
|
<a href=/people/a/apurva-patil/>Apurva Patil</a>
|
<a href=/people/j/jungyeul-park/>Jungyeul Park</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4425><div class="card-body p-3 small">In this paper, we explore two approaches of generating error-focused phrases and examine whether these <a href=https://en.wikipedia.org/wiki/Phrase>phrases</a> can lead to better performance in <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>grammatical error correction</a> for the restricted track of BEA 2019 Shared Task on GEC. Our results show that phrases directly extracted from GEC corpora outperform phrases from statistical machine translation phrase table by a large margin. Appending error+context phrases to the original GEC corpora yields comparably high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a>. We also explore the generation of artificial syntactic error sentences using error+context phrases for the unrestricted track. The additional <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> greatly facilitates syntactic error correction (e.g., verb form) and contributes to better overall performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4428.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4428 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4428 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4428" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4428/>Evaluation of automatic collocation extraction methods for <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learning</a></a></strong><br><a href=/people/v/vishal-bhalla/>Vishal Bhalla</a>
|
<a href=/people/k/klara-klimcikova/>Klara Klimcikova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4428><div class="card-body p-3 small">A number of methods have been proposed to automatically extract collocations, i.e., conventionalized lexical combinations, from <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpora</a>. However, the attempts to evaluate and compare <a href=https://en.wikipedia.org/wiki/Them_(band)>them</a> with a specific application in mind lag behind. This paper compares three end-to-end resources for collocation learning, all of which used the same corpus but different methods. Adopting a gold-standard evaluation method, the results show that the method of dependency parsing outperforms regex-over-pos in collocation identification. The lexical association measures (AMs) used for collocation ranking perform about the same overall but differently for individual collocation types. Further analysis has also revealed that there are considerable differences between other commonly used <a href=https://en.wikipedia.org/wiki/Amplitude_modulation>AMs</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4429.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4429 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4429 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4429/>Anglicized Words and Misspelled Cognates in <a href=https://en.wikipedia.org/wiki/Native_Language_Identification>Native Language Identification</a></a></strong><br><a href=/people/i/ilia-markov/>Ilia Markov</a>
|
<a href=/people/v/vivi-nastase/>Vivi Nastase</a>
|
<a href=/people/c/carlo-strapparava/>Carlo Strapparava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4429><div class="card-body p-3 small">In this paper, we present experiments that estimate the impact of specific lexical choices of people writing in a second language (L2). In particular, we look at misspelled words that indicate lexical uncertainty on the part of the author, and separate them into three categories : misspelled cognates, L2-ed (in our case, anglicized) words, and all other spelling errors. We test the assumption that such <a href=https://en.wikipedia.org/wiki/Error_(linguistics)>errors</a> contain clues about the native language of an essay&#8217;s author through the task of native language identification. The results of the experiments show that the information brought by each of these <a href=https://en.wikipedia.org/wiki/Category_(mathematics)>categories</a> is complementary. We also note that while the distribution of such <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> changes with the proficiency level of the writer, their contribution towards native language identification remains significant at all levels.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4430.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4430 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4430 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4430/>Linguistically-Driven Strategy for Concept Prerequisites Learning on Italian<span class=acl-fixed-case>I</span>talian</a></strong><br><a href=/people/a/alessio-miaschi/>Alessio Miaschi</a>
|
<a href=/people/c/chiara-alzetta/>Chiara Alzetta</a>
|
<a href=/people/f/franco-alberto-cardillo/>Franco Alberto Cardillo</a>
|
<a href=/people/f/felice-dellorletta/>Felice Dell’Orletta</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4430><div class="card-body p-3 small">We present a new concept prerequisite learning method for Learning Object (LO) ordering that exploits only linguistic features extracted from textual educational resources. The method was tested in a cross- and in- domain scenario both for <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a> and <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Additionally, we performed experiments based on a incremental training strategy to study the impact of the training set size on the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> performances. The paper also introduces ITA-PREREQ, to the best of our knowledge the first Italian dataset annotated with prerequisite relations between pairs of educational concepts, and describe the automatic strategy devised to build it.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4431.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4431 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4431 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4431/>Grammatical-Error-Aware Incorrect Example Retrieval System for Learners of <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> as a Second Language<span class=acl-fixed-case>J</span>apanese as a Second Language</a></strong><br><a href=/people/m/mio-arai/>Mio Arai</a>
|
<a href=/people/m/masahiro-kaneko/>Masahiro Kaneko</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4431><div class="card-body p-3 small">Existing example retrieval systems do not include grammatically incorrect examples or present only a few examples, if any. Even if a retrieval system has a wide coverage of incorrect examples along with the correct counterpart, learners need to know whether their query includes errors or not. Considering the usability of retrieving incorrect examples, our proposed method uses a large-scale corpus and presents correct expressions along with incorrect expressions using a grammatical error detection system so that the learner do not need to be aware of how to search for the examples. Intrinsic and extrinsic evaluations indicate that our method improves accuracy of example sentence retrieval and quality of learner&#8217;s writing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4432.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4432 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4432 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4432/>Toward Automated Content Feedback Generation for Non-native Spontaneous Speech</a></strong><br><a href=/people/s/su-youn-yoon/>Su-Youn Yoon</a>
|
<a href=/people/c/ching-ni-hsieh/>Ching-Ni Hsieh</a>
|
<a href=/people/k/klaus-zechner/>Klaus Zechner</a>
|
<a href=/people/m/matthew-mulholland/>Matthew Mulholland</a>
|
<a href=/people/y/yuan-wang/>Yuan Wang</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4432><div class="card-body p-3 small">In this study, we developed an <a href=https://en.wikipedia.org/wiki/Algorithm>automated algorithm</a> to provide feedback about the specific content of non-native English speakers&#8217; spoken responses. The responses were spontaneous speech, elicited using integrated tasks where the language learners listened to and/or read passages and integrated the core content in their spoken responses. Our models detected the absence of key points considered to be important in a spoken response to a particular test question, based on two different models : (a) a model using word-embedding based content features and (b) a state-of-the art short response scoring engine using traditional n-gram based features. Both <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a> achieved a substantially improved performance over the majority baseline, and the combination of the two <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a> achieved a significant further improvement. In particular, the <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> were robust to automated speech recognition (ASR) errors, and performance based on the ASR word hypotheses was comparable to that based on manual transcriptions. The <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of the best <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for the questions included in the train set were 0.80 and 0.68, respectively. Finally, we discussed possible approaches to generating targeted feedback about the content of a language learner&#8217;s response, based on automatically detected missing key points.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4435.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4435 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4435 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4435/>Curio SmartChat : A system for Natural Language Question Answering for Self-Paced K-12 Learning<span class=acl-fixed-case>S</span>mart<span class=acl-fixed-case>C</span>hat : A system for Natural Language Question Answering for Self-Paced K-12 Learning</a></strong><br><a href=/people/s/srikrishna-raamadhurai/>Srikrishna Raamadhurai</a>
|
<a href=/people/r/ryan-baker/>Ryan Baker</a>
|
<a href=/people/v/vikraman-poduval/>Vikraman Poduval</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4435><div class="card-body p-3 small">During learning, students often have questions which they would benefit from responses to in real time. In class, a student can ask a question to a teacher. During homework, or even in class if the student is shy, it can be more difficult to receive a rapid response. In this work, we introduce Curio SmartChat, an automated question answering system for middle school Science topics. Our <a href=https://en.wikipedia.org/wiki/System>system</a> has now been used by around 20,000 students who have so far asked over 100,000 questions. We present data on the challenge created by students&#8217; <a href=https://en.wikipedia.org/wiki/Grammatical_error>grammatical errors</a> and spelling mistakes, and discuss our <a href=https://en.wikipedia.org/wiki/System>system</a>&#8217;s approach and degree of effectiveness at disambiguating questions that the <a href=https://en.wikipedia.org/wiki/System>system</a> is initially unsure about. We also discuss the prevalence of student small talk not related to science topics, the pluses and minuses of this behavior, and how a <a href=https://en.wikipedia.org/wiki/System>system</a> should respond to these conversational acts. We conclude with discussions and point to directions for potential future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4436.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4436 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4436 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4436/>Supporting content evaluation of student summaries by Idea Unit embedding</a></strong><br><a href=/people/m/marcello-gecchele/>Marcello Gecchele</a>
|
<a href=/people/h/hiroaki-yamada/>Hiroaki Yamada</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a>
|
<a href=/people/y/yasuyo-sawaki/>Yasuyo Sawaki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4436><div class="card-body p-3 small">This paper discusses the computer-assisted content evaluation of summaries. We propose a <a href=https://en.wikipedia.org/wiki/Scientific_method>method</a> to make a correspondence between the segments of the source text and its summary. As a unit of the segment, we adopt Idea Unit (IU) which is proposed in <a href=https://en.wikipedia.org/wiki/Applied_linguistics>Applied Linguistics</a>. Introducing IUs enables us to make a correspondence even for the sentences that contain multiple ideas. The IU correspondence is made based on the similarity between vector representations of IU. An evaluation experiment with two source texts and 20 summaries showed that the proposed method is more robust against rephrased expressions than the conventional ROUGE-based baselines. Also, the proposed method outperformed the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> in recall. We im-plemented the proposed method in a GUI toolSegment Matcher that aids teachers to estab-lish a link between corresponding IUs acrossthe summary and source text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4437.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4437 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4437 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4437" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4437/>On Understanding the Relation between Expert Annotations of Text Readability and Target Reader Comprehension</a></strong><br><a href=/people/s/sowmya-vajjala/>Sowmya Vajjala</a>
|
<a href=/people/i/ivana-lucic/>Ivana Lucic</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4437><div class="card-body p-3 small">Automatic readability assessment aims to ensure that readers read texts that they can comprehend. However, <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> are typically trained on texts created from the perspective of the text writer, not the target reader. There is little experimental research on the relationship between expert annotations of readability, reader&#8217;s language proficiency, and different levels of <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>. To address this gap, we conducted a <a href=https://en.wikipedia.org/wiki/User_study>user study</a> in which over a 100 participants read texts of different reading levels and answered questions created to test three forms of <a href=https://en.wikipedia.org/wiki/Sentence_processing>comprehension</a>. Our results indicate that more than readability annotation or reader proficiency, it is the type of comprehension question asked that shows differences between reader responses-inferential questions were difficult for users of all levels of proficiency across reading levels. The data collected from this study will be released with this paper, which will, for the first time, provide a collection of 45 reader bench marked texts to evaluate readability assessment systems developed for <a href=https://en.wikipedia.org/wiki/Adult_learner>adult learners</a> of <a href=https://en.wikipedia.org/wiki/English_language>English</a>. It can also potentially be useful for the development of question generation approaches in <a href=https://en.wikipedia.org/wiki/Intelligent_tutoring_system>intelligent tutoring systems research</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4440.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4440 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4440 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4440/>Analyzing Linguistic Complexity and Accuracy in Academic Language Development of <a href=https://en.wikipedia.org/wiki/German_language>German</a> across Elementary and Secondary School<span class=acl-fixed-case>G</span>erman across Elementary and Secondary School</a></strong><br><a href=/people/z/zarah-weiss/>Zarah Weiss</a>
|
<a href=/people/d/detmar-meurers/>Detmar Meurers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4440><div class="card-body p-3 small">We track the development of writing complexity and <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> in German students&#8217; early academic language development from first to eighth grade. Combining an empirically broad approach to linguistic complexity with the high-quality error annotation included in the Karlsruhe Children&#8217;s Text corpus (Lavalley et al. 2015) used, we construct models of German academic language development that successfully identify the student&#8217;s grade level. We show that <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifiers</a> for the early years rely more on accuracy development, whereas development in <a href=https://en.wikipedia.org/wiki/Secondary_school>secondary school</a> is better characterized by increasingly complex language in all domains : <a href=https://en.wikipedia.org/wiki/Linguistic_system>linguistic system</a>, language use, and human sentence processing characteristics. We demonstrate the generalizability and robustness of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using such a broad complexity feature set across writing topics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4442.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4442 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4442 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4442/>Learning Outcomes and Their Relatedness in a Medical Curriculum</a></strong><br><a href=/people/s/sneha-mondal/>Sneha Mondal</a>
|
<a href=/people/t/tejas-dhamecha/>Tejas Dhamecha</a>
|
<a href=/people/s/shantanu-godbole/>Shantanu Godbole</a>
|
<a href=/people/s/smriti-pathak/>Smriti Pathak</a>
|
<a href=/people/r/red-mendoza/>Red Mendoza</a>
|
<a href=/people/k/k-gayathri-wijayarathna/>K Gayathri Wijayarathna</a>
|
<a href=/people/n/nabil-zary/>Nabil Zary</a>
|
<a href=/people/s/swarnadeep-saha/>Swarnadeep Saha</a>
|
<a href=/people/m/malolan-chetlur/>Malolan Chetlur</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4442><div class="card-body p-3 small">A typical medical curriculum is organized in a hierarchy of instructional objectives called Learning Outcomes (LOs) ; a few thousand LOs span five years of study. Gaining a thorough understanding of the <a href=https://en.wikipedia.org/wiki/Curriculum>curriculum</a> requires learners to recognize and apply related LOs across years, and across different parts of the curriculum. However, given the large scope of the curriculum, manually labeling related LOs is tedious, and almost impossible to scale. In this paper, we build a <a href=https://en.wikipedia.org/wiki/System>system</a> that learns relationships between LOs, and we achieve up to human-level performance in the LO relationship extraction task. We then present an application where the proposed <a href=https://en.wikipedia.org/wiki/System>system</a> is employed to build a map of related LOs and Learning Resources (LRs) pertaining to a virtual patient case. We believe that our system can help medical students grasp the curriculum better, within classroom as well as in Intelligent Tutoring Systems (ITS) settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4446.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4446 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4446 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4446/>Equity Beyond Bias in Language Technologies for Education</a></strong><br><a href=/people/e/elijah-mayfield/>Elijah Mayfield</a>
|
<a href=/people/m/michael-madaio/>Michael Madaio</a>
|
<a href=/people/s/shrimai-prabhumoye/>Shrimai Prabhumoye</a>
|
<a href=/people/d/david-gerritsen/>David Gerritsen</a>
|
<a href=/people/b/brittany-mclaughlin/>Brittany McLaughlin</a>
|
<a href=/people/e/ezekiel-dixon-roman/>Ezekiel Dixon-Román</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4446><div class="card-body p-3 small">There is a long record of research on equity in schools. As machine learning researchers begin to study fairness and bias in earnest, language technologies in education have an unusually strong theoretical and applied foundation to build on. Here, we introduce concepts from culturally relevant pedagogy and other frameworks for teaching and learning, identifying future work on equity in <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a>. We present case studies in a range of topics like <a href=https://en.wikipedia.org/wiki/Intelligent_tutoring_system>intelligent tutoring systems</a>, <a href=https://en.wikipedia.org/wiki/Computer-assisted_language_learning>computer-assisted language learning</a>, automated essay scoring, and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> in classrooms, and provide an actionable agenda for research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4447.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4447 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4447 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4447/>From Receptive to Productive : Learning to Use Confusing Words through Automatically Selected Example Sentences</a></strong><br><a href=/people/c/chieh-yang-huang/>Chieh-Yang Huang</a>
|
<a href=/people/y/yi-ting-huang/>Yi-Ting Huang</a>
|
<a href=/people/m/meihua-chen/>MeiHua Chen</a>
|
<a href=/people/l/lun-wei-ku/>Lun-Wei Ku</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4447><div class="card-body p-3 small">Knowing how to use words appropriately has been a key to improving language proficiency. Previous studies typically discuss how students learn receptively to select the correct candidate from a set of confusing words in the fill-in-the-blank task where specific context is given. In this paper, we go one step further, assisting students to learn to use confusing words appropriately in a productive task : sentence translation. We leverage the GiveMe-Example system, which suggests example sentences for each confusing word, to achieve this goal. In this study, students learn to differentiate the confusing words by reading the example sentences, and then choose the appropriate word(s) to complete the sentence translation task. Results show students made substantial progress in terms of <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence structure</a>. In addition, highly proficient students better managed to learn confusing words. In view of the influence of the first language on learners, we further propose an effective approach to improve the quality of the suggested sentences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4450.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4450 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4450 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4450/>Automated Essay Scoring with Discourse-Aware Neural Models</a></strong><br><a href=/people/f/farah-nadeem/>Farah Nadeem</a>
|
<a href=/people/h/huy-nguyen/>Huy Nguyen</a>
|
<a href=/people/y/yang-liu-icsi/>Yang Liu</a>
|
<a href=/people/m/mari-ostendorf/>Mari Ostendorf</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4450><div class="card-body p-3 small">Automated essay scoring systems typically rely on hand-crafted features to predict essay quality, but such systems are limited by the cost of <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a>. Neural networks offer an alternative to <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a>, but they typically require more annotated data. This paper explores network structures, contextualized embeddings and pre-training strategies aimed at capturing discourse characteristics of essays. Experiments on three essay scoring tasks show benefits from all three <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> in different combinations, with simpler <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> being more effective when less <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> is available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4452.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4452 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4452 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4452" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4452/>Rubric Reliability and Annotation of Content and Argument in Source-Based Argument Essays</a></strong><br><a href=/people/y/yanjun-gao/>Yanjun Gao</a>
|
<a href=/people/a/alex-driban/>Alex Driban</a>
|
<a href=/people/b/brennan-xavier-mcmanus/>Brennan Xavier McManus</a>
|
<a href=/people/e/elena-musi/>Elena Musi</a>
|
<a href=/people/p/patricia-davies/>Patricia Davies</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/r/rebecca-j-passonneau/>Rebecca J. Passonneau</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4452><div class="card-body p-3 small">We present a unique dataset of student source-based argument essays to facilitate research on the relations between <a href=https://en.wikipedia.org/wiki/Content_(media)>content</a>, <a href=https://en.wikipedia.org/wiki/Argumentation_theory>argumentation skills</a>, and <a href=https://en.wikipedia.org/wiki/Educational_assessment>assessment</a>. Two classroom writing assignments were given to college students in a STEM major, accompanied by a carefully designed rubric. The paper presents a reliability study of the <a href=https://en.wikipedia.org/wiki/Rubric>rubric</a>, showing it to be highly reliable, and initial annotation on content and argumentation annotation of the essays.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>