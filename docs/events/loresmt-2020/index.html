<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Workshop on Technologies for MT of Low Resource Languages (2020) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Workshop on Technologies for MT of Low Resource Languages (2020)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2020loresmt-1>Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li></ul></div></div><div id=2020loresmt-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.loresmt-1/>Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.0/>Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages</a></strong><br><a href=/people/a/alina-karakanta/>Alina Karakanta</a>
|
<a href=/people/a/atul-kr-ojha/>Atul Kr. Ojha</a>
|
<a href=/people/c/chao-hong-liu/>Chao-Hong Liu</a>
|
<a href=/people/j/jade-abbott/>Jade Abbott</a>
|
<a href=/people/j/john-ortega/>John Ortega</a>
|
<a href=/people/j/jonathan-washington/>Jonathan Washington</a>
|
<a href=/people/n/nathaniel-oco/>Nathaniel Oco</a>
|
<a href=/people/s/surafel-melaku-lakew/>Surafel Melaku Lakew</a>
|
<a href=/people/t/tommi-a-pirinen/>Tommi A Pirinen</a>
|
<a href=/people/v/valentin-malykh/>Valentin Malykh</a>
|
<a href=/people/v/varvara-logacheva/>Varvara Logacheva</a>
|
<a href=/people/x/xiaobing-zhao/>Xiaobing Zhao</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--loresmt-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.loresmt-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.2/>Bridging Philippine Languages With Multilingual Neural Machine Translation<span class=acl-fixed-case>P</span>hilippine Languages With Multilingual Neural Machine Translation</a></strong><br><a href=/people/r/renz-iver-baliber/>Renz Iver Baliber</a>
|
<a href=/people/c/charibeth-cheng/>Charibeth Cheng</a>
|
<a href=/people/k/kristine-mae-adlaon/>Kristine Mae Adlaon</a>
|
<a href=/people/v/virgion-mamonong/>Virgion Mamonong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--loresmt-1--2><div class="card-body p-3 small">The Philippines is home to more than 150 languages that is considered to be low-resourced even on its major languages. This results into a lack of pursuit in developing a <a href=https://en.wikipedia.org/wiki/Translation>translation system</a> for the underrepresented languages. To simplify the process of developing translation system for multiple languages, and to aid in improving the translation quality of zero to low-resource languages, multilingual NMT became an active area of research. However, existing works in multilingual NMT disregards the analysis of a multilingual model on a closely related and low-resource language group in the context of pivot-based translation and zero-shot translation. In this paper, we benchmarked <a href=https://en.wikipedia.org/wiki/Translation>translation</a> for several <a href=https://en.wikipedia.org/wiki/Languages_of_the_Philippines>Philippine Languages</a>, provided an analysis of a multilingual NMT system for morphologically rich and low-resource languages in terms of its effectiveness in translating zero-resource languages with zero-shot translations. To further evaluate the capability of the multilingual NMT model in translating unseen language pairs in training, we tested the model to translate between <a href=https://en.wikipedia.org/wiki/Tagalog_language>Tagalog</a> and <a href=https://en.wikipedia.org/wiki/Cebuano_language>Cebuano</a> and compared its performance with a simple NMT model that is directly trained on a parallel Tagalog and Cebuano data in which we showed that zero-shot translation outperforms a directly trained model in some instances, while utilizing English as a pivot language in translating outperform both approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--loresmt-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.loresmt-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.4/>Findings of the LoResMT 2020 Shared Task on Zero-Shot for Low-Resource languages<span class=acl-fixed-case>L</span>o<span class=acl-fixed-case>R</span>es<span class=acl-fixed-case>MT</span> 2020 Shared Task on Zero-Shot for Low-Resource languages</a></strong><br><a href=/people/a/atul-kr-ojha/>Atul Kr. Ojha</a>
|
<a href=/people/v/valentin-malykh/>Valentin Malykh</a>
|
<a href=/people/a/alina-karakanta/>Alina Karakanta</a>
|
<a href=/people/c/chao-hong-liu/>Chao-Hong Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--loresmt-1--4><div class="card-body p-3 small">This paper presents the findings of the LoResMT 2020 Shared Task on zero-shot translation for low resource languages. This task was organised as part of the 3rd Workshop on Technologies for MT of Low Resource Languages (LoResMT) at AACL-IJCNLP 2020. The focus was on the zero-shot approach as a notable development in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> to build MT systems for language pairs where parallel corpora are small or even non-existent. The shared task experience suggests that back-translation and domain adaptation methods result in better <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> for small-size datasets. We further noted that, although <a href=https://en.wikipedia.org/wiki/Translation>translation</a> between similar languages is no cakewalk, linguistically distinct languages require more data to give better results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--loresmt-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.loresmt-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.5/>Zero-Shot Neural Machine Translation : Russian-Hindi @LoResMT 2020<span class=acl-fixed-case>R</span>ussian-<span class=acl-fixed-case>H</span>indi @<span class=acl-fixed-case>L</span>o<span class=acl-fixed-case>R</span>es<span class=acl-fixed-case>MT</span> 2020</a></strong><br><a href=/people/s/sahinur-rahman-laskar/>Sahinur Rahman Laskar</a>
|
<a href=/people/a/abdullah-faiz-ur-rahman-khilji/>Abdullah Faiz Ur Rahman Khilji</a>
|
<a href=/people/p/partha-pakray/>Partha Pakray</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--loresmt-1--5><div class="card-body p-3 small">Neural machine translation (NMT) is a widely accepted approach in the machine translation (MT) community, translating from one natural language to another natural language. Although, NMT shows remarkable performance in both high and low resource languages, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> needs sufficient training corpus. The availability of a <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> in low resource language pairs is one of the challenging tasks in MT. To mitigate this issue, NMT attempts to utilize a monolingual corpus to get better at <a href=https://en.wikipedia.org/wiki/Translation>translation</a> for low resource language pairs. Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) organized shared tasks of low resource language pair translation using zero-shot NMT. Here, the <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpus</a> is not used and only monolingual corpora is allowed. We have participated in the same shared task with our team name CNLP-NITS for the Russian-Hindi language pair. We have used masked sequence to sequence pre-training for language generation (MASS) with only monolingual corpus following the unsupervised NMT architecture. The evaluated results are declared at the LoResMT 2020 shared task, which reports that our system achieves the bilingual evaluation understudy (BLEU) score of 0.59, precision score of 3.43, recall score of 5.48, F-measure score of 4.22, and rank-based intuitive bilingual evaluation score (RIBES) of 0.180147 in Russian to Hindi translation. And for Hindi to Russian translation, we have achieved <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a>, <a href=https://en.wikipedia.org/wiki/Precision_and_recall>recall</a>, <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a>, and <a href=https://en.wikipedia.org/wiki/International_Bureau_of_Weights_and_Measures>RIBES score</a> of 1.11, 4.72, 4.41, 4.56, and 0.026842 respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--loresmt-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.loresmt-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.6/>Unsupervised Approach for Zero-Shot Experiments : BhojpuriHindi and MagahiHindi@LoResMT 2020<span class=acl-fixed-case>B</span>hojpuri–<span class=acl-fixed-case>H</span>indi and <span class=acl-fixed-case>M</span>agahi–<span class=acl-fixed-case>H</span>indi@<span class=acl-fixed-case>L</span>o<span class=acl-fixed-case>R</span>es<span class=acl-fixed-case>MT</span> 2020</a></strong><br><a href=/people/a/amit-kumar/>Amit Kumar</a>
|
<a href=/people/r/rajesh-kumar-mundotiya/>Rajesh Kumar Mundotiya</a>
|
<a href=/people/a/anil-kumar-singh/>Anil Kumar Singh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--loresmt-1--6><div class="card-body p-3 small">This paper reports a Machine Translation (MT) system submitted by the NLPRL team for the BhojpuriHindi and MagahiHindi language pairs at LoResMT 2020 shared task. We used an unsupervised domain adaptation approach that gives promising results for zero or extremely low resource languages. Task organizers provide the development and the test sets for evaluation and the monolingual data for training. Our <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> is a hybrid approach of <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> and <a href=https://en.wikipedia.org/wiki/Translation_(biology)>back-translation</a>. Metrics used to evaluate the trained model are BLEU, RIBES, <a href=https://en.wikipedia.org/wiki/Precision_(statistics)>Precision</a>, Recall and <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a>. Our approach gives relatively promising results, with a wide range, of 19.5, 13.71, 2.54, and 3.16 BLEU points for <a href=https://en.wikipedia.org/wiki/Bhojpuri_language>Bhojpuri</a> to <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>, Magahi to Hindi, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> to Bhojpuri and <a href=https://en.wikipedia.org/wiki/Hindi>Hindi to Magahi language pairs</a>, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--loresmt-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.loresmt-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.loresmt-1.12" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.12/>Towards Machine Translation for the <a href=https://en.wikipedia.org/wiki/Kurdish_languages>Kurdish Language</a><span class=acl-fixed-case>K</span>urdish Language</a></strong><br><a href=/people/s/sina-ahmadi/>Sina Ahmadi</a>
|
<a href=/people/m/maraim-masoud/>Maraim Masoud</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--loresmt-1--12><div class="card-body p-3 small">Machine translation is the task of translating texts from one language to another using <a href=https://en.wikipedia.org/wiki/Computer>computers</a>. It has been one of the major tasks in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> and has been motivating to facilitate <a href=https://en.wikipedia.org/wiki/Human_communication>human communication</a>. Kurdish, an <a href=https://en.wikipedia.org/wiki/Indo-European_languages>Indo-European language</a>, has received little attention in this realm due to the language being less-resourced. Therefore, in this paper, we are addressing the main issues in creating a <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation system</a> for the <a href=https://en.wikipedia.org/wiki/Kurdish_languages>Kurdish language</a>, with a focus on the <a href=https://en.wikipedia.org/wiki/Sorani>Sorani dialect</a>. We describe the available scarce <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallel data</a> suitable for training a neural machine translation model for Sorani Kurdish-English translation. We also discuss some of the major challenges in Kurdish language translation and demonstrate how fundamental text processing tasks, such as <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a>, can improve <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.loresmt-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--loresmt-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.loresmt-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.loresmt-1.15/>Investigating Low-resource Machine Translation for English-to-Tamil<span class=acl-fixed-case>E</span>nglish-to-<span class=acl-fixed-case>T</span>amil</a></strong><br><a href=/people/a/akshai-ramesh/>Akshai Ramesh</a>
|
<a href=/people/v/venkatesh-balavadhani-parthasa/>Venkatesh Balavadhani parthasa</a>
|
<a href=/people/r/rejwanul-haque/>Rejwanul Haque</a>
|
<a href=/people/a/andy-way/>Andy Way</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--loresmt-1--15><div class="card-body p-3 small">Statistical machine translation (SMT) which was the dominant paradigm in machine translation (MT) research for nearly three decades has recently been superseded by the end-to-end deep learning approaches to MT. Although <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural models</a> produce state-of-the-art results in many translation tasks, they are found to under-perform on resource-poor scenarios. Despite some success, none of the present-day benchmarks that have tried to overcome this problem can be regarded as a universal solution to the problem of <a href=https://en.wikipedia.org/wiki/Translation>translation</a> of many low-resource languages. In this work, we investigate the performance of phrase-based SMT (PB-SMT) and neural MT (NMT) on a rarely-tested low-resource language-pair, English-to-Tamil, taking a specialised data domain (software localisation) into consideration. In particular, we produce rankings of our MT systems via a social media platform-based human evaluation scheme, and demonstrate our findings in the low-resource domain-specific text translation task.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>