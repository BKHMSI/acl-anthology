<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP (2019) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP (2019)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#w19-48>Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</a>
<span class="badge badge-info align-middle ml-1">16&nbsp;papers</span></li></ul></div></div><div id=w19-48><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-48.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/W19-48/>Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4800.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4800/>Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</a></strong><br><a href=/people/t/tal-linzen/>Tal Linzen</a>
|
<a href=/people/g/grzegorz-chrupala/>Grzegorz Chrupała</a>
|
<a href=/people/y/yonatan-belinkov/>Yonatan Belinkov</a>
|
<a href=/people/d/dieuwke-hupkes/>Dieuwke Hupkes</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4802.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4802 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4802 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4802" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4802/>Sentiment Analysis Is Not Solved ! Assessing and Probing Sentiment Classification</a></strong><br><a href=/people/j/jeremy-barnes/>Jeremy Barnes</a>
|
<a href=/people/l/lilja-ovrelid/>Lilja Øvrelid</a>
|
<a href=/people/e/erik-velldal/>Erik Velldal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4802><div class="card-body p-3 small">Neural methods for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> have led to quantitative improvements over previous approaches, but these advances are not always accompanied with a thorough analysis of the qualitative differences. Therefore, it is not clear what outstanding conceptual challenges for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> remain. In this work, we attempt to discover what challenges still prove a problem for sentiment classifiers for <a href=https://en.wikipedia.org/wiki/English_language>English</a> and to provide a challenging <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. We collect the subset of sentences that an (oracle) ensemble of state-of-the-art sentiment classifiers misclassify and then annotate them for 18 linguistic and paralinguistic phenomena, such as <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a>, <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a>, <a href=https://en.wikipedia.org/wiki/Linguistic_modality>modality</a>, etc. Finally, we provide a case study that demonstrates the usefulness of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> to probe the performance of a given sentiment classifier with respect to <a href=https://en.wikipedia.org/wiki/Linguistics>linguistic phenomena</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4805.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4805 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4805 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4805/>Multi-Granular Text Encoding for Self-Explaining Categorization</a></strong><br><a href=/people/z/zhiguo-wang/>Zhiguo Wang</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/w/wei-zhang/>Wei Zhang</a>
|
<a href=/people/l/lin-pan/>Lin Pan</a>
|
<a href=/people/l/linfeng-song/>Linfeng Song</a>
|
<a href=/people/k/kun-xu/>Kun Xu</a>
|
<a href=/people/y/yousef-el-kurdi/>Yousef El-Kurdi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4805><div class="card-body p-3 small">Self-explaining text categorization requires a <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifier</a> to make a prediction along with supporting evidence. A popular type of evidence is sub-sequences extracted from the input text which are sufficient for the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> to make the prediction. In this work, we define multi-granular ngrams as basic units for explanation, and organize all <a href=https://en.wikipedia.org/wiki/Ngram>ngrams</a> into a hierarchical structure, so that shorter <a href=https://en.wikipedia.org/wiki/Ngram>ngrams</a> can be reused while computing longer <a href=https://en.wikipedia.org/wiki/Ngram>ngrams</a>. We leverage the tree-structured LSTM to learn a context-independent representation for each unit via parameter sharing. Experiments on <a href=https://en.wikipedia.org/wiki/Medical_classification>medical disease classification</a> show that our model is more accurate, efficient and compact than the BiLSTM and CNN baselines. More importantly, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can extract intuitive multi-granular evidence to support its predictions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4806.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4806 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4806 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4806/>The Meaning of Most for Visual Question Answering Models</a></strong><br><a href=/people/a/alexander-kuhnle/>Alexander Kuhnle</a>
|
<a href=/people/a/ann-copestake/>Ann Copestake</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4806><div class="card-body p-3 small">The correct interpretation of quantifier statements in the context of a <a href=https://en.wikipedia.org/wiki/Visual_system>visual scene</a> requires non-trivial <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference mechanisms</a>. For the example of most, we discuss two <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> which rely on fundamentally different <a href=https://en.wikipedia.org/wiki/Cognition>cognitive concepts</a>. Our aim is to identify what strategy deep learning models for visual question answering learn when trained on such questions. To this end, we carefully design data to replicate experiments from <a href=https://en.wikipedia.org/wiki/Psycholinguistics>psycholinguistics</a> where the same question was investigated for humans. Focusing on the FiLM visual question answering model, our experiments indicate that a form of approximate number system emerges whose performance declines with more difficult scenes as predicted by Weber&#8217;s law. Moreover, we identify confounding factors, like spatial arrangement of the scene, which impede the effectiveness of this system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4809.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4809 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4809 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4809/>Detecting Political Bias in <a href=https://en.wikipedia.org/wiki/Article_(publishing)>News Articles</a> Using Headline Attention</a></strong><br><a href=/people/r/rama-rohit-reddy-gangula/>Rama Rohit Reddy Gangula</a>
|
<a href=/people/s/suma-reddy-duggenpudi/>Suma Reddy Duggenpudi</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4809><div class="card-body p-3 small">Language is a powerful tool which can be used to state the facts as well as express our views and perceptions. Most of the times, we find a subtle bias towards or against someone or something. When it comes to <a href=https://en.wikipedia.org/wiki/Politics>politics</a>, media houses and journalists are known to create bias by shrewd means such as misinterpreting reality and distorting viewpoints towards some parties. This misinterpretation on a large scale can lead to the production of <a href=https://en.wikipedia.org/wiki/News_bias>biased news</a> and <a href=https://en.wikipedia.org/wiki/Conspiracy_theory>conspiracy theories</a>. Automating bias detection in newspaper articles could be a good challenge for research in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. We proposed a headline attention network for this bias detection. Our model has two distinctive characteristics : (i) it has a structure that mirrors a person&#8217;s way of reading a news article (ii) it has attention mechanism applied on the article based on its headline, enabling it to attend to more critical content to predict bias. As the required datasets were not available, we created a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> comprising of 1329 <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> collected from various <a href=https://en.wikipedia.org/wiki/List_of_newspapers_in_India>Telugu newspapers</a> and marked them for bias towards a particular political party. The experiments conducted on it demonstrated that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms various baseline methods by a substantial margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4810.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4810 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4810 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4810/>Testing the Generalization Power of Neural Network Models across NLI Benchmarks<span class=acl-fixed-case>NLI</span> Benchmarks</a></strong><br><a href=/people/a/aarne-talman/>Aarne Talman</a>
|
<a href=/people/s/stergios-chatzikyriakidis/>Stergios Chatzikyriakidis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4810><div class="card-body p-3 small">Neural network models have been very successful in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language inference</a>, with the best <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> reaching 90 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> in some benchmarks. However, the success of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> turns out to be largely benchmark specific. We show that <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on a natural language inference dataset drawn from one benchmark fail to perform well in others, even if the notion of <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a> assumed in these <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a> is the same or similar. We train six high performing neural network models on different datasets and show that each one of these has problems of generalizing when we replace the original test set with a test set taken from another corpus designed for the same task. In light of these results, we argue that most of the current neural network models are not able to generalize well in the task of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language inference</a>. We find that using large pre-trained language models helps with <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> when the datasets are similar enough. Our results also highlight that the current NLI datasets do not cover the different nuances of <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a> extensively enough.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4811.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4811 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4811 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4811" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4811/>Character Eyes : Seeing Language through Character-Level Taggers</a></strong><br><a href=/people/y/yuval-pinter/>Yuval Pinter</a>
|
<a href=/people/m/marc-marone/>Marc Marone</a>
|
<a href=/people/j/jacob-eisenstein/>Jacob Eisenstein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4811><div class="card-body p-3 small">Character-level models have been used extensively in recent years in NLP tasks as both supplements and replacements for closed-vocabulary token-level word representations. In one popular architecture, character-level LSTMs are used to feed token representations into a sequence tagger predicting token-level annotations such as part-of-speech (POS) tags. In this work, we examine the behavior of POS taggers across languages from the perspective of individual hidden units within the character LSTM. We aggregate the behavior of these units into language-level metrics which quantify the challenges that taggers face on languages with different morphological properties, and identify links between synthesis and affixation preference and emergent behavior of the hidden tagger layer. In a comparative experiment, we show how modifying the balance between forward and backward hidden units affects model arrangement and performance in these types of languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4812.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4812 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4812 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4812/>Faithful Multimodal Explanation for Visual Question Answering</a></strong><br><a href=/people/j/jialin-wu/>Jialin Wu</a>
|
<a href=/people/r/raymond-mooney/>Raymond Mooney</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4812><div class="card-body p-3 small">AI systems&#8217; ability to explain their reasoning is critical to their utility and trustworthiness. Deep neural networks have enabled significant progress on many challenging <a href=https://en.wikipedia.org/wiki/Problem_solving>problems</a> such as visual question answering (VQA). However, most of them are opaque black boxes with limited explanatory capability. This paper presents a novel approach to developing a high-performing VQA system that can elucidate its answers with integrated textual and visual explanations that faithfully reflect important aspects of its underlying reasoning while capturing the style of comprehensible human explanations. Extensive experimental evaluation demonstrates the advantages of this approach compared to competing methods using both automated metrics and human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4813.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4813 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4813 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4813" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4813/>Evaluating Recurrent Neural Network Explanations</a></strong><br><a href=/people/l/leila-arras/>Leila Arras</a>
|
<a href=/people/a/ahmed-osman/>Ahmed Osman</a>
|
<a href=/people/k/klaus-robert-muller/>Klaus-Robert Müller</a>
|
<a href=/people/w/wojciech-samek/>Wojciech Samek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4813><div class="card-body p-3 small">Recently, several methods have been proposed to explain the predictions of <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks (RNNs)</a>, in particular of <a href=https://en.wikipedia.org/wiki/Linear_time-invariant_system>LSTMs</a>. The goal of these methods is to understand the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>network</a>&#8217;s decisions by assigning to each input variable, e.g., a word, a relevance indicating to which extent it contributed to a particular prediction. In previous works, some of these <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> were not yet compared to one another, or were evaluated only qualitatively. We close this gap by systematically and quantitatively comparing these methods in different settings, namely (1) a toy arithmetic task which we use as a sanity check, (2) a five-class sentiment prediction of movie reviews, and besides (3) we explore the usefulness of word relevances to build sentence-level representations. Lastly, using the method that performed best in our experiments, we show how specific linguistic phenomena such as the <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a> in <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> reflect in terms of relevance patterns, and how the relevance visualization can help to understand the misclassification of individual samples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4816.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4816 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4816 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4816" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4816/>Modeling Paths for Explainable Knowledge Base Completion</a></strong><br><a href=/people/j/josua-stadelmaier/>Josua Stadelmaier</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4816><div class="card-body p-3 small">A common approach in knowledge base completion (KBC) is to learn representations for entities and relations in order to infer missing facts by generalizing existing ones. A shortcoming of standard models is that they do not explain their predictions to make them verifiable easily to human inspection. In this paper, we propose the Context Path Model (CPM) which generates explanations for new facts in KBC by providing sets of context paths as supporting evidence for these triples. For example, a new triple (Theresa May, nationality, Britain) may be explained by the path (Theresa May, born in, Eastbourne, contained in, Britain). The CPM is formulated as a <a href=https://en.wikipedia.org/wiki/Wrapper_function>wrapper</a> that can be applied on top of various existing KBC models. We evaluate <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> for the well-established TransE model. We observe that its performance remains very close despite the added complexity, and that most of the paths proposed as explanations provide meaningful evidence to assess the correctness.<i>context paths</i> as supporting evidence for these triples. For example, a new triple (Theresa May, nationality, Britain) may be explained by the path (Theresa May, born in, Eastbourne, contained in, Britain). The CPM is formulated as a wrapper that can be applied on top of various existing KBC models. We evaluate it for the well-established TransE model. We observe that its performance remains very close despite the added complexity, and that most of the paths proposed as explanations provide meaningful evidence to assess the correctness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4817.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4817 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4817 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4817/>Probing Word and Sentence Embeddings for Long-distance Dependencies Effects in <a href=https://en.wikipedia.org/wiki/French_language>French</a> and <a href=https://en.wikipedia.org/wiki/English_language>English</a><span class=acl-fixed-case>F</span>rench and <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/p/paola-merlo/>Paola Merlo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4817><div class="card-body p-3 small">The recent wide-spread and strong interest in RNNs has spurred detailed investigations of the distributed representations they generate and specifically if they exhibit properties similar to those characterising <a href=https://en.wikipedia.org/wiki/Language>human languages</a>. Results are at present inconclusive. In this paper, we extend previous work on <a href=https://en.wikipedia.org/wiki/Long-distance_dependencies>long-distance dependencies</a> in three ways. We manipulate <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> to translate them in a space that is attuned to the linguistic properties under study. We extend the <a href=https://en.wikipedia.org/wiki/Work_(physics)>work</a> to <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a> and to <a href=https://en.wikipedia.org/wiki/Formal_language>new languages</a>. We confirm previous negative results : <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a> do not unequivocally encode fine-grained linguistic properties of long-distance dependencies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4819.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4819 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4819 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4819/>Hierarchical Representation in Neural Language Models : Suppression and Recovery of Expectations</a></strong><br><a href=/people/e/ethan-wilcox/>Ethan Wilcox</a>
|
<a href=/people/r/roger-levy/>Roger Levy</a>
|
<a href=/people/r/richard-futrell/>Richard Futrell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4819><div class="card-body p-3 small">Work using artificial languages as training input has shown that LSTMs are capable of inducing the stack-like data structures required to represent <a href=https://en.wikipedia.org/wiki/Context-free_language>context-free</a> and certain mildly context-sensitive languages formal language classes which correspond in theory to the hierarchical structures of natural language. Here we present a suite of experiments probing whether neural language models trained on linguistic data induce these stack-like data structures and deploy them while incrementally predicting words. We study two natural language phenomena : center embedding sentences and syntactic island constraints on the fillergap dependency. In order to properly predict words in these structures, a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> must be able to temporarily suppress certain expectations and then recover those expectations later, essentially pushing and popping these expectations on a stack. Our results provide evidence that models can successfully suppress and recover expectations in many cases, but do not fully recover their previous grammatical state.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4821.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4821 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4821 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4821" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4821/>An LSTM Adaptation Study of (Un)grammaticality<span class=acl-fixed-case>LSTM</span> Adaptation Study of (Un)grammaticality</a></strong><br><a href=/people/s/shammur-absar-chowdhury/>Shammur Absar Chowdhury</a>
|
<a href=/people/r/roberto-zamparelli/>Roberto Zamparelli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4821><div class="card-body p-3 small">We propose a novel approach to the study of how <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>artificial neural network</a> perceive the distinction between grammatical and ungrammatical sentences, a crucial task in the growing field of synthetic linguistics. The method is based on performance measures of <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> trained on corpora and fine-tuned with either <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>grammatical or ungrammatical sentences</a>, then applied to (different types of) <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>grammatical or ungrammatical sentences</a>. The results show that both in the difficult and highly symmetrical task of detecting subject islands and in the more open CoLA dataset, grammatical sentences give rise to better scores than ungrammatical ones, possibly because they can be better integrated within the body of linguistic structural knowledge that the <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> has accumulated.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4825.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4825 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4825 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4825" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4825/>Open Sesame : Getting inside BERT’s Linguistic Knowledge<span class=acl-fixed-case>BERT</span>’s Linguistic Knowledge</a></strong><br><a href=/people/y/yongjie-lin/>Yongjie Lin</a>
|
<a href=/people/y/yi-chern-tan/>Yi Chern Tan</a>
|
<a href=/people/r/robert-frank/>Robert Frank</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4825><div class="card-body p-3 small">How and to what extent does BERT encode syntactically-sensitive hierarchical information or positionally-sensitive linear information? Recent work has shown that contextual representations like <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> perform well on tasks that require sensitivity to linguistic structure. We present here two studies which aim to provide a better understanding of the nature of BERT&#8217;s representations. The first of these focuses on the identification of structurally-defined elements using diagnostic classifiers, while the second explores BERT&#8217;s representation of subject-verb agreement and <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphor-antecedent dependencies</a> through a quantitative assessment of self-attention vectors. In both cases, we find that BERT encodes positional information about word tokens well on its lower layers, but switches to a hierarchically-oriented encoding on higher layers. We conclude then that BERT&#8217;s representations do indeed model linguistically relevant aspects of <a href=https://en.wikipedia.org/wiki/Hierarchical_structure>hierarchical structure</a>, though they do not appear to show the sharp sensitivity to <a href=https://en.wikipedia.org/wiki/Hierarchical_structure>hierarchical structure</a> that is found in human processing of reflexive anaphora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4826.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4826 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4826 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4826/>GEval : Tool for Debugging NLP Datasets and Models<span class=acl-fixed-case>GE</span>val: Tool for Debugging <span class=acl-fixed-case>NLP</span> Datasets and Models</a></strong><br><a href=/people/f/filip-gralinski/>Filip Graliński</a>
|
<a href=/people/a/anna-wroblewska/>Anna Wróblewska</a>
|
<a href=/people/t/tomasz-stanislawek/>Tomasz Stanisławek</a>
|
<a href=/people/k/kamil-grabowski/>Kamil Grabowski</a>
|
<a href=/people/t/tomasz-gorecki/>Tomasz Górecki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4826><div class="card-body p-3 small">This paper presents a simple but general and effective method to debug the output of machine learning (ML) supervised models, including <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. The <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> looks for <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> that lower the evaluation metric in such a way that it can not be ascribed to chance (as measured by their p-values). Using this method implemented as MLEval tool you can find : (1) anomalies in test sets, (2) issues in preprocessing, (3) problems in the ML model itself. It can give you an insight into what can be improved in the datasets and/or the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. The same <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> can be used to compare ML models or different versions of the same <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. We present the <a href=https://en.wikipedia.org/wiki/Tool>tool</a>, the theory behind it and use cases for text-based models of various types.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4827.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4827 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4827 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4827/>From Balustrades to Pierre Vinken : Looking for Syntax in Transformer Self-Attentions</a></strong><br><a href=/people/d/david-marecek/>David Mareček</a>
|
<a href=/people/r/rudolf-rosa/>Rudolf Rosa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4827><div class="card-body p-3 small">We inspect the multi-head self-attention in Transformer NMT encoders for three source languages, looking for patterns that could have a syntactic interpretation. In many of the attention heads, we frequently find sequences of consecutive states attending to the same position, which resemble syntactic phrases. We propose a transparent deterministic method of quantifying the amount of syntactic information present in the self-attentions, based on automatically building and evaluating phrase-structure trees from the phrase-like sequences. We compare the resulting <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>trees</a> to existing constituency treebanks, both manually and by computing <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>precision</a> and recall.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>