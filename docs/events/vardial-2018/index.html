<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects (2018) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects (2018)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#w18-39>Proceedings of the Fifth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial 2018)</a>
<span class="badge badge-info align-middle ml-1">16&nbsp;papers</span></li></ul></div></div><div id=w18-39><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-39.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/W18-39/>Proceedings of the Fifth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial 2018)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3900.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3900/>Proceedings of the Fifth Workshop on <span class=acl-fixed-case>NLP</span> for Similar Languages, Varieties and Dialects (<span class=acl-fixed-case>V</span>ar<span class=acl-fixed-case>D</span>ial 2018)</a></strong><br><a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/n/nikola-ljubesic/>Nikola Ljubešić</a>
|
<a href=/people/j/jorg-tiedemann/>Jörg Tiedemann</a>
|
<a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/a/ahmed-ali/>Ahmed Ali</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3902.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3902 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3902 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-3902" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-3902/>Encoder-Decoder Methods for Text Normalization</a></strong><br><a href=/people/m/massimo-lusetti/>Massimo Lusetti</a>
|
<a href=/people/t/tatyana-ruzsics/>Tatyana Ruzsics</a>
|
<a href=/people/a/anne-gohring/>Anne Göhring</a>
|
<a href=/people/t/tanja-samardzic/>Tanja Samardžić</a>
|
<a href=/people/e/elisabeth-stark/>Elisabeth Stark</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3902><div class="card-body p-3 small">Text normalization is the task of mapping non-canonical language, typical of <a href=https://en.wikipedia.org/wiki/Speech_transcription>speech transcription</a> and <a href=https://en.wikipedia.org/wiki/Computer-mediated_communication>computer-mediated communication</a>, to a standardized writing. It is an up-stream task necessary to enable the subsequent direct employment of standard natural language processing tools and indispensable for languages such as <a href=https://en.wikipedia.org/wiki/Swiss_German>Swiss German</a>, with strong regional variation and no written standard. Text normalization has been addressed with a variety of methods, most successfully with character-level statistical machine translation (CSMT). In the meantime, <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> has changed and the new methods, known as neural encoder-decoder (ED) models, resulted in remarkable improvements. Text normalization, however, has not yet followed. A number of <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural methods</a> have been tried, but <a href=https://en.wikipedia.org/wiki/Signal-to-noise_ratio>CSMT</a> remains the state-of-the-art. In this work, we normalize Swiss German WhatsApp messages using the ED framework. We exploit the flexibility of this <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a>, which allows us to learn from the same training data in different ways. In particular, we modify the decoding stage of a plain ED model to include target-side language models operating at different levels of granularity : <a href=https://en.wikipedia.org/wiki/Character_(computing)>characters</a> and words. Our systematic comparison shows that our approach results in an improvement over the CSMT state-of-the-art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3903.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3903 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3903 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W18-3903.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-3903" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-3903/>A High Coverage Method for Automatic False Friends Detection for <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> and Portuguese<span class=acl-fixed-case>F</span>riends Detection for <span class=acl-fixed-case>S</span>panish and <span class=acl-fixed-case>P</span>ortuguese</a></strong><br><a href=/people/s/santiago-castro/>Santiago Castro</a>
|
<a href=/people/j/jairo-bonanata/>Jairo Bonanata</a>
|
<a href=/people/a/aiala-rosa/>Aiala Rosá</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3903><div class="card-body p-3 small">False friends are words in two languages that look or sound similar, but have different meanings. They are a common source of confusion among <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learners</a>. Methods to detect them automatically do exist, however they make use of large aligned bilingual corpora, which are hard to find and expensive to build, or encounter problems dealing with infrequent words. In this work we propose a high coverage method that uses word vector representations to build a false friends classifier for any pair of languages, which we apply to the particular case of <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> and <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese</a>. The required resources are a large corpus for each language and a small bilingual lexicon for the pair.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3905.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3905 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3905 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3905/>Part of Speech Tagging in <a href=https://en.wikipedia.org/wiki/Luyia_language>Luyia</a> : A Bantu Macrolanguage<span class=acl-fixed-case>L</span>uyia: A <span class=acl-fixed-case>B</span>antu Macrolanguage</a></strong><br><a href=/people/k/kenneth-steimel/>Kenneth Steimel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3905><div class="card-body p-3 small">Luyia is a <a href=https://en.wikipedia.org/wiki/ISO_639_macrolanguage>macrolanguage</a> in central Kenya. The <a href=https://en.wikipedia.org/wiki/Luyia_languages>Luyia languages</a>, like other <a href=https://en.wikipedia.org/wiki/Bantu_languages>Bantu languages</a>, have a complex morphological system. This system can be leveraged to aid in <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part of speech tagging</a>. Bag-of-characters taggers trained on a source <a href=https://en.wikipedia.org/wiki/Luyia_language>Luyia language</a> can be applied directly to another <a href=https://en.wikipedia.org/wiki/Luyia_language>Luyia language</a> with some degree of success. In addition, mixing data from the target language with data from the source language does produce more accurate predictive models compared to <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on just the target language data when the training set size is small. However, for both of these tagging tasks, <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> involving the more distantly related language, <a href=https://en.wikipedia.org/wiki/Tiriki_language>Tiriki</a>, are better at predicting <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part of speech tags</a> for Wanga data. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> incorporating <a href=https://en.wikipedia.org/wiki/Bukusu>Bukusu data</a> are not as successful despite the closer relationship between <a href=https://en.wikipedia.org/wiki/Bukusu>Bukusu</a> and <a href=https://en.wikipedia.org/wiki/Wanga_language>Wanga</a>. Overlapping vocabulary between the Wanga and Tiriki corpora as well as a bias towards open class words help <a href=https://en.wikipedia.org/wiki/Tiriki_language>Tiriki</a> outperform <a href=https://en.wikipedia.org/wiki/Bukusu_language>Bukusu</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3907.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3907 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3907 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3907/>Iterative Language Model Adaptation for <a href=https://en.wikipedia.org/wiki/Indo-Aryan_languages>Indo-Aryan Language Identification</a><span class=acl-fixed-case>I</span>ndo-<span class=acl-fixed-case>A</span>ryan Language Identification</a></strong><br><a href=/people/t/tommi-jauhiainen/>Tommi Jauhiainen</a>
|
<a href=/people/h/heidi-jauhiainen/>Heidi Jauhiainen</a>
|
<a href=/people/k/krister-linden/>Krister Lindén</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3907><div class="card-body p-3 small">This paper presents the experiments and results obtained by the SUKI team in the Indo-Aryan Language Identification shared task of the VarDial 2018 Evaluation Campaign. The shared task was an open one, but we did not use any corpora other than what was distributed by the organizers. A total of eight teams provided results for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>shared task</a>. Our submission using a HeLI-method based language identifier with iterative language model adaptation obtained the best results in the shared task with a macro F1-score of 0.958.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3910.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3910 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3910 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-3910" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-3910/>Varying image description tasks : spoken versus written descriptions</a></strong><br><a href=/people/e/emiel-van-miltenburg/>Emiel van Miltenburg</a>
|
<a href=/people/r/ruud-koolen/>Ruud Koolen</a>
|
<a href=/people/e/emiel-krahmer/>Emiel Krahmer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3910><div class="card-body p-3 small">Automatic image description systems are commonly trained and evaluated on written image descriptions. At the same time, these systems are often used to provide <a href=https://en.wikipedia.org/wiki/Linguistic_description>spoken descriptions</a> (e.g. for visually impaired users) through <a href=https://en.wikipedia.org/wiki/Mobile_app>apps</a> like TapTapSee or Seeing AI. This is not a problem, as long as spoken and written descriptions are very similar. However, linguistic research suggests that <a href=https://en.wikipedia.org/wiki/Spoken_language>spoken language</a> often differs from <a href=https://en.wikipedia.org/wiki/Written_language>written language</a>. These differences are not regular, and vary from context to context. Therefore, this paper investigates whether there are differences between written and spoken image descriptions, even if they are elicited through similar tasks. We compare descriptions produced in two <a href=https://en.wikipedia.org/wiki/Language>languages</a> (English and Dutch), and in both <a href=https://en.wikipedia.org/wiki/Language>languages</a> observe substantial differences between spoken and written descriptions. Future research should see if users prefer the spoken over the written style and, if so, aim to emulate spoken descriptions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3911.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3911 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3911 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3911/>Transfer Learning for British Sign Language Modelling<span class=acl-fixed-case>B</span>ritish <span class=acl-fixed-case>S</span>ign <span class=acl-fixed-case>L</span>anguage Modelling</a></strong><br><a href=/people/b/boris-mocialov/>Boris Mocialov</a>
|
<a href=/people/h/helen-hastie/>Helen Hastie</a>
|
<a href=/people/g/graham-turner/>Graham Turner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3911><div class="card-body p-3 small">Automatic speech recognition and <a href=https://en.wikipedia.org/wiki/Speech_recognition>spoken dialogue systems</a> have made great advances through the use of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep machine learning methods</a>. This is partly due to greater computing power but also through the large amount of data available in <a href=https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers>common languages</a>, such as <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Conversely, research in <a href=https://en.wikipedia.org/wiki/Minority_language>minority languages</a>, including <a href=https://en.wikipedia.org/wiki/Sign_language>sign languages</a>, is hampered by the severe lack of data. This has led to work on transfer learning methods, whereby a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> developed for one language is reused as the starting point for a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on a <a href=https://en.wikipedia.org/wiki/Second_language>second language</a>, which is less resourced. In this paper, we examine two transfer learning techniques of <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> and layer substitution for language modelling of <a href=https://en.wikipedia.org/wiki/British_Sign_Language>British Sign Language</a>. Our results show improvement in perplexity when using <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> with standard stacked LSTM models, trained initially using a large corpus for standard English from the Penn Treebank corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3913.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3913 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3913 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3913/>Character Level Convolutional Neural Network for Arabic Dialect Identification<span class=acl-fixed-case>A</span>rabic Dialect Identification</a></strong><br><a href=/people/m/mohamed-ali/>Mohamed Ali</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3913><div class="card-body p-3 small">This submission is for the description paper for our <a href=https://en.wikipedia.org/wiki/System>system</a> in the ADI shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3918.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3918 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3918 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3918/>Computationally efficient discrimination between <a href=https://en.wikipedia.org/wiki/Variety_(linguistics)>language varieties</a> with large feature vectors and regularized classifiers</a></strong><br><a href=/people/a/adrien-barbaresi/>Adrien Barbaresi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3918><div class="card-body p-3 small">The present contribution revolves around efficient approaches to <a href=https://en.wikipedia.org/wiki/Language_classification>language classification</a> which have been field-tested in the Vardial evaluation campaign. The methods used in several language identification tasks comprising different language types are presented and their results are discussed, giving insights on real-world application of <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a>, <a href=https://en.wikipedia.org/wiki/Linear_classifier>linear classifiers</a> and corresponding <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a>. The use of a specially adapted Ridge classifier proved useful in 2 <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> out of 3. The overall approach (XAC) has slightly outperformed most of the other systems on the DFS task (Dutch and Flemish) and on the ILI task (Indo-Aryan languages), while its comparative performance was poorer in on the GDI task (Swiss German dialects).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3922.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3922 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3922 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3922/>Exploring Classifier Combinations for Language Variety Identification</a></strong><br><a href=/people/t/tim-kreutz/>Tim Kreutz</a>
|
<a href=/people/w/walter-daelemans/>Walter Daelemans</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3922><div class="card-body p-3 small">This paper describes CLiPS&#8217;s submissions for the Discriminating between Dutch and Flemish in Subtitles (DFS) shared task at VarDial 2018. We explore different ways to combine <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> trained on different <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature groups</a>. Our best system uses two Linear SVM classifiers ; one trained on lexical features (word n-grams) and one trained on syntactic features (PoS n-grams). The final prediction for a document to be in Flemish Dutch or Netherlandic Dutch is made by the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> that outputs the highest probability for one of the two labels. This confidence vote approach outperforms a meta-classifier on the <a href=https://en.wikipedia.org/wiki/Software_development_process>development data</a> and on the <a href=https://en.wikipedia.org/wiki/Test_data>test data</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3927.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3927 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3927 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3927/>Using Neural Transfer Learning for Morpho-syntactic Tagging of South-Slavic Languages Tweets<span class=acl-fixed-case>S</span>outh-<span class=acl-fixed-case>S</span>lavic Languages Tweets</a></strong><br><a href=/people/s/sara-meftah/>Sara Meftah</a>
|
<a href=/people/n/nasredine-semmar/>Nasredine Semmar</a>
|
<a href=/people/f/fatiha-sadat/>Fatiha Sadat</a>
|
<a href=/people/s/stephan-raaijmakers/>Stephan Raaijmakers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3927><div class="card-body p-3 small">In this paper, we describe a morpho-syntactic tagger of <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>, an important component of the CEA List DeepLIMA tool which is a multilingual text analysis platform based on <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a>. This tagger is built for the Morpho-syntactic Tagging of Tweets (MTT) Shared task of the 2018 VarDial Evaluation Campaign. The MTT task focuses on morpho-syntactic annotation of non-canonical Twitter varieties of three <a href=https://en.wikipedia.org/wiki/South_Slavic_languages>South-Slavic languages</a> : <a href=https://en.wikipedia.org/wiki/Slovene_language>Slovene</a>, Croatian and <a href=https://en.wikipedia.org/wiki/Serbian_language>Serbian</a>. We propose to use a neural network model trained in an end-to-end manner for the three languages without any need for task or domain specific features engineering. The proposed approach combines both character and word level representations. Considering the lack of annotated data in the social media domain for South-Slavic languages, we have also implemented a cross-domain Transfer Learning (TL) approach to exploit any available related out-of-domain annotated data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3928.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3928 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3928 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3928/>When Simple n-gram Models Outperform Syntactic Approaches : Discriminating between <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a> and Flemish<span class=acl-fixed-case>D</span>utch and <span class=acl-fixed-case>F</span>lemish</a></strong><br><a href=/people/m/martin-kroon/>Martin Kroon</a>
|
<a href=/people/m/masha-medvedeva/>Masha Medvedeva</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3928><div class="card-body p-3 small">In this paper we present the results of our participation in the Discriminating between <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a> and <a href=https://en.wikipedia.org/wiki/Flemish>Flemish</a> in Subtitles VarDial 2018 shared task. We try techniques proven to work well for discriminating between language varieties as well as explore the potential of using <a href=https://en.wikipedia.org/wiki/Syntax_(linguistics)>syntactic features</a>, i.e. hierarchical syntactic subtrees. We experiment with different combinations of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. Discriminating between these two languages turned out to be a very hard task, not only for a machine : human performance is only around 0.51 <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> ; our best system is still a simple Naive Bayes model with <a href=https://en.wikipedia.org/wiki/Unigram>word unigrams</a> and <a href=https://en.wikipedia.org/wiki/Bigram>bigrams</a>. The <a href=https://en.wikipedia.org/wiki/System>system</a> achieved an F1 score (macro) of 0.62, which ranked us 4th in the <a href=https://en.wikipedia.org/wiki/Task_(computing)>shared task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3930.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3930 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3930 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3930/>Deep Models for Arabic Dialect Identification on Benchmarked Data<span class=acl-fixed-case>A</span>rabic Dialect Identification on Benchmarked Data</a></strong><br><a href=/people/m/mohamed-elaraby/>Mohamed Elaraby</a>
|
<a href=/people/m/muhammad-abdul-mageed/>Muhammad Abdul-Mageed</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3930><div class="card-body p-3 small">The Arabic Online Commentary (AOC) (Zaidan and Callison-Burch, 2011) is a large-scale repos-itory of <a href=https://en.wikipedia.org/wiki/Varieties_of_Arabic>Arabic dialects</a> with manual labels for4varieties of the language. Existing dialect iden-tification models exploiting the dataset pre-date the recent boost <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> brought to NLPand hence the data are not benchmarked for use with <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a>, nor is it clear how much neural networks can help tease the categories in the data apart. We treat these two limitations : We (1) benchmark the data, and (2) empirically test6different deep learning methods on <a href=https://en.wikipedia.org/wiki/Task_(project_management)>thetask</a>, comparing peformance to several classical machine learning models under different condi-tions (i.e., both binary and multi-way classification). Our experimental results show that variantsof (attention-based) bidirectional recurrent neural networks achieve best accuracy (acc) on thetask, significantly outperforming all competitive baselines. On <a href=https://en.wikipedia.org/wiki/Blinded_experiment>blind test data</a>, our <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> reach87.65%acc on the binary task (MSA vs. dialects),87.4%acc on the 3-way dialect task (Egyptianvs. Gulf vs. Levantine), and82.45%acc on the 4-way variants task (MSA vs. Egyptian vs. Gulfvs. Levantine). We release our benchmark for future work on the dataset</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3931.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3931 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3931 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3931/>A Neural Approach to Language Variety Translation</a></strong><br><a href=/people/m/marta-r-costa-jussa/>Marta R. Costa-jussà</a>
|
<a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/s/santanu-pal/>Santanu Pal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3931><div class="card-body p-3 small">In this paper we present the first neural-based machine translation system trained to translate between standard national varieties of the same language. We take the pair <a href=https://en.wikipedia.org/wiki/Brazilian_Portuguese>Brazilian-European Portuguese</a> as an example and compare the performance of this method to a phrase-based statistical machine translation system. We report a performance improvement of 0.9 BLEU points in translating from European to Brazilian Portuguese and 0.2 BLEU points when translating in the opposite direction. We also carried out a human evaluation experiment with native speakers of <a href=https://en.wikipedia.org/wiki/Brazilian_Portuguese>Brazilian Portuguese</a> which indicates that humans prefer the output produced by the neural-based system in comparison to the statistical system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3932.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3932 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3932 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3932/>Character Level Convolutional Neural Network for Indo-Aryan Language Identification<span class=acl-fixed-case>I</span>ndo-<span class=acl-fixed-case>A</span>ryan Language Identification</a></strong><br><a href=/people/m/mohamed-ali/>Mohamed Ali</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3932><div class="card-body p-3 small">This submission is a description paper for our <a href=https://en.wikipedia.org/wiki/System>system</a> in ILI shared task</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3933.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3933 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3933 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3933/>German Dialect Identification Using Classifier Ensembles<span class=acl-fixed-case>G</span>erman Dialect Identification Using Classifier Ensembles</a></strong><br><a href=/people/a/alina-maria-ciobanu/>Alina Maria Ciobanu</a>
|
<a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/l/liviu-p-dinu/>Liviu P. Dinu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3933><div class="card-body p-3 small">In this paper we present the GDI classification entry to the second German Dialect Identification (GDI) shared task organized within the scope of the VarDial Evaluation Campaign 2018. We present a system based on SVM classifier ensembles trained on <a href=https://en.wikipedia.org/wiki/Character_(computing)>characters</a> and words. The <a href=https://en.wikipedia.org/wiki/System>system</a> was trained on a collection of speech transcripts of five <a href=https://en.wikipedia.org/wiki/Swiss_German>Swiss-German dialects</a> provided by the organizers. The transcripts included in the dataset contained speakers from <a href=https://en.wikipedia.org/wiki/Canton_of_Basel-Stadt>Basel</a>, <a href=https://en.wikipedia.org/wiki/Canton_of_Bern>Bern</a>, Lucerne, and <a href=https://en.wikipedia.org/wiki/Canton_of_Z&#252;rich>Zurich</a>. Our entry in the <a href=https://en.wikipedia.org/wiki/Challenge_(competition)>challenge</a> reached 62.03 % F1 score and was ranked third out of eight teams.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>