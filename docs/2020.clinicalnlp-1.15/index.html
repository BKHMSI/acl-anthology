<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining" name=citation_title><meta content="Zhi Wen" name=citation_author><meta content="Xing Han Lu" name=citation_author><meta content="Siva Reddy" name=citation_author><meta content="Proceedings of the 3rd Clinical Natural Language Processing Workshop" name=citation_conference_title><meta content="2020/11" name=citation_publication_date><meta content="https://aclanthology.org/2020.clinicalnlp-1.15.pdf" name=citation_pdf_url><meta content="130" name=citation_firstpage><meta content="135" name=citation_lastpage><meta content="10.18653/v1/2020.clinicalnlp-1.15" name=citation_doi><meta property="og:title" content="MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining"><meta property="og:image" content="https://aclanthology.org/thumb/2020.clinicalnlp-1.15.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.clinicalnlp-1.15"><meta property="og:description" content="Zhi Wen, Xing Han Lu, Siva Reddy. Proceedings of the 3rd Clinical Natural Language Processing Workshop. 2020."><link rel=canonical href=https://aclanthology.org/2020.clinicalnlp-1.15></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining<span class=acl-fixed-case>M</span>e<span class=acl-fixed-case>DAL</span>: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Mediese afbreidingsafbreidingsdataaset vir Natuurlike Taal Verstaan</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medical Abbreviation Disambiguation Dataset for Natural language Understanding Pretraining</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: مجموعة بيانات توضيح الاختصارات الطبية للتدريب المسبق على فهم اللغة الطبيعية</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Təbiətli Dil Düşünməsi üçün Təbbi Qısqa Qısqa Qısqa Qısqa Qısqa Datatları</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>Медицински съкращения Диамбигационен набор от данни за разбиране на естествения език</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>মেডিয়াল অ্যাব্রেভিয়েশন ডিসাম্প্রাকৃতিক ভাষার প্রশিক্ষণের জন্য ডাটাসেট</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Datati o disambiguaciji medicinskog smanjenja za prirodno razumijevanje jezika pretvaranje</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Lékařská zkratka Disambiguation Dataset pro předškolení přirozeného jazyka</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medicinsk forkortelse Disambiguation Datasæt for Natural Language Understanding Pretraining</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medizinische Abkürzung Disambiguation Dataset for Natural Language Understanding Pretraining</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>Σύνολο δεδομένων αποσαφήνισης ιατρικών συντομεύσεων για την κατανόηση της φυσικής γλώσσας</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MEdAL: Conjunto de datos de desambiguación de abreviaturas médicas para la preformación de comprensión</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Meditsiinilise lühendi disambiguatsiooni andmekogum loodusliku keele mõistmiseks eelõpetamiseks</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Databases Disambiguation Abbreviation Medical Disambiguation for Natural Language Understanding Pretraining</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Lääketieteellinen lyhenne Disambiguation Dataset for Natural Language Understanding Esiharjoittelu</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MEDal : jeu de données de désambiguïsation des abréviations médicales pour la compréhension</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MedAL: Giorrúchán Míochaine Tacar Sonraí Disathbhrí le haghaidh Tuiscint Teanga Nádúrtha Réamhoiliúint</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: קבוצת נתונים של התקצרות רפואית על מנת להבין את השפה הטבעית</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: प्राकृतिक भाषा समझ Pretraining के लिए चिकित्सा संक्षिप्त नाम Disambiguation डेटासेट</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Datati o disambiguaciji liječnika za razumijevanje prirodnog jezika pretvaranje</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Orvosi rövidítés Szétegyértelműsítő adatkészlet a természetes nyelv megértéséhez</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Բնական լեզուների բացատրման բժշկական աբրիվացիան</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Pangkalan Data Pengambangan Medis untuk Pemahaman Bahasa Alami</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Set di dati di disambiguazione per la comprensione del linguaggio naturale</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medical Abbreviation Natural Language Understanding Pre - Trainingのための曖昧さ解消データセット</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDEL: theraperiation disabled mbiguation dataase for Normal Language Compromient</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: მედიციო დახმარება განსხვავება მონაცემების მონაცემების მონაცემებისთვის</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Медициялық қысқарту деңгейінің бақылау деректер бағдарламасы</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>메달: 자연 언어 이해 훈련 전 의학 줄임말 변조 데이터 집합</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Медицинска набрзина Датотека за дебабигуација за разбирање на природниот јазик</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>മെഡിയാള്‍: മെഡിക്കല്‍ അബ്രെവേഷന്‍ ഡിസ്പ്യൂമിഗഷന്‍ ഡേറ്റാസറ്റ് സ്വാഭാഷയുടെ വിവരങ്ങള്‍</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Медицийн эмчилгээний багасгал хөгжлийн мэдээллийн багасгал хэл ойлгохын тулд</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Dataset Pemindahan Persingkatan Perubatan untuk Pemahaman Bahasa Biasa</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Sett ta’ Dejta dwar id-Diżambigwazzjoni ta’ Abbrevjazzjoni Medika għall-Qbil ta’ Lingwi Naturali</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medische afkorting Disambiguation Dataset voor Natural Language Understanding Pretraining</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medisisk forbedringsdatabater for naturspråk forståking</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Zestaw danych dotyczących rozdzielania skrótów medycznych dla wstępnego treningu języka naturalnego</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Conjunto de dados de desambiguação de abreviaturas médicas para pré-treinamento de compreensão de linguagem natural</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Set de date de dezambiguizare a abreviării medicale pentru înțelegerea limbii naturale</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Медицинская аббревиатура Disambiguation Dataset for Natural Language Understanding Pretraining</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: මධ්‍යාත්මක ක්‍රියාත්මක විශ්වාසය නිෂ්ප්‍රායාත්මක භාෂාව තේරුම්ගන්න</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Zbirka podatkov o razjasnitvi medicinskih okrajšav za razumevanje naravnega jezika</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Disambiguation Dataset for Natural language Understanding Preparation</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Paketa e të dhënave për çambiguacionin e shkurtimeve mjekësore për kuptimin e gjuhës natyrore</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Datati za disambiguaciju medicinskog smanjenja za prirodno razumevanje jezika pretvaranje</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medicinsk förkortning Disambiguation Dataset för Natural Language Understanding Pretraining</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Takwimu za Kupuuzwa kwa Madaktari zilizotengenezwa kwa ajili ya mafunzo ya lugha ya asili</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>சாதாரண மொழி புரிந்து கொள்ளும் முன்பயிற்சி</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL: dữ liệu hỗ trợ thảm biến dạng y học cho hiểu biết ngôn ngữ tự nhiên</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>MeDAL曰:自然语言解预训练之医缩写消歧义数据集</a></h2><p class=lead><a href=/people/z/zhi-wen/>Zhi Wen</a>,
<a href=/people/x/xing-han-lu/>Xing Han Lu</a>,
<a href=/people/s/siva-reddy/>Siva Reddy</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>One of the biggest challenges that prohibit the use of many current <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP methods</a> in clinical settings is the availability of <a href=https://en.wikipedia.org/wiki/Data_set>public datasets</a>. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a> pre-training in the medical domain. We pre-trained several models of common architectures on this dataset and empirically showed that such pre-training leads to improved performance and <a href=https://en.wikipedia.org/wiki/Convergence_of_random_variables>convergence speed</a> when <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> on downstream medical tasks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Een van die grootste uitdagings wat die gebruik van baie huidige NLP metodes in kliniske instellings verhinder is die beskikbaarheid van publieke datastelle. In hierdie werk het ons MeDAL voorgestel, 'n groot mediese teks datastel wat voorgestel is vir kruipende ontsammings, ontwerp vir natuurlike taal verstaan voor-oefening in die mediese domein. Ons het verskeie modele van gemeenskaplike arkitektuur vooraf opgelei op hierdie datastel en empiriese vertoon dat sodanige vooraf opgelegging lei na verbeterde prestasie en konvergensie spoed wanneer fyn-tuning op onderstreem mediese opdragte.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የአሁኑን የNLP ሥርዓት በኪኒካሌ አካባቢዎች ውስጥ የሚከለክሉ ትልቁ ውጤቶች አንዱ የህዝብ ዳታዎችን ማግኘት ነው፡፡ በዚህ ስራ፣ መዳኛ፣ ለጥብቀት የቋንቋ ማስተማር የጥቅረት ድምፅ ማህበረሰብ የተደረገ የድምፅ ጽሑፍ ማድረጊያውን እናቀርባታለን፡፡ በዚህ ዳታ ሳንሰር የተለየ ብዙዎችን የአካባቢ መሠረቶች አስተማርተናል፡፡ እንደዚህም የፊተኛውን ትምህርት ፈጥኖችን በወንዝ ውኃ ባለው መድኃኒት ስራዎችን በመጠቀም የሚሻለውን ፍጥረት እና የሚለውጥ ፍጥረት ማድረግ ያሳየናል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>أحد أكبر التحديات التي تحظر استخدام العديد من أساليب البرمجة اللغوية العصبية الحالية في الإعدادات السريرية هو توافر مجموعات البيانات العامة. في هذا العمل ، نقدم MeDAL ، وهي مجموعة بيانات نصية طبية كبيرة تم تنسيقها لإزالة الغموض عن الاختصارات ، وهي مصممة للتدريب المسبق لفهم اللغة الطبيعية في المجال الطبي. لقد قمنا مسبقًا بتدريب العديد من نماذج البنى الشائعة على مجموعة البيانات هذه وأظهرنا بشكل تجريبي أن مثل هذا التدريب المسبق يؤدي إلى تحسين الأداء وسرعة التقارب عند ضبط المهام الطبية النهائية.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ən böyük çətinliklərdən biri, kliniki qurğularda olan çoxlu NLP metodlarını istifadə etməyi qadağan edir. Bu işdə, MeDAL'i təhsil dillərinin əvvəlcə təhsil edilməsi üçün təbiətli təhsil edilməsi üçün təbiətli təhsil edilən böyük məhsul məlumatları təyin edirik. Biz bu verilənlər qutusunda bir neçə modeli təhsil etdik və empirik olaraq, bu təhsil təhsil təhsil təhsil etdiyi təhsil və konverģenci sürəti daha yaxşılaşdırdığını göstərdik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Едно от най-големите предизвикателства, които забраняват използването на много съвременни методи за НЛП в клинични условия, е наличието на обществени набори от данни. В тази работа представяме голям медицински текстов набор от данни, подбран за обобщаване на съкращенията, предназначен за разбиране на естествения език предобучение в областта на медицината. Предварително обучихме няколко модела общи архитектури на този набор от данни и емпирично показахме, че такова предварително обучение води до подобряване на производителността и скоростта на сближаване при фино настройване на медицински задачи надолу по веригата.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ক্লিনিক্যাল বৈশিষ্ট্যে বর্তমান এনএলপি পদ্ধতি ব্যবহার নিষিদ্ধ করা সবচেয়ে বড় চ্যালেঞ্জের মধ্যে একটি হচ্ছে জনগণের ডাটাস এই কাজে আমরা মেডিয়ালের উপস্থাপন করছি বিশাল মেডিকেল টেক্সটের ডাটাসেট, যারা মেডিকেল ডোমেইনে প্রাকৃতিক ভাষা বুঝতে পারে নির্দিষ্ আমরা এই ডাটাসেটে সাধারণ প্রশিক্ষণের বেশ কয়েকটি মডেল প্রশিক্ষণ পূর্বে প্রশিক্ষণ প্রদান করেছি এবং সাধারণ প্রশিক্ষণ দেখিয়েছি যে এই প্রশিক্ষণের ফলে প্রথম প্রশ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>གནད་དོན་ལྡན་གྱི་སྒྲིག་སྟངས In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. ང་ཚོས་གཞི་ཚོགས་སྔོན་གྱིས་མཐུན་གྱི་མིག་གཟུགས་རྩལ་མང་ཙམ་གྱི་སྔོན་གྲངས་སྒྲིག</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Jedan od najvećih izazova koji zabranjuju korištenje mnogih trenutnih metoda NLP-a u kliničkim nastavama je dostupnost javnih podataka. U ovom poslu predstavljamo MeDAL, veliku medicinsku tekstualnu kompetu podataka koja je zaključena za disambiguaciju kratkosti, dizajniranu za prirodno razumijevanje jezika pre obuke u medicinskom domenu. Pretrenirali smo nekoliko modela zajedničkih arhitektura na ovom setu podataka i empirički pokazali da takva predobuka vodi do poboljšane učinkovitosti i konverģencije kada se dobro održava na leđim medicinskim zadacima.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Un dels reptes més grans que prohibeixen l'ús de molts mètodes NLP actuals en entorns clínics és la disponibilitat de conjunts de dades públics. En aquesta feina, presentem el MeDAL, un gran conjunt de dades de text mèdic curat per la desambiguació d'abreviatura, dissenyat per a entendre la llengua natural, la pré-entrenament en el domini mèdic. Vam preparar varis models d'arquitectures comunes en aquest conjunt de dades i vam demostrar empíricament que aquesta pré-formació porta a millor rendiment i velocitat de convergència quan s'ajusten a tasques mèdiques avall.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Jednou z největších výzev, které zakazují použití mnoha současných metod NLP v klinickém prostředí, je dostupnost veřejných datových sad. V této práci představujeme MeDAL, rozsáhlý medicínský textový datový soubor kurátorovaný pro zkratkové disambiguace, určený pro porozumění přirozenému jazyku předškolení v lékařské oblasti. Na tomto datovém souboru jsme předškolili několik modelů běžných architektur a empiricky ukázali, že takové předškolení vede ke zlepšení výkonu a konvergenční rychlosti při jemném ladění následných lékařských úkolů.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En af de største udfordringer, der forbyder brugen af mange nuværende NLP-metoder i kliniske omgivelser, er tilgængeligheden af offentlige datasæt. I dette arbejde præsenterer vi MeDAL, et stort medicinsk tekstdatasæt kurateret til forkortelse disambiguation, designet til naturlig sprogforståelse pre-training på det medicinske område. Vi prætrænede flere modeller af fælles arkitekturer på dette datasæt og viste empirisk, at en sådan prætræning fører til forbedret ydeevne og konvergens hastighed ved finjustering af downstream medicinske opgaver.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Eine der größten Herausforderungen, die den Einsatz vieler aktueller NLP-Methoden im klinischen Umfeld verbieten, ist die Verfügbarkeit öffentlicher Datensätze. In dieser Arbeit stellen wir MeDAL vor, einen großen medizinischen Textdatensatz, der für Abkürzungsdisambiguation kuratiert wurde und für das Verständnis natürlicher Sprache im medizinischen Bereich entwickelt wurde. Wir trainierten mehrere Modelle gängiger Architekturen auf diesem Datensatz und zeigten empirisch, dass ein solches Vortraining zu verbesserter Leistung und Konvergenzgeschwindigkeit bei der Feinabstimmung von nachgelagerten medizinischen Aufgaben führt.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Μία από τις μεγαλύτερες προκλήσεις που απαγορεύουν τη χρήση πολλών σύγχρονων μεθόδων σε κλινικά περιβάλλοντα είναι η διαθεσιμότητα δημόσιων συνόλων δεδομένων. Σε αυτή την εργασία, παρουσιάζουμε ένα μεγάλο σύνολο δεδομένων ιατρικού κειμένου που επιμελήθηκε για αποσαφήνιση συντομεύσεων, σχεδιασμένο για την κατανόηση φυσικής γλώσσας προεκπαίδευση στον ιατρικό τομέα. Προεκπαιδεύσαμε αρκετά μοντέλα κοινών αρχιτεκτονικών σε αυτό το σύνολο δεδομένων και εμπειρικά δείξαμε ότι μια τέτοια προεκπαίδευση οδηγεί σε βελτιωμένη απόδοση και ταχύτητα σύγκλισης κατά την Feinabstimmung σε μεταγενέστερες ιατρικές εργασίες.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Uno de los mayores desafíos que prohíben el uso de muchos métodos actuales de PNL en entornos clínicos es la disponibilidad de conjuntos de datos públicos. En este trabajo, presentamos MedAL, un gran conjunto de datos de textos médicos curados para la desambiguación de las abreviaturas, diseñado para la comprensión del lenguaje natural antes del entrenamiento en el dominio médico. Entrenamos previamente varios modelos de arquitecturas comunes en este conjunto de datos y demostramos empíricamente que dicha capacitación previa mejora el rendimiento y la velocidad de convergencia al ajustar las tareas médicas posteriores.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Üks suurimaid väljakutseid, mis keelavad paljude praeguste NLP meetodite kasutamise kliinilistes tingimustes, on avalike andmekogumite kättesaadavus. Käesolevas töös tutvustame MeDAL-i, lühendite selgitamiseks kureeritud suurt meditsiinilist teksti andmekogumit, mis on mõeldud looduskeele mõistmiseks meditsiini valdkonnas. Me eelkoolitasime selles andmekogumis mitmeid ühiste arhitektuuride mudeleid ja näitasime empiiriliselt, et selline eelkoolitus toob kaasa parema jõudluse ja lähenemise kiiruse järgnevate meditsiiniliste ülesannete täpsustamisel.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>یکی از بزرگترین چالش‌هایی که از استفاده از روش‌های NLP فعلی در تنظیمات کلینیک ممنوع می‌کند دسترسی داده‌های عمومی است. در این کار، ما MeDAL را نشان می دهیم، یک مجموعه داده‌های پزشکی بزرگ که برای تغییر کوتاهی تغییر داده می‌شود، برای درک زبان طبیعی پیش آموزش پیش از آموزش در دومین پزشکی طراحی شده است. ما چندتا مدل معماری مشترک را در این مجموعه داده‌ها پیش آموزش دادیم و به طور امپراطوری نشان دادیم که چنین آموزش پیش آموزش به سرعت عملکرد و کنترلژی بهتر می‌شود وقتی پایین‌ترین کار های پزشکی پایین‌ترین تغییر می‌دهد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Yksi suurimmista haasteista, jotka estävät monien nykyisten NLP-menetelmien käytön kliinisissä olosuhteissa, on julkisten aineistojen saatavuus. Tässä työssä esittelemme MeDAL-tietokannan, joka on koottu lyhenteiden selventämiseen ja joka on suunniteltu luonnollisen kielen ymmärtämiseen lääketieteellisen alan esikoulutukseen. Esikoulutimme useita yhteisiä arkkitehtuurimalleja tähän aineistoon ja empiirisesti osoitimme, että tällainen esikoulutus johtaa parempaan suorituskykyyn ja konvergenssinopeuteen jatko-lääketieteellisissä tehtävissä.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L'un des plus grands défis qui interdisent l'utilisation de nombreuses méthodes de PNL actuelles en milieu clinique est la disponibilité d'ensembles de données publics. Dans ce travail, nous présentons MEDal, un vaste ensemble de données de textes médicaux conçu pour la désambiguïsation des abréviations, conçu pour la pré-formation en compréhension du langage naturel dans le domaine médical. Nous avons préformé plusieurs modèles d'architectures communes sur cet ensemble de données et avons démontré de manière empirique qu'une telle pré-formation permet d'améliorer les performances et la vitesse de convergence lors du réglage précis des tâches médicales en aval.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ceann de na dúshláin is mó a chuireann cosc ar úsáid a bhaint as go leor modhanna reatha NLP i suíomhanna cliniciúla ná infhaighteacht tacar sonraí poiblí. Sa saothar seo, cuirimid i láthair MeDAL, tacar sonraí mór téacs leighis atá coimeádta le haghaidh dí-athbhrí giniúna, atá deartha le haghaidh réamhoiliúint nádúrtha i dtuiscint teanga sa réimse leighis. Rinneamar réamhoiliúna ar roinnt samhlacha ailtireachta coitianta ar an tacar sonraí seo agus léirigh sé go heimpíreach go n-eascraíonn feidhmíocht níos fearr agus luas cóineasaithe dá leithéid de réamhoiliúint agus iad ag mionchoigeartú ar thascanna leighis iartheachtacha.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Babu ɗayan muramman masu girma da za'a hana su yi amfani da wasu hanyoyin NLP na yanzu a cikin kayan daidaita kwanza, yana da amfani da tsarin mutane. Daga wannan aikin, Munã halatar da MeDAL, ma'anar matsayi mai girma na matsayin da aka tsare wa abbration, aka design wa fahimtar harshen asiyya da zaman mafunzo a cikin taƙaita. Ba mu taƙaita wasu misãlai na ɗayan matsayin bakwai a kan wannan dataset, kuma muka yi empirin ya nuna cewa wannan zaman shawarar ta ƙara ga gyarawa na gyarata da sauri idan ya gyara a kan aikin da za'a shida shi na ƙarami.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>אחד האתגרים הגדולים ביותר שמאסרים את השימוש בשיטות NLP הנוכחיות רבות במסגרות קליניות הוא הזמינות של קבוצות נתונים ציבוריים. בעבודה הזו, אנו מציגים את MeDAL, קבוצת נתונים רפואיים גדולה טקסט מטופלת למסגרת התקצרות, מוכנה להבין שפה טבעית לפני האימונים בתחום הרפואי. אימנו מראש מספר דוגמנים של ארכיטקטורות משותפות על קבוצת נתונים זו ואימפרית הראה כי אימון מראש כזה מוביל להופעה משתפרת ומהירות הקונגרנציה כאשר מתאים על משימות רפואיות למטה.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>नैदानिक सेटिंग्स में कई वर्तमान एनएलपी विधियों के उपयोग को प्रतिबंधित करने वाली सबसे बड़ी चुनौतियों में से एक सार्वजनिक डेटासेट की उपलब्धता है। इस काम में, हम MeDAL, एक बड़ा चिकित्सा पाठ डेटासेट प्रस्तुत करते हैं जो संक्षिप्त रूप के लिए क्यूरेट किया गया है, जो चिकित्सा डोमेन में पूर्व-प्रशिक्षण को समझने वाली प्राकृतिक भाषा के लिए डिज़ाइन किया गया है। हमने इस डेटासेट पर आम आर्किटेक्चर के कई मॉडलों को पूर्व-प्रशिक्षित किया और अनुभवजन्य रूप से दिखाया कि इस तरह के पूर्व-प्रशिक्षण से डाउनस्ट्रीम चिकित्सा कार्यों पर ठीक-ट्यूनिंग करते समय बेहतर प्रदर्शन और अभिसरण गति होती है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Jedan od najvećih izazova koji zabranjuju uporabu mnogih trenutnih metoda NLP-a u kliničkim nastavama je dostupnost javnih podataka. U ovom poslu predstavljamo MeDAL, veliku medicinsku tekstualnu kompletu podataka koja je navedena za disambiguaciju kratkog reda, dizajniranu za prirodno razumijevanje jezika prije obuke u medicinskoj domenu. Pretrenirali smo nekoliko modela zajedničkih arhitektura na ovom sastavu podataka i empirički pokazali da takva predobuka vodi do poboljšane učinkovitosti i konverģencije brzine kada se dobro održava na sporednim medicinskim zadatkima.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Az egyik legnagyobb kihívás, amely megtiltja számos jelenlegi NLP-módszer klinikai környezetben történő alkalmazását, a nyilvános adatkészletek rendelkezésre állása. Ebben a munkában bemutatjuk a MeDAL-t, egy nagy orvosi szövegadatkészletet, amely rövidítésekkel egyértelműsíthető, természetes nyelv megértésére szolgál az orvosi területen. Ezen adatkészleten több közös architektúra modellt is előkészítettünk, és empirikusan megmutattuk, hogy az előkészítés javult teljesítményt és konvergencia sebességet eredményez a downstream orvosi feladatok finomhangolásakor.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ամենամեծ մարտահրավերներից մեկը, որը արգելնում է օգտագործել բազմաթիվ ներկայիս ՆԼՊ մեթոդներ կլինիկական միջավայրում, հանրային տվյալների համակարգերի հասանելիությունն է: In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. Մենք նախապատրաստում էինք այս տվյալների համակարգի ընդհանուր ճարտարապետության մի քանի մոդելներ և էմպիրիկապես ցույց տվեցինք, որ այդպիսի նախապատրաստման գործընթացը հանգեցնում է բարելավելու արդյունավետության և համընդհանուր արագության, երբ կատարվում</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Salah satu tantangan terbesar yang melarang penggunaan banyak metode NLP saat ini dalam pengaturan klinis adalah kemampuan dataset publik. Dalam pekerjaan ini, kami mempersembahkan MeDAL, sebuah set data teks medis besar yang direksi untuk penyerapan tidak ambiguasi, direncanakan untuk pemahaman bahasa alam pre-pelatihan di daerah medis. We pre-trained several models of common architectures on this dataset and empirically showed that such pre-training leads to improved performance and convergence speed when fine-tuning on downstream medical tasks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Una delle maggiori sfide che vietano l'uso di molti metodi attuali di PNL in contesti clinici è la disponibilità di set di dati pubblici. In questo lavoro presentiamo MeDAL, un ampio set di dati di testo medico curato per la disambiguazione delle abbreviazioni, progettato per la comprensione del linguaggio naturale pre-formazione nel campo medico. Abbiamo pre-addestrato diversi modelli di architetture comuni su questo set di dati e abbiamo dimostrato empiricamente che tale pre-formazione porta a migliorare le prestazioni e la velocità di convergenza quando si perfeziona le attività mediche a valle.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>現在の多くのNLP方法の臨床現場での使用を禁止する最大の課題の1つは、公開データセットの利用可能性です。この研究では、MeDALを紹介します。MeDALは、略語の曖昧さを解消するために策定された、医療領域でのトレーニング前の自然言語理解のために設計された大規模な医療テキストデータセットです。私たちは、このデータセット上で共通のアーキテクチャのいくつかのモデルを事前にトレーニングし、そのような事前トレーニングが下流の医療タスクを微調整する際のパフォーマンスと収束速度の向上につながることを経験的に示しました。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Awak sing perbudhakan sing gak dhéwé kanggo ngnggawe sistem NLP gak bener tentang kanggo nggawe dataset publik. Nan in é, we present MeDEL, un banter text dataset curate para abbreviation dismbiguation, disenyongno kanggo langgambar terbiyang nggawe mulai-terbiyang kanggo wé-terbiyang ning token dhéwé. Awak dhéwé éntuk akses ditulaké sistem sing gak bener-ingkang sampeyan karo dataset iki lan kelangan sing nyimpen kuwi tindang kuwi tindakan ono wektu nggawe barang kelangan karo nggawe barang langgar sampeyan akeh lanjut lan ijol-ijolan, winih.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ერთი უფრო დიდი გამოცდილებები, რომლებიც კლინიკური პარამეტრებში გამოყენებას წაშლა მხოლოდ NLP მეტოვების გამოყენება, არის საზოგადო მონაცემების ხელსახულ ამ სამუშაოში ჩვენ MeDAL-ს, დიდი მედიცინური ტექსტის მონაცემების სექტი, რომელიც განახლებელად განახლებელად გავაკეთებულია, რომელიც განახლებელად განახლებელად განახ ჩვენ დავიტანეთ რამდენიმე საერთო არქტიქტურის მოდელები ამ მონაცემების სექტირებში და ემპერიკურად გამოჩვენეთ, რომ ასეთი საერთო განაცემების წინასწორება იქნება უფრო მეფექტირების და კ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Клиникалық параметрлерде қазіргі NLP әдістерін қолдану қажет ететін ең үлкен мәселелердің бірі - көпшілік деректер қорларының мүмкіндігі. Бұл жұмыс ішінде, медицина доменінде алдын- ала оқыту үшін табиғи тілдерді түсінуге арналған үлкен медицина мәтін деректер жинағын келтіреміз. Біз бұл деректер жиынында бірнеше жалпы архитектуралар үлгілерін алдын- ала үйрендік. Бұл алдын- ала үйрендік медицина тапсырмаларын жақсы баптауға және конвергенциялық жылдамдығын жақсарту үшін көр</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>임상 환경에서 현재 NLP 방법을 많이 사용하지 못하게 하는 가장 큰 도전 중 하나는 공공 데이터 세트의 가용성이다.이 작업에서 우리는 메달을 제시했고 대형 의학 텍스트 데이터 집합의 줄임말로 잘못된 뜻을 없애고 자연 언어 이해를 위한 의학 분야의 예비 교육을 실시했다.우리는 이 데이터 집합에서 몇 가지 흔히 볼 수 있는 체계 구조의 모델을 미리 훈련했고 경험에 의하면 하류 의료 임무를 미세하게 조정할 때 이런 사전 훈련은 성능과 수렴 속도를 높일 수 있다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vienas didžiausių uždavinių, uždraudžiančių naudoti daugelį dabartinių NLP metodų klinikinėse aplinkybėse, yra viešų duomenų rinkinių prieinamumas. Šiame darbe pristatome MeDAL, didelį medicininio teksto duomenų rinkinį, kuruojamą santrumpų nedviprasmiškumui, sukurtą gamtiniam kalbų supratimui medicinos srityje. Šiuo duomenų rinkiniu iš anksto parengėme keletą bendrų architektūrų modelių ir empiriniu požiūriu parodėme, kad dėl tokio parengimo rezultatai ir konvergencijos greitis pagerėja, kai patobulinamos tolesnės medicinos užduotys.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Еден од најголемите предизвици кои забрануваат употреба на многу актуелни методи на НЛП во клиничките услови е достапноста на јавни податоци. Во оваа работа, го претставуваме МеДАЛ, голем медицински текст податок куриран за кратење на дејамбигуацијата, дизајниран за природно разбирање на јазикот предобука во медицинската област. Претрениравме неколку модели на заеднички архитектури на овој податок и емпирички покажавме дека ваквата претренирање води до подобрена резултатност и брзина на конвергенција кога се поправи на понатамошните медицински задачи.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>നിലവിലുള്ള NLP രീതികള്‍ ഉപയോഗിക്കാന്‍ നിഷിദ്ധമാക്കുന്ന ഏറ്റവും വലിയ വ്യാല്‍ക്കാരില്‍ ഒന്നാണ് പൊതു ഡാറ്റാസറ്റു ഈ ജോലിയില്‍ ഞങ്ങള്‍ മെഡിയാല്‍ ഒരു വലിയ മെഡിക്കല്‍ ടെക്സ്റ്റേറ്റ് ഡാറ്റാസ്റ്റ് സജ്ജീകരിക്കുന്നു. മെഡിക്കല്‍ ഡോമെയിനില്‍ സ്വാഭാ ഈ ഡാറ്റാസസെറ്റില്‍ സാധാരണ ആര്‍ക്കിട്ടറുകളുടെ പല മാതൃകങ്ങള്‍ മുന്‍പ് പരിശീലനം നടത്തിയിട്ടുണ്ട്. അതിനു മുന്‍പ് പരിശീലനം കാണിച്ചുകൊണ്ടിരിക്</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Сэтгэцийн хэмжээнд олон NLP методуудыг ашиглахыг зориулсан хамгийн том сорилтуудын нэг нь нийтийн өгөгдлийн сангуудын хэрэглээ. Энэ ажлын хувьд бид MeDAL-г, эмнэлгийн эрүүл мэндийн хэлбэрээс өмнө сургалтыг ойлгохын тулд зориулагдсан том эмнэлгийн өгөгдлийн санг тайлбарлаж байна. Бид эдгээр өгөгдлийн сангийн олон нийтийн архитектуруудыг сургалтын өмнө сургалтын архитектуруудын хэд хэдэн загвар сургалтын өмнө сургалтын дасгал нь эмнэлгийн ажил дээр сайжруулах үед үйл ажиллагаа болон хурдыг са</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Salah satu cabaran terbesar yang melarang penggunaan banyak kaedah NLP semasa dalam tetapan klinik adalah kemampuan set data awam. Dalam kerja ini, kami memperkenalkan MeDAL, set data teks perubatan besar yang disiapkan untuk pengsingkatan tidak ambiguasi, direka untuk pemahaman bahasa semulajadi praselatihan dalam bidang perubatan. Kami melatih beberapa model arkitektur umum pada set data ini dan secara empirik menunjukkan bahawa pelatihan awal seperti itu membawa kepada prestasi yang lebih baik dan kelajuan konvergensi apabila memperbaiki tugas perubatan turun.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Waħda mill-akbar sfidi li tipprojbixxi l-użu ta’ ħafna metodi NLP attwali f’ambjenti kliniċi hija d-disponibbiltà ta’ settijiet ta’ dejta pubbliċi. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. Aħna mħarrġin minn qabel bosta mudelli ta’ arkitetturi komuni fuq dan is-sett ta’ dejta u wrejna empirikament li tali taħriġ minn qabel iwassal għal prestazzjoni mtejba u veloċità ta’ konverġenza meta jiġu aġġustati l-kompiti mediċi downstream.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Een van de grootste uitdagingen die het gebruik van veel huidige NLP-methoden in klinische omgevingen verbieden, is de beschikbaarheid van publieke datasets. In dit werk presenteren we MeDAL, een grote medische tekstdataset samengesteld voor afkortingsverduidelijking, ontworpen voor het begrijpen van natuurlijke taal pre-training in het medische domein. We hebben verschillende modellen van gemeenschappelijke architecturen vooraf getraind op deze dataset en empirisch aangetoond dat dergelijke pre-training leidt tot verbeterde prestaties en convergentiesnelheid bij het finetunen van downstream medische taken.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ein av dei største utfordringane som hindrar bruk av mange gjeldande NLP-metodar i kliniske innstillingar er tilgjengeleg offentlige datasett. I denne arbeiden presenterer vi MeDAL, eit stor medisinsk tekstdataset som er korrigert for forkortingar, utforma for naturleg språk forståelse før opplæring i medisinsk domene. Vi har forelært fleire modeller av felles arkitektur på denne dataset og empirisk vist at slike føreøvinga fører til forbetra utviklingsfart og konvergensfart når det finst oppsett på nedstrekkende medisinske oppgåver.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Jednym z największych wyzwań zakazujących stosowania wielu obecnych metod NLP w warunkach klinicznych jest dostępność publicznych zbiorów danych. W niniejszej pracy przedstawiamy MeDAL, duży zestaw danych tekstowych medycznych kuracjonowany dla skrótów, przeznaczony do rozumienia języka naturalnego przedszkolenia w dziedzinie medycznej. Wcześniej przeszkoliliśmy kilka modeli wspólnych architektur na tym zbiorze danych i empirycznie wykazaliśmy, że takie szkolenie wstępne prowadzi do poprawy wydajności i szybkości konwergencji podczas dostrajania zadań medycznych w dalszym szczeblu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Um dos maiores desafios que proíbem o uso de muitos métodos atuais de PNL em ambientes clínicos é a disponibilidade de conjuntos de dados públicos. Neste trabalho, apresentamos o MeDAL, um grande conjunto de dados de texto médico com curadoria para desambiguação de abreviaturas, projetado para pré-treinamento de compreensão de linguagem natural no domínio médico. Nós pré-treinamos vários modelos de arquiteturas comuns neste conjunto de dados e mostramos empiricamente que esse pré-treinamento leva a um melhor desempenho e velocidade de convergência ao ajustar tarefas médicas downstream.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Una dintre cele mai mari provocări care interzic utilizarea multor metode actuale de PNL în cadrul clinic este disponibilitatea seturilor de date publice. În această lucrare, vă prezentăm MeDAL, un set mare de date medicale de text curat pentru dezambiguizarea abrevierilor, conceput pentru înțelegerea limbajului natural pre-formare în domeniul medical. Am pre-instruit mai multe modele de arhitecturi comune pe acest set de date și am arătat empiric că o astfel de pre-instruire duce la îmbunătățirea performanței și vitezei de convergență atunci când ajustăm fin sarcinile medicale din aval.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Одной из самых больших проблем, которая запрещает использование многих современных методов NLP в клинических условиях, является доступность общедоступных наборов данных. В этой работе мы представляем MeDAL, большой набор медицинских текстовых данных, предназначенный для аббревиатурной размытости, предназначенный для предварительного обучения пониманию естественного языка в медицинской области. Мы предварительно обучили несколько моделей общих архитектур на этом наборе данных и эмпирически показали, что такое предварительное обучение приводит к улучшению производительности и скорости конвергенции при тонкой настройке на последующих медицинских задачах.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ලොකු ප්‍රශ්නයක් තියෙන්නේ ප්‍රශ්නයක් තියෙන්නේ ප්‍රශ්නයක් තියෙන්නේ NLP විදියට ප්‍රයෝජනය විදියට ප්‍රයෝ මේ වැඩේ අපි MeDAL වෙනුවෙන්, ලොකු වෛද්‍ය විද්‍යාත්මක තේරුම් සැකසුම් සඳහා ප්‍රශ්නයක් වෙනුවෙන්, ස්වභාවික භාෂාව අපි මේ දත්ත සූදානයේ සාමාන්‍ය විශ්වාසිකරණ විතරක් ප්‍රධානය කරලා තියෙනවා ඒ වගේ ප්‍රධානය ප්‍රධානය සහ සම්බන්ධ වේගය ප්‍රධානය</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Eden največjih izzivov, ki prepoveduje uporabo številnih sedanjih metod NLP v kliničnih okoljih, je razpoložljivost javnih naborov podatkov. V tem delu predstavljamo MeDAL, obsežen medicinski besedilni nabor podatkov, urejen za razločitev okrajšav, namenjen razumevanju naravnega jezika pred usposabljanjem na področju medicine. Na tem naboru podatkov smo vnaprej usposobili več modelov skupnih arhitektur in empirično pokazali, da takšno predusposabljanje vodi k izboljšanju zmogljivosti in hitrosti konvergence pri natančnem nastavitvi zdravstvenih nalog na koncu verige.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mid ka mid ah dhibaatooyinka ugu waaweyn ee diida isticmaalka hababka dhakhaatiirta ee NLP waa helitaanka macluumaadka dadweynaha. Markaas waxan shaqada ku qornaa MeDAL oo ah macluumaad warqad caafimaad oo weyn oo loo qoray baaritaanka burburinta, oo loo qoray garashada afka dabiiciga ah oo lagu barto waxbarasho horumar ah gudaha caafimaadka. Waxaannu horay u tababarinnay tusaalo kala duduwan dhismahan caadiga ah oo ku saabsan taariikhdan, waxaana ku muuqanay in waxbarashadaas horumarinta ah uu hagaajiyo tababarka iyo isbedelka marka lagu hagaajiyo shaqooyinka caafimaadka hoose.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Një nga sfidat më të mëdha që ndalojnë përdorimin e shumë metodave aktuale të NLP-së në bazat klinike është disponueshmëria e të dhënave publike. Në këtë punë, ne paraqesim MeDAL, një set të madh teksti mjekësor të dhënash kuruar për shkurtimin e çambiguacionit, të dizajnuar për kuptimin natyror të gjuhës paratrajnimi në fushën mjekësore. Ne paratrajnuam disa modele arkitekturash të përbashkëta në këtë set të dhënash dhe empirikisht treguam se paratrajnimi i tillë shpie në përmirësim të performancës dhe shpejtësisë konvergencës kur rregullohet në detyrat mjekësore më poshtë.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Jedan od najvećih izazova koji zabranjuje upotrebu mnogih trenutnih metoda NLP-a u kliničkim nastavama je dostupnost javnih podataka. U ovom poslu predstavljamo MeDAL, veliku medicinsku tekstualnu kompetu podataka koja je navedena za disambiguaciju kratkog reda, dizajniranu za prirodno razumevanje jezika pre obuke u medicinskom domenu. Prije treniranja smo nekoliko modela zajedničkih arhitektura na ovom setu podataka i empirički pokazali da takva predobuka vodi do poboljšanog provedbe i konverģencije brzine kada se dobro održava na ležnim medicinskim zadacima.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En av de största utmaningarna som förbjuder användningen av många nuvarande NLP-metoder i kliniska miljöer är tillgången till offentliga datamängder. I det här arbetet presenterar vi MeDAL, ett stort medicinskt textdataset som är framtaget för förkortningsbrytning, utformat för att förstå naturligt språk pre-training inom det medicinska området. Vi tränade flera modeller av gemensamma arkitekturer på denna datauppsättning och visade empiriskt att sådan fortbildning leder till förbättrad prestanda och konvergenshastighet vid finjustering av nedströms medicinska uppgifter.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Moja ya changamoto kubwa zaidi zinazozuia matumizi ya njia nyingi za sasa za NLP katika mazingira ya kliniki ni upatikanaji wa taarifa za umma. In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. Tumejifunza mifano kadhaa ya majengo ya kawaida kwenye seti hii ya data na kwa makini tulionyesha kuwa mafunzo haya yanapelekea kuboresha ufanisi na haraka za mazungumzo wakati wa kutangaza kazi za afya chini ya mito.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>தற்போதைய NLP முறைகளை பயன்படுத்த தடுக்கும் பெரிய சவால்களில் ஒன்று சிகிச்சை அமைப்பு In this work, we present MeDAL, a large medical text dataset curated for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. இந்த தரவுத்தளத்தில் பொதுவான அடைவுகளின் மாதிரிகளை நாம் முன் பயிற்சி செய்தோம் மற்றும் முன்பயிற்சி செய்துள்ளோம் இது முன்பயிற்சி செயல்பாட</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kliniki düzümlerde birnäçe häzirki NLP metodlaryny ulanmaky mümkin edýän iň uly kynçylyklardan biri, halk maglumat düzümleri bar. Bu işde, biz MeDAL'i, tıbbi domaýda öň-öňünden öňünden öňünden okamak üçin guruldyran uly medenik metin setirini görkeýäris. Biz bu datasynda birnäçe nusgalary öň-okuwçylaşdyryp bilýän arhitekturlyklary we empirik bilen bu ön-okuwçylygyň täzeliklerini gowurarak we ýuwaşlyk ýigrendigini görkezdik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>سب سے بڑی چالوں میں سے ایک ہے جو کلینیکی سیٹیوں میں بہت سی موجود NLP طریقوں کا استعمال کرنے سے منع کرتی ہے۔ اس کام میں ہم نے MeDAL کو پیش آموزش دینے کے لئے طراحی کیا ہے، ایک بڑی پزشکی ٹیکسٹ ڈاکسیٹ ڈاکسیٹ ڈاکسیٹ، جو مصنوعی ڈاکسیٹ میں پیش آموزش کی تعلیم کے لئے مصنوعی زبان کے لئے طراحی کی ہے ہم نے اس ڈیٹ سٹ پر بہت سی معماری معماری نمونوں کو پہلے تدریس کی اور مضبوط طور پر دکھایا کہ اس سے پہلے تدریس کی طرح عملکرد اور سرعت کی تدریج کے لئے اچھی طرح دکھائی ہوتی ہے۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Name Bu vazifanda, biz MeDAL, tibbiy domenning oldini o'rganish uchun katta medikam matn maʼlumotlarini ko'rganamiz. Biz bu maʼlumotlar sahifadagi bir necha ko'plab bir modellarni o'rganishga o'rganishmiz va shunday o'rganishdan oldin, bu taʼminlovchi tibbiy vazifalarga yaxshi tashkilotni bajarishda bajarish va tadbirlik tezligini oshirish mumkin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Một trong những thử thách lớn nhất ngăn chặn việc sử dụng nhiều phương pháp NIP hiện thời trong các thiết lập lâm sàng là việc có các bộ dữ liệu công cộng. Trong công việc này, chúng tôi giới thiệu MeDAL, một tập tin văn bản y học lớn được cung cấp cho khả năng hủy hợp rút ngắn, được thiết kế để hiểu ngôn ngữ tự nhiên trước khi được đào tạo trong lĩnh vực y học. Chúng tôi đã rèn luyện trước nhiều mô hình kiến trúc chung trên bộ dữ liệu này và có kinh nghiệm cho thấy rằng tiền đào tạo có hiệu quả và tốc độ hội tụ khi nghiên cứu các công trình y học xuôi dòng.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>禁临床境内多用NLP法最大者,公共数据集之可用性。 此乃大医文本据MeDAL,以缩写消歧义,专为医域自然语言解预练之计也。 凡此数集上预,常见架构形,明于经验,微于下流,可以收敛。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.clinicalnlp-1.15</dd><dt>Volume:</dt><dd><a href=/volumes/2020.clinicalnlp-1/>Proceedings of the 3rd Clinical Natural Language Processing Workshop</a></dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/clinicalnlp/>ClinicalNLP</a>
| <a href=/venues/emnlp/>EMNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>130–135</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.clinicalnlp-1.15>https://aclanthology.org/2020.clinicalnlp-1.15</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2020.clinicalnlp-1.15 title="To the current version of the paper by DOI">10.18653/v1/2020.clinicalnlp-1.15</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">wen-etal-2020-medal</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Zhi Wen, Xing Han Lu, and Siva Reddy. 2020. <a href=https://aclanthology.org/2020.clinicalnlp-1.15>MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a>. In <i>Proceedings of the 3rd Clinical Natural Language Processing Workshop</i>, pages 130–135, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.clinicalnlp-1.15>MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a> (Wen et al., ClinicalNLP 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf>https://aclanthology.org/2020.clinicalnlp-1.15.pdf</a></dd><dt class=acl-button-row>Optional supplementary material:</dt><dd class=acl-button-row><a href=https://aclanthology.org/attachments/2020.clinicalnlp-1.15.OptionalSupplementaryMaterial.zip class="btn btn-attachment btn-sm"><i class="fas fa-file"></i>
&nbsp;2020.clinicalnlp-1.15.OptionalSupplementaryMaterial.zip</a></dd><dt class=acl-button-row>Video:</dt><dd class=acl-button-row><a href=https://slideslive.com/38939819 class="btn btn-attachment btn-sm"><i class="fas fa-video"></i>&nbsp;https://slideslive.com/38939819</a></dd><dt>Code</dt><dd><a href=https://github.com/BruceWen120/medal><i class="fab fa-github"></i>&nbsp;BruceWen120/medal</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/medal>MeDAL</a>,&nbsp;<a href=https://paperswithcode.com/dataset/adam>ADAM</a>,&nbsp;<a href=https://paperswithcode.com/dataset/mimic-iii>MIMIC-III</a>,&nbsp;<a href=https://paperswithcode.com/dataset/pubmed>Pubmed</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.clinicalnlp-1.15.pdf title="Open PDF of 'MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=MeDAL+%3A+Medical+Abbreviation+Disambiguation+Dataset+for+Natural+Language+Understanding+PretrainingMeDAL%3A+Medical+Abbreviation+Disambiguation+Dataset+for+Natural+Language+Understanding+Pretraining" title="Search for 'MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=2020.clinicalnlp-1.15" title="Code for 'MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=https://aclanthology.org/attachments/2020.clinicalnlp-1.15.OptionalSupplementaryMaterial.zip title="Open optional supplementary material for 'MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining'"><span class="align-self-center px-1"><i class="fas fa-file"></i></span>
<span class=px-1>Optional supplementary material</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=https://slideslive.com/38939819 title="Open video for 'MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining'"><span class="align-self-center px-1"><i class="fas fa-video"></i></span>
<span class=px-1>Video</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining](https://aclanthology.org/2020.clinicalnlp-1.15) (Wen et al., ClinicalNLP 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.clinicalnlp-1.15>MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a> (Wen et al., ClinicalNLP 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Zhi Wen, Xing Han Lu, and Siva Reddy. 2020. <a href=https://aclanthology.org/2020.clinicalnlp-1.15>MeDAL : Medical Abbreviation Disambiguation Dataset for Natural Language Understanding PretrainingMeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining</a>. In <i>Proceedings of the 3rd Clinical Natural Language Processing Workshop</i>, pages 130–135, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>